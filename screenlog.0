2020-04-01 19:38:10,235 Reading data from data
2020-04-01 19:38:10,235 Train: data/train.txt
2020-04-01 19:38:10,235 Dev: data/valid.txt
2020-04-01 19:38:10,235 Test: data/test.txt
Corpus: 14041 train + 3250 dev + 3453 test sentences
Dictionary with 12 tags: <unk>, O, B-ORG, B-MISC, B-PER, I-PER, B-LOC, I-ORG, I-MISC, I-LOC, <START>, <STOP>
mix_xf
2020-04-01 19:38:36,787 ----------------------------------------------------------------------------------------------------
2020-04-01 19:38:36,788 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): XLNetEmbeddings(
      model=0-xlnet-large-cased
      (model): XLNetModel(
        (word_embedding): Embedding(32000, 1024)
        (layer): ModuleList(
          (0): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (3): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (4): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (5): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (6): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (7): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (8): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (9): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (10): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (11): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (12): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (13): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (14): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (15): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (16): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (17): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (18): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (19): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (20): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (21): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (22): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (23): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (list_embedding_1): PooledFlairEmbeddings(
      (context_embeddings): FlairEmbeddings(
        (lm): LanguageModel(
          (drop): Dropout(p=0.05, inplace=False)
          (encoder): Embedding(300, 100)
          (rnn): LSTM(100, 2048)
          (decoder): Linear(in_features=2048, out_features=300, bias=True)
        )
      )
    )
    (list_embedding_2): PooledFlairEmbeddings(
      (context_embeddings): FlairEmbeddings(
        (lm): LanguageModel(
          (drop): Dropout(p=0.05, inplace=False)
          (encoder): Embedding(300, 100)
          (rnn): LSTM(100, 2048)
          (decoder): Linear(in_features=2048, out_features=300, bias=True)
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=10240, out_features=10240, bias=True)
  (rnn): LSTM(10240, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=12, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2020-04-01 19:38:36,789 ----------------------------------------------------------------------------------------------------
2020-04-01 19:38:36,789 Corpus: "Corpus: 14041 train + 3250 dev + 3453 test sentences"
2020-04-01 19:38:36,789 ----------------------------------------------------------------------------------------------------
2020-04-01 19:38:36,789 Parameters:
2020-04-01 19:38:36,789  - learning_rate: "0.01"
2020-04-01 19:38:36,789  - mini_batch_size: "64"
2020-04-01 19:38:36,789  - patience: "3"
2020-04-01 19:38:36,789  - anneal_factor: "0.5"
2020-04-01 19:38:36,789  - max_epochs: "150"
2020-04-01 19:38:36,789  - shuffle: "True"
2020-04-01 19:38:36,789  - train_with_dev: "False"
2020-04-01 19:38:36,789  - batch_growth_annealing: "False"
2020-04-01 19:38:36,789 ----------------------------------------------------------------------------------------------------
2020-04-01 19:38:36,789 Model training base path: "log/mix_xf_20200401193836"
2020-04-01 19:38:36,789 ----------------------------------------------------------------------------------------------------
2020-04-01 19:38:36,789 Device: cpu
2020-04-01 19:38:36,789 ----------------------------------------------------------------------------------------------------
2020-04-01 19:38:36,789 Embeddings storage mode: cpu
2020-04-01 19:38:36,792 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-01 19:45:16,384 epoch 1 - iter 22/220 - loss 28.82727359 - samples/sec: 3.52
2020-04-01 19:52:23,846 epoch 1 - iter 44/220 - loss 19.43761673 - samples/sec: 3.60
2020-04-01 19:59:32,163 epoch 1 - iter 66/220 - loss 15.53855290 - samples/sec: 3.61
^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^C2020-04-01 20:05:18,050 ----------------------------------------------------------------------------------------------------
2020-04-01 20:05:18,050 Exiting from training early.
2020-04-01 20:05:18,050 Saving model ...
^C^C^C^C^CTraceback (most recent call last):
  File "/home/qingpeng/anaconda3/envs/py/lib/python3.6/site-packages/flair/trainers/trainer.py", line 331, in train
    loss = self.model.forward_loss(batch_step)
  File "/home/qingpeng/anaconda3/envs/py/lib/python3.6/site-packages/flair/models/sequence_tagger_model.py", line 493, in forward_loss
    features = self.forward(data_points)
  File "/home/qingpeng/anaconda3/envs/py/lib/python3.6/site-packages/flair/models/sequence_tagger_model.py", line 498, in forward
    self.embeddings.embed(sentences)
  File "/home/qingpeng/anaconda3/envs/py/lib/python3.6/site-packages/flair/embeddings.py", line 177, in embed
    embedding.embed(sentences)
  File "/home/qingpeng/anaconda3/envs/py/lib/python3.6/site-packages/flair/embeddings.py", line 96, in embed
    self._add_embeddings_internal(sentences)
  File "/home/qingpeng/anaconda3/envs/py/lib/python3.6/site-packages/flair/embeddings.py", line 1322, in _add_embeddings_internal
    eos_token="</s>",
  File "/home/qingpeng/anaconda3/envs/py/lib/python3.6/site-packages/flair/embeddings.py", line 1188, in _get_transformer_sentence_embeddings
    hidden_states = model(tokens_tensor)[-1]
  File "/home/qingpeng/anaconda3/envs/py/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/qingpeng/anaconda3/envs/py/lib/python3.6/site-packages/transformers/modeling_xlnet.py", line 882, in forward
    head_mask=head_mask[i],
  File "/home/qingpeng/anaconda3/envs/py/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/qingpeng/anaconda3/envs/py/lib/python3.6/site-packages/transformers/modeling_xlnet.py", line 444, in forward
    head_mask=head_mask,
  File "/home/qingpeng/anaconda3/envs/py/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/qingpeng/anaconda3/envs/py/lib/python3.6/site-packages/transformers/modeling_xlnet.py", line 379, in forward
    v_head_h = torch.einsum("ibh,hnd->ibnd", cat, self.v)
  File "/home/qingpeng/anaconda3/envs/py/lib/python3.6/site-packages/torch/functional.py", line 241, in einsum
    return torch._C._VariableFunctions.einsum(equation, operands)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/qingpeng/anaconda3/envs/py/lib/python3.6/site-packages/torch/serialization.py", line 328, in save
    _legacy_save(obj, opened_file, pickle_module, pickle_protocol)
  File "/home/qingpeng/anaconda3/envs/py/lib/python3.6/site-packages/torch/serialization.py", line 407, in _legacy_save
    serialized_storages[key]._write_file(f, _should_read_directly(f))
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "train.py", line 112, in <module>
    max_epochs=150)
  File "/home/qingpeng/anaconda3/envs/py/lib/python3.6/site-packages/flair/trainers/trainer.py", line 548, in train
    self.model.save(base_path / "final-model.pt")
  File "/home/qingpeng/anaconda3/envs/py/lib/python3.6/site-packages/flair/nn.py", line 70, in save
    torch.save(model_state, str(model_file), pickle_protocol=4)
  File "/home/qingpeng/anaconda3/envs/py/lib/python3.6/site-packages/torch/serialization.py", line 328, in save
    _legacy_save(obj, opened_file, pickle_module, pickle_protocol)
  File "/home/qingpeng/anaconda3/envs/py/lib/python3.6/site-packages/torch/serialization.py", line 196, in __exit__
    self.file_like.close()
KeyboardInterrupt
2020-04-01 20:41:21,454 Reading data from data
2020-04-01 20:41:21,454 Train: data/train.txt
2020-04-01 20:41:21,454 Dev: data/valid.txt
2020-04-01 20:41:21,454 Test: data/test.txt
Corpus: 14041 train + 3250 dev + 3453 test sentences
Dictionary with 12 tags: <unk>, O, B-ORG, B-MISC, B-PER, I-PER, B-LOC, I-ORG, I-MISC, I-LOC, <START>, <STOP>
mix_xfe
2020-04-01 20:41:36,161 ----------------------------------------------------------------------------------------------------
2020-04-01 20:41:36,161 ATTENTION! The library "allennlp" is not installed!
2020-04-01 20:41:36,161 To use ELMoEmbeddings, please first install with "pip install allennlp"
2020-04-01 20:41:36,161 ----------------------------------------------------------------------------------------------------
Traceback (most recent call last):
  File "train.py", line 82, in <module>
    ELMoEmbeddings("small")
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/embeddings.py", line 802, in __init__
    options_file = allennlp.commands.elmo.DEFAULT_OPTIONS_FILE
UnboundLocalError: local variable 'allennlp' referenced before assignment
2020-04-01 20:45:22,066 Reading data from data
2020-04-01 20:45:22,066 Train: data/train.txt
2020-04-01 20:45:22,066 Dev: data/valid.txt
2020-04-01 20:45:22,066 Test: data/test.txt
Corpus: 14041 train + 3250 dev + 3453 test sentences
Dictionary with 12 tags: <unk>, O, B-ORG, B-MISC, B-PER, I-PER, B-LOC, I-ORG, I-MISC, I-LOC, <START>, <STOP>
mix_xfe
2020-04-01 20:45:53,971 ----------------------------------------------------------------------------------------------------
2020-04-01 20:45:53,973 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): XLNetEmbeddings(
      model=0-xlnet-large-cased
      (model): XLNetModel(
        (word_embedding): Embedding(32000, 1024)
        (layer): ModuleList(
          (0): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (3): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (4): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (5): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (6): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (7): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (8): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (9): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (10): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (11): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (12): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (13): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (14): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (15): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (16): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (17): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (18): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (19): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (20): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (21): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (22): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (23): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (list_embedding_1): PooledFlairEmbeddings(
      (context_embeddings): FlairEmbeddings(
        (lm): LanguageModel(
          (drop): Dropout(p=0.05, inplace=False)
          (encoder): Embedding(300, 100)
          (rnn): LSTM(100, 2048)
          (decoder): Linear(in_features=2048, out_features=300, bias=True)
        )
      )
    )
    (list_embedding_2): PooledFlairEmbeddings(
      (context_embeddings): FlairEmbeddings(
        (lm): LanguageModel(
          (drop): Dropout(p=0.05, inplace=False)
          (encoder): Embedding(300, 100)
          (rnn): LSTM(100, 2048)
          (decoder): Linear(in_features=2048, out_features=300, bias=True)
        )
      )
    )
    (list_embedding_3): ELMoEmbeddings(model=3-elmo-small)
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=11008, out_features=11008, bias=True)
  (rnn): LSTM(11008, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=12, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2020-04-01 20:45:53,973 ----------------------------------------------------------------------------------------------------
2020-04-01 20:45:53,973 Corpus: "Corpus: 14041 train + 3250 dev + 3453 test sentences"
2020-04-01 20:45:53,973 ----------------------------------------------------------------------------------------------------
2020-04-01 20:45:53,973 Parameters:
2020-04-01 20:45:53,973  - learning_rate: "0.01"
2020-04-01 20:45:53,973  - mini_batch_size: "64"
2020-04-01 20:45:53,973  - patience: "3"
2020-04-01 20:45:53,973  - anneal_factor: "0.5"
2020-04-01 20:45:53,974  - max_epochs: "150"
2020-04-01 20:45:53,974  - shuffle: "True"
2020-04-01 20:45:53,974  - train_with_dev: "False"
2020-04-01 20:45:53,974  - batch_growth_annealing: "False"
2020-04-01 20:45:53,974 ----------------------------------------------------------------------------------------------------
2020-04-01 20:45:53,974 Model training base path: "log/mix_xfe_20200401204553_256"
2020-04-01 20:45:53,974 ----------------------------------------------------------------------------------------------------
2020-04-01 20:45:53,974 Device: cuda:0
2020-04-01 20:45:53,974 ----------------------------------------------------------------------------------------------------
2020-04-01 20:45:53,974 Embeddings storage mode: cpu
2020-04-01 20:45:53,976 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-01 20:46:59,647 epoch 1 - iter 22/220 - loss 23.05279029 - samples/sec: 21.44
2020-04-01 20:48:46,997 epoch 1 - iter 44/220 - loss 15.97472772 - samples/sec: 21.23
2020-04-01 20:52:33,877 epoch 1 - iter 66/220 - loss 12.90668929 - samples/sec: 21.21
2020-04-01 20:56:08,020 epoch 1 - iter 88/220 - loss 11.01309988 - samples/sec: 21.25
 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

204 packages can be updated.
136 updates are security updates.

New release '18.04.4 LTS' available.
Run 'do-release-upgrade' to upgrade to it.

Traceback (most recent call last):
  File "train.py", line 16, in <module>
    from flair.data import Corpus
ModuleNotFoundError: No module named 'flair'
Traceback (most recent call last):
  File "train.py", line 16, in <module>
    from flair.data import Corpus
ModuleNotFoundError: No module named 'flair'
2020-04-01 20:59:12,210 Reading data from data
2020-04-01 20:59:12,210 Train: data/train.txt
2020-04-01 20:59:12,210 Dev: data/valid.txt
2020-04-01 20:59:12,210 Test: data/test.txt
Corpus: 14041 train + 3250 dev + 3453 test sentences
Dictionary with 12 tags: <unk>, O, B-ORG, B-MISC, B-PER, I-PER, B-LOC, I-ORG, I-MISC, I-LOC, <START>, <STOP>
mix_xfeb
2020-04-01 20:59:28,919 epoch 1 - iter 110/220 - loss 9.72475253 - samples/sec: 20.86
2020-04-01 21:01:02,719 ----------------------------------------------------------------------------------------------------
2020-04-01 21:01:02,722 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): XLNetEmbeddings(
      model=0-xlnet-large-cased
      (model): XLNetModel(
        (word_embedding): Embedding(32000, 1024)
        (layer): ModuleList(
          (0): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (3): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (4): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (5): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (6): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (7): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (8): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (9): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (10): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (11): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (12): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (13): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (14): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (15): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (16): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (17): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (18): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (19): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (20): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (21): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (22): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (23): XLNetLayer(
            (rel_attn): XLNetRelativeAttention(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (ff): XLNetFeedForward(
              (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (layer_1): Linear(in_features=1024, out_features=4096, bias=True)
              (layer_2): Linear(in_features=4096, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (list_embedding_1): PooledFlairEmbeddings(
      (context_embeddings): FlairEmbeddings(
        (lm): LanguageModel(
          (drop): Dropout(p=0.05, inplace=False)
          (encoder): Embedding(300, 100)
          (rnn): LSTM(100, 2048)
          (decoder): Linear(in_features=2048, out_features=300, bias=True)
        )
      )
    )
    (list_embedding_2): PooledFlairEmbeddings(
      (context_embeddings): FlairEmbeddings(
        (lm): LanguageModel(
          (drop): Dropout(p=0.05, inplace=False)
          (encoder): Embedding(300, 100)
          (rnn): LSTM(100, 2048)
          (decoder): Linear(in_features=2048, out_features=300, bias=True)
        )
      )
    )
    (list_embedding_3): ELMoEmbeddings(model=3-elmo-small)
    (list_embedding_4): BertEmbeddings(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1, inplace=False)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=14080, out_features=14080, bias=True)
  (rnn): LSTM(14080, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=12, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2020-04-01 21:01:02,723 ----------------------------------------------------------------------------------------------------
2020-04-01 21:01:02,723 Corpus: "Corpus: 14041 train + 3250 dev + 3453 test sentences"
2020-04-01 21:01:02,723 ----------------------------------------------------------------------------------------------------
2020-04-01 21:01:02,723 Parameters:
2020-04-01 21:01:02,723  - learning_rate: "0.01"
2020-04-01 21:01:02,723  - mini_batch_size: "32"
2020-04-01 21:01:02,723  - patience: "3"
2020-04-01 21:01:02,723  - anneal_factor: "0.5"
2020-04-01 21:01:02,724  - max_epochs: "150"
2020-04-01 21:01:02,724  - shuffle: "True"
2020-04-01 21:01:02,724  - train_with_dev: "False"
2020-04-01 21:01:02,724  - batch_growth_annealing: "False"
2020-04-01 21:01:02,724 ----------------------------------------------------------------------------------------------------
2020-04-01 21:01:02,724 Model training base path: "log/mix_xfeb_20200401210102_256"
2020-04-01 21:01:02,724 ----------------------------------------------------------------------------------------------------
2020-04-01 21:01:02,724 Device: cuda:0
2020-04-01 21:01:02,724 ----------------------------------------------------------------------------------------------------
2020-04-01 21:01:02,724 Embeddings storage mode: cpu
2020-04-01 21:01:02,727 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-01 21:03:05,985 epoch 1 - iter 132/220 - loss 8.74485291 - samples/sec: 20.81
^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B2020-04-01 21:04:09,235 epoch 1 - iter 43/439 - loss 12.50606582 - samples/sec: 7.38
2020-04-01 21:07:30,790 epoch 1 - iter 154/220 - loss 8.02713283 - samples/sec: 20.97
2020-04-01 21:11:59,398 epoch 1 - iter 86/439 - loss 9.44572608 - samples/sec: 7.87

2020-04-01 21:16:17,781 epoch 1 - iter 198/220 - loss 6.96563075 - samples/sec: 21.59
2020-04-01 21:19:11,757 epoch 1 - iter 129/439 - loss 7.90453832 - samples/sec: 7.39
Traceback (most recent call last):
  File "train.py", line 23, in <module>
    ARGS = parse_args()
  File "train.py", line 16, in parse_args
    arg_parser = argparse.ArgumentParser()
NameError: name 'argparse' is not defined
2020-04-01 21:19:40,198 epoch 1 - iter 220/220 - loss 6.57351060 - samples/sec: 21.57
Traceback (most recent call last):
  File "train.py", line 23, in <module>
    ARGS = parse_args()
  File "train.py", line 16, in parse_args
    arg_parser = argparse.ArgumentParser()
NameError: name 'argparse' is not defined
2020-04-01 21:20:33,972 Reading data from data
2020-04-01 21:20:33,973 Train: data/train.txt
2020-04-01 21:20:33,973 Dev: data/valid.txt
2020-04-01 21:20:33,973 Test: data/test.txt
Corpus: 14041 train + 3250 dev + 3453 test sentences
Dictionary with 12 tags: <unk>, O, B-ORG, B-MISC, B-PER, I-PER, B-LOC, I-ORG, I-MISC, I-LOC, <START>, <STOP>
elmo_s
2020-04-01 21:21:03,043 ----------------------------------------------------------------------------------------------------
2020-04-01 21:21:03,043 Model: "SequenceTagger(
  (embeddings): ELMoEmbeddings(model=elmo-small)
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=768, out_features=768, bias=True)
  (rnn): LSTM(768, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=12, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2020-04-01 21:21:03,043 ----------------------------------------------------------------------------------------------------
2020-04-01 21:21:03,043 Corpus: "Corpus: 14041 train + 3250 dev + 3453 test sentences"
2020-04-01 21:21:03,043 ----------------------------------------------------------------------------------------------------
2020-04-01 21:21:03,043 Parameters:
2020-04-01 21:21:03,043  - learning_rate: "0.01"
2020-04-01 21:21:03,043  - mini_batch_size: "64"
2020-04-01 21:21:03,043  - patience: "3"
2020-04-01 21:21:03,043  - anneal_factor: "0.5"
2020-04-01 21:21:03,044  - max_epochs: "150"
2020-04-01 21:21:03,044  - shuffle: "True"
2020-04-01 21:21:03,044  - train_with_dev: "False"
2020-04-01 21:21:03,044  - batch_growth_annealing: "False"
2020-04-01 21:21:03,044 ----------------------------------------------------------------------------------------------------
2020-04-01 21:21:03,044 Model training base path: "log/elmo_s_20200401212103_256"
2020-04-01 21:21:03,044 ----------------------------------------------------------------------------------------------------
2020-04-01 21:21:03,044 Device: cuda:0
2020-04-01 21:21:03,044 ----------------------------------------------------------------------------------------------------
2020-04-01 21:21:03,044 Embeddings storage mode: cpu
2020-04-01 21:21:03,046 ----------------------------------------------------------------------------------------------------
2020-04-01 21:21:12,945 epoch 1 - iter 22/220 - loss 35.03582027 - samples/sec: 142.27
2020-04-01 21:21:28,151 epoch 1 - iter 44/220 - loss 23.82255249 - samples/sec: 151.00
2020-04-01 21:21:44,571 epoch 1 - iter 66/220 - loss 18.77589798 - samples/sec: 151.30
2020-04-01 21:22:00,821 epoch 1 - iter 88/220 - loss 15.91463776 - samples/sec: 142.54
2020-04-01 21:22:17,832 epoch 1 - iter 110/220 - loss 13.99874860 - samples/sec: 138.73
2020-04-01 21:22:34,279 epoch 1 - iter 132/220 - loss 12.62927651 - samples/sec: 145.65
2020-04-01 21:22:58,413 ----------------------------------------------------------------------------------------------------
2020-04-01 21:22:58,414 EPOCH 1 done: loss 6.5735 - lr 0.0100
2020-04-01 21:23:07,841 epoch 1 - iter 176/220 - loss 10.74979358 - samples/sec: 145.79
2020-04-01 21:23:17,980 epoch 1 - iter 198/220 - loss 10.01813947 - samples/sec: 177.91
2020-04-01 21:23:32,110 epoch 1 - iter 220/220 - loss 9.42842141 - samples/sec: 166.09
2020-04-01 21:23:37,858 ----------------------------------------------------------------------------------------------------
2020-04-01 21:23:37,858 EPOCH 1 done: loss 9.4284 - lr 0.0100
2020-04-01 21:23:53,583 DEV : loss 3.372437000274658 - score 0.638
2020-04-01 21:23:53,679 BAD EPOCHS (no improvement): 0
2020-04-01 21:23:54,973 ----------------------------------------------------------------------------------------------------
2020-04-01 21:23:58,414 epoch 2 - iter 22/220 - loss 4.00663425 - samples/sec: 409.44
2020-04-01 21:24:07,158 epoch 2 - iter 44/220 - loss 3.96884356 - samples/sec: 410.01
2020-04-01 21:24:11,658 epoch 2 - iter 66/220 - loss 3.85298993 - samples/sec: 422.85
2020-04-01 21:24:16,482 epoch 2 - iter 88/220 - loss 3.73746727 - samples/sec: 417.50
2020-04-01 21:24:18,336 epoch 1 - iter 172/439 - loss 6.91762997 - samples/sec: 18.82
2020-04-01 21:24:26,182 epoch 2 - iter 110/220 - loss 3.67647593 - samples/sec: 329.02
2020-04-01 21:24:36,468 epoch 2 - iter 132/220 - loss 3.64520037 - samples/sec: 307.19
^C2020-04-01 21:24:40,767 ----------------------------------------------------------------------------------------------------
2020-04-01 21:24:40,768 Exiting from training early.
2020-04-01 21:24:40,768 Saving model ...
2020-04-01 21:24:42,070 Done.
2020-04-01 21:24:42,070 ----------------------------------------------------------------------------------------------------
2020-04-01 21:24:42,070 Testing using best model ...
2020-04-01 21:24:42,071 loading file log/elmo_s_20200401212103_256/best-model.pt
^CTraceback (most recent call last):
  File "train.py", line 132, in <module>
    max_epochs=150)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/trainers/trainer.py", line 553, in train
    final_score = self.final_test(base_path, mini_batch_chunk_size, num_workers)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/trainers/trainer.py", line 601, in final_test
    embedding_storage_mode="none",
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/models/sequence_tagger_model.py", line 412, in evaluate
    features = self.forward(batch)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/models/sequence_tagger_model.py", line 498, in forward
    self.embeddings.embed(sentences)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/embeddings.py", line 96, in embed
    self._add_embeddings_internal(sentences)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/embeddings.py", line 853, in _add_embeddings_internal
    embeddings = self.ee.embed_batch(sentence_words)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/allennlp/commands/elmo.py", line 255, in embed_batch
    embeddings, mask = self.batch_to_embeddings(batch)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/allennlp/commands/elmo.py", line 197, in batch_to_embeddings
    bilm_output = self.elmo_bilm(character_ids)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/allennlp/modules/elmo.py", line 610, in forward
    lstm_outputs = self._elmo_lstm(type_representation, mask)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/allennlp/modules/elmo_lstm.py", line 123, in forward
    self.sort_and_run_forward(self._lstm_forward, inputs, mask)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/allennlp/modules/encoder_base.py", line 116, in sort_and_run_forward
    module_output, final_states = module(packed_sequence_input, initial_states)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/allennlp/modules/elmo_lstm.py", line 217, in _lstm_forward
    forward_state)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/allennlp/modules/lstm_cell_with_projection.py", line 155, in forward
    while batch_lengths[current_length_index] <= index:
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/torch/tensor.py", line 28, in wrapped
    return f(*args, **kwargs)
KeyboardInterrupt
2020-04-01 21:25:19,963 DEV : loss 2.177973985671997 - score 0.7812
2020-04-01 21:25:20,346 BAD EPOCHS (no improvement): 0
2020-04-01 21:26:00,192 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-01 21:26:11,804 epoch 2 - iter 22/220 - loss 2.81551353 - samples/sec: 121.96
2020-04-01 21:27:09,532 Reading data from data
2020-04-01 21:27:09,532 Train: data/train.txt
2020-04-01 21:27:09,532 Dev: data/valid.txt
2020-04-01 21:27:09,532 Test: data/test.txt
Corpus: 14041 train + 3250 dev + 3453 test sentences
Dictionary with 12 tags: <unk>, O, B-ORG, B-MISC, B-PER, I-PER, B-LOC, I-ORG, I-MISC, I-LOC, <START>, <STOP>
elmo_s
2020-04-01 21:27:30,587 ----------------------------------------------------------------------------------------------------
2020-04-01 21:27:30,587 Model: "SequenceTagger(
  (embeddings): ELMoEmbeddings(model=elmo-small)
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=768, out_features=768, bias=True)
  (rnn): LSTM(768, 64, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=128, out_features=12, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2020-04-01 21:27:30,587 ----------------------------------------------------------------------------------------------------
2020-04-01 21:27:30,587 Corpus: "Corpus: 14041 train + 3250 dev + 3453 test sentences"
2020-04-01 21:27:30,587 ----------------------------------------------------------------------------------------------------
2020-04-01 21:27:30,587 Parameters:
2020-04-01 21:27:30,587  - learning_rate: "0.01"
2020-04-01 21:27:30,588  - mini_batch_size: "64"
2020-04-01 21:27:30,588  - patience: "3"
2020-04-01 21:27:30,588  - anneal_factor: "0.5"
2020-04-01 21:27:30,588  - max_epochs: "150"
2020-04-01 21:27:30,588  - shuffle: "True"
2020-04-01 21:27:30,588  - train_with_dev: "False"
2020-04-01 21:27:30,588  - batch_growth_annealing: "False"
2020-04-01 21:27:30,588 ----------------------------------------------------------------------------------------------------
2020-04-01 21:27:30,588 Model training base path: "log/elmo_s_20200401212730_64"
2020-04-01 21:27:30,588 ----------------------------------------------------------------------------------------------------
2020-04-01 21:27:30,588 Device: cuda:0
2020-04-01 21:27:30,588 ----------------------------------------------------------------------------------------------------
2020-04-01 21:27:30,588 Embeddings storage mode: cpu
2020-04-01 21:27:30,591 ----------------------------------------------------------------------------------------------------
2020-04-01 21:27:40,394 epoch 1 - iter 22/220 - loss 39.79415495 - samples/sec: 143.69
2020-04-01 21:27:55,919 epoch 1 - iter 44/220 - loss 27.52343548 - samples/sec: 149.45
2020-04-01 21:28:12,793 epoch 1 - iter 66/220 - loss 21.38604313 - samples/sec: 147.24
2020-04-01 21:28:28,770 epoch 1 - iter 88/220 - loss 17.96315986 - samples/sec: 158.99
2020-04-01 21:28:44,796 epoch 1 - iter 110/220 - loss 15.66231513 - samples/sec: 156.28
2020-04-01 21:29:00,722 epoch 1 - iter 132/220 - loss 14.01706880 - samples/sec: 153.66
2020-04-01 21:29:15,907 epoch 1 - iter 154/220 - loss 12.81337747 - samples/sec: 169.71
2020-04-01 21:29:30,393 epoch 1 - iter 176/220 - loss 11.88006270 - samples/sec: 170.34
2020-04-01 21:29:44,073 epoch 1 - iter 198/220 - loss 11.08801648 - samples/sec: 170.60
2020-04-01 21:29:41,775 epoch 2 - iter 44/220 - loss 2.66102071 - samples/sec: 118.96
2020-04-01 21:29:59,964 epoch 1 - iter 220/220 - loss 10.44810167 - samples/sec: 157.15
2020-04-01 21:30:10,187 epoch 1 - iter 215/439 - loss 6.22563925 - samples/sec: 18.46
2020-04-01 21:30:06,284 ----------------------------------------------------------------------------------------------------
2020-04-01 21:30:06,284 EPOCH 1 done: loss 10.4481 - lr 0.0100
2020-04-01 21:30:21,984 DEV : loss 3.4431979656219482 - score 0.6137
2020-04-01 21:30:22,080 BAD EPOCHS (no improvement): 0
2020-04-01 21:30:23,250 ----------------------------------------------------------------------------------------------------
2020-04-01 21:30:27,775 epoch 2 - iter 22/220 - loss 4.11335719 - samples/sec: 311.46
2020-04-01 21:30:39,320 epoch 2 - iter 44/220 - loss 4.17356785 - samples/sec: 321.17
2020-04-01 21:30:49,653 epoch 2 - iter 66/220 - loss 4.18907496 - samples/sec: 370.87
2020-04-01 21:30:59,911 epoch 2 - iter 88/220 - loss 4.08926412 - samples/sec: 341.82
2020-04-01 21:31:10,051 epoch 2 - iter 110/220 - loss 4.03015066 - samples/sec: 351.96
2020-04-01 21:31:20,552 epoch 2 - iter 132/220 - loss 3.99759074 - samples/sec: 320.36
2020-04-01 21:31:30,787 epoch 2 - iter 154/220 - loss 3.93516772 - samples/sec: 313.65
2020-04-01 21:31:40,429 epoch 2 - iter 176/220 - loss 3.87047158 - samples/sec: 372.47
2020-04-01 21:31:48,005 Reading data from data
2020-04-01 21:31:48,005 Train: data/train.txt
2020-04-01 21:31:48,005 Dev: data/valid.txt
2020-04-01 21:31:48,005 Test: data/test.txt
Corpus: 14041 train + 3250 dev + 3453 test sentences
Dictionary with 12 tags: <unk>, O, B-ORG, B-MISC, B-PER, I-PER, B-LOC, I-ORG, I-MISC, I-LOC, <START>, <STOP>
elmo_s
2020-04-01 21:31:59,232 epoch 2 - iter 220/220 - loss 3.76740683 - samples/sec: 310.85
2020-04-01 21:32:07,472 ----------------------------------------------------------------------------------------------------
2020-04-01 21:32:07,472 EPOCH 2 done: loss 3.7674 - lr 0.0100
2020-04-01 21:32:11,393 DEV : loss 2.2762773036956787 - score 0.7485
2020-04-01 21:32:11,492 BAD EPOCHS (no improvement): 0
2020-04-01 21:32:12,837 ----------------------------------------------------------------------------------------------------
2020-04-01 21:32:17,832 Reading data from data
2020-04-01 21:32:17,832 Train: data/train.txt
2020-04-01 21:32:17,832 Dev: data/valid.txt
2020-04-01 21:32:17,832 Test: data/test.txt
2020-04-01 21:32:17,286 epoch 3 - iter 22/220 - loss 3.22084894 - samples/sec: 316.72
2020-04-01 21:32:19,140 ----------------------------------------------------------------------------------------------------
2020-04-01 21:32:19,140 Model: "SequenceTagger(
  (embeddings): ELMoEmbeddings(model=elmo-small)
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=768, out_features=768, bias=True)
  (rnn): LSTM(768, 128, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=256, out_features=12, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2020-04-01 21:32:19,140 ----------------------------------------------------------------------------------------------------
2020-04-01 21:32:19,140 Corpus: "Corpus: 14041 train + 3250 dev + 3453 test sentences"
2020-04-01 21:32:19,140 ----------------------------------------------------------------------------------------------------
2020-04-01 21:32:19,140 Parameters:
2020-04-01 21:32:19,140  - learning_rate: "0.01"
2020-04-01 21:32:19,141  - mini_batch_size: "32"
2020-04-01 21:32:19,141  - patience: "3"
2020-04-01 21:32:19,141  - anneal_factor: "0.5"
2020-04-01 21:32:19,141  - max_epochs: "150"
2020-04-01 21:32:19,141  - shuffle: "True"
2020-04-01 21:32:19,141  - train_with_dev: "False"
2020-04-01 21:32:19,141  - batch_growth_annealing: "False"
2020-04-01 21:32:19,141 ----------------------------------------------------------------------------------------------------
2020-04-01 21:32:19,141 Model training base path: "log/elmo_s_20200401213219_128"
2020-04-01 21:32:19,141 ----------------------------------------------------------------------------------------------------
2020-04-01 21:32:19,142 Device: cuda:0
2020-04-01 21:32:19,142 ----------------------------------------------------------------------------------------------------
2020-04-01 21:32:19,142 Embeddings storage mode: cpu
2020-04-01 21:32:19,144 ----------------------------------------------------------------------------------------------------
Corpus: 14041 train + 3250 dev + 3453 test sentences
Dictionary with 12 tags: <unk>, O, B-ORG, B-MISC, B-PER, I-PER, B-LOC, I-ORG, I-MISC, I-LOC, <START>, <STOP>
elmo_s
2020-04-01 21:32:35,693 epoch 1 - iter 43/439 - loss 20.21545135 - samples/sec: 83.17
2020-04-01 21:32:37,727 ----------------------------------------------------------------------------------------------------
2020-04-01 21:32:37,727 Model: "SequenceTagger(
  (embeddings): ELMoEmbeddings(model=elmo-small)
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=768, out_features=768, bias=True)
  (rnn): LSTM(768, 512, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=1024, out_features=12, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2020-04-01 21:32:37,728 ----------------------------------------------------------------------------------------------------
2020-04-01 21:32:37,728 Corpus: "Corpus: 14041 train + 3250 dev + 3453 test sentences"
2020-04-01 21:32:37,728 ----------------------------------------------------------------------------------------------------
2020-04-01 21:32:37,728 Parameters:
2020-04-01 21:32:37,728  - learning_rate: "0.01"
2020-04-01 21:32:37,728  - mini_batch_size: "32"
2020-04-01 21:32:37,728  - patience: "3"
2020-04-01 21:32:37,728  - anneal_factor: "0.5"
2020-04-01 21:32:37,729  - max_epochs: "150"
2020-04-01 21:32:37,729  - shuffle: "True"
2020-04-01 21:32:37,729  - train_with_dev: "False"
2020-04-01 21:32:37,729  - batch_growth_annealing: "False"
2020-04-01 21:32:37,729 ----------------------------------------------------------------------------------------------------
2020-04-01 21:32:37,729 Model training base path: "log/elmo_s_20200401213237_512"
2020-04-01 21:32:37,729 ----------------------------------------------------------------------------------------------------
2020-04-01 21:32:37,729 Device: cuda:0
2020-04-01 21:32:37,730 ----------------------------------------------------------------------------------------------------
2020-04-01 21:32:37,730 Embeddings storage mode: cpu
2020-04-01 21:32:37,732 ----------------------------------------------------------------------------------------------------
2020-04-01 21:32:38,024 epoch 3 - iter 66/220 - loss 3.27085012 - samples/sec: 327.64
2020-04-01 21:32:54,719 epoch 1 - iter 43/439 - loss 24.18184657 - samples/sec: 81.03
2020-04-01 21:32:58,265 epoch 3 - iter 110/220 - loss 3.15433049 - samples/sec: 293.00
2020-04-01 21:32:58,432 epoch 1 - iter 86/439 - loss 14.54825652 - samples/sec: 84.68
2020-04-01 21:33:10,177 epoch 3 - iter 132/220 - loss 3.12477849 - samples/sec: 312.66
2020-04-01 21:33:18,180 epoch 1 - iter 86/439 - loss 16.89347043 - samples/sec: 87.01
2020-04-01 21:33:19,603 epoch 2 - iter 66/220 - loss 2.62366649 - samples/sec: 116.11
2020-04-01 21:33:20,298 epoch 3 - iter 154/220 - loss 3.06768955 - samples/sec: 322.36
2020-04-01 21:33:32,458 epoch 3 - iter 176/220 - loss 3.03557301 - samples/sec: 304.21
2020-04-01 21:33:42,395 epoch 3 - iter 198/220 - loss 3.00944991 - samples/sec: 322.83
2020-04-01 21:33:41,162 epoch 1 - iter 129/439 - loss 13.57292346 - samples/sec: 88.59
2020-04-01 21:33:53,669 epoch 3 - iter 220/220 - loss 2.98844217 - samples/sec: 335.01
2020-04-01 21:33:59,448 ----------------------------------------------------------------------------------------------------
2020-04-01 21:33:59,448 EPOCH 3 done: loss 2.9884 - lr 0.0100
2020-04-01 21:34:03,348 DEV : loss 1.8400617837905884 - score 0.8083
2020-04-01 21:34:03,442 BAD EPOCHS (no improvement): 0
2020-04-01 21:34:04,745 ----------------------------------------------------------------------------------------------------
2020-04-01 21:34:03,993 epoch 1 - iter 172/439 - loss 11.65512070 - samples/sec: 87.25
2020-04-01 21:34:08,794 epoch 4 - iter 22/220 - loss 2.76261543 - samples/sec: 348.09
2020-04-01 21:34:27,543 epoch 1 - iter 215/439 - loss 10.34302983 - samples/sec: 82.79
2020-04-01 21:34:28,799 epoch 4 - iter 66/220 - loss 2.73243501 - samples/sec: 330.20
2020-04-01 21:34:40,728 epoch 4 - iter 88/220 - loss 2.70961524 - samples/sec: 272.53
2020-04-01 21:34:53,662 epoch 1 - iter 301/439 - loss 7.79467046 - samples/sec: 84.73
2020-04-01 21:34:50,347 epoch 1 - iter 258/439 - loss 9.47112029 - samples/sec: 85.39

2020-04-01 21:35:00,288 epoch 4 - iter 132/220 - loss 2.66820064 - samples/sec: 361.93
2020-04-01 21:35:15,331 epoch 1 - iter 344/439 - loss 7.27884709 - samples/sec: 88.15
2020-04-01 21:35:12,184 epoch 1 - iter 301/439 - loss 8.67228918 - samples/sec: 86.55
2020-04-01 21:35:25,997 epoch 4 - iter 154/220 - loss 2.67381330 - samples/sec: 334.96
2020-04-01 21:35:38,487 epoch 4 - iter 176/220 - loss 2.65466158 - samples/sec: 420.10
2020-04-01 21:35:46,540 epoch 1 - iter 387/439 - loss 6.86759966 - samples/sec: 87.17

2020-04-01 21:35:46,238 epoch 1 - iter 344/439 - loss 8.06112305 - samples/sec: 88.16
2020-04-01 21:35:57,391 epoch 4 - iter 220/220 - loss 2.60977543 - samples/sec: 441.15
2020-04-01 21:36:09,593 epoch 1 - iter 430/439 - loss 6.52380347 - samples/sec: 86.98
-------------------------------------
2020-04-01 21:36:03,258 EPOCH 4 done: loss 2.6098 - lr 0.0100
2020-04-01 21:36:07,052 DEV : loss 1.627373218536377 - score 0.8342
2020-04-01 21:36:07,149 BAD EPOCHS (no improvement): 0
2020-04-01 21:36:08,363 ----------------------------------------------------------------------------------------------------
2020-04-01 21:36:09,277 epoch 1 - iter 387/439 - loss 7.57554916 - samples/sec: 87.10
2020-04-01 21:36:19,939 ----------------------------------------------------------------------------------------------------
2020-04-01 21:36:19,940 EPOCH 1 done: loss 6.4624 - lr 0.0100
2020-04-01 21:36:11,694 epoch 5 - iter 22/220 - loss 2.54594045 - samples/sec: 423.03
2020-04-01 21:36:21,650 epoch 5 - iter 44/220 - loss 2.51522622 - samples/sec: 428.52
2020-04-01 21:36:30,307 epoch 5 - iter 66/220 - loss 2.47072703 - samples/sec: 449.27
2020-04-01 21:36:40,496 epoch 5 - iter 88/220 - loss 2.46736960 - samples/sec: 451.75
0,101 BAD EPOCHS (no improvement): 0
2020-04-01 21:36:40,541 epoch 1 - iter 258/439 - loss 5.68784215 - samples/sec: 17.92
2020-04-01 21:36:31,334 epoch 1 - iter 430/439 - loss 7.17362034 - samples/sec: 90.08
2020-04-01 21:36:41,267 ----------------------------------------------------------------------------------------------------
2020-04-01 21:36:49,555 epoch 2 - iter 43/439 - loss 3.32943107 - samples/sec: 166.13
2020-04-01 21:36:41,680 ----------------------------------------------------------------------------------------------------
2020-04-01 21:36:41,680 EPOCH 1 done: loss 7.1007 - lr 0.0100
2020-04-01 21:37:00,572 epoch 5 - iter 132/220 - loss 2.44656590 - samples/sec: 425.31
2020-04-01 21:37:10,570 epoch 5 - iter 154/220 - loss 2.42678076 - samples/sec: 351.85
2020-04-01 21:37:01,671 DEV : loss 2.477200984954834 - score 0.7229
2020-04-01 21:37:01,766 BAD EPOCHS (no improvement): 0
2020-04-01 21:37:03,313 ----------------------------------------------------------------------------------------------------
2020-04-01 21:37:19,023 epoch 2 - iter 129/439 - loss 3.16603205 - samples/sec: 159.26
2020-04-01 21:37:12,283 epoch 2 - iter 43/439 - loss 3.23970755 - samples/sec: 153.50
2020-04-01 21:37:28,758 epoch 2 - iter 86/439 - loss 3.17399048 - samples/sec: 150.15

2020-04-01 21:37:39,591 epoch 5 - iter 220/220 - loss 2.38171303 - samples/sec: 329.12
2020-04-01 21:37:45,620 ----------------------------------------------------------------------------------------------------
2020-04-01 21:37:45,620 EPOCH 5 done: loss 2.3817 - lr 0.0100
2020-04-01 21:37:49,539 DEV : loss 1.4545732736587524 - score 0.8467
2020-04-01 21:37:49,636 BAD EPOCHS (no improvement): 0
2020-04-01 21:37:43,273 epoch 2 - iter 129/439 - loss 3.16415327 - samples/sec: 152.66
2020-04-01 21:37:58,214 epoch 2 - iter 172/439 - loss 3.08355412 - samples/sec: 154.53
------------------------------------
2020-04-01 21:37:56,300 epoch 6 - iter 22/220 - loss 2.16660491 - samples/sec: 264.25
2020-04-01 21:38:04,749 epoch 2 - iter 258/439 - loss 2.97694567 - samples/sec: 149.66
2020-04-01 21:38:06,719 epoch 6 - iter 44/220 - loss 2.19433539 - samples/sec: 299.36
2020-04-01 21:38:16,089 epoch 6 - iter 66/220 - loss 2.16100183 - samples/sec: 335.41

2020-04-01 21:38:12,566 epoch 2 - iter 215/439 - loss 3.00200265 - samples/sec: 156.71
2020-04-01 21:38:27,121 epoch 2 - iter 258/439 - loss 2.94925553 - samples/sec: 155.89
2020-04-01 21:38:33,402 epoch 2 - iter 344/439 - loss 2.92821742 - samples/sec: 149.96
2020-04-01 21:38:36,569 epoch 6 - iter 110/220 - loss 2.21361254 - samples/sec: 322.67
2020-04-01 21:38:46,531 epoch 6 - iter 132/220 - loss 2.20887944 - samples/sec: 325.46
2020-04-01 21:38:41,909 epoch 2 - iter 301/439 - loss 2.93458247 - samples/sec: 151.81
2020-04-01 21:38:57,129 epoch 2 - iter 344/439 - loss 2.86467131 - samples/sec: 154.65
2020-04-01 21:39:01,924 epoch 2 - iter 430/439 - loss 2.86299448 - samples/sec: 153.96
2020-04-01 21:39:09,610 ----------------------------------------------------------------------------------------------------
2020-04-01 21:39:09,610 EPOCH 2 done: loss 2.8572 - lr 0.0100
2020-04-01 21:39:07,095 epoch 6 - iter 176/220 - loss 2.20298877 - samples/sec: 328.91
2020-04-01 21:39:17,217 epoch 6 - iter 198/220 - loss 2.18213246 - samples/sec: 316.14
131 BAD EPOCHS (no improvement): 0
2020-04-01 21:39:15,394 ----------------------------------------------------------------------------------------------------
2020-04-01 21:39:12,273 epoch 2 - iter 387/439 - loss 2.81064785 - samples/sec: 153.96
2020-04-01 21:39:24,345 epoch 3 - iter 43/439 - loss 2.65878336 - samples/sec: 153.82
2020-04-01 21:39:27,617 epoch 2 - iter 430/439 - loss 2.76734592 - samples/sec: 149.21
2020-04-01 21:39:39,512 epoch 3 - iter 86/439 - loss 2.50912381 - samples/sec: 157.71
2020-04-01 21:39:33,646 ----------------------------------------------------------------------------------------------------
2020-04-01 21:39:33,646 EPOCH 6 done: loss 2.1749 - lr 0.0100
2020-04-01 21:39:38,206 DEV : loss 1.3680142164230347 - score 0.8573
2020-04-01 21:39:38,303 BAD EPOCHS (no improvement): 0
2020-04-01 21:39:39,522 ----------------------------------------------------------------------------------------------------
2020-04-01 21:39:35,566 ----------------------------------------------------------------------------------------------------
2020-04-01 21:39:35,567 EPOCH 2 done: loss 2.7620 - lr 0.0100
2020-04-01 21:39:40,034 DEV : loss 1.704492211341858 - score 0.8192
2020-04-01 21:39:40,132 BAD EPOCHS (no improvement): 0
2020-04-01 21:39:41,696 ----------------------------------------------------------------------------------------------------
2020-04-01 21:39:50,445 epoch 3 - iter 43/439 - loss 2.28576596 - samples/sec: 157.36
2020-04-01 21:39:53,492 epoch 7 - iter 44/220 - loss 2.13552532 - samples/sec: 325.13

2020-04-01 21:40:03,862 epoch 7 - iter 66/220 - loss 2.14883314 - samples/sec: 312.97

2020-04-01 21:40:05,330 epoch 3 - iter 86/439 - loss 2.33192456 - samples/sec: 148.83
2020-04-01 21:40:13,374 epoch 7 - iter 88/220 - loss 2.14331494 - samples/sec: 331.61

2020-04-01 21:40:23,394 epoch 7 - iter 110/220 - loss 2.13746674 - samples/sec: 320.05
2020-04-01 21:40:34,065 epoch 7 - iter 132/220 - loss 2.11088457 - samples/sec: 319.64
2020-04-01 21:40:34,515 epoch 3 - iter 172/439 - loss 2.30076522 - samples/sec: 150.51
2020-04-01 21:40:49,061 epoch 3 - iter 215/439 - loss 2.30701990 - samples/sec: 154.65
2020-04-01 21:40:43,836 epoch 7 - iter 154/220 - loss 2.09121851 - samples/sec: 338.23
2020-04-01 21:40:54,709 epoch 7 - iter 176/220 - loss 2.07414247 - samples/sec: 293.30
2020-04-01 21:41:04,763 epoch 7 - iter 198/220 - loss 2.06793714 - samples/sec: 311.28
2020-04-01 21:41:02,756 epoch 3 - iter 258/439 - loss 2.29832838 - samples/sec: 158.73
2020-04-01 21:41:14,867 epoch 7 - iter 220/220 - loss 2.06164550 - samples/sec: 332.37
2020-04-01 21:41:20,878 ----------------------------------------------------------------------------------------------------
2020-04-01 21:41:20,878 EPOCH 7 done: loss 2.0616 - lr 0.0100
2020-04-01 21:41:24,805 DEV : loss 1.275213599205017 - score 0.8673
2020-04-01 21:41:24,904 BAD EPOCHS (no improvement): 0
2020-04-01 21:41:26,248 ----------------------------------------------------------------------------------------------------
2020-04-01 21:41:30,247 epoch 8 - iter 22/220 - loss 2.04286985 - samples/sec: 352.38
2020-04-01 21:41:39,757 epoch 8 - iter 44/220 - loss 1.96595742 - samples/sec: 415.47

2020-04-01 21:41:32,950 epoch 3 - iter 344/439 - loss 2.27300712 - samples/sec: 151.07
2020-04-01 21:41:48,036 epoch 8 - iter 66/220 - loss 2.00640383 - samples/sec: 444.12
-------------------------------------
2020-04-01 21:41:46,384 EPOCH 3 done: loss 2.3083 - lr 0.0100
2020-04-01 21:41:50,826 DEV : loss 1.4465934038162231 - score 0.8499
2020-04-01 21:41:50,923 BAD EPOCHS (no improvement): 0
2020-04-01 21:41:47,244 epoch 3 - iter 387/439 - loss 2.24959243 - samples/sec: 164.49
2020-04-01 21:41:57,295 epoch 8 - iter 88/220 - loss 2.03183837 - samples/sec: 399.05
-------------------------------------
2020-04-01 21:42:00,922 epoch 4 - iter 43/439 - loss 2.09336041 - samples/sec: 157.73
2020-04-01 21:42:02,041 epoch 3 - iter 430/439 - loss 2.22058238 - samples/sec: 159.85
2020-04-01 21:42:07,155 epoch 8 - iter 110/220 - loss 2.00193302 - samples/sec: 368.24
------------------------------------
2020-04-01 21:42:09,789 EPOCH 3 done: loss 2.2192 - lr 0.0100
2020-04-01 21:42:15,521 epoch 4 - iter 86/439 - loss 2.09201870 - samples/sec: 161.40
2020-04-01 21:42:14,251 DEV : loss 1.4527064561843872 - score 0.8459
2020-04-01 21:42:14,350 BAD EPOCHS (no improvement): 0
2020-04-01 21:42:15,897 ----------------------------------------------------------------------------------------------------
2020-04-01 21:42:15,836 epoch 8 - iter 132/220 - loss 1.96915596 - samples/sec: 411.49
2020-04-01 21:42:25,103 epoch 8 - iter 154/220 - loss 1.96012258 - samples/sec: 415.09
2020-04-01 21:42:24,977 epoch 4 - iter 43/439 - loss 2.05819545 - samples/sec: 151.62
2020-04-01 21:42:33,878 epoch 8 - iter 176/220 - loss 1.95264421 - samples/sec: 441.32
2020-04-01 21:42:41,959 epoch 8 - iter 198/220 - loss 1.96255601 - samples/sec: 439.16
2020-04-01 21:42:43,824 epoch 1 - iter 301/439 - loss 5.29225222 - samples/sec: 18.25
2020-04-01 21:42:44,461 epoch 4 - iter 172/439 - loss 2.05093456 - samples/sec: 154.92
2020-04-01 21:42:52,686 epoch 8 - iter 220/220 - loss 1.94824966 - samples/sec: 296.74
2020-04-01 21:42:58,830 ----------------------------------------------------------------------------------------------------
2020-04-01 21:42:58,830 EPOCH 8 done: loss 1.9482 - lr 0.0100
2020-04-01 21:43:02,742 DEV : loss 1.2007293701171875 - score 0.8683
2020-04-01 21:43:02,841 BAD EPOCHS (no improvement): 0
2020-04-01 21:43:04,106 ----------------------------------------------------------------------------------------------------
2020-04-01 21:43:08,540 epoch 9 - iter 22/220 - loss 1.82617320 - samples/sec: 317.86
2020-04-01 21:43:19,211 epoch 9 - iter 44/220 - loss 1.84777444 - samples/sec: 294.07

2020-04-01 21:43:29,542 epoch 9 - iter 66/220 - loss 1.84459770 - samples/sec: 306.91

2020-04-01 21:43:24,661 epoch 4 - iter 215/439 - loss 1.99320234 - samples/sec: 149.32
2020-04-01 21:43:41,095 epoch 9 - iter 88/220 - loss 1.84994867 - samples/sec: 294.75

2020-04-01 21:43:50,824 epoch 9 - iter 110/220 - loss 1.83930867 - samples/sec: 367.33
2020-04-01 21:44:00,748 epoch 9 - iter 132/220 - loss 1.83039615 - samples/sec: 326.59
2020-04-01 21:43:54,650 epoch 4 - iter 301/439 - loss 1.97795234 - samples/sec: 153.62
2020-04-01 21:44:10,427 epoch 9 - iter 154/220 - loss 1.84792253 - samples/sec: 327.04
2020-04-01 21:44:12,445 epoch 4 - iter 430/439 - loss 2.01634902 - samples/sec: 153.19
2020-04-01 21:44:09,197 epoch 4 - iter 344/439 - loss 1.95785314 - samples/sec: 151.84
2020-04-01 21:44:20,434 epoch 9 - iter 176/220 - loss 1.83977492 - samples/sec: 319.90
------------------------------------
2020-04-01 21:44:19,787 EPOCH 4 done: loss 2.0207 - lr 0.0100
2020-04-01 21:44:31,423 epoch 9 - iter 198/220 - loss 1.82202780 - samples/sec: 340.48
4,322 BAD EPOCHS (no improvement): 0
2020-04-01 21:44:25,640 ----------------------------------------------------------------------------------------------------
2020-04-01 21:44:23,270 epoch 4 - iter 387/439 - loss 1.95705066 - samples/sec: 159.46
2020-04-01 21:44:40,926 epoch 9 - iter 220/220 - loss 1.82671459 - samples/sec: 330.63
020-04-01 21:44:38,814 epoch 4 - iter 430/439 - loss 1.93929782 - samples/sec: 155.19
2020-04-01 21:44:47,463 ----------------------------------------------------------------------------------------------------
2020-04-01 21:44:47,463 EPOCH 9 done: loss 1.8267 - lr 0.0100
2020-04-01 21:44:51,385 DEV : loss 1.1279640197753906 - score 0.8774
2020-04-01 21:44:51,482 BAD EPOCHS (no improvement): 0
2020-04-01 21:44:46,853 ----------------------------------------------------------------------------------------------------
2020-04-01 21:44:46,854 EPOCH 4 done: loss 1.9394 - lr 0.0100
2020-04-01 21:44:51,315 DEV : loss 1.2620447874069214 - score 0.8666
2020-04-01 21:44:51,412 BAD EPOCHS (no improvement): 0
2020-04-01 21:44:53,964 ----------------------------------------------------------------------------------------------------
2020-04-01 21:45:02,859 epoch 5 - iter 43/439 - loss 1.74750936 - samples/sec: 154.79

2020-04-01 21:45:09,653 epoch 10 - iter 44/220 - loss 1.81162738 - samples/sec: 272.70
2020-04-01 21:45:19,592 epoch 10 - iter 66/220 - loss 1.79101694 - samples/sec: 328.52
2020-04-01 21:45:17,092 epoch 5 - iter 86/439 - loss 1.78394671 - samples/sec: 151.08
2020-04-01 21:45:32,060 epoch 5 - iter 129/439 - loss 1.85722717 - samples/sec: 156.49
2020-04-01 21:45:40,174 epoch 10 - iter 110/220 - loss 1.77114039 - samples/sec: 312.02
2020-04-01 21:45:50,691 epoch 10 - iter 132/220 - loss 1.76667174 - samples/sec: 314.87
2020-04-01 21:45:46,197 epoch 5 - iter 172/439 - loss 1.83710702 - samples/sec: 156.92
2020-04-01 21:46:00,827 epoch 5 - iter 215/439 - loss 1.80370729 - samples/sec: 151.36

2020-04-01 21:46:12,037 epoch 10 - iter 176/220 - loss 1.76539801 - samples/sec: 290.18
2020-04-01 21:46:21,935 epoch 10 - iter 198/220 - loss 1.76230999 - samples/sec: 283.11
020-04-01 21:46:16,185 epoch 5 - iter 258/439 - loss 1.78259088 - samples/sec: 151.00
2020-04-01 21:46:31,732 epoch 10 - iter 220/220 - loss 1.76746280 - samples/sec: 339.69
2020-04-01 21:46:36,775 ----------------------------------------------------------------------------------------------------
2020-04-01 21:46:36,776 EPOCH 10 done: loss 1.7675 - lr 0.0100
2020-04-01 21:46:40,699 DEV : loss 1.0893893241882324 - score 0.8848
2020-04-01 21:46:40,795 BAD EPOCHS (no improvement): 0
2020-04-01 21:46:42,135 ----------------------------------------------------------------------------------------------------
2020-04-01 21:46:46,339 epoch 11 - iter 22/220 - loss 1.63370965 - samples/sec: 335.26
2020-04-01 21:46:45,354 epoch 5 - iter 344/439 - loss 1.77337415 - samples/sec: 151.80
2020-04-01 21:46:56,079 epoch 11 - iter 44/220 - loss 1.74600538 - samples/sec: 332.03
------------------------------------
2020-04-01 21:46:59,288 EPOCH 5 done: loss 1.8676 - lr 0.0100
2020-04-01 21:47:03,679 DEV : loss 1.1658430099487305 - score 0.8743
2020-04-01 21:47:03,773 BAD EPOCHS (no improvement): 0
2020-04-01 21:47:00,069 epoch 5 - iter 387/439 - loss 1.77302968 - samples/sec: 152.27
2020-04-01 21:47:06,395 epoch 11 - iter 66/220 - loss 1.73971033 - samples/sec: 336.73
------------------------------------
2020-04-01 21:47:14,301 epoch 6 - iter 43/439 - loss 1.81863330 - samples/sec: 149.63
2020-04-01 21:47:16,079 epoch 5 - iter 430/439 - loss 1.75848615 - samples/sec: 153.49
2020-04-01 21:47:23,941 ----------------------------------------------------------------------------------------------------
2020-04-01 21:47:23,942 EPOCH 5 done: loss 1.7539 - lr 0.0100
2020-04-01 21:47:27,257 epoch 11 - iter 110/220 - loss 1.72509954 - samples/sec: 343.062020-04-01 21:47:28,420 DEV : loss 1.1610677242279053 - score 0.8752
2020-04-01 21:47:28,520 BAD EPOCHS (no improvement): 0
2020-04-01 21:47:30,157 ----------------------------------------------------------------------------------------------------
2020-04-01 21:47:44,343 epoch 6 - iter 129/439 - loss 1.79080721 - samples/sec: 157.26
2020-04-01 21:47:39,309 epoch 6 - iter 43/439 - loss 1.68767588 - samples/sec: 150.44

2020-04-01 21:47:53,834 epoch 6 - iter 86/439 - loss 1.65148848 - samples/sec: 152.88

2020-04-01 21:47:54,886 epoch 11 - iter 176/220 - loss 1.70115935 - samples/sec: 452.10
2020-04-01 21:48:03,807 epoch 11 - iter 198/220 - loss 1.70054864 - samples/sec: 415.86
2020-04-01 21:48:13,302 epoch 11 - iter 220/220 - loss 1.70434876 - samples/sec: 451.552020-04-01 21:48:08,508 epoch 6 - iter 129/439 - loss 1.66262347 - samples/sec: 150.00
2020-04-01 21:48:23,272 epoch 6 - iter 172/439 - loss 1.68654476 - samples/sec: 153.70
------------------------------------
2020-04-01 21:48:18,556 EPOCH 11 done: loss 1.7043 - lr 0.0100
2020-04-01 21:48:22,327 DEV : loss 1.0230379104614258 - score 0.889
2020-04-01 21:48:22,426 BAD EPOCHS (no improvement): 0
2020-04-01 21:48:23,613 ----------------------------------------------------------------------------------------------------
2020-04-01 21:48:26,709 epoch 12 - iter 22/220 - loss 1.80518748 - samples/sec: 455.13
2020-04-01 21:48:35,459 epoch 12 - iter 44/220 - loss 1.77231604 - samples/sec: 456.52
2020-04-01 21:48:38,158 epoch 6 - iter 215/439 - loss 1.64102029 - samples/sec: 154.08
2020-04-01 21:48:48,069 epoch 1 - iter 344/439 - loss 4.96443959 - samples/sec: 18.18
2020-04-01 21:48:52,626 epoch 6 - iter 258/439 - loss 1.65250879 - samples/sec: 150.50
2020-04-01 21:48:57,287 epoch 6 - iter 344/439 - loss 1.71208084 - samples/sec: 153.83
2020-04-01 21:49:01,567 epoch 12 - iter 110/220 - loss 1.67465328 - samples/sec: 444.64
2020-04-01 21:49:11,307 epoch 12 - iter 132/220 - loss 1.64432798 - samples/sec: 346.072020-04-01 21:49:07,115 epoch 6 - iter 301/439 - loss 1.64996905 - samples/sec: 152.49
2020-04-01 21:49:21,895 epoch 6 - iter 344/439 - loss 1.62419509 - samples/sec: 152.20

2020-04-01 21:49:27,568 epoch 6 - iter 430/439 - loss 1.70643118 - samples/sec: 153.46
2020-04-01 21:49:31,113 epoch 12 - iter 176/220 - loss 1.63095013 - samples/sec: 316.45
2020-04-01 21:49:41,523 epoch 12 - iter 198/220 - loss 1.63245380 - samples/sec: 312.90
-----------------------------------
2020-04-01 21:49:35,057 EPOCH 6 done: loss 1.7084 - lr 0.0100
2020-04-01 21:49:39,502 DEV : loss 1.0917867422103882 - score 0.8792
2020-04-01 21:49:39,598 BAD EPOCHS (no improvement): 0
2020-04-01 21:49:40,989 ----------------------------------------------------------------------------------------------------
2020-04-01 21:49:35,595 epoch 6 - iter 387/439 - loss 1.62275309 - samples/sec: 155.18
2020-04-01 21:49:50,010 epoch 7 - iter 43/439 - loss 1.58709106 - samples/sec: 152.63
2020-04-01 21:49:51,487 epoch 6 - iter 430/439 - loss 1.60658270 - samples/sec: 152.40

2020-04-01 21:50:04,875 epoch 7 - iter 86/439 - loss 1.54316079 - samples/sec: 164.82
2020-04-01 21:49:57,916 ----------------------------------------------------------------------------------------------------
2020-04-01 21:49:57,916 EPOCH 12 done: loss 1.6422 - lr 0.0100
2020-04-01 21:50:01,859 DEV : loss 1.0198478698730469 - score 0.8905
2020-04-01 21:50:01,956 BAD EPOCHS (no improvement): 0
2020-04-01 21:50:03,161 ----------------------------------------------------------------------------------------------------
2020-04-01 21:49:59,542 ----------------------------------------------------------------------------------------------------
2020-04-01 21:49:59,543 EPOCH 6 done: loss 1.6076 - lr 0.0100
2020-04-01 21:50:03,974 DEV : loss 1.0791224241256714 - score 0.883
2020-04-01 21:50:04,069 BAD EPOCHS (no improvement): 0
2020-04-01 21:50:05,506 ----------------------------------------------------------------------------------------------------
2020-04-01 21:50:14,542 epoch 7 - iter 43/439 - loss 1.55998673 - samples/sec: 152.37
2020-04-01 21:50:18,323 epoch 13 - iter 44/220 - loss 1.64513641 - samples/sec: 314.49
2020-04-01 21:50:28,148 epoch 13 - iter 66/220 - loss 1.63187860 - samples/sec: 320.02
2020-04-01 21:50:28,526 epoch 7 - iter 86/439 - loss 1.61170508 - samples/sec: 154.59
2020-04-01 21:50:43,402 epoch 7 - iter 129/439 - loss 1.58554847 - samples/sec: 151.49
2020-04-01 21:50:39,027 epoch 13 - iter 88/220 - loss 1.61736178 - samples/sec: 277.10
2020-04-01 21:50:50,509 epoch 7 - iter 215/439 - loss 1.55431106 - samples/sec: 155.47
2020-04-01 21:50:49,449 epoch 13 - iter 110/220 - loss 1.62177719 - samples/sec: 306.11
2020-04-01 21:51:00,407 epoch 13 - iter 132/220 - loss 1.61235202 - samples/sec: 284.48
020-04-01 21:51:05,166 epoch 7 - iter 258/439 - loss 1.58111041 - samples/sec: 157.47
2020-04-01 21:50:57,328 epoch 7 - iter 172/439 - loss 1.56078806 - samples/sec: 154.99
2020-04-01 21:51:11,461 epoch 13 - iter 154/220 - loss 1.58739590 - samples/sec: 279.66
2020-04-01 21:51:21,704 epoch 13 - iter 176/220 - loss 1.57277068 - samples/sec: 293.84
2020-04-01 21:51:32,015 epoch 13 - iter 198/220 - loss 1.56818258 - samples/sec: 293.75
020-04-01 21:51:26,641 epoch 7 - iter 258/439 - loss 1.58239161 - samples/sec: 151.90
2020-04-01 21:51:42,789 epoch 13 - iter 220/220 - loss 1.56477538 - samples/sec: 294.12
2020-04-01 21:51:49,140 epoch 7 - iter 387/439 - loss 1.60558063 - samples/sec: 154.25
2020-04-01 21:51:49,302 ----------------------------------------------------------------------------------------------------
2020-04-01 21:51:49,302 EPOCH 13 done: loss 1.5648 - lr 0.0100
2020-04-01 21:51:53,229 DEV : loss 0.9595125317573547 - score 0.8949
2020-04-01 21:51:53,325 BAD EPOCHS (no improvement): 0
2020-04-01 21:51:54,643 ----------------------------------------------------------------------------------------------------
2020-04-01 21:51:58,790 epoch 14 - iter 22/220 - loss 1.51173158 - samples/sec: 339.81
2020-04-01 21:51:56,103 epoch 7 - iter 344/439 - loss 1.56065140 - samples/sec: 153.44
2020-04-01 21:52:12,928 ----------------------------------------------------------------------------------------------------
2020-04-01 21:52:12,928 EPOCH 7 done: loss 1.6083 - lr 0.0100
2020-04-01 21:52:10,605 epoch 7 - iter 387/439 - loss 1.55124961 - samples/sec: 170.68
2020-04-01 21:52:10,008 epoch 14 - iter 44/220 - loss 1.51242736 - samples/sec: 292.93
2020-04-01 21:52:21,089 epoch 14 - iter 66/220 - loss 1.53968004 - samples/sec: 313.78
7,387 BAD EPOCHS (no improvement): 0
2020-04-01 21:52:18,740 ----------------------------------------------------------------------------------------------------
2020-04-01 21:52:32,659 epoch 14 - iter 88/220 - loss 1.53801650 - samples/sec: 302.20
020-04-01 21:52:26,301 epoch 7 - iter 430/439 - loss 1.54199089 - samples/sec: 154.06
2020-04-01 21:52:34,969 ----------------------------------------------------------------------------------------------------
2020-04-01 21:52:34,969 EPOCH 7 done: loss 1.5428 - lr 0.0100
2020-04-01 21:52:43,208 epoch 14 - iter 110/220 - loss 1.54125435 - samples/sec: 326.14
20-04-01 21:52:39,453 DEV : loss 1.0382102727890015 - score 0.8874
2020-04-01 21:52:39,551 BAD EPOCHS (no improvement): 0
2020-04-01 21:52:41,109 ----------------------------------------------------------------------------------------------------
2020-04-01 21:52:53,709 epoch 14 - iter 132/220 - loss 1.53412529 - samples/sec: 328.40
020-04-01 21:52:50,054 epoch 8 - iter 43/439 - loss 1.54923632 - samples/sec: 153.90
2020-04-01 21:53:03,599 epoch 14 - iter 154/220 - loss 1.54635927 - samples/sec: 323.77
2020-04-01 21:53:14,009 epoch 14 - iter 176/220 - loss 1.53796637 - samples/sec: 341.68
2020-04-01 21:53:23,068 epoch 14 - iter 198/220 - loss 1.53540944 - samples/sec: 423.91
020-04-01 21:53:20,830 epoch 8 - iter 129/439 - loss 1.50661691 - samples/sec: 152.54
2020-04-01 21:53:32,876 epoch 14 - iter 220/220 - loss 1.53395760 - samples/sec: 424.83
2020-04-01 21:53:38,599 ----------------------------------------------------------------------------------------------------
2020-04-01 21:53:38,599 EPOCH 14 done: loss 1.5340 - lr 0.0100
2020-04-01 21:53:43,168 DEV : loss 0.9630600214004517 - score 0.8976
2020-04-01 21:53:43,266 BAD EPOCHS (no improvement): 0
2020-04-01 21:53:44,469 ----------------------------------------------------------------------------------------------------
2020-04-01 21:53:47,959 epoch 15 - iter 22/220 - loss 1.45197306 - samples/sec: 403.68
2020-04-01 21:53:50,985 epoch 8 - iter 215/439 - loss 1.47931425 - samples/sec: 151.25
2020-04-01 21:53:57,129 epoch 15 - iter 44/220 - loss 1.45900394 - samples/sec: 430.88
2020-04-01 21:54:06,361 epoch 15 - iter 66/220 - loss 1.47710453 - samples/sec: 402.33
2020-04-01 21:54:15,666 epoch 15 - iter 88/220 - loss 1.44124281 - samples/sec: 455.95
2020-04-01 21:54:24,479 epoch 15 - iter 110/220 - loss 1.43323888 - samples/sec: 471.92
020-04-01 21:54:21,222 epoch 8 - iter 301/439 - loss 1.47405698 - samples/sec: 150.72
2020-04-01 21:54:24,529 Reading data from data
2020-04-01 21:54:24,529 Train: data/train.txt
2020-04-01 21:54:24,529 Dev: data/valid.txt
2020-04-01 21:54:24,529 Test: data/test.txt
Corpus: 14041 train + 3250 dev + 3453 test sentences
Dictionary with 12 tags: <unk>, O, B-ORG, B-MISC, B-PER, I-PER, B-LOC, I-ORG, I-MISC, I-LOC, <START>, <STOP>
bert
2020-04-01 21:54:35,837 epoch 8 - iter 344/439 - loss 1.47392947 - samples/sec: 160.12
2020-04-01 21:54:34,636 epoch 15 - iter 132/220 - loss 1.42712537 - samples/sec: 451.15
2020-04-01 21:54:33,724 epoch 2 - iter 198/220 - loss 2.48358749 - samples/sec: 127.43
2020-04-01 21:54:39,565 epoch 8 - iter 430/439 - loss 1.50801164 - samples/sec: 152.46
2020-04-01 21:54:50,414 Reading data from data
2020-04-01 21:54:50,414 Train: data/train.txt
2020-04-01 21:54:50,414 Dev: data/valid.txt
2020-04-01 21:54:50,414 Test: data/test.txt
2020-04-01 21:54:46,028 ----------------------------------------------------------------------------------------------------
2020-04-01 21:54:46,031 Model: "SequenceTagger(
  (embeddings): BertEmbeddings(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3072, out_features=3072, bias=True)
  (rnn): LSTM(3072, 512, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=1024, out_features=12, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2020-04-01 21:54:46,032 ----------------------------------------------------------------------------------------------------
2020-04-01 21:54:46,032 Corpus: "Corpus: 14041 train + 3250 dev + 3453 test sentences"
2020-04-01 21:54:46,032 ----------------------------------------------------------------------------------------------------
2020-04-01 21:54:46,032 Parameters:
2020-04-01 21:54:46,033  - learning_rate: "0.01"
2020-04-01 21:54:46,033  - mini_batch_size: "32"
2020-04-01 21:54:46,033  - patience: "3"
2020-04-01 21:54:46,033  - anneal_factor: "0.5"
2020-04-01 21:54:46,033  - max_epochs: "150"
2020-04-01 21:54:46,033  - shuffle: "True"
2020-04-01 21:54:46,033  - train_with_dev: "False"
2020-04-01 21:54:46,033  - batch_growth_annealing: "False"
2020-04-01 21:54:46,033 ----------------------------------------------------------------------------------------------------
2020-04-01 21:54:46,033 Model training base path: "log/bert_20200401215445_512"
2020-04-01 21:54:46,034 ----------------------------------------------------------------------------------------------------
2020-04-01 21:54:46,034 Device: cuda:0
2020-04-01 21:54:46,034 ----------------------------------------------------------------------------------------------------
2020-04-01 21:54:46,034 Embeddings storage mode: cpu
2020-04-01 21:54:46,042 ----------------------------------------------------------------------------------------------------
2020-04-01 21:54:51,923 ----------------------------------------------------------------------------------------------------
2020-04-01 21:54:51,923 EPOCH 8 done: loss 1.5066 - lr 0.0100
2020-04-01 21:54:56,366 DEV : loss 0.9768828749656677 - score 0.8907
2020-04-01 21:55:00,937 epoch 8 - iter 387/439 - loss 1.46021805 - samples/sec: 131.45

2020-04-01 21:54:57,457 epoch 1 - iter 387/439 - loss 4.68698699 - samples/sec: 18.17
Corpus: 14041 train + 3250 dev + 3453 test sentences
Dictionary with 12 tags: <unk>, O, B-ORG, B-MISC, B-PER, I-PER, B-LOC, I-ORG, I-MISC, I-LOC, <START>, <STOP>
bert
2020-04-01 21:54:59,257 epoch 1 - iter 43/439 - loss 18.23910446 - samples/sec: 104.17
2020-04-01 21:54:56,463 BAD EPOCHS (no improvement): 0
2020-04-01 21:55:03,680 ----------------------------------------------------------------------------------------------------
2020-04-01 21:55:07,036 ----------------------------------------------------------------------------------------------------
2020-04-01 21:55:07,038 Model: "SequenceTagger(
  (embeddings): BertEmbeddings(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3072, out_features=3072, bias=True)
  (rnn): LSTM(3072, 128, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=256, out_features=12, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2020-04-01 21:55:07,038 ----------------------------------------------------------------------------------------------------
2020-04-01 21:55:07,038 Corpus: "Corpus: 14041 train + 3250 dev + 3453 test sentences"
2020-04-01 21:55:07,038 ----------------------------------------------------------------------------------------------------
2020-04-01 21:55:07,039 Parameters:
2020-04-01 21:55:07,039  - learning_rate: "0.01"
2020-04-01 21:55:07,039  - mini_batch_size: "32"
2020-04-01 21:55:07,039  - patience: "3"
2020-04-01 21:55:07,039  - anneal_factor: "0.5"
2020-04-01 21:55:07,039  - max_epochs: "150"
2020-04-01 21:55:07,039  - shuffle: "True"
2020-04-01 21:55:07,039  - train_with_dev: "False"
2020-04-01 21:55:07,039  - batch_growth_annealing: "False"
2020-04-01 21:55:07,039 ----------------------------------------------------------------------------------------------------
2020-04-01 21:55:07,039 Model training base path: "log/bert_20200401215506_128"
2020-04-01 21:55:07,039 ----------------------------------------------------------------------------------------------------
2020-04-01 21:55:07,039 Device: cuda:0
2020-04-01 21:55:07,039 ----------------------------------------------------------------------------------------------------
2020-04-01 21:55:07,040 Embeddings storage mode: cpu
2020-04-01 21:55:07,043 ----------------------------------------------------------------------------------------------------
2020-04-01 21:55:12,680 epoch 9 - iter 43/439 - loss 1.44061262 - samples/sec: 152.97
2020-04-01 21:55:13,817 epoch 15 - iter 176/220 - loss 1.46727217 - samples/sec: 301.37
2020-04-01 21:55:18,753 epoch 8 - iter 430/439 - loss 1.45238254 - samples/sec: 167.08
2020-04-01 21:55:21,550 epoch 1 - iter 43/439 - loss 18.83657748 - samples/sec: 94.88
2020-04-01 21:55:24,342 epoch 9 - iter 86/439 - loss 1.46337468 - samples/sec: 273.24

2020-04-01 21:55:28,295 ----------------------------------------------------------------------------------------------------
2020-04-01 21:55:28,295 EPOCH 8 done: loss 1.4554 - lr 0.0100
2020-04-01 21:55:32,748 DEV : loss 0.9808292984962463 - score 0.8952
2020-04-01 21:55:32,846 BAD EPOCHS (no improvement): 0
2020-04-01 21:55:37,021 epoch 15 - iter 220/220 - loss 1.48314253 - samples/sec: 319.53
2020-04-01 21:55:34,364 ----------------------------------------------------------------------------------------------------
2020-04-01 21:55:42,223 epoch 9 - iter 43/439 - loss 1.47077640 - samples/sec: 175.19
2020-04-01 21:55:48,247 epoch 9 - iter 172/439 - loss 1.46705744 - samples/sec: 307.80
------------------------------------
2020-04-01 21:55:44,310 EPOCH 15 done: loss 1.4831 - lr 0.0100
2020-04-01 21:55:48,359 DEV : loss 0.9177575707435608 - score 0.9002
2020-04-01 21:55:48,456 BAD EPOCHS (no improvement): 0
2020-04-01 21:55:50,016 ----------------------------------------------------------------------------------------------------
2020-04-01 21:55:59,330 epoch 9 - iter 215/439 - loss 1.47314890 - samples/sec: 337.79
2020-04-01 21:55:57,789 epoch 9 - iter 86/439 - loss 1.45282372 - samples/sec: 162.72
2020-04-01 21:56:11,136 epoch 9 - iter 258/439 - loss 1.45996768 - samples/sec: 305.75
2020-04-01 21:56:18,560 epoch 16 - iter 66/220 - loss 1.44822650 - samples/sec: 294.58
2020-04-01 21:56:13,220 epoch 9 - iter 129/439 - loss 1.44839018 - samples/sec: 165.23
2020-04-01 21:56:31,180 epoch 16 - iter 88/220 - loss 1.44960806 - samples/sec: 306.54
2020-04-01 21:56:31,426 epoch 9 - iter 172/439 - loss 1.43673607 - samples/sec: 156.99
2020-04-01 21:56:43,059 epoch 16 - iter 110/220 - loss 1.45639673 - samples/sec: 348.16
2020-04-01 21:56:44,927 epoch 9 - iter 344/439 - loss 1.44758897 - samples/sec: 157.48
2020-04-01 21:56:47,890 epoch 9 - iter 215/439 - loss 1.40981872 - samples/sec: 161.89
2020-04-01 21:57:01,098 epoch 9 - iter 387/439 - loss 1.43368162 - samples/sec: 151.59
2020-04-01 21:56:53,899 epoch 16 - iter 132/220 - loss 1.46787085 - samples/sec: 366.92
2020-04-01 21:57:04,186 epoch 16 - iter 154/220 - loss 1.46245877 - samples/sec: 334.58
2020-04-01 21:57:15,301 epoch 9 - iter 430/439 - loss 1.42501250 - samples/sec: 167.09
2020-04-01 21:57:15,435 epoch 16 - iter 176/220 - loss 1.45815436 - samples/sec: 297.20
2020-04-01 21:57:16,713 epoch 1 - iter 86/439 - loss 13.50084000 - samples/sec: 86.26
2020-04-01 21:57:24,496 ----------------------------------------------------------------------------------------------------
2020-04-01 21:57:24,497 EPOCH 9 done: loss 1.4213 - lr 0.0100
2020-04-01 21:57:32,722 DEV : loss 0.9550383687019348 - score 0.8983
2020-04-01 21:57:32,820 BAD EPOCHS (no improvement): 0
2020-04-01 21:57:31,916 epoch 1 - iter 86/439 - loss 14.36439381 - samples/sec: 92.67

2020-04-01 21:57:30,003 epoch 9 - iter 344/439 - loss 1.39858716 - samples/sec: 305.18
2020-04-01 21:57:34,332 ----------------------------------------------------------------------------------------------------
2020-04-01 21:57:37,854 epoch 16 - iter 220/220 - loss 1.43910055 - samples/sec: 314.92
2020-04-01 21:57:43,954 ----------------------------------------------------------------2020-04-01 21:57:46,598 epoch 9 - iter 387/439 - loss 1.41239705 - samples/sec: 150.89
 - lr 0.0100
2020-04-01 21:57:47,899 DEV : loss 0.8816548585891724 - score 0.9005
2020-04-01 21:57:47,997 BAD EPOCHS (no improvement): 0
2020-04-01 21:57:49,605 ----------------------------------------------------------------------------------------------------
2020-04-01 21:57:54,609 epoch 17 - iter 22/220 - loss 1.55306437 - samples/sec: 281.58
^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A2020-04-01 21:58:03,463 epoch 9 - iter 430/439 - loss 1.39516708 - samples/sec: 152.81
2020-04-01 21:58:13,685 ----------------------------------------------------------------------------------------------------
2020-04-01 21:58:13,686 EPOCH 9 done: loss 1.3967 - lr 0.0100
2020-04-01 21:58:18,916 epoch 17 - iter 66/220 - loss 1.41068662 - samples/sec: 310.74

2020-04-01 21:58:18,789 DEV : loss 0.9608155488967896 - score 0.8982
2020-04-01 21:58:18,888 BAD EPOCHS (no improvement): 0
2020-04-01 21:58:20,546 ----------------------------------------------------------------------------------------------------
2020-04-01 21:58:29,635 epoch 10 - iter 43/439 - loss 1.41727304 - samples/sec: 151.47
2020-04-01 21:58:35,981 epoch 10 - iter 172/439 - loss 1.37872863 - samples/sec: 154.29
2020-04-01 21:58:44,514 epoch 17 - iter 110/220 - loss 1.40434168 - samples/sec: 268.00
2020-04-01 21:58:45,317 epoch 10 - iter 86/439 - loss 1.32659741 - samples/sec: 155.54
2020-04-01 21:58:53,962 Reading data from data
2020-04-01 21:58:53,962 Train: data/train.txt
2020-04-01 21:58:53,962 Dev: data/valid.txt
2020-04-01 21:58:53,962 Test: data/test.txt
Corpus: 14041 train + 3250 dev + 3453 test sentences
Dictionary with 12 tags: <unk>, O, B-ORG, B-MISC, B-PER, I-PER, B-LOC, I-ORG, I-MISC, I-LOC, <START>, <STOP>
bert
2020-04-01 21:59:02,193 epoch 10 - iter 129/439 - loss 1.30631590 - samples/sec: 163.55
020-04-01 21:58:57,081 epoch 17 - iter 132/220 - loss 1.40848124 - samples/sec: 344.20
2020-04-01 21:59:07,586 epoch 17 - iter 154/220 - loss 1.40470626 - samples/sec: 312.79
2020-04-01 21:59:18,085 epoch 17 - iter 176/220 - loss 1.41401305 - samples/sec: 330.50
2020-04-01 21:59:18,160 epoch 10 - iter 172/439 - loss 1.32892481 - samples/sec: 144.50
Traceback (most recent call last):
  File "train.py", line 132, in <module>
    max_epochs=150)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/trainers/trainer.py", line 331, in train
    loss = self.model.forward_loss(batch_step)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/models/sequence_tagger_model.py", line 493, in forward_loss
    features = self.forward(data_points)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/models/sequence_tagger_model.py", line 498, in forward
    self.embeddings.embed(sentences)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/embeddings.py", line 96, in embed
    self._add_embeddings_internal(sentences)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/embeddings.py", line 2338, in _add_embeddings_internal
    all_encoder_layers = self.model(all_input_ids, attention_mask=all_input_masks)[
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/transformers/modeling_bert.py", line 790, in forward
    encoder_attention_mask=encoder_extended_attention_mask,
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/transformers/modeling_bert.py", line 407, in forward
    hidden_states, attention_mask, head_mask[i], encoder_hidden_states, encoder_attention_mask
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/transformers/modeling_bert.py", line 368, in forward
    self_attention_outputs = self.attention(hidden_states, attention_mask, head_mask)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/transformers/modeling_bert.py", line 314, in forward
    hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/transformers/modeling_bert.py", line 234, in forward
    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))
RuntimeError: CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 10.73 GiB total capacity; 3.89 GiB already allocated; 36.56 MiB free; 4.46 GiB reserved in total by PyTorch)
2020-04-01 21:59:36,381 epoch 10 - iter 215/439 - loss 1.33406806 - samples/sec: 170.35
2020-04-01 21:59:32,546 ----------------------------------------------------------------------------------------------------
2020-04-01 21:59:32,549 Model: "SequenceTagger(
  (embeddings): BertEmbeddings(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3072, out_features=3072, bias=True)
  (rnn): LSTM(3072, 64, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=128, out_features=12, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2020-04-01 21:59:32,549 ----------------------------------------------------------------------------------------------------
2020-04-01 21:59:32,549 Corpus: "Corpus: 14041 train + 3250 dev + 3453 test sentences"
2020-04-01 21:59:32,549 ----------------------------------------------------------------------------------------------------
2020-04-01 21:59:32,549 Parameters:
2020-04-01 21:59:32,550  - learning_rate: "0.01"
2020-04-01 21:59:32,550  - mini_batch_size: "32"
2020-04-01 21:59:32,550  - patience: "3"
2020-04-01 21:59:32,550  - anneal_factor: "0.5"
2020-04-01 21:59:32,550  - max_epochs: "150"
2020-04-01 21:59:32,550  - shuffle: "True"
2020-04-01 21:59:32,550  - train_with_dev: "False"
2020-04-01 21:59:32,550  - batch_growth_annealing: "False"
2020-04-01 21:59:32,550 ----------------------------------------------------------------------------------------------------
2020-04-01 21:59:32,550 Model training base path: "log/bert_20200401215932_64"
2020-04-01 21:59:32,550 ----------------------------------------------------------------------------------------------------
2020-04-01 21:59:32,550 Device: cuda:0
2020-04-01 21:59:32,550 ----------------------------------------------------------------------------------------------------
2020-04-01 21:59:32,551 Embeddings storage mode: cpu
2020-04-01 21:59:32,554 ----------------------------------------------------------------------------------------------------
2020-04-01 21:59:39,951 epoch 10 - iter 344/439 - loss 1.35328612 - samples/sec: 145.02
2020-04-01 21:59:42,347 epoch 17 - iter 220/220 - loss 1.41120465 - samples/sec: 324.07
2020-04-01 21:59:45,454 epoch 1 - iter 43/439 - loss 14.81685906 - samples/sec: 106.71
2020-04-01 21:59:47,639 epoch 1 - iter 129/439 - loss 12.09737765 - samples/sec: 84.15
2020-04-01 21:59:51,119 epoch 10 - iter 258/439 - loss 1.32563704 - samples/sec: 164.40
-----------------------------------
2020-04-01 21:59:48,844 EPOCH 17 done: loss 1.4112 - lr 0.0100
2020-04-01 21:59:52,770 DEV : loss 0.8678370118141174 - score 0.9061
2020-04-01 21:59:52,867 BAD EPOCHS (no improvement): 0
2020-04-01 21:59:54,169 ----------------------------------------------------------------------------------------------------
2020-04-01 21:59:55,550 epoch 10 - iter 387/439 - loss 1.35914658 - samples/sec: 152.10
2020-04-01 21:59:58,942 epoch 18 - iter 22/220 - loss 1.45376080 - samples/sec: 295.29
2020-04-01 22:00:06,433 epoch 10 - iter 301/439 - loss 1.30420611 - samples/sec: 154.24
2020-04-01 22:00:11,155 epoch 10 - iter 430/439 - loss 1.36304460 - samples/sec: 150.80
2020-04-01 22:00:10,653 epoch 18 - iter 44/220 - loss 1.44350730 - samples/sec: 285.88
2020-04-01 22:00:22,152 epoch 18 - iter 66/220 - loss 1.41003594 - samples/sec: 295.31
------------------------------------
2020-04-01 22:00:19,768 EPOCH 10 done: loss 1.3630 - lr 0.0100
2020-04-01 22:00:21,178 epoch 10 - iter 344/439 - loss 1.31115504 - samples/sec: 156.50
2020-04-01 22:00:24,928 DEV : loss 0.9043971300125122 - score 0.9004
2020-04-01 22:00:25,022 BAD EPOCHS (no improvement): 0
2020-04-01 22:00:26,328 ----------------------------------------------------------------------------------------------------
2020-04-01 22:00:33,466 epoch 18 - iter 88/220 - loss 1.40026486 - samples/sec: 343.85
2020-04-01 22:00:45,383 epoch 18 - iter 110/220 - loss 1.40697594 - samples/sec: 330.47
2020-04-01 22:00:37,925 epoch 10 - iter 387/439 - loss 1.31668852 - samples/sec: 151.11
^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B^[[B2020-04-01 22:00:52,381 epoch 11 - iter 86/439 - loss 1.34986869 - samples/sec: 152.08
2020-04-01 22:00:55,135 epoch 18 - iter 132/220 - loss 1.40172650 - samples/sec: 418.11
2020-04-01 22:00:54,295 epoch 10 - iter 430/439 - loss 1.32239571 - samples/sec: 157.44
2020-04-01 22:01:02,053 ----------------------------------------------------------------------------------------------------
2020-04-01 22:01:02,054 EPOCH 10 done: loss 1.3243 - lr 0.0100
2020-04-01 22:01:06,467 DEV : loss 0.9548019170761108 - score 0.8957
2020-04-01 22:01:06,564 BAD EPOCHS (no improvement): 1
2020-04-01 22:01:06,591 ----------------------------------------------------------------------------------------------------
2020-04-01 22:01:06,470 epoch 11 - iter 129/439 - loss 1.34918560 - samples/sec: 166.66
2020-04-01 22:01:14,165 epoch 18 - iter 176/220 - loss 1.37682163 - samples/sec: 392.89
2020-04-01 22:01:15,334 epoch 11 - iter 43/439 - loss 1.20262373 - samples/sec: 157.47
2020-04-01 22:01:21,210 epoch 11 - iter 172/439 - loss 1.36571110 - samples/sec: 152.90
2020-04-01 22:01:23,085 epoch 18 - iter 198/220 - loss 1.37373448 - samples/sec: 455.11
2020-04-01 22:01:30,162 epoch 11 - iter 86/439 - loss 1.29032152 - samples/sec: 152.08

2020-04-01 22:01:37,895 -----------------------------------------------------------------2020-04-01 22:01:44,809 epoch 11 - iter 129/439 - loss 1.30730593 - samples/sec: 159.23
 lr 0.0100
2020-04-01 22:01:41,709 DEV : loss 0.8458755612373352 - score 0.9092
2020-04-01 22:01:41,809 BAD EPOCHS (no improvement): 0
2020-04-01 22:01:43,012 ----------------------------------------------------------------------------------------------------
2020-04-01 22:01:46,062 epoch 19 - iter 22/220 - loss 1.41248542 - samples/sec: 461.95
2020-04-01 22:01:42,758 epoch 1 - iter 86/439 - loss 11.46792178 - samples/sec: 100.76
2020-04-01 22:01:53,221 epoch 11 - iter 258/439 - loss 1.35376990 - samples/sec: 140.12
2020-04-01 22:01:47,435 epoch 1 - iter 172/439 - loss 10.61539973 - samples/sec: 85.81
2020-04-01 22:01:52,554 Reading data from data
2020-04-01 22:01:52,554 Train: data/train.txt
2020-04-01 22:01:52,554 Dev: data/valid.txt
2020-04-01 22:01:52,554 Test: data/test.txt
Corpus: 14041 train + 3250 dev + 3453 test sentences
Dictionary with 12 tags: <unk>, O, B-ORG, B-MISC, B-PER, I-PER, B-LOC, I-ORG, I-MISC, I-LOC, <START>, <STOP>
2020-04-01 22:02:01,086 epoch 1 - iter 430/439 - loss 4.47602986 - samples/sec: 18.10
2020-04-01 22:01:59,057 epoch 11 - iter 172/439 - loss 1.27550333 - samples/sec: 157.41
2020-04-01 22:02:05,102 epoch 19 - iter 66/220 - loss 1.38562889 - samples/sec: 369.02
2020-04-01 22:02:15,949 epoch 19 - iter 88/220 - loss 1.38791063 - samples/sec: 336.59

2020-04-01 22:02:13,748 epoch 11 - iter 215/439 - loss 1.26943312 - samples/sec: 153.12
2020-04-01 22:02:25,780 epoch 19 - iter 110/220 - loss 1.36841407 - samples/sec: 364.42
2020-04-01 22:02:36,982 epoch 19 - iter 132/220 - loss 1.36382490 - samples/sec: 339.91
2020-04-01 22:02:33,222 ----------------------------------------------------------------------------------------------------
2020-04-01 22:02:33,223 EPOCH 2 done: loss 2.4282 - lr 0.0100
2020-04-01 22:02:39,538 epoch 11 - iter 387/439 - loss 1.33352792 - samples/sec: 152.59
2020-04-01 22:02:47,335 epoch 19 - iter 154/220 - loss 1.35792208 - samples/sec: 334.73
2020-04-01 22:02:47,650 DEV : loss 1.5189762115478516 - score 0.8511
2020-04-01 22:02:48,052 BAD EPOCHS (no improvement): 0
2020-04-01 22:02:58,164 epoch 19 - iter 176/220 - loss 1.34618039 - samples/sec: 306.98
2020-04-01 22:03:02,297 ----------------------------------------------------------------------------------------------------
2020-04-01 22:03:02,298 EPOCH 11 done: loss 1.3169 - lr 0.0100
2020-04-01 22:02:58,560 epoch 11 - iter 344/439 - loss 1.26867280 - samples/sec: 151.05
2020-04-01 22:03:09,081 epoch 19 - iter 198/220 - loss 1.34763021 - samples/sec: 335.29
,837 BAD EPOCHS (no improvement): 0
2020-04-01 22:03:13,855 epoch 11 - iter 387/439 - loss 1.26989604 - samples/sec: 160.96
2020-04-01 22:03:25,635 ----------------------------------------------------------------------------------------------------
2020-04-01 22:03:34,706 epoch 12 - iter 43/439 - loss 1.28271191 - samples/sec: 151.78
2020-04-01 22:03:27,847 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-01 22:03:38,330 epoch 19 - iter 220/220 - loss 1.34726993 - samples/sec: 324.59
2020-04-01 22:03:44,853 ----------------------------------------------------------------------------------------------------
2020-04-01 22:03:44,853 EPOCH 19 done: loss 1.3473 - lr 0.0100
2020-04-01 22:03:42,338 epoch 11 - iter 430/439 - loss 1.28490451 - samples/sec: 163.70
2020-04-01 22:03:39,214 epoch 3 - iter 22/220 - loss 2.11951895 - samples/sec: 123.99
2020-04-01 22:03:48,795 DEV : loss 0.8364024758338928 - score 0.91
2020-04-01 22:03:48,894 BAD EPOCHS (no improvement): 0
2020-04-01 22:03:50,197 ----------------------------------------------------------------------------------------------------
2020-04-01 22:03:54,713 epoch 20 - iter 22/220 - loss 1.32854799 - samples/sec: 312.08
      (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3072, out_features=3072, bias=True)
  (rnn): LSTM(3072, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=12, bias=True)
), SequenceTagger(
  (embeddings): ELMoEmbeddings(model=elmo-small)
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=768, out_features=768, bias=True)
  (rnn): LSTM(768, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=12, bias=True)
)]"
2020-04-01 22:03:48,083 ----------------------------------------------------------------------------------------------------
2020-04-01 22:03:48,083 Corpus: "Corpus: 14041 train + 3250 dev + 3453 test sentences"
2020-04-01 22:03:48,083 ----------------------------------------------------------------------------------------------------
2020-04-01 22:03:48,083 Parameters:
2020-04-01 22:03:48,083  - learning_rate: "0.01"
2020-04-01 22:03:48,083  - mini_batch_size: "32"
2020-04-01 22:03:48,083  - patience: "3"
2020-04-01 22:03:48,083  - anneal_factor: "0.5"
2020-04-01 22:03:48,083  - max_epochs: "150"
2020-04-01 22:03:48,083  - shuffle: "True"
2020-04-01 22:03:48,083  - train_with_dev: "False"
2020-04-01 22:03:48,083  - batch_growth_annealing: "False"
2020-04-01 22:03:48,083 ----------------------------------------------------------------------------------------------------
2020-04-01 22:03:48,083 Model training base path: "log/avg_loss_20200401220348"
2020-04-01 22:03:48,083 ----------------------------------------------------------------------------------------------------
2020-04-01 22:03:48,083 Device: cuda:0
2020-04-01 22:03:48,084 ----------------------------------------------------------------------------------------------------
2020-04-01 22:03:48,084 Embeddings storage mode: cpu
2020-04-01 22:03:48,086 ----------------------------------------------------------------------------------------------------
2020-04-01 22:03:49,890 ----------------------------------------------------------------------------------------------------
2020-04-01 22:03:49,890 EPOCH 11 done: loss 1.2813 - lr 0.0100
2020-04-01 22:03:54,410 DEV : loss 0.8968967199325562 - score 0.9043
2020-04-01 22:03:54,509 BAD EPOCHS (no improvement): 0
2020-04-01 22:04:01,674 epoch 1 - iter 215/439 - loss 9.62748516 - samples/sec: 123.59
2020-04-01 22:03:56,131 ----------------------------------------------------------------------------------------------------
2020-04-01 22:04:04,192 epoch 12 - iter 43/439 - loss 1.16936068 - samples/sec: 170.82
2020-04-01 22:04:11,922 epoch 1 - iter 43/439 - loss 22.17318967 - samples/sec: 57.74
2020-04-01 22:04:06,314 epoch 20 - iter 44/220 - loss 1.33258898 - samples/sec: 307.43
2020-04-01 22:04:07,326 epoch 12 - iter 129/439 - loss 1.26510887 - samples/sec: 149.24
2020-04-01 22:04:18,290 epoch 20 - iter 66/220 - loss 1.29859365 - samples/sec: 299.05

2020-04-01 22:04:19,779 epoch 12 - iter 86/439 - loss 1.20577435 - samples/sec: 154.57
2020-04-01 22:04:35,400 epoch 12 - iter 129/439 - loss 1.26276145 - samples/sec: 164.29
2020-04-01 22:04:40,927 epoch 20 - iter 110/220 - loss 1.29933875 - samples/sec: 307.33
2020-04-01 22:04:52,208 epoch 20 - iter 132/220 - loss 1.31785583 - samples/sec: 373.13
2020-04-01 22:04:50,665 epoch 12 - iter 172/439 - loss 1.25982245 - samples/sec: 165.86
2020-04-01 22:05:03,728 epoch 20 - iter 154/220 - loss 1.32697849 - samples/sec: 443.98
2020-04-01 22:05:14,369 epoch 20 - iter 176/220 - loss 1.32892170 - samples/sec: 428.89
2020-04-01 22:05:07,843 epoch 12 - iter 215/439 - loss 1.26650553 - samples/sec: 150.44
2020-04-01 22:05:24,104 epoch 12 - iter 258/439 - loss 1.24539898 - samples/sec: 149.44
2020-04-01 22:05:35,418 epoch 20 - iter 220/220 - loss 1.32874308 - samples/sec: 425.90
2020-04-01 22:05:42,326 ----------------------------------------------------------------------------------------------------
2020-04-01 22:05:42,326 EPOCH 20 done: loss 1.3287 - lr 0.0100
2020-04-01 22:05:46,233 DEV : loss 0.8259894847869873 - score 0.9113
2020-04-01 22:05:46,331 BAD EPOCHS (no improvement): 0
2020-04-01 22:05:47,990 ----------------------------------------------------------------------------------------------------
2020-04-01 22:05:51,994 epoch 21 - iter 22/220 - loss 1.22412772 - samples/sec: 351.93
2020-04-01 22:06:03,438 epoch 21 - iter 44/220 - loss 1.27588359 - samples/sec: 302.29
2020-04-01 22:06:01,924 epoch 12 - iter 430/439 - loss 1.27054861 - samples/sec: 144.61
Traceback (most recent call last):
  File "train.py", line 132, in <module>
    max_epochs=150)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/trainers/trainer.py", line 331, in train
    loss = self.model.forward_loss(batch_step)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/models/sequence_tagger_model.py", line 493, in forward_loss
    features = self.forward(data_points)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/models/sequence_tagger_model.py", line 498, in forward
    self.embeddings.embed(sentences)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/embeddings.py", line 96, in embed
    self._add_embeddings_internal(sentences)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/embeddings.py", line 2338, in _add_embeddings_internal
    all_encoder_layers = self.model(all_input_ids, attention_mask=all_input_masks)[
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/transformers/modeling_bert.py", line 790, in forward
    encoder_attention_mask=encoder_extended_attention_mask,
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/transformers/modeling_bert.py", line 407, in forward
    hidden_states, attention_mask, head_mask[i], encoder_hidden_states, encoder_attention_mask
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/transformers/modeling_bert.py", line 368, in forward
    self_attention_outputs = self.attention(hidden_states, attention_mask, head_mask)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/transformers/modeling_bert.py", line 314, in forward
    hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/transformers/modeling_bert.py", line 251, in forward
    context_layer = torch.matmul(attention_probs, value_layer)
RuntimeError: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 10.73 GiB total capacity; 3.89 GiB already allocated; 9.25 MiB free; 4.27 GiB reserved in total by PyTorch)
2020-04-01 22:06:14,919 epoch 21 - iter 66/220 - loss 1.28301949 - samples/sec: 295.01
------------------------------------
2020-04-01 22:06:10,249 EPOCH 12 done: loss 1.2688 - lr 0.0100
2020-04-01 22:06:14,580 DEV : loss 0.8280799388885498 - score 0.9087
2020-04-01 22:06:14,674 BAD EPOCHS (no improvement): 0
2020-04-01 22:06:16,023 ----------------------------------------------------------------------------------------------------
2020-04-01 22:06:10,362 epoch 12 - iter 387/439 - loss 1.24165886 - samples/sec: 158.64
2020-04-01 22:06:26,280 epoch 21 - iter 88/220 - loss 1.27390667 - samples/sec: 285.73
2020-04-01 22:06:26,116 epoch 12 - iter 430/439 - loss 1.24118202 - samples/sec: 161.17
2020-04-01 22:06:34,641 ---------------------------------------------------------------2020-04-01 22:06:37,084 epoch 21 - iter 110/220 - loss 1.26384816 - samples/sec: 345.72
 - lr 0.0100
2020-04-01 22:06:40,145 epoch 13 - iter 86/439 - loss 1.25045732 - samples/sec: 160.24
2020-04-01 22:06:39,113 DEV : loss 0.8902693390846252 - score 0.9085
2020-04-01 22:06:39,212 BAD EPOCHS (no improvement): 0
2020-04-01 22:06:40,853 ----------------------------------------------------------------------------------------------------
2020-04-01 22:06:48,237 epoch 21 - iter 132/220 - loss 1.26918249 - samples/sec: 321.34
2020-04-01 22:06:49,861 epoch 13 - iter 43/439 - loss 1.16249217 - samples/sec: 152.84
2020-04-01 22:06:58,523 epoch 21 - iter 154/220 - loss 1.26891523 - samples/sec: 343.67
2020-04-01 22:07:09,531 epoch 21 - iter 176/220 - loss 1.27074471 - samples/sec: 344.50
2020-04-01 22:07:21,888 epoch 21 - iter 198/220 - loss 1.25922752 - samples/sec: 322.43
2020-04-01 22:07:32,906 epoch 21 - iter 220/220 - loss 1.25825909 - samples/sec: 351.30
2020-04-01 22:07:36,172 epoch 13 - iter 172/439 - loss 1.17193190 - samples/sec: 153.25
2020-04-01 22:07:38,067 ----------------------------------------------------------------------------------------------------
2020-04-01 22:07:38,068 EPOCH 21 done: loss 1.2583 - lr 0.0100
2020-04-01 22:07:42,062 DEV : loss 0.812343955039978 - score 0.9143
2020-04-01 22:07:42,160 BAD EPOCHS (no improvement): 0
2020-04-01 22:07:43,429 ----------------------------------------------------------------------------------------------------
2020-04-01 22:07:47,274 epoch 22 - iter 22/220 - loss 1.27476255 - samples/sec: 366.54
2020-04-01 22:07:56,420 epoch 22 - iter 44/220 - loss 1.24710869 - samples/sec: 453.49

2020-04-01 22:07:58,110 epoch 13 - iter 301/439 - loss 1.24027689 - samples/sec: 151.87
-----------------------------------
2020-04-01 22:07:59,901 EPOCH 1 done: loss 4.4270 - lr 0.0100
2020-04-01 22:08:05,983 epoch 22 - iter 66/220 - loss 1.27148385 - samples/sec: 408.47

2020-04-01 22:08:15,070 epoch 22 - iter 88/220 - loss 1.24761965 - samples/sec: 421.93

2020-04-01 22:08:24,614 epoch 22 - iter 110/220 - loss 1.25153497 - samples/sec: 428.12
2020-04-01 22:08:32,926 epoch 22 - iter 132/220 - loss 1.26156333 - samples/sec: 448.39
2020-04-01 22:08:34,378 epoch 13 - iter 344/439 - loss 1.17631838 - samples/sec: 150.26
2020-04-01 22:08:41,987 epoch 22 - iter 154/220 - loss 1.26346595 - samples/sec: 457.84
020-04-01 22:08:44,193 epoch 13 - iter 430/439 - loss 1.22756716 - samples/sec: 152.42
2020-04-01 22:08:52,376 ----------------------------------------------------------------------------------------------------
2020-04-01 22:08:52,376 EPOCH 13 done: loss 1.2197 - lr 0.0100
2020-04-01 22:08:56,769 DEV : loss 0.8093656301498413 - score 0.9124
2020-04-01 22:08:56,862 BAD EPOCHS (no improvement): 0
2020-04-01 22:08:49,369 epoch 13 - iter 387/439 - loss 1.18982808 - samples/sec: 153.86
2020-04-01 22:08:51,391 epoch 22 - iter 176/220 - loss 1.25598037 - samples/sec: 439.72
2020-04-01 22:09:00,345 epoch 22 - iter 198/220 - loss 1.25653279 - samples/sec: 463.54
-----------------------------------
2020-04-01 22:09:07,292 epoch 14 - iter 43/439 - loss 1.29339910 - samples/sec: 150.63
2020-04-01 22:09:03,821 epoch 13 - iter 430/439 - loss 1.19220143 - samples/sec: 159.95
2020-04-01 22:09:09,253 epoch 22 - iter 220/220 - loss 1.25261335 - samples/sec: 424.62
2020-04-01 22:09:15,701 ----------------------------------------------------------------------------------------------------
2020-04-01 22:09:15,701 EPOCH 22 done: loss 1.2526 - lr 0.0100
,153 BAD EPOCHS (no improvement): 1
2020-04-01 22:09:16,225 ----------------------------------------------------------------------------------------------------
2020-04-01 22:09:19,518 DEV : loss 0.7809383273124695 - score 0.915
2020-04-01 22:09:192020-04-01 22:09:25,314 epoch 14 - iter 43/439 - loss 1.22928443 - samples/sec: 151.45
-------------------------------------------------------------------------
2020-04-01 22:09:24,499 epoch 23 - iter 22/220 - loss 1.23705516 - samples/sec: 389.13
2020-04-01 22:09:34,086 epoch 23 - iter 44/220 - loss 1.22405094 - samples/sec: 469.21

2020-04-01 22:09:43,698 epoch 23 - iter 66/220 - loss 1.22381181 - samples/sec: 466.26
2020-04-01 22:09:52,563 epoch 23 - iter 88/220 - loss 1.24486364 - samples/sec: 476.95
2020-04-01 22:09:53,266 epoch 14 - iter 172/439 - loss 1.21238441 - samples/sec: 154.18
2020-04-01 22:09:56,269 epoch 14 - iter 129/439 - loss 1.20954016 - samples/sec: 149.85
2020-04-01 22:10:03,662 epoch 23 - iter 110/220 - loss 1.22648735 - samples/sec: 406.50
2020-04-01 22:10:13,001 epoch 23 - iter 132/220 - loss 1.22276646 - samples/sec: 472.96
2020-04-01 22:10:12,495 epoch 14 - iter 172/439 - loss 1.15168946 - samples/sec: 152.14
2020-04-01 22:10:24,092 epoch 23 - iter 154/220 - loss 1.23097563 - samples/sec: 460.98
2020-04-01 22:10:29,653 epoch 14 - iter 215/439 - loss 1.14022610 - samples/sec: 152.67
2020-04-01 22:10:32,602 epoch 23 - iter 176/220 - loss 1.21932058 - samples/sec: 391.33
2020-04-01 22:10:44,384 epoch 1 - iter 172/439 - loss 11.40918848 - samples/sec: 58.42
2020-04-01 22:10:42,438 epoch 14 - iter 301/439 - loss 1.17793888 - samples/sec: 151.42
2020-04-01 22:10:44,440 epoch 14 - iter 258/439 - loss 1.14783317 - samples/sec: 154.12
2020-04-01 22:10:41,708 epoch 23 - iter 198/220 - loss 1.22298828 - samples/sec: 450.24
2020-04-01 22:10:46,900 DEV : loss 1.4441591501235962 - score 0.8476
2020-04-01 22:10:47,325 BAD EPOCHS (no improvement): 0
2020-04-01 22:10:50,646 epoch 23 - iter 220/220 - loss 1.21992702 - samples/sec: 479.41
2020-04-01 22:10:59,497 epoch 14 - iter 301/439 - loss 1.16092566 - samples/sec: 154.82
2020-04-01 22:11:12,290 epoch 14 - iter 387/439 - loss 1.18273397 - samples/sec: 151.20
2020-04-01 22:11:14,357 epoch 14 - iter 344/439 - loss 1.16927582 - samples/sec: 153.21
2020-04-01 22:11:44,009 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-01 22:11:44,953 ----------------------------------------------------------------------------------------------------
2020-04-01 22:11:44,953 EPOCH 23 done: loss 1.2199 - lr 0.0100
2020-04-01 22:11:48,829 DEV : loss 0.7689538598060608 - score 0.9154
2020-04-01 22:11:48,929 BAD EPOCHS (no improvement): 0
2020-04-01 22:11:50,110 ----------------------------------------------------------------------------------------------------
2020-04-01 22:11:53,242 epoch 24 - iter 22/220 - loss 1.10904266 - samples/sec: 449.86
2020-04-01 22:12:02,241 epoch 24 - iter 44/220 - loss 1.08069569 - samples/sec: 401.82
,568 BAD EPOCHS (no improvement): 0
2020-04-01 22:11:59,955 ----------------------------------------------------------------------------------------------------
2020-04-01 22:12:00,733 epoch 14 - iter 430/439 - loss 1.16840018 - samples/sec: 159.56
2020-04-01 22:11:58,908 epoch 2 - iter 43/439 - loss 2.12921738 - samples/sec: 92.77
2020-04-01 22:12:11,804 epoch 24 - iter 66/220 - loss 1.14096270 - samples/sec: 412.49
2020-04-01 22:12:08,852 ----------------------------------------------------------------------------------------------------
2020-04-01 22:12:08,853 EPOCH 14 done: loss 1.1672 - lr 0.0100
2020-04-01 22:12:13,323 DEV : loss 0.8250696063041687 - score 0.9136
2020-04-01 22:12:13,423 BAD EPOCHS (no improvement): 0
2020-04-01 22:12:15,231 ----------------------------------------------------------------------------------------------------
2020-04-01 22:12:24,377 epoch 15 - iter 43/439 - loss 1.13792732 - samples/sec: 150.53
2020-04-01 22:12:33,122 epoch 24 - iter 110/220 - loss 1.19225733 - samples/sec: 408.86
2020-04-01 22:12:42,275 epoch 24 - iter 132/220 - loss 1.19230420 - samples/sec: 441.45
2020-04-01 22:12:40,676 epoch 15 - iter 86/439 - loss 1.15322869 - samples/sec: 153.49
2020-04-01 22:12:53,111 epoch 24 - iter 154/220 - loss 1.19651050 - samples/sec: 394.01
2020-04-01 22:13:02,260 epoch 24 - iter 176/220 - loss 1.19697503 - samples/sec: 389.15
2020-04-01 22:12:57,081 epoch 15 - iter 129/439 - loss 1.16518495 - samples/sec: 152.05
2020-04-01 22:13:13,535 epoch 15 - iter 215/439 - loss 1.17024789 - samples/sec: 151.17
2020-04-01 22:13:12,353 epoch 15 - iter 172/439 - loss 1.15201410 - samples/sec: 151.45
2020-04-01 22:13:20,997 epoch 1 - iter 215/439 - loss 10.31587092 - samples/sec: 55.65
2020-04-01 22:13:21,785 epoch 24 - iter 220/220 - loss 1.20325836 - samples/sec: 382.85
2020-04-01 22:13:27,203 -----------------------------------------------------------------2020-04-01 22:13:27,288 epoch 15 - iter 215/439 - loss 1.14100332 - samples/sec: 153.06
 lr 0.0100
2020-04-01 22:13:31,148 DEV : loss 0.762737512588501 - score 0.9168
2020-04-01 22:13:31,245 BAD EPOCHS (no improvement): 0
2020-04-01 22:13:33,025 ----------------------------------------------------------------------------------------------------
2020-04-01 22:13:43,910 epoch 15 - iter 301/439 - loss 1.15890733 - samples/sec: 150.17
2020-04-01 22:13:37,161 epoch 25 - iter 22/220 - loss 1.19434727 - samples/sec: 340.80
2020-04-01 22:13:42,983 epoch 15 - iter 258/439 - loss 1.14835432 - samples/sec: 153.22
2020-04-01 22:14:08,130 epoch 25 - iter 44/220 - loss 1.20751318 - samples/sec: 387.30
22020-04-01 22:14:16,012 epoch 15 - iter 301/439 - loss 1.12702598 - samples/sec: 149.65
2020-04-01 22:14:21,673 epoch 1 - iter 344/439 - loss 6.53348168 - samples/sec: 111.32
2020-04-01 22:14:32,770 epoch 15 - iter 387/439 - loss 1.14949538 - samples/sec: 153.32
2020-04-01 22:14:29,545 epoch 25 - iter 88/220 - loss 1.20017768 - samples/sec: 352.28
2020-04-01 22:14:32,881 epoch 15 - iter 344/439 - loss 1.12972506 - samples/sec: 150.76
2020-04-01 22:14:40,082 epoch 25 - iter 110/220 - loss 1.19943495 - samples/sec: 359.28
2020-04-01 22:14:50,246 epoch 15 - iter 430/439 - loss 1.14769553 - samples/sec: 148.53
2020-04-01 22:14:50,137 epoch 15 - iter 387/439 - loss 1.13331952 - samples/sec: 153.91
2020-04-01 22:15:03,364 epoch 25 - iter 154/220 - loss 1.18852445 - samples/sec: 314.58
-----------------------------------
2020-04-01 22:15:00,237 EPOCH 15 done: loss 1.1462 - lr 0.0100
2020-04-01 22:15:04,691 DEV : loss 0.7799997329711914 - score 0.9131
2020-04-01 22:15:04,789 BAD EPOCHS (no improvement): 0
2020-04-01 22:15:06,155 ----------------------------------------------------------------------------------------------------
2020-04-01 22:15:06,687 epoch 15 - iter 430/439 - loss 1.12610346 - samples/sec: 159.34
2020-04-01 22:15:15,065 epoch 16 - iter 43/439 - loss 1.03281531 - samples/sec: 154.52

2020-04-01 22:15:14,909 ----------------------------------------------------------------------------------------------------
2020-04-01 22:15:14,909 EPOCH 15 done: loss 1.1253 - lr 0.0100
2020-04-01 22:15:26,330 epoch 25 - iter 198/220 - loss 1.17661392 - samples/sec: 310.16
2020-04-01 22:15:19,366 DEV : loss 0.7981631755828857 - score 0.9138
2020-04-01 22:15:19,465 BAD EPOCHS (no improvement): 0
2020-04-01 22:15:21,173 ----------------------------------------------------------------------------------------------------
2020-04-01 22:15:37,067 epoch 25 - iter 220/220 - loss 1.18250806 - samples/sec: 323.58
2020-04-01 22:15:30,167 epoch 16 - iter 43/439 - loss 1.12934425 - samples/sec: 153.08
2020-04-01 22:15:43,903 -----------------------------------------------------------------2020-04-01 22:15:45,512 epoch 16 - iter 86/439 - loss 1.10836682 - samples/sec: 151.81
- lr 0.0100
2020-04-01 22:15:47,830 DEV : loss 0.7382555603981018 - score 0.9191
2020-04-01 22:15:47,926 BAD EPOCHS (no improvement): 0
2020-04-01 22:15:49,219 ----------------------------------------------------------------------------------------------------
2020-04-01 22:15:53,457 epoch 26 - iter 22/220 - loss 1.14281265 - samples/sec: 332.61
2020-04-01 22:16:03,326 epoch 26 - iter 44/220 - loss 1.17764898 - samples/sec: 360.91

2020-04-01 22:16:00,587 epoch 16 - iter 129/439 - loss 1.06566873 - samples/sec: 154.07
2020-04-01 22:16:16,288 epoch 26 - iter 66/220 - loss 1.18371614 - samples/sec: 291.87

2020-04-01 22:16:26,851 epoch 26 - iter 88/220 - loss 1.18887014 - samples/sec: 321.97
2020-04-01 22:16:20,199 epoch 16 - iter 215/439 - loss 1.08430852 - samples/sec: 147.53
2020-04-01 22:16:38,111 epoch 26 - iter 110/220 - loss 1.17754840 - samples/sec: 303.08
2020-04-01 22:16:32,644 epoch 16 - iter 215/439 - loss 1.08170477 - samples/sec: 152.67
2020-04-01 22:16:48,298 epoch 16 - iter 258/439 - loss 1.07399617 - samples/sec: 151.35
2020-04-01 22:16:48,926 epoch 26 - iter 132/220 - loss 1.16608381 - samples/sec: 326.50
2020-04-01 22:17:00,335 epoch 26 - iter 154/220 - loss 1.17133600 - samples/sec: 336.70
2020-04-01 22:17:04,401 epoch 16 - iter 301/439 - loss 1.08341312 - samples/sec: 155.31
2020-04-01 22:17:11,420 epoch 26 - iter 176/220 - loss 1.16430360 - samples/sec: 302.69
2020-04-01 22:17:22,933 epoch 26 - iter 198/220 - loss 1.16117039 - samples/sec: 299.91
2020-04-01 22:17:20,109 epoch 16 - iter 344/439 - loss 1.07319430 - samples/sec: 153.79
2020-04-01 22:17:34,902 epoch 26 - iter 220/220 - loss 1.16634524 - samples/sec: 310.38
2020-04-01 22:17:41,342 ----------------------------------------------------------------------------------------------------
2020-04-01 22:17:41,342 EPOCH 26 done: loss 1.1663 - lr 0.0100
2020-04-01 22:17:45,172 DEV : loss 0.728958010673523 - score 0.9196
2020-04-01 22:17:45,269 BAD EPOCHS (no improvement): 0
2020-04-01 22:17:46,504 ----------------------------------------------------------------------------------------------------
2020-04-01 22:17:53,468 epoch 2 - iter 86/439 - loss 2.04580265 - samples/sec: 90.94
2020-04-01 22:17:50,017 epoch 27 - iter 22/220 - loss 1.14123704 - samples/sec: 401.05
------------------------------------
2020-04-01 22:17:48,514 EPOCH 16 done: loss 1.1161 - lr 0.0100
2020-04-01 22:17:52,970 DEV : loss 0.7506149411201477 - score 0.9149
2020-04-01 22:17:53,066 BAD EPOCHS (no improvement): 0
2020-04-01 22:17:54,508 ----------------------------------------------------------------------------------------------------
2020-04-01 22:17:51,074 epoch 16 - iter 430/439 - loss 1.08088698 - samples/sec: 161.00
2020-04-01 22:18:00,524 epoch 27 - iter 44/220 - loss 1.16795203 - samples/sec: 322.69
020-04-01 22:18:03,535 epoch 17 - iter 43/439 - loss 1.03692387 - samples/sec: 152.52
2020-04-01 22:17:59,342 ----------------------------------------------------------------------------------------------------
2020-04-01 22:17:59,343 EPOCH 16 done: loss 1.0855 - lr 0.0100
2020-04-01 22:18:03,783 DEV : loss 0.7930755615234375 - score 0.9137
2020-04-01 22:18:03,879 BAD EPOCHS (no improvement): 1
2020-04-01 22:18:03,938 ----------------------------------------------------------------------------------------------------
2020-04-01 22:18:10,791 epoch 27 - iter 66/220 - loss 1.15185566 - samples/sec: 328.04
2020-04-01 22:18:21,104 epoch 27 - iter 88/220 - loss 1.17044806 - samples/sec: 332.55
2020-04-01 22:18:18,757 epoch 17 - iter 86/439 - loss 1.11092610 - samples/sec: 154.81
2020-04-01 22:18:27,979 epoch 17 - iter 86/439 - loss 1.08107637 - samples/sec: 150.65
2020-04-01 22:18:31,636 epoch 27 - iter 110/220 - loss 1.14942252 - samples/sec: 317.36
2020-04-01 22:18:42,353 epoch 17 - iter 129/439 - loss 1.05462194 - samples/sec: 160.53
2020-04-01 22:18:42,081 epoch 27 - iter 132/220 - loss 1.14550234 - samples/sec: 352.71
2020-04-01 22:18:49,848 epoch 17 - iter 172/439 - loss 1.06078192 - samples/sec: 151.87
2020-04-01 22:18:58,065 epoch 17 - iter 172/439 - loss 1.06079543 - samples/sec: 153.37
2020-04-01 22:18:52,961 epoch 27 - iter 154/220 - loss 1.13403872 - samples/sec: 338.57
2020-04-01 22:19:04,660 epoch 27 - iter 176/220 - loss 1.14038060 - samples/sec: 305.84
2020-04-01 22:19:15,864 epoch 27 - iter 198/220 - loss 1.13235979 - samples/sec: 429.82
2020-04-01 22:19:26,214 epoch 27 - iter 220/220 - loss 1.13792513 - samples/sec: 439.97
2020-04-01 22:19:33,736 ----------------------------------------------------------------------------------------------------
2020-04-01 22:19:33,736 EPOCH 27 done: loss 1.1379 - lr 0.0100
2020-04-01 22:19:37,638 DEV : loss 0.7447772026062012 - score 0.9187
2020-04-01 22:19:37,737 BAD EPOCHS (no improvement): 1
2020-04-01 22:19:37,761 ----------------------------------------------------------------------------------------------------
2020-04-01 22:19:40,684 epoch 28 - iter 22/220 - loss 1.15745943 - samples/sec: 481.94

2020-04-01 22:19:50,489 epoch 28 - iter 44/220 - loss 1.13081054 - samples/sec: 419.07
2020-04-01 22:19:53,868 epoch 17 - iter 344/439 - loss 1.07991062 - samples/sec: 153.45
2020-04-01 22:20:01,711 epoch 28 - iter 66/220 - loss 1.15043766 - samples/sec: 315.88

2020-04-01 22:20:11,899 epoch 28 - iter 88/220 - loss 1.18288908 - samples/sec: 344.57

-----------------------------------
2020-04-01 22:20:11,698 EPOCH 1 done: loss 5.9095 - lr 0.0100
2020-04-01 22:20:16,286 epoch 17 - iter 387/439 - loss 1.07470012 - samples/sec: 153.54
2020-04-01 22:20:21,810 epoch 28 - iter 110/220 - loss 1.15662593 - samples/sec: 323.40
20-04-01 22:20:26,977 DEV : loss 2.5116119384765625 - score 0.7575
2020-04-01 22:20:27,073 BAD EPOCHS (no improvement): 0
2020-04-01 22:20:24,337 epoch 17 - iter 430/439 - loss 1.08319063 - samples/sec: 154.18
2020-04-01 22:20:32,557 epoch 28 - iter 132/220 - loss 1.14379884 - samples/sec: 345.19
-----------------------------------
2020-04-01 22:20:33,081 EPOCH 17 done: loss 1.0813 - lr 0.0100
2020-04-01 22:20:37,526 DEV : loss 0.723701000213623 - score 0.9166
2020-04-01 22:20:37,622 BAD EPOCHS (no improvement): 0
2020-04-01 22:20:30,992 epoch 17 - iter 430/439 - loss 1.07027200 - samples/sec: 151.86
2020-04-01 22:20:48,484 epoch 28 - iter 154/220 - loss 1.14549419 - samples/sec: 315.55
20-04-01 22:20:39,043 ----------------------------------------------------------------------------------------------------
2020-04-01 22:20:47,725 epoch 18 - iter 43/439 - loss 0.95497301 - samples/sec: 158.57
2020-04-01 22:20:45,504 ----------------------------------------------------------------------------------------------------
2020-04-01 22:20:45,505 EPOCH 17 done: loss 1.0688 - lr 0.0100
2020-04-01 22:20:49,921 DEV : loss 0.7602602243423462 - score 0.9174
2020-04-01 22:20:50,018 BAD EPOCHS (no improvement): 0
2020-04-01 22:20:51,618 ----------------------------------------------------------------------------------------------------
2020-04-01 22:21:01,502 epoch 28 - iter 176/220 - loss 1.13519138 - samples/sec: 304.69
020-04-01 22:21:00,858 epoch 18 - iter 43/439 - loss 1.06285469 - samples/sec: 149.00
2020-04-01 22:21:14,949 epoch 28 - iter 198/220 - loss 1.12594235 - samples/sec: 295.13
2020-04-01 22:21:27,066 epoch 28 - iter 220/220 - loss 1.12774398 - samples/sec: 289.91
2020-04-01 22:21:37,976 epoch 18 - iter 172/439 - loss 1.03970711 - samples/sec: 151.32
2020-04-01 22:21:34,405 epoch 18 - iter 129/439 - loss 1.05191842 - samples/sec: 151.25
2020-04-01 22:21:33,857 ----------------------------------------------------------------------------------------------------
2020-04-01 22:21:33,858 EPOCH 28 done: loss 1.1277 - lr 0.0100
2020-04-01 22:21:37,781 DEV : loss 0.7154833674430847 - score 0.918
2020-04-01 22:21:37,878 BAD EPOCHS (no improvement): 2
2020-04-01 22:21:37,913 ----------------------------------------------------------------------------------------------------
2020-04-01 22:21:41,440 epoch 29 - iter 22/220 - loss 1.09705371 - samples/sec: 399.48
2020-04-01 22:21:54,022 epoch 18 - iter 215/439 - loss 1.03810794 - samples/sec: 150.25
2020-04-01 22:21:49,829 epoch 18 - iter 172/439 - loss 1.04169247 - samples/sec: 156.78
2020-04-01 22:21:53,006 epoch 29 - iter 44/220 - loss 1.10996347 - samples/sec: 338.16
2020-04-01 22:22:04,812 epoch 29 - iter 66/220 - loss 1.13369675 - samples/sec: 313.61

2020-04-01 22:22:15,801 epoch 29 - iter 88/220 - loss 1.14189773 - samples/sec: 319.92

2020-04-01 22:22:27,260 epoch 29 - iter 110/220 - loss 1.13832104 - samples/sec: 297.02
2020-04-01 22:22:21,911 epoch 18 - iter 258/439 - loss 1.04241772 - samples/sec: 152.64
2020-04-01 22:22:38,920 epoch 29 - iter 132/220 - loss 1.13458602 - samples/sec: 323.81
2020-04-01 22:22:49,943 epoch 29 - iter 154/220 - loss 1.13429068 - samples/sec: 311.89
20-04-01 22:22:44,021 epoch 2 - iter 86/439 - loss 3.29245018 - samples/sec: 187.65
2020-04-01 22:22:41,996 epoch 18 - iter 344/439 - loss 1.05389685 - samples/sec: 149.66
2020-04-01 22:23:00,008 epoch 29 - iter 176/220 - loss 1.12500238 - samples/sec: 479.79
2020-04-01 22:22:52,306 epoch 18 - iter 344/439 - loss 1.03402100 - samples/sec: 156.00
2020-04-01 22:23:09,726 epoch 29 - iter 198/220 - loss 1.10728306 - samples/sec: 438.06
2020-04-01 22:23:13,120 epoch 18 - iter 430/439 - loss 1.06311978 - samples/sec: 153.75
2020-04-01 22:23:20,348 epoch 29 - iter 220/220 - loss 1.10850884 - samples/sec: 421.08
2020-04-01 22:23:27,925 ----------------------------------------------------------------------------------------------------
2020-04-01 22:23:27,925 EPOCH 29 done: loss 1.1085 - lr 0.0100
,765 BAD EPOCHS (no improvement): 0
2020-04-01 22:23:27,197 ----------------------------------------------------------------------------------------------------
2020-04-01 22:23:24,190 epoch 18 - iter 430/439 - loss 1.03586582 - samples/sec: 152.89
2020-04-01 22:23:35,987 epoch 19 - iter 43/439 - loss 0.97021200 - samples/sec: 156.622020-04-01 22:23:31,749 DEV : loss 0.7203491926193237 - score 0.9213
2020-04-01 22:23:31,846 BAD EPOCHS (no improvement): 0
2020-04-01 22:23:33,091 ----------------------------------------------------------------------------------------------------
2020-04-01 22:23:36,762 epoch 30 - iter 22/220 - loss 1.08302976 - samples/sec: 383.98
2020-04-01 22:23:48,927 epoch 30 - iter 44/220 - loss 1.08047762 - samples/sec: 299.35
------------------------------------
2020-04-01 22:23:49,065 epoch 19 - iter 43/439 - loss 1.06536044 - samples/sec: 150.29
2020-04-01 22:23:50,444 epoch 3 - iter 132/220 - loss 1.98598351 - samples/sec: 113.67
2020-04-01 22:23:53,107 epoch 19 - iter 86/439 - loss 0.95865798 - samples/sec: 149.33
2020-04-01 22:24:01,931 epoch 30 - iter 66/220 - loss 1.09548627 - samples/sec: 318.59
2020-04-01 22:24:10,667 epoch 19 - iter 129/439 - loss 1.00799338 - samples/sec: 151.89
2020-04-01 22:24:14,474 epoch 30 - iter 88/220 - loss 1.08276680 - samples/sec: 316.89
2020-04-01 22:24:26,946 epoch 30 - iter 110/220 - loss 1.08179081 - samples/sec: 284.47
2020-04-01 22:24:23,169 epoch 19 - iter 129/439 - loss 1.04402065 - samples/sec: 152.19
2020-04-01 22:24:38,769 epoch 30 - iter 132/220 - loss 1.08170430 - samples/sec: 362.05
2020-04-01 22:24:50,519 epoch 30 - iter 154/220 - loss 1.09490540 - samples/sec: 292.80
020-04-01 22:24:43,816 epoch 19 - iter 215/439 - loss 0.99913699 - samples/sec: 151.81
2020-04-01 22:24:59,782 epoch 30 - iter 176/220 - loss 1.10020892 - samples/sec: 413.00
2020-04-01 22:24:55,174 epoch 19 - iter 215/439 - loss 1.04197480 - samples/sec: 150.69
2020-04-01 22:25:10,756 epoch 30 - iter 198/220 - loss 1.09984390 - samples/sec: 311.04
2020-04-01 22:25:14,704 epoch 19 - iter 301/439 - loss 1.01095544 - samples/sec: 151.75
2020-04-01 22:25:10,740 epoch 19 - iter 258/439 - loss 1.02451311 - samples/sec: 153.42
2020-04-01 22:25:23,088 epoch 30 - iter 220/220 - loss 1.09855406 - samples/sec: 331.46
2020-04-01 22:25:29,751 ----------------------------------------------------------------------------------------------------
2020-04-01 22:25:29,751 EPOCH 30 done: loss 1.0986 - lr 0.0100
2020-04-01 22:25:31,614 epoch 19 - iter 344/439 - loss 1.03086114 - samples/sec: 152.99
2020-04-01 22:25:33,693 DEV : loss 0.7148537039756775 - score 0.9209
2020-04-01 22:25:33,791 BAD EPOCHS (no improvement): 1
2020-04-01 22:25:33,844 ----------------------------------------------------------------------------------------------------
2020-04-01 22:25:37,730 epoch 31 - iter 22/220 - loss 1.08581254 - samples/sec: 362.61
2020-04-01 22:25:48,023 epoch 31 - iter 44/220 - loss 1.07129381 - samples/sec: 311.68

2020-04-01 22:25:43,376 epoch 19 - iter 344/439 - loss 1.00248984 - samples/sec: 152.46
2020-04-01 22:25:59,460 epoch 31 - iter 66/220 - loss 1.06353145 - samples/sec: 317.66

2020-04-01 22:26:10,243 epoch 31 - iter 88/220 - loss 1.06096945 - samples/sec: 316.02

2020-04-01 22:26:20,554 epoch 31 - iter 110/220 - loss 1.07504185 - samples/sec: 322.74
-----------------------------------
2020-04-01 22:26:11,584 EPOCH 19 done: loss 1.0309 - lr 0.0100
2020-04-01 22:26:16,053 DEV : loss 0.700398325920105 - score 0.9199
2020-04-01 22:26:16,149 BAD EPOCHS (no improvement): 0
2020-04-01 22:26:17,599 ----------------------------------------------------------------------------------------------------
2020-04-01 22:26:13,779 epoch 19 - iter 430/439 - loss 1.00498363 - samples/sec: 159.47
2020-04-01 22:26:26,544 epoch 20 - iter 43/439 - loss 1.14451951 - samples/sec: 153.91
2020-04-01 22:26:22,387 ----------------------------------------------------------------------------------------------------
2020-04-01 22:26:22,387 EPOCH 19 done: loss 1.0070 - lr 0.0100
2020-04-01 22:26:26,814 DEV : loss 0.7289733290672302 - score 0.9205
2020-04-01 22:26:26,909 BAD EPOCHS (no improvement): 0
2020-04-01 22:26:28,496 ----------------------------------------------------------------------------------------------------
2020-04-01 22:26:31,298 epoch 31 - iter 132/220 - loss 1.07003295 - samples/sec: 283.40
2020-04-01 22:26:41,755 epoch 31 - iter 154/220 - loss 1.07875810 - samples/sec: 303.16
2020-04-01 22:26:52,714 epoch 31 - iter 176/220 - loss 1.07929085 - samples/sec: 309.89
-----------------------------------
2020-04-01 22:26:50,387 EPOCH 1 done: loss 7.2311 - lr 0.0100
2020-04-01 22:26:52,769 epoch 20 - iter 86/439 - loss 0.93482424 - samples/sec: 154.08
2020-04-01 22:27:07,849 epoch 20 - iter 129/439 - loss 0.92745090 - samples/sec: 148.95
ent call last):
  File "bagging_train.py", line 63, in <module>
    max_epochs=150)
  File "/hdd2/qingpeng/code/mix_ner_flair/ensemble_trainer.py", line 426, in train
    embedding_storage_mode=embeddings_storage_mode,
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/models/sequence_tagger_model.py", line 412, in evaluate
    features = self.forward(batch)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/models/sequence_tagger_model.py", line 526, in forward
    self.embeddings.embedding_length,
RuntimeError: shape '[32, 41, 768]' is invalid for input of size 3142656
2020-04-01 22:27:03,072 epoch 31 - iter 198/220 - loss 1.06556765 - samples/sec: 310.24
2020-04-01 22:27:13,044 epoch 20 - iter 172/439 - loss 0.99383828 - samples/sec: 151.25
2020-04-01 22:27:14,059 epoch 31 - iter 220/220 - loss 1.06209479 - samples/sec: 269.74
2020-04-01 22:27:20,795 ----------------------------------------------------------------------------------------------------
2020-04-01 22:27:20,796 EPOCH 31 done: loss 1.0621 - lr 0.0100
2020-04-01 22:27:28,949 epoch 20 - iter 215/439 - loss 0.98975640 - samples/sec: 150.06
486 BAD EPOCHS (no improvement): 0
2020-04-01 22:27:26,801 ----------------------------------------------------------------------------------------------------
2020-04-01 22:27:31,342 epoch 32 - iter 22/220 - loss 1.04321940 - samples/sec: 310.31
2020-04-01 22:27:22,703 epoch 20 - iter 172/439 - loss 0.96502139 - samples/sec: 157.29
2020-04-01 22:27:38,189 epoch 20 - iter 215/439 - loss 0.97906363 - samples/sec: 153.18
2020-04-01 22:27:45,187 epoch 3 - iter 154/220 - loss 1.97281688 - samples/sec: 123.35
2020-04-01 22:27:44,488 epoch 20 - iter 258/439 - loss 0.99285302 - samples/sec: 151.90
2020-04-01 22:27:59,695 epoch 20 - iter 301/439 - loss 1.00421022 - samples/sec: 150.40
2020-04-01 22:27:52,989 epoch 20 - iter 258/439 - loss 0.97184248 - samples/sec: 151.84
2020-04-01 22:28:08,506 epoch 20 - iter 301/439 - loss 0.98756474 - samples/sec: 155.55
2020-04-01 22:28:15,272 epoch 20 - iter 344/439 - loss 1.01293292 - samples/sec: 155.70
2020-04-01 22:28:14,946 epoch 32 - iter 110/220 - loss 1.05666693 - samples/sec: 321.79
2020-04-01 22:28:25,717 epoch 32 - iter 132/220 - loss 1.06326907 - samples/sec: 304.03
2020-04-01 22:28:23,525 epoch 20 - iter 344/439 - loss 0.98948573 - samples/sec: 152.71
2020-04-01 22:28:38,373 epoch 20 - iter 387/439 - loss 0.99123881 - samples/sec: 151.32
020-04-01 22:28:35,752 epoch 32 - iter 154/220 - loss 1.05957161 - samples/sec: 339.48
2020-04-01 22:28:45,240 epoch 20 - iter 430/439 - loss 1.01127324 - samples/sec: 153.70
2020-04-01 22:28:46,398 epoch 32 - iter 176/220 - loss 1.06236655 - samples/sec: 291.75
2020-04-01 22:28:53,745 ----------------------------------------------------------------------------------------------------
2020-04-01 22:28:53,745 EPOCH 20 done: loss 1.0122 - lr 0.0100
2020-04-01 22:28:58,206 DEV : loss 0.6987057328224182 - score 0.92
2020-04-01 22:28:58,302 BAD EPOCHS (no improvement): 0
2020-04-01 22:28:59,733 ----------------------------------------------------------------------------------------------------
2020-04-01 22:28:53,847 epoch 20 - iter 430/439 - loss 0.99925692 - samples/sec: 151.18
2020-04-01 22:29:07,573 epoch 32 - iter 220/220 - loss 1.06139905 - samples/sec: 416.662020-04-01 22:29:03,309 ----------------------------------------------------------------------------------------------------
2020-04-01 22:29:03,310 EPOCH 20 done: loss 1.0033 - lr 0.0100
2020-04-01 22:29:08,436 DEV : loss 0.723555862903595 - score 0.9222
2020-04-01 22:29:08,535 BAD EPOCHS (no improvement): 0
2020-04-01 22:29:10,217 ----------------------------------------------------------------------------------------------------
2020-04-01 22:29:15,060 epoch 2 - iter 172/439 - loss 2.06010061 - samples/sec: 84.46
2020-04-01 22:29:18,958 epoch 21 - iter 43/439 - loss 0.93098529 - samples/sec: 157.51
------------------------------------
2020-04-01 22:29:14,507 EPOCH 32 done: loss 1.0614 - lr 0.0100
2020-04-01 22:29:18,388 DEV : loss 0.6845597624778748 - score 0.9244
2020-04-01 22:29:18,487 BAD EPOCHS (no improvement): 0
2020-04-01 22:29:19,697 ----------------------------------------------------------------------------------------------------
2020-04-01 22:29:24,447 epoch 33 - iter 22/220 - loss 1.03587099 - samples/sec: 296.71
2020-04-01 22:29:35,728 epoch 33 - iter 44/220 - loss 1.09540549 - samples/sec: 307.28

2020-04-01 22:29:34,717 epoch 21 - iter 86/439 - loss 0.91711094 - samples/sec: 151.98
2020-04-01 22:29:50,339 epoch 21 - iter 129/439 - loss 0.91889873 - samples/sec: 158.02
2020-04-01 22:29:47,231 epoch 33 - iter 66/220 - loss 1.11044694 - samples/sec: 310.50
2020-04-01 22:29:56,037 epoch 21 - iter 172/439 - loss 0.95284515 - samples/sec: 157.99
2020-04-01 22:29:56,926 epoch 33 - iter 88/220 - loss 1.08345733 - samples/sec: 339.05
2020-04-01 22:30:07,740 epoch 33 - iter 110/220 - loss 1.06651901 - samples/sec: 322.50
2020-04-01 22:30:05,781 epoch 21 - iter 172/439 - loss 0.93487866 - samples/sec: 155.46
2020-04-01 22:30:19,565 epoch 33 - iter 132/220 - loss 1.05885797 - samples/sec: 277.04
2020-04-01 22:30:30,131 epoch 33 - iter 154/220 - loss 1.05896042 - samples/sec: 324.07
020-04-01 22:30:26,114 epoch 21 - iter 258/439 - loss 0.96379958 - samples/sec: 157.54
2020-04-01 22:30:41,233 epoch 33 - iter 176/220 - loss 1.06188872 - samples/sec: 288.99
2020-04-01 22:30:36,297 epoch 21 - iter 258/439 - loss 0.96703849 - samples/sec: 167.68
2020-04-01 22:30:52,088 epoch 33 - iter 198/220 - loss 1.05525446 - samples/sec: 324.25
2020-04-01 22:30:57,004 epoch 21 - iter 344/439 - loss 0.97703245 - samples/sec: 150.06
2020-04-01 22:31:12,599 epoch 21 - iter 387/439 - loss 0.97611260 - samples/sec: 151.91
2020-04-01 22:31:08,516 epoch 21 - iter 344/439 - loss 0.97656828 - samples/sec: 148.78
2020-04-01 22:31:11,064 ----------------------------------------------------------------------------------------------------
2020-04-01 22:31:11,065 EPOCH 33 done: loss 1.0549 - lr 0.0100
2020-04-01 22:31:14,972 DEV : loss 0.6695409417152405 - score 0.9245
2020-04-01 22:31:15,071 BAD EPOCHS (no improvement): 0
2020-04-01 22:31:16,359 ----------------------------------------------------------------------------------------------------
2020-04-01 22:31:20,819 epoch 34 - iter 22/220 - loss 0.99926110 - samples/sec: 316.01
2020-04-01 22:31:31,565 epoch 34 - iter 44/220 - loss 1.03448697 - samples/sec: 363.38

2020-04-01 22:31:24,489 epoch 21 - iter 387/439 - loss 0.97675874 - samples/sec: 152.18
2020-04-01 22:31:41,817 epoch 34 - iter 66/220 - loss 1.03430758 - samples/sec: 345.31
2020-04-01 22:31:36,763 ----------------------------------------------------------------------------------------------------
2020-04-01 22:31:36,763 EPOCH 21 done: loss 0.9790 - lr 0.0100
2020-04-01 22:31:41,868 DEV : loss 0.6803356409072876 - score 0.9214
2020-04-01 22:31:41,965 BAD EPOCHS (no improvement): 0
2020-04-01 22:31:43,371 ----------------------------------------------------------------------------------------------------
2020-04-01 22:31:40,011 epoch 21 - iter 430/439 - loss 0.97575722 - samples/sec: 159.19
2020-04-01 22:31:53,246 epoch 34 - iter 88/220 - loss 1.04688312 - samples/sec: 332.55
2020-04-01 22:31:49,693 ----------------------------------------------------------------------------------------------------
2020-04-01 22:31:49,693 EPOCH 21 done: loss 0.9752 - lr 0.0100
2020-04-01 22:31:54,106 DEV : loss 0.7093740701675415 - score 0.9231
2020-04-01 22:31:54,201 BAD EPOCHS (no improvement): 0
2020-04-01 22:31:55,843 ----------------------------------------------------------------------------------------------------
2020-04-01 22:32:09,283 epoch 22 - iter 86/439 - loss 0.89078678 - samples/sec: 147.10
2020-04-01 22:32:04,961 epoch 22 - iter 43/439 - loss 0.94109108 - samples/sec: 151.01
2020-04-01 22:32:04,652 epoch 34 - iter 110/220 - loss 1.02829847 - samples/sec: 353.36
2020-04-01 22:32:15,544 epoch 34 - iter 132/220 - loss 1.03068711 - samples/sec: 309.26
2020-04-01 22:32:25,065 epoch 34 - iter 154/220 - loss 1.03406727 - samples/sec: 309.52
020-04-01 22:32:24,218 epoch 22 - iter 129/439 - loss 0.94303212 - samples/sec: 156.00
2020-04-01 22:32:35,840 epoch 34 - iter 176/220 - loss 1.03532866 - samples/sec: 312.31
2020-04-01 22:32:34,847 epoch 22 - iter 129/439 - loss 0.93221807 - samples/sec: 152.29
2020-04-01 22:32:47,153 epoch 34 - iter 198/220 - loss 1.02889185 - samples/sec: 301.70
2020-04-01 22:32:55,386 epoch 22 - iter 215/439 - loss 0.96223873 - samples/sec: 150.08
2020-04-01 22:32:58,207 epoch 34 - iter 220/220 - loss 1.02906070 - samples/sec: 281.27
2020-04-01 22:33:04,605 ----------------------------------------------------------------------------------------------------
2020-04-01 22:33:04,605 EPOCH 34 done: loss 1.0291 - lr 0.0100
2020-04-01 22:33:08,547 DEV : loss 0.675734281539917 - score 0.9242
2020-04-01 22:33:08,645 BAD EPOCHS (no improvement): 1
2020-04-01 22:33:08,652 ----------------------------------------------------------------------------------------------------
2020-04-01 22:33:12,210 epoch 35 - iter 22/220 - loss 1.07348208 - samples/sec: 396.04
2020-04-01 22:33:22,189 epoch 35 - iter 44/220 - loss 1.08716050 - samples/sec: 339.57

2020-04-01 22:33:33,147 epoch 35 - iter 66/220 - loss 1.06031402 - samples/sec: 324.33

2020-04-01 22:33:43,793 epoch 35 - iter 88/220 - loss 1.05161887 - samples/sec: 338.64

2020-04-01 22:33:37,386 epoch 22 - iter 301/439 - loss 0.95105501 - samples/sec: 150.82
2020-04-01 22:33:52,015 epoch 22 - iter 344/439 - loss 0.94779944 - samples/sec: 159.30
2020-04-01 22:33:55,406 epoch 35 - iter 110/220 - loss 1.02272118 - samples/sec: 292.23
2020-04-01 22:34:06,572 epoch 35 - iter 132/220 - loss 1.01593103 - samples/sec: 318.48
2020-04-01 22:34:07,024 epoch 22 - iter 387/439 - loss 0.94196108 - samples/sec: 155.52
2020-04-01 22:34:17,187 epoch 35 - iter 154/220 - loss 1.00351951 - samples/sec: 332.61
020-04-01 22:34:19,587 ----------------------------------------------------------------------------------------------------
2020-04-01 22:34:19,587 EPOCH 22 done: loss 0.9601 - lr 0.0100
2020-04-01 22:34:24,051 DEV : loss 0.6718564033508301 - score 0.9204
2020-04-01 22:34:22,129 epoch 22 - iter 430/439 - loss 0.94257438 - samples/sec: 157.96
2020-04-01 22:34:24,148 BAD EPOCHS (no improvement): 1
2020-04-01 22:34:24,199 ----------------------------------------------------------------------------------------------------
2020-04-01 22:34:33,052 epoch 23 - iter 43/439 - loss 1.01625965 - samples/sec: 155.50
2020-04-01 22:34:30,302 ----------------------------------------------------------------------------------------------------
2020-04-01 22:34:30,302 EPOCH 22 done: loss 0.9460 - lr 0.0100
2020-04-01 22:34:28,269 epoch 35 - iter 176/220 - loss 1.00395678 - samples/sec: 298.10
2020-04-01 22:34:34,781 DEV : loss 0.7033692598342896 - score 0.924
2020-04-01 22:34:34,880 BAD EPOCHS (no improvement): 0
2020-04-01 22:34:36,458 ----------------------------------------------------------------------------------------------------
2020-04-01 22:34:37,934 epoch 35 - iter 198/220 - loss 0.99915965 - samples/sec: 447.87
2020-04-01 22:34:47,416 epoch 2 - iter 215/439 - loss 2.00042899 - samples/sec: 91.54
2020-04-01 22:34:49,202 epoch 23 - iter 86/439 - loss 1.02711902 - samples/sec: 148.57
2020-04-01 22:34:45,319 epoch 23 - iter 43/439 - loss 0.85342754 - samples/sec: 155.38
2020-04-01 22:34:47,487 epoch 35 - iter 220/220 - loss 1.00079692 - samples/sec: 407.76
2020-04-01 22:34:55,176 ----------------------------------------------------------------------------------------------------
2020-04-01 22:34:55,176 EPOCH 35 done: loss 1.0008 - lr 0.0100
2020-04-01 22:34:59,104 DEV : loss 0.6954030394554138 - score 0.9244
2020-04-01 22:34:59,204 BAD EPOCHS (no improvement): 2
2020-04-01 22:34:59,215 ----------------------------------------------------------------------------------------------------
2020-04-01 22:35:03,577 epoch 36 - iter 22/220 - loss 1.09201290 - samples/sec: 323.07
2020-04-01 22:35:13,994 epoch 36 - iter 44/220 - loss 1.03635884 - samples/sec: 341.10

2020-04-01 22:35:24,668 epoch 36 - iter 66/220 - loss 1.04193582 - samples/sec: 309.20
2020-04-01 22:35:20,455 epoch 23 - iter 172/439 - loss 0.94779307 - samples/sec: 151.71
2020-04-01 22:35:16,566 epoch 23 - iter 129/439 - loss 0.89872037 - samples/sec: 153.95
2020-04-01 22:35:31,660 epoch 23 - iter 172/439 - loss 0.88973554 - samples/sec: 155.64
2020-04-01 22:35:35,714 epoch 23 - iter 215/439 - loss 0.95391000 - samples/sec: 149.98
2020-04-01 22:35:36,247 epoch 36 - iter 88/220 - loss 1.04726486 - samples/sec: 310.86
2020-04-01 22:35:51,399 epoch 23 - iter 258/439 - loss 0.97487926 - samples/sec: 150.96
2020-04-01 22:35:47,077 epoch 23 - iter 215/439 - loss 0.91741821 - samples/sec: 152.70
2020-04-01 22:35:47,370 epoch 36 - iter 110/220 - loss 1.03765329 - samples/sec: 306.71
2020-04-01 22:36:03,454 epoch 23 - iter 258/439 - loss 0.91443037 - samples/sec: 155.04
2020-04-01 22:35:59,520 epoch 36 - iter 132/220 - loss 1.03669743 - samples/sec: 317.17
2020-04-01 22:36:08,316 epoch 2 - iter 387/439 - loss 2.90878900 - samples/sec: 164.45
2020-04-01 22:36:07,892 epoch 23 - iter 301/439 - loss 0.96188500 - samples/sec: 150.51
2020-04-01 22:36:09,603 epoch 36 - iter 154/220 - loss 1.03889519 - samples/sec: 345.88
2020-04-01 22:36:23,694 epoch 23 - iter 344/439 - loss 0.95649766 - samples/sec: 152.32
2020-04-01 22:36:18,348 epoch 23 - iter 301/439 - loss 0.92074910 - samples/sec: 153.53
2020-04-01 22:36:20,578 epoch 36 - iter 176/220 - loss 1.02944236 - samples/sec: 332.16
2020-04-01 22:36:33,363 epoch 23 - iter 344/439 - loss 0.91669401 - samples/sec: 155.13
2020-04-01 22:36:31,078 epoch 36 - iter 198/220 - loss 1.01666160 - samples/sec: 330.10
2020-04-01 22:36:38,673 epoch 23 - iter 387/439 - loss 0.96228298 - samples/sec: 156.39
2020-04-01 22:36:41,989 epoch 36 - iter 220/220 - loss 1.00928550 - samples/sec: 334.28
2020-04-01 22:36:54,050 epoch 23 - iter 430/439 - loss 0.94783840 - samples/sec: 151.36
2020-04-01 22:36:48,881 epoch 23 - iter 387/439 - loss 0.92757844 - samples/sec: 151.78
2020-04-01 22:36:48,612 ----------------------------------------------------------------------------------------------------
2020-04-01 22:36:48,612 EPOCH 36 done: loss 1.0093 - lr 0.0100
2020-04-01 22:36:52,561 DEV : loss 0.6774526238441467 - score 0.9256
2020-04-01 22:36:52,658 BAD EPOCHS (no improvement): 0
2020-04-01 22:36:53,927 ----------------------------------------------------------------------------------------------------
2020-04-01 22:37:02,026 ----------------------------------------------------------------------------------------------------
2020-04-01 22:37:02,027 EPOCH 23 done: loss 0.9500 - lr 0.0100
2020-04-01 22:37:04,232 epoch 23 - iter 430/439 - loss 0.92916705 - samples/sec: 161.74
2020-04-01 22:36:58,451 epoch 37 - iter 22/220 - loss 1.03656698 - samples/sec: 311.49
2020-04-01 22:37:06,470 DEV : loss 0.6618894338607788 - score 0.9222
2020-04-01 22:37:06,569 BAD EPOCHS (no improvement): 0
2020-04-01 22:37:07,866 ----------------------------------------------------------------------------------------------------
2020-04-01 22:37:14,004 ----------------------------------------------------------------------------------------------------
2020-04-01 22:37:14,005 EPOCH 23 done: loss 0.9255 - lr 0.0100
2020-04-01 22:37:09,030 epoch 37 - iter 44/220 - loss 1.02025699 - samples/sec: 350.83
2020-04-01 22:37:16,749 epoch 24 - iter 43/439 - loss 0.87511147 - samples/sec: 155.00
2020-04-01 22:37:18,476 DEV : loss 0.695991039276123 - score 0.9267
2020-04-01 22:37:18,574 BAD EPOCHS (no improvement): 0
2020-04-01 22:37:20,271 ----------------------------------------------------------------------------------------------------
2020-04-01 22:37:19,726 epoch 37 - iter 66/220 - loss 0.99345345 - samples/sec: 338.09
2020-04-01 22:37:32,871 epoch 24 - iter 86/439 - loss 0.91593520 - samples/sec: 153.67
2020-04-01 22:37:28,436 epoch 24 - iter 43/439 - loss 0.94068302 - samples/sec: 168.64
2020-04-01 22:37:30,641 epoch 37 - iter 88/220 - loss 1.01535823 - samples/sec: 324.09
2020-04-01 22:37:42,874 epoch 24 - iter 86/439 - loss 0.94789178 - samples/sec: 170.45
2020-04-01 22:37:42,996 epoch 37 - iter 110/220 - loss 1.02537937 - samples/sec: 295.72
2020-04-01 22:37:47,754 epoch 24 - iter 129/439 - loss 0.88987386 - samples/sec: 183.31
2020-04-01 22:37:54,842 epoch 37 - iter 132/220 - loss 1.00599461 - samples/sec: 323.12
2020-04-01 22:38:04,292 epoch 2 - iter 430/439 - loss 2.87786329 - samples/sec: 175.10

2020-04-01 22:37:59,354 epoch 24 - iter 129/439 - loss 0.92740157 - samples/sec: 152.63
2020-04-01 22:38:14,225 epoch 24 - iter 172/439 - loss 0.91585528 - samples/sec: 152.88
2020-04-01 22:38:05,752 epoch 37 - iter 154/220 - loss 0.99531655 - samples/sec: 284.76
2020-04-01 22:38:19,173 epoch 24 - iter 215/439 - loss 0.88792473 - samples/sec: 152.99
2020-04-01 22:38:17,032 epoch 37 - iter 176/220 - loss 0.99966339 - samples/sec: 273.74
2020-04-01 22:38:30,173 epoch 24 - iter 215/439 - loss 0.91493888 - samples/sec: 149.78
2020-04-01 22:38:28,660 epoch 37 - iter 198/220 - loss 1.00112357 - samples/sec: 312.73
2020-04-01 22:38:35,157 epoch 24 - iter 258/439 - loss 0.89621043 - samples/sec: 150.58
2020-04-01 22:38:39,358 epoch 37 - iter 220/220 - loss 0.99916655 - samples/sec: 296.37
2020-04-01 22:38:45,177 ----------------------------------------------------------------------------------------------------
2020-04-01 22:38:45,178 EPOCH 37 done: loss 0.9992 - lr 0.0100
2020-04-01 22:38:49,135 DEV : loss 0.6515819430351257 - score 0.9259
2020-04-01 22:38:49,232 BAD EPOCHS (no improvement): 0
2020-04-01 22:38:50,518 ----------------------------------------------------------------------------------------------------
2020-04-01 22:38:55,040 epoch 38 - iter 22/220 - loss 0.98075215 - samples/sec: 311.67
2020-04-01 22:39:01,927 epoch 24 - iter 301/439 - loss 0.92297865 - samples/sec: 151.28
2020-04-01 22:39:07,499 epoch 3 - iter 220/220 - loss 1.92399627 - samples/sec: 131.14
2020-04-01 22:39:06,020 epoch 24 - iter 344/439 - loss 0.90753901 - samples/sec: 154.85
2020-04-01 22:39:06,299 epoch 38 - iter 44/220 - loss 0.99962111 - samples/sec: 323.27
2020-04-01 22:39:22,088 epoch 24 - iter 387/439 - loss 0.90611980 - samples/sec: 148.54
2020-04-01 22:39:17,287 epoch 24 - iter 344/439 - loss 0.92014401 - samples/sec: 155.05
2020-04-01 22:39:17,226 epoch 38 - iter 66/220 - loss 1.02412221 - samples/sec: 340.25
2020-04-01 22:39:32,785 epoch 24 - iter 387/439 - loss 0.91484328 - samples/sec: 152.34
2020-04-01 22:39:27,995 epoch 38 - iter 88/220 - loss 1.01080594 - samples/sec: 331.05
2020-04-01 22:39:37,429 epoch 24 - iter 430/439 - loss 0.90716390 - samples/sec: 150.85
2020-04-01 22:39:38,637 epoch 38 - iter 110/220 - loss 1.00583299 - samples/sec: 298.13
2020-04-01 22:39:48,667 ----------------------------------------------------------------------------------------------------
2020-04-01 22:39:48,668 EPOCH 2 done: loss 2.8696 - lr 0.0100
2020-04-01 22:39:45,769 ----------------------------------------------------------------------------------------------------
2020-04-01 22:39:45,770 EPOCH 24 done: loss 0.9122 - lr 0.0100
2020-04-01 22:39:50,230 DEV : loss 0.6315142512321472 - score 0.9258
2020-04-01 22:39:50,326 BAD EPOCHS (no improvement): 0
2020-04-01 22:39:51,611 ----------------------------------------------------------------------------------------------------
2020-04-01 22:39:47,483 epoch 24 - iter 430/439 - loss 0.91001634 - samples/sec: 156.45
2020-04-01 22:39:48,434 epoch 38 - iter 132/220 - loss 1.00679805 - samples/sec: 412.27
2020-04-01 22:39:53,403 DEV : loss 1.6938010454177856 - score 0.8211
2020-04-01 22:39:53,500 BAD EPOCHS (no improvement): 0
2020-04-01 22:40:00,282 epoch 25 - iter 43/439 - loss 0.85946103 - samples/sec: 158.80
2020-04-01 22:39:56,754 ----------------------------------------------------------------------------------------------------
2020-04-01 22:39:56,755 EPOCH 24 done: loss 0.9131 - lr 0.0100
2020-04-01 22:40:01,191 DEV : loss 0.6621038913726807 - score 0.9268
2020-04-01 22:40:01,286 BAD EPOCHS (no improvement): 0
2020-04-01 22:40:03,711 ----------------------------------------------------------------------------------------------------
2020-04-01 22:40:00,309 epoch 38 - iter 154/220 - loss 1.00505167 - samples/sec: 283.05
2020-04-01 22:40:02,188 ----------------------------------------------------------------------------------------------------
2020-04-01 22:40:10,377 epoch 3 - iter 43/439 - loss 2.25811576 - samples/sec: 168.15
2020-04-01 22:40:12,805 epoch 25 - iter 43/439 - loss 0.78097937 - samples/sec: 151.40
2020-04-01 22:40:12,860 epoch 38 - iter 176/220 - loss 1.00404546 - samples/sec: 412.87
2020-04-01 22:40:23,178 epoch 38 - iter 198/220 - loss 1.00216386 - samples/sec: 380.77
2020-04-01 22:40:22,905 epoch 2 - iter 258/439 - loss 2.00190742 - samples/sec: 83.94
2020-04-01 22:40:33,047 epoch 38 - iter 220/220 - loss 0.99407845 - samples/sec: 368.56
2020-04-01 22:40:28,153 epoch 25 - iter 86/439 - loss 0.88928327 - samples/sec: 157.66
2020-04-01 22:40:38,998 ----------------------------------------------------------------------------------------------------
2020-04-01 22:40:38,999 EPOCH 38 done: loss 0.9941 - lr 0.0100
2020-04-01 22:40:42,942 DEV : loss 0.6532366275787354 - score 0.924
2020-04-01 22:40:43,040 BAD EPOCHS (no improvement): 1
2020-04-01 22:40:43,075 ----------------------------------------------------------------------------------------------------
2020-04-01 22:40:49,207 epoch 25 - iter 172/439 - loss 0.91075244 - samples/sec: 153.07
2020-04-01 22:40:46,988 epoch 39 - iter 22/220 - loss 0.99520001 - samples/sec: 360.03
2020-04-01 22:41:04,314 epoch 25 - iter 215/439 - loss 0.92861138 - samples/sec: 157.05
2020-04-01 22:40:58,051 epoch 25 - iter 172/439 - loss 0.91290664 - samples/sec: 157.02
2020-04-01 22:40:57,434 epoch 39 - iter 44/220 - loss 1.02171272 - samples/sec: 340.48
2020-04-01 22:41:12,884 epoch 25 - iter 215/439 - loss 0.90282787 - samples/sec: 155.91
2020-04-01 22:41:07,835 epoch 39 - iter 66/220 - loss 0.99282545 - samples/sec: 321.89
2020-04-01 22:41:19,723 epoch 25 - iter 258/439 - loss 0.91743416 - samples/sec: 152.43
2020-04-01 22:41:18,217 epoch 39 - iter 88/220 - loss 1.00263403 - samples/sec: 338.88
2020-04-01 22:41:34,864 epoch 25 - iter 301/439 - loss 0.90940161 - samples/sec: 151.24
2020-04-01 22:41:27,606 epoch 25 - iter 258/439 - loss 0.90093148 - samples/sec: 153.63
2020-04-01 22:41:28,839 epoch 39 - iter 110/220 - loss 0.98837663 - samples/sec: 307.34
2020-04-01 22:41:43,065 epoch 25 - iter 301/439 - loss 0.89965921 - samples/sec: 154.01
2020-04-01 22:41:40,305 epoch 39 - iter 132/220 - loss 0.99283270 - samples/sec: 288.46
2020-04-01 22:41:50,966 epoch 39 - iter 154/220 - loss 0.98236762 - samples/sec: 317.71
2020-04-01 22:42:01,960 epoch 39 - iter 176/220 - loss 0.97852269 - samples/sec: 319.20
20-04-01 22:42:05,665 epoch 25 - iter 387/439 - loss 0.90569982 - samples/sec: 148.78
2020-04-01 22:41:57,949 epoch 25 - iter 344/439 - loss 0.89708960 - samples/sec: 156.04
2020-04-01 22:42:13,102 epoch 25 - iter 387/439 - loss 0.89273060 - samples/sec: 150.14
2020-04-01 22:42:21,124 epoch 39 - iter 198/220 - loss 0.98483443 - samples/sec: 333.23
2020-04-01 22:42:29,825 epoch 25 - iter 430/439 - loss 0.90517365 - samples/sec: 152.93
2020-04-01 22:42:31,717 epoch 25 - iter 430/439 - loss 0.88914073 - samples/sec: 154.70
2020-04-01 22:42:39,261 epoch 39 - iter 220/220 - loss 0.98929727 - samples/sec: 398.08
2020-04-01 22:42:45,764 ----------------------------------------------------------------------------------------------------
2020-04-01 22:42:45,764 EPOCH 39 done: loss 0.9893 - lr 0.0100
-----------------------------------
2020-04-01 22:42:44,304 EPOCH 25 done: loss 0.8881 - lr 0.0100
2020-04-01 22:42:48,670 DEV : loss 0.6309200525283813 - score 0.9257
2020-04-01 22:42:48,767 BAD EPOCHS (no improvement): 1
2020-04-01 22:42:48,779 ----------------------------------------------------------------------------------------------------
2020-04-01 22:42:48,730 DEV : loss 0.6889482736587524 - score 0.9256
2020-04-01 22:42:48,826 BAD EPOCHS (no improvement): 1
2020-04-01 22:42:48,868 ----------------------------------------------------------------------------------------------------
2020-04-01 22:42:50,210 DEV : loss 0.6459847688674927 - score 0.9254
2020-04-01 22:42:50,309 BAD EPOCHS (no improvement): 2
2020-04-01 22:42:50,360 ----------------------------------------------------------------------------------------------------
2020-04-01 22:42:53,274 epoch 40 - iter 22/220 - loss 0.94623385 - samples/sec: 483.53
2020-04-01 22:43:02,613 epoch 40 - iter 44/220 - loss 0.93038068 - samples/sec: 419.02
------------------------------------
2020-04-01 22:42:58,474 EPOCH 3 done: loss 1.9240 - lr 0.0100
2020-04-01 22:42:57,837 epoch 26 - iter 43/439 - loss 0.97600094 - samples/sec: 151.97
2020-04-01 22:42:57,721 epoch 26 - iter 43/439 - loss 0.91171942 - samples/sec: 155.51
2020-04-01 22:43:12,189 epoch 26 - iter 86/439 - loss 0.92196741 - samples/sec: 153.00
2020-04-01 22:43:12,149 epoch 26 - iter 86/439 - loss 0.94260505 - samples/sec: 150.91
2020-04-01 22:43:10,615 epoch 40 - iter 66/220 - loss 0.94346963 - samples/sec: 424.09
2020-04-01 22:43:12,624 DEV : loss 1.2689586877822876 - score 0.8689
2020-04-01 22:43:13,018 BAD EPOCHS (no improvement): 0
2020-04-01 22:43:19,736 epoch 40 - iter 88/220 - loss 0.94745619 - samples/sec: 433.69
2020-04-01 22:43:27,472 epoch 26 - iter 129/439 - loss 0.90115679 - samples/sec: 148.46
2020-04-01 22:43:27,091 epoch 26 - iter 129/439 - loss 0.89142580 - samples/sec: 154.03
2020-04-01 22:43:54,703 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-01 22:44:06,267 epoch 4 - iter 22/220 - loss 1.75423801 - samples/sec: 121.86

2020-04-01 22:44:03,901 epoch 26 - iter 172/439 - loss 0.90832654 - samples/sec: 149.44
2020-04-01 22:44:11,962 epoch 40 - iter 154/220 - loss 0.95096970 - samples/sec: 259.10
2020-04-01 22:44:21,649 epoch 3 - iter 129/439 - loss 2.32052841 - samples/sec: 163.52
2020-04-01 22:44:20,052 epoch 26 - iter 215/439 - loss 0.92898344 - samples/sec: 151.35
2020-04-01 22:44:19,368 epoch 26 - iter 215/439 - loss 0.88810452 - samples/sec: 152.87
2020-04-01 22:44:23,021 epoch 40 - iter 176/220 - loss 0.95128272 - samples/sec: 311.69
2020-04-01 22:44:34,267 epoch 40 - iter 198/220 - loss 0.95984746 - samples/sec: 319.04
2020-04-01 22:44:34,795 epoch 26 - iter 258/439 - loss 0.88040853 - samples/sec: 154.16
2020-04-01 22:44:44,687 epoch 40 - iter 220/220 - loss 0.95165641 - samples/sec: 319.20
2020-04-01 22:44:49,937 ----------------------------------------------------------------------------------------------------
2020-04-01 22:44:49,938 EPOCH 40 done: loss 0.9517 - lr 0.0100
2020-04-01 22:44:53,879 DEV : loss 0.6421146392822266 - score 0.9274
2020-04-01 22:44:53,977 BAD EPOCHS (no improvement): 0
2020-04-01 22:44:55,339 ----------------------------------------------------------------------------------------------------
2020-04-01 22:44:59,845 epoch 41 - iter 22/220 - loss 0.95224854 - samples/sec: 312.85

2020-04-01 22:45:05,217 epoch 26 - iter 344/439 - loss 0.87865945 - samples/sec: 152.43
2020-04-01 22:45:09,576 epoch 41 - iter 44/220 - loss 0.96774975 - samples/sec: 316.98
2020-04-01 22:45:19,563 epoch 41 - iter 66/220 - loss 0.94402588 - samples/sec: 325.72

2020-04-01 22:45:19,604 epoch 26 - iter 387/439 - loss 0.88026473 - samples/sec: 151.40
2020-04-01 22:45:30,402 epoch 41 - iter 88/220 - loss 0.92502088 - samples/sec: 334.84

2020-04-01 22:45:35,156 epoch 26 - iter 430/439 - loss 0.88145081 - samples/sec: 153.45
2020-04-01 22:45:40,764 epoch 41 - iter 110/220 - loss 0.93435436 - samples/sec: 310.65
-----------------------------------
2020-04-01 22:45:45,005 EPOCH 26 done: loss 0.8947 - lr 0.0100
2020-04-01 22:45:42,628 ----------------------------------------------------------------------------------------------------
2020-04-01 22:45:42,629 EPOCH 26 done: loss 0.8792 - lr 0.0100
2020-04-01 22:45:47,084 DEV : loss 0.6576452255249023 - score 0.9268
2020-04-01 22:45:47,179 BAD EPOCHS (no improvement): 2
2020-04-01 22:45:48,965 ----------------------------------------------------------------------------------------------------
2020-04-01 22:45:50,866 epoch 41 - iter 132/220 - loss 0.96210111 - samples/sec: 334.66
2020-04-01 22:45:59,114 epoch 41 - iter 154/220 - loss 0.95576971 - samples/sec: 461.70
------------------------------------------------------------------------
2020-04-01 22:45:57,588 epoch 27 - iter 43/439 - loss 0.81633655 - samples/sec: 159.67
2020-04-01 22:46:08,829 epoch 41 - iter 176/220 - loss 0.94399318 - samples/sec: 329.72
020-04-01 22:45:59,936 epoch 27 - iter 43/439 - loss 0.87347872 - samples/sec: 151.15
2020-04-01 22:46:11,012 epoch 2 - iter 301/439 - loss 1.95609856 - samples/sec: 84.67
2020-04-01 22:46:19,485 epoch 41 - iter 198/220 - loss 0.94461730 - samples/sec: 287.89
020-04-01 22:46:12,084 epoch 27 - iter 86/439 - loss 0.85131707 - samples/sec: 154.83
2020-04-01 22:46:29,648 epoch 41 - iter 220/220 - loss 0.95077016 - samples/sec: 345.73
2020-04-01 22:46:36,722 ----------------------------------------------------------------------------------------------------
2020-04-01 22:46:36,722 EPOCH 41 done: loss 0.9508 - lr 0.0100
2020-04-01 22:46:40,694 DEV : loss 0.6289722919464111 - score 0.929
2020-04-01 22:46:40,791 BAD EPOCHS (no improvement): 0
2020-04-01 22:46:42,106 ----------------------------------------------------------------------------------------------------
2020-04-01 22:46:46,618 epoch 42 - iter 22/220 - loss 0.93409976 - samples/sec: 312.30
2020-04-01 22:46:57,159 epoch 42 - iter 44/220 - loss 0.97530871 - samples/sec: 314.17

2020-04-01 22:47:08,513 epoch 42 - iter 66/220 - loss 0.93437485 - samples/sec: 311.90

2020-04-01 22:47:18,812 epoch 42 - iter 88/220 - loss 0.95308055 - samples/sec: 313.01

2020-04-01 22:47:12,207 epoch 27 - iter 258/439 - loss 0.85200848 - samples/sec: 154.61
2020-04-01 22:47:29,087 epoch 42 - iter 110/220 - loss 0.94403580 - samples/sec: 312.12
2020-04-01 22:47:39,468 epoch 42 - iter 132/220 - loss 0.97178022 - samples/sec: 309.76
20-04-01 22:47:31,388 epoch 27 - iter 301/439 - loss 0.88473272 - samples/sec: 151.24
2020-04-01 22:47:48,611 epoch 42 - iter 154/220 - loss 0.95924639 - samples/sec: 350.93
2020-04-01 22:47:41,742 epoch 27 - iter 344/439 - loss 0.85236420 - samples/sec: 154.45
2020-04-01 22:47:58,915 epoch 42 - iter 176/220 - loss 0.95345234 - samples/sec: 318.24
020-04-01 22:47:56,281 epoch 27 - iter 387/439 - loss 0.86072476 - samples/sec: 150.32
2020-04-01 22:48:09,656 epoch 42 - iter 198/220 - loss 0.94810165 - samples/sec: 295.98
2020-04-01 22:48:19,590 epoch 42 - iter 220/220 - loss 0.94981478 - samples/sec: 328.50
2020-04-01 22:48:10,718 epoch 27 - iter 430/439 - loss 0.86607012 - samples/sec: 155.86
2020-04-01 22:48:18,149 ----------------------------------------------------------------------------------------------------
2020-04-01 22:48:18,149 EPOCH 27 done: loss 0.8633 - lr 0.0100
2020-04-01 22:48:26,604 ----------------------------------------------------------------------------------------------------
2020-04-01 22:48:26,604 EPOCH 42 done: loss 0.9498 - lr 0.0100
2020-04-01 22:48:27,745 DEV : loss 0.6140109300613403 - score 0.9283
2020-04-01 22:48:27,839 BAD EPOCHS (no improvement): 0
2020-04-01 22:48:29,288 ----------------------------------------------------------------------------------------------------
2020-04-01 22:48:22,638 DEV : loss 0.6662327647209167 - score 0.9274
2020-04-01 22:48:22,736 BAD EPOCHS (no improvement): 0
2020-04-01 22:48:24,362 ----------------------------------------------------------------------------------------------------
2020-04-01 22:48:30,509 DEV : loss 0.6373466849327087 - score 0.9279
2020-04-01 22:48:30,606 BAD EPOCHS (no improvement): 1
2020-04-01 22:48:30,649 ----------------------------------------------------------------------------------------------------
2020-04-01 22:48:34,388 epoch 43 - iter 22/220 - loss 1.02146001 - samples/sec: 376.81
2020-04-01 22:48:44,500 epoch 43 - iter 44/220 - loss 1.00385252 - samples/sec: 364.60
2020-04-01 22:48:53,355 epoch 43 - iter 66/220 - loss 0.97383024 - samples/sec: 433.22
2020-04-01 22:49:01,610 epoch 43 - iter 88/220 - loss 0.95764969 - samples/sec: 445.68

2020-04-01 22:49:02,477 epoch 28 - iter 129/439 - loss 0.82227420 - samples/sec: 156.11
2020-04-01 22:49:10,885 epoch 43 - iter 110/220 - loss 0.94831181 - samples/sec: 450.07
2020-04-01 22:49:21,817 epoch 43 - iter 132/220 - loss 0.95218027 - samples/sec: 281.70
2020-04-01 22:49:32,479 epoch 43 - iter 154/220 - loss 0.95689579 - samples/sec: 292.52
2020-04-01 22:49:32,723 epoch 28 - iter 215/439 - loss 0.81622500 - samples/sec: 151.31
2020-04-01 22:49:42,558 epoch 43 - iter 176/220 - loss 0.94975674 - samples/sec: 318.14
2020-04-01 22:49:52,259 epoch 43 - iter 198/220 - loss 0.94065221 - samples/sec: 357.45
2020-04-01 22:50:02,089 epoch 43 - iter 220/220 - loss 0.94204219 - samples/sec: 340.97
2020-04-01 22:50:07,632 ----------------------------------------------------------------------------------------------------
2020-04-01 22:50:07,632 EPOCH 43 done: loss 0.9420 - lr 0.0100
2020-04-01 22:50:15,770 epoch 28 - iter 344/439 - loss 0.84923763 - samples/sec: 154.40
2020-04-01 22:50:11,593 DEV : loss 0.6329496502876282 - score 0.927
2020-04-01 22:50:11,692 BAD EPOCHS (no improvement): 2
2020-04-01 22:50:11,740 ----------------------------------------------------------------------------------------------------
2020-04-01 22:50:14,718 epoch 44 - iter 22/220 - loss 0.84556081 - samples/sec: 473.12
2020-04-01 22:50:23,405 epoch 28 - iter 344/439 - loss 0.86248683 - samples/sec: 154.72
2020-04-01 22:50:24,198 epoch 44 - iter 44/220 - loss 0.86207222 - samples/sec: 428.31
2020-04-01 22:50:33,345 epoch 44 - iter 66/220 - loss 0.87930357 - samples/sec: 417.19

2020-04-01 22:50:31,017 epoch 28 - iter 387/439 - loss 0.84470308 - samples/sec: 151.32
2020-04-01 22:50:42,068 epoch 44 - iter 88/220 - loss 0.90921240 - samples/sec: 427.91
2020-04-01 22:50:50,800 epoch 44 - iter 110/220 - loss 0.90306049 - samples/sec: 431.89
2020-04-01 22:50:59,459 epoch 44 - iter 132/220 - loss 0.90741088 - samples/sec: 451.95
2020-04-01 22:51:00,109 ----------------------------------------------------------------------------------------------------
2020-04-01 22:51:00,110 EPOCH 28 done: loss 0.8584 - lr 0.0100
2020-04-01 22:50:52,317 ----------------------------------------------------------------------------------------------------
2020-04-01 22:50:52,318 EPOCH 28 done: loss 0.8423 - lr 0.0100
2020-04-01 22:50:56,779 DEV : loss 0.6385217308998108 - score 0.9261
2020-04-01 22:50:56,878 BAD EPOCHS (no improvement): 1
2020-04-01 22:50:56,922 ----------------------------------------------------------------------------------------------------
2020-04-01 22:51:09,213 epoch 44 - iter 154/220 - loss 0.90951673 - samples/sec: 421.19
20-04-01 22:51:04,577 DEV : loss 0.6049749255180359 - score 0.9279
2020-04-01 22:51:04,674 BAD EPOCHS (no improvement): 1
2020-04-01 22:51:04,740 ----------------------------------------------------------------------------------------------------
2020-04-01 22:51:04,330 epoch 29 - iter 43/439 - loss 0.83998446 - samples/sec: 185.85
2020-04-01 22:51:09,650 epoch 2 - iter 344/439 - loss 1.92722925 - samples/sec: 87.56
2020-04-01 22:51:19,336 epoch 44 - iter 176/220 - loss 0.90441233 - samples/sec: 351.05
020-04-01 22:51:19,477 epoch 29 - iter 86/439 - loss 0.84216809 - samples/sec: 153.26
2020-04-01 22:51:29,742 epoch 44 - iter 198/220 - loss 0.91220827 - samples/sec: 309.64
2020-04-01 22:51:40,148 epoch 44 - iter 220/220 - loss 0.91163442 - samples/sec: 325.74
2020-04-01 22:51:45,120 ----------------------------------------------------------------------------------------------------
2020-04-01 22:51:45,120 EPOCH 44 done: loss 0.9116 - lr 0.0100
2020-04-01 22:51:49,069 DEV : loss 0.6295884251594543 - score 0.9301
2020-04-01 22:51:49,167 BAD EPOCHS (no improvement): 0
2020-04-01 22:51:50,451 ----------------------------------------------------------------------------------------------------
2020-04-01 22:51:58,911 epoch 29 - iter 172/439 - loss 0.81687602 - samples/sec: 152.83
2020-04-01 22:51:54,324 epoch 45 - iter 22/220 - loss 0.88463564 - samples/sec: 363.82
2020-04-01 22:52:03,991 epoch 45 - iter 44/220 - loss 0.89111229 - samples/sec: 361.15

2020-04-01 22:52:13,749 epoch 29 - iter 215/439 - loss 0.82502491 - samples/sec: 155.34
2020-04-01 22:52:17,554 epoch 29 - iter 258/439 - loss 0.83069558 - samples/sec: 158.68
2020-04-01 22:52:14,444 epoch 45 - iter 66/220 - loss 0.89632992 - samples/sec: 309.56
2020-04-01 22:52:28,368 epoch 29 - iter 258/439 - loss 0.83149085 - samples/sec: 152.21
2020-04-01 22:52:24,795 epoch 45 - iter 88/220 - loss 0.88017991 - samples/sec: 301.81
2020-04-01 22:52:34,217 epoch 45 - iter 110/220 - loss 0.87572010 - samples/sec: 354.90
2020-04-01 22:52:42,042 epoch 29 - iter 301/439 - loss 0.83442181 - samples/sec: 159.68
2020-04-01 22:52:45,827 epoch 29 - iter 344/439 - loss 0.81944136 - samples/sec: 154.81
2020-04-01 22:52:44,494 epoch 45 - iter 132/220 - loss 0.88511968 - samples/sec: 334.86
2020-04-01 22:52:55,392 epoch 45 - iter 154/220 - loss 0.88503784 - samples/sec: 287.51
2020-04-01 22:52:56,213 epoch 3 - iter 344/439 - loss 2.30582107 - samples/sec: 165.22
2020-04-01 22:52:59,930 epoch 29 - iter 387/439 - loss 0.82241025 - samples/sec: 156.32
2020-04-01 22:52:56,678 epoch 29 - iter 344/439 - loss 0.83648732 - samples/sec: 159.98
2020-04-01 22:53:26,530 epoch 29 - iter 430/439 - loss 0.81863142 - samples/sec: 164.18
2020-04-01 22:53:26,773 epoch 29 - iter 387/439 - loss 0.83946642 - samples/sec: 158.58
2020-04-01 22:53:34,578 ----------------------------------------------------------------------------------------------------
2020-04-01 22:53:34,578 EPOCH 29 done: loss 0.8190 - lr 0.0100
2020-04-01 22:53:38,924 DEV : loss 0.6549858450889587 - score 0.9276
2020-04-01 22:53:39,019 BAD EPOCHS (no improvement): 0
2020-04-01 22:53:40,591 ----------------------------------------------------------------------------------------------------
2020-04-01 22:53:49,265 epoch 30 - iter 43/439 - loss 0.89180037 - samples/sec: 158.72
2020-04-01 22:53:40,622 epoch 29 - iter 430/439 - loss 0.84407168 - samples/sec: 180.53
2020-04-01 22:53:47,959 ----------------------------------------------------------------------------------------------------
2020-04-01 22:53:47,960 EPOCH 29 done: loss 0.8428 - lr 0.0100
2020-04-01 22:53:52,416 DEV : loss 0.6024790406227112 - score 0.9296
2020-04-01 22:53:52,513 BAD EPOCHS (no improvement): 0
2020-04-01 22:53:53,815 ----------------------------------------------------------------------------------------------------
0.9263
2020-04-01 22:53:56,064 BAD EPOCHS (no improvement): 1
2020-04-01 22:53:56,124 ----------------------------------------------------------------------------------------------------
2020-04-01 22:54:05,165 epoch 30 - iter 86/439 - loss 0.82716664 - samples/sec: 157.87
2020-04-01 22:54:02,314 epoch 30 - iter 43/439 - loss 0.78287171 - samples/sec: 161.99
2020-04-01 22:54:17,167 epoch 30 - iter 86/439 - loss 0.80550467 - samples/sec: 158.91
2020-04-01 22:54:21,162 epoch 46 - iter 66/220 - loss 0.90673812 - samples/sec: 343.46
2020-04-01 22:54:20,176 epoch 30 - iter 129/439 - loss 0.81679093 - samples/sec: 157.24
2020-04-01 22:54:35,484 epoch 30 - iter 172/439 - loss 0.79613446 - samples/sec: 158.92
2020-04-01 22:54:32,077 epoch 30 - iter 129/439 - loss 0.83519193 - samples/sec: 161.18
2020-04-01 22:54:46,927 epoch 30 - iter 172/439 - loss 0.81695780 - samples/sec: 155.11
2020-04-01 22:54:52,554 epoch 46 - iter 132/220 - loss 0.91312657 - samples/sec: 356.94
2020-04-01 22:54:50,698 epoch 30 - iter 215/439 - loss 0.81430309 - samples/sec: 153.06
2020-04-01 22:55:05,098 epoch 30 - iter 258/439 - loss 0.81144593 - samples/sec: 165.33
020-04-01 22:55:02,753 epoch 46 - iter 154/220 - loss 0.92009407 - samples/sec: 316.51
2020-04-01 22:55:02,135 epoch 30 - iter 215/439 - loss 0.82382422 - samples/sec: 153.89
2020-04-01 22:55:19,077 epoch 30 - iter 301/439 - loss 0.80822512 - samples/sec: 161.05
20-04-01 22:55:12,951 epoch 46 - iter 176/220 - loss 0.92378686 - samples/sec: 317.48
2020-04-01 22:55:16,817 epoch 30 - iter 258/439 - loss 0.82909311 - samples/sec: 150.29
2020-04-01 22:55:23,043 epoch 46 - iter 198/220 - loss 0.92941508 - samples/sec: 320.70
2020-04-01 22:55:32,581 epoch 46 - iter 220/220 - loss 0.92159861 - samples/sec: 374.55
2020-04-01 22:55:39,559 ----------------------------------------------------------------------------------------------------
2020-04-01 22:55:39,559 EPOCH 46 done: loss 0.9216 - lr 0.0100
2020-04-01 22:55:33,427 epoch 30 - iter 344/439 - loss 0.81277207 - samples/sec: 165.44
2020-04-01 22:55:31,641 epoch 30 - iter 301/439 - loss 0.83842472 - samples/sec: 152.58
2020-04-01 22:55:48,916 epoch 30 - iter 387/439 - loss 0.80914738 - samples/sec: 164.46
,577 BAD EPOCHS (no improvement): 2
2020-04-01 22:55:43,624 ----------------------------------------------------------------------------------------------------
2020-04-01 22:55:48,135 epoch 47 - iter 22/220 - loss 0.91073217 - samples/sec: 312.34
2020-04-01 22:55:47,401 epoch 30 - iter 344/439 - loss 0.83550587 - samples/sec: 154.52
2020-04-01 22:55:58,443 epoch 47 - iter 44/220 - loss 0.87913938 - samples/sec: 339.99
2020-04-01 22:56:08,923 epoch 47 - iter 66/220 - loss 0.90763629 - samples/sec: 309.61
2020-04-01 22:56:03,525 epoch 30 - iter 430/439 - loss 0.80930296 - samples/sec: 164.22
2020-04-01 22:56:02,480 epoch 30 - iter 387/439 - loss 0.83973378 - samples/sec: 151.94
2020-04-01 22:56:12,168 ----------------------------------------------------------------------------------------------------
2020-04-01 22:56:12,169 EPOCH 30 done: loss 0.8129 - lr 0.0100
2020-04-01 22:56:16,598 DEV : loss 0.6316584348678589 - score 0.9286
2020-04-01 22:56:16,694 BAD EPOCHS (no improvement): 0
2020-04-01 22:56:18,330 ----------------------------------------------------------------------------------------------------
2020-04-01 22:56:17,213 epoch 30 - iter 430/439 - loss 0.84804487 - samples/sec: 178.89
2020-04-01 22:56:26,965 epoch 31 - iter 43/439 - loss 0.77471762 - samples/sec: 159.44

2020-04-01 22:56:26,498 ----------------------------------------------------------------------------------------------------
2020-04-01 22:56:26,499 EPOCH 30 done: loss 0.8476 - lr 0.0100
2020-04-01 22:56:39,587 epoch 47 - iter 132/220 - loss 0.91288423 - samples/sec: 379.45
2020-04-01 22:56:36,972 epoch 2 - iter 387/439 - loss 1.89087982 - samples/sec: 84.04
2020-04-01 22:56:30,951 DEV : loss 0.5997864603996277 - score 0.928
2020-04-01 22:56:31,048 BAD EPOCHS (no improvement): 1
2020-04-01 22:56:31,087 ----------------------------------------------------------------------------------------------------
2020-04-01 22:56:40,093 epoch 31 - iter 43/439 - loss 0.82957020 - samples/sec: 152.86
2020-04-01 22:56:42,145 epoch 31 - iter 86/439 - loss 0.77808759 - samples/sec: 161.21
2020-04-01 22:56:57,583 epoch 31 - iter 129/439 - loss 0.79884674 - samples/sec: 151.20
020-04-01 22:56:50,679 epoch 47 - iter 154/220 - loss 0.90793019 - samples/sec: 287.66
2020-04-01 22:56:55,434 epoch 31 - iter 86/439 - loss 0.82421250 - samples/sec: 151.61
2020-04-01 22:57:00,581 epoch 47 - iter 176/220 - loss 0.91892301 - samples/sec: 366.21
2020-04-01 22:57:10,862 epoch 47 - iter 198/220 - loss 0.91143286 - samples/sec: 319.74
2020-04-01 22:57:12,207 epoch 31 - iter 172/439 - loss 0.79897148 - samples/sec: 165.14
2020-04-01 22:57:10,465 epoch 31 - iter 129/439 - loss 0.83728790 - samples/sec: 154.29
2020-04-01 22:57:27,352 epoch 31 - iter 215/439 - loss 0.78293394 - samples/sec: 159.76
2020-04-01 22:57:27,465 ----------------------------------------------------------------------------------------------------
2020-04-01 22:57:27,465 EPOCH 47 done: loss 0.9087 - lr 0.0100
2020-04-01 22:57:25,860 epoch 31 - iter 172/439 - loss 0.84470509 - samples/sec: 152.34
2020-04-01 22:57:31,399 DEV : loss 0.6186742782592773 - score 0.928
2020-04-01 22:57:31,495 BAD EPOCHS (no improvement): 3
2020-04-01 22:57:31,529 ----------------------------------------------------------------------------------------------------
2020-04-01 22:57:35,592 epoch 48 - iter 22/220 - loss 0.89985636 - samples/sec: 346.78
2020-04-01 22:57:45,732 epoch 48 - iter 44/220 - loss 0.90668547 - samples/sec: 305.16
2020-04-01 22:57:42,190 epoch 31 - iter 258/439 - loss 0.77539649 - samples/sec: 158.61
2020-04-01 22:57:40,989 epoch 31 - iter 215/439 - loss 0.84518064 - samples/sec: 153.03
2020-04-01 22:57:57,001 epoch 31 - iter 301/439 - loss 0.77683856 - samples/sec: 153.92
2020-04-01 22:57:55,942 epoch 31 - iter 258/439 - loss 0.83416060 - samples/sec: 150.09
2020-04-01 22:58:05,967 epoch 48 - iter 88/220 - loss 0.89902321 - samples/sec: 322.46
2020-04-01 22:58:15,670 epoch 48 - iter 110/220 - loss 0.88964536 - samples/sec: 341.28
2020-04-01 22:58:12,024 epoch 31 - iter 344/439 - loss 0.77510035 - samples/sec: 155.88
2020-04-01 22:58:11,579 epoch 31 - iter 301/439 - loss 0.82889077 - samples/sec: 149.77
2020-04-01 22:58:26,942 epoch 31 - iter 387/439 - loss 0.77449372 - samples/sec: 158.03
-----------------------------------
2020-04-01 22:58:26,741 EPOCH 3 done: loss 2.2841 - lr 0.0100
2020-04-01 22:58:25,210 epoch 48 - iter 132/220 - loss 0.87990197 - samples/sec: 338.94
2020-04-01 22:58:26,631 epoch 31 - iter 344/439 - loss 0.83027170 - samples/sec: 154.25
2020-04-01 22:58:31,343 DEV : loss 1.382155179977417 - score 0.8669
2020-04-01 22:58:31,439 BAD EPOCHS (no improvement): 0
2020-04-01 22:58:36,182 epoch 48 - iter 154/220 - loss 0.89429303 - samples/sec: 314.80
2020-04-01 22:58:41,063 epoch 31 - iter 430/439 - loss 0.78542524 - samples/sec: 178.10
2020-04-01 22:58:48,471 ----------------------------------------------------------------------------------------------------
2020-04-01 22:58:48,472 EPOCH 31 done: loss 0.7877 - lr 0.0100
2020-04-01 22:58:41,837 epoch 31 - iter 387/439 - loss 0.82806746 - samples/sec: 155.33
2020-04-01 22:58:53,594 DEV : loss 0.6203979849815369 - score 0.9279
2020-04-01 22:58:53,692 BAD EPOCHS (no improvement): 1
2020-04-01 22:58:53,736 ----------------------------------------------------------------------------------------------------
2020-04-01 22:58:56,038 epoch 31 - iter 430/439 - loss 0.83514139 - samples/sec: 163.53
2020-04-01 22:59:02,038 epoch 32 - iter 43/439 - loss 0.79001102 - samples/sec: 165.83
2020-04-01 22:59:03,797 ----------------------------------------------------------------------------------------------------
2020-04-01 22:59:03,798 EPOCH 31 done: loss 0.8368 - lr 0.0100
2020-04-01 22:59:08,196 DEV : loss 0.5851397514343262 - score 0.9295
2020-04-01 22:59:08,291 BAD EPOCHS (no improvement): 2
2020-04-01 22:59:08,320 ----------------------------------------------------------------------------------------------------
2020-04-01 22:59:16,838 epoch 32 - iter 86/439 - loss 0.78373811 - samples/sec: 156.49

2020-04-01 22:59:16,222 ----------------------------------------------------------------------------------------------------
2020-04-01 22:59:16,222 EPOCH 48 done: loss 0.8999 - lr 0.0100
2020-04-01 22:59:17,260 epoch 32 - iter 43/439 - loss 0.92034482 - samples/sec: 153.99
2020-04-01 22:59:20,830 DEV : loss 0.6104193329811096 - score 0.9273
Epoch    48: reducing learning rate of group 0 to 5.0000e-03.
2020-04-01 22:59:20,928 BAD EPOCHS (no improvement): 4
2020-04-01 22:59:20,993 ----------------------------------------------------------------------------------------------------
2020-04-01 22:59:25,030 epoch 49 - iter 22/220 - loss 0.84618744 - samples/sec: 348.99
2020-04-01 22:59:34,034 epoch 49 - iter 44/220 - loss 0.88524615 - samples/sec: 370.94
2020-04-01 22:59:31,658 epoch 32 - iter 129/439 - loss 0.79088103 - samples/sec: 152.63
2020-04-01 22:59:32,174 epoch 32 - iter 86/439 - loss 0.83463070 - samples/sec: 152.79
2020-04-01 22:59:47,397 epoch 32 - iter 172/439 - loss 0.80705325 - samples/sec: 153.43
2020-04-01 22:59:47,900 epoch 32 - iter 129/439 - loss 0.83550248 - samples/sec: 153.92
2020-04-01 22:59:55,179 epoch 49 - iter 88/220 - loss 0.88657793 - samples/sec: 329.32
2020-04-01 23:00:05,361 epoch 49 - iter 110/220 - loss 0.87866289 - samples/sec: 338.27
2020-04-01 23:00:03,277 epoch 32 - iter 172/439 - loss 0.82704774 - samples/sec: 148.73
2020-04-01 23:00:16,476 epoch 32 - iter 258/439 - loss 0.81638073 - samples/sec: 164.59
2020-04-01 23:00:18,269 epoch 32 - iter 215/439 - loss 0.82693859 - samples/sec: 153.98
2020-04-01 23:00:29,811 epoch 4 - iter 86/439 - loss 2.06930173 - samples/sec: 166.52
2020-04-01 23:00:30,903 epoch 32 - iter 301/439 - loss 0.80514487 - samples/sec: 169.82
2020-04-01 23:00:26,508 epoch 49 - iter 154/220 - loss 0.87937114 - samples/sec: 301.46
2020-04-01 23:00:33,717 epoch 32 - iter 258/439 - loss 0.81295249 - samples/sec: 152.27
2020-04-01 23:00:45,706 epoch 32 - iter 344/439 - loss 0.79762755 - samples/sec: 159.44
2020-04-01 23:00:49,123 epoch 32 - iter 301/439 - loss 0.81503267 - samples/sec: 152.05
2020-04-01 23:00:58,164 epoch 49 - iter 220/220 - loss 0.87899343 - samples/sec: 304.01
2020-04-01 23:01:03,238 ----------------------------------------------------------------------------------------------------
2020-04-01 23:01:03,238 EPOCH 49 done: loss 0.8790 - lr 0.0050
2020-04-01 23:01:07,183 DEV : loss 0.6165839433670044 - score 0.9288
2020-04-01 23:01:07,280 BAD EPOCHS (no improvement): 1
2020-04-01 23:01:07,289 ----------------------------------------------------------------------------------------------------
2020-04-01 23:01:14,880 epoch 32 - iter 430/439 - loss 0.79610077 - samples/sec: 165.87
2020-04-01 23:01:11,438 epoch 50 - iter 22/220 - loss 0.84127089 - samples/sec: 339.61

2020-04-01 23:01:22,797 ----------------------------------------------------------------------------------------------------
2020-04-01 23:01:22,797 EPOCH 32 done: loss 0.7964 - lr 0.0100
2020-04-01 23:01:27,232 DEV : loss 0.6159575581550598 - score 0.9291
2020-04-01 23:01:27,328 BAD EPOCHS (no improvement): 0
2020-04-01 23:01:28,874 ----------------------------------------------------------------------------------------------------
2020-04-01 23:01:21,879 epoch 50 - iter 44/220 - loss 0.86847088 - samples/sec: 326.21
2020-04-01 23:01:37,662 epoch 33 - iter 43/439 - loss 0.78701662 - samples/sec: 156.68
2020-04-01 23:01:31,679 epoch 50 - iter 66/220 - loss 0.85166987 - samples/sec: 389.89

2020-04-01 23:01:43,757 ---------------------------------------------------------------2020-04-01 23:01:41,507 epoch 50 - iter 88/220 - loss 0.84464591 - samples/sec: 431.32
3 - lr 0.0100
2020-04-01 23:01:48,869 DEV : loss 0.5851595401763916 - score 0.9303
2020-04-01 23:01:48,967 BAD EPOCHS (no improvement): 0
2020-04-01 23:01:50,251 ----------------------------------------------------------------------------------------------------
2020-04-01 23:01:51,721 epoch 33 - iter 86/439 - loss 0.76141810 - samples/sec: 175.38
2020-04-01 23:01:53,362 epoch 50 - iter 110/220 - loss 0.86005939 - samples/sec: 302.01
2020-04-01 23:02:06,534 epoch 33 - iter 129/439 - loss 0.77387964 - samples/sec: 166.55
2020-04-01 23:02:04,171 epoch 50 - iter 132/220 - loss 0.86943889 - samples/sec: 316.15
2020-04-01 23:02:19,821 epoch 4 - iter 129/439 - loss 2.10307605 - samples/sec: 156.84
2020-04-01 23:02:14,001 epoch 50 - iter 154/220 - loss 0.87793152 - samples/sec: 334.60
2020-04-01 23:02:23,837 epoch 50 - iter 176/220 - loss 0.87823994 - samples/sec: 324.52
2020-04-01 23:02:28,514 epoch 33 - iter 129/439 - loss 0.78818789 - samples/sec: 154.20
2020-04-01 23:02:32,884 epoch 50 - iter 198/220 - loss 0.87845014 - samples/sec: 427.69
2020-04-01 23:02:42,823 epoch 50 - iter 220/220 - loss 0.86986800 - samples/sec: 326.74
2020-04-01 23:02:49,417 ----------------------------------------------------------------------------------------------------
2020-04-01 23:02:49,417 EPOCH 50 done: loss 0.8699 - lr 0.0050
2020-04-01 23:02:53,371 DEV : loss 0.6075324416160583 - score 0.9299
2020-04-01 23:02:53,468 BAD EPOCHS (no improvement): 2
2020-04-01 23:02:53,580 ----------------------------------------------------------------------------------------------------
2020-04-01 23:02:57,721 epoch 51 - iter 22/220 - loss 0.89062015 - samples/sec: 340.24
2020-04-01 23:03:07,371 epoch 51 - iter 44/220 - loss 0.88084873 - samples/sec: 333.34

2020-04-01 23:03:17,531 epoch 51 - iter 66/220 - loss 0.86254424 - samples/sec: 324.30

2020-04-01 23:03:14,621 epoch 33 - iter 258/439 - loss 0.80572779 - samples/sec: 153.06
2020-04-01 23:03:28,332 epoch 51 - iter 88/220 - loss 0.86662257 - samples/sec: 338.52

2020-04-01 23:03:39,144 epoch 51 - iter 110/220 - loss 0.87136905 - samples/sec: 289.55
2020-04-01 23:03:49,450 epoch 51 - iter 132/220 - loss 0.86271944 - samples/sec: 329.30
2020-04-01 23:03:45,269 epoch 33 - iter 344/439 - loss 0.80393758 - samples/sec: 153.21
2020-04-01 23:04:00,307 epoch 51 - iter 154/220 - loss 0.87555305 - samples/sec: 301.70
-----------------------------------
2020-04-01 23:03:57,140 EPOCH 33 done: loss 0.7803 - lr 0.0100
2020-04-01 23:04:01,609 DEV : loss 0.6044745445251465 - score 0.9298
2020-04-01 23:04:01,707 BAD EPOCHS (no improvement): 0
2020-04-01 23:03:59,422 epoch 33 - iter 387/439 - loss 0.79770580 - samples/sec: 157.05
2020-04-01 23:04:05,573 epoch 4 - iter 172/439 - loss 2.08493361 - samples/sec: 168.83
2020-04-01 23:04:11,170 epoch 51 - iter 176/220 - loss 0.87562241 - samples/sec: 312.23
-----------------------------------
2020-04-01 23:04:11,489 epoch 34 - iter 43/439 - loss 0.72435830 - samples/sec: 169.23
2020-04-01 23:04:21,207 epoch 51 - iter 198/220 - loss 0.87084737 - samples/sec: 347.67
2020-04-01 23:04:29,934 epoch 51 - iter 220/220 - loss 0.87365773 - samples/sec: 437.55
020-04-01 23:04:22,966 ----------------------------------------------------------------------------------------------------
2020-04-01 23:04:22,967 EPOCH 33 done: loss 0.7884 - lr 0.0100
2020-04-01 23:04:27,414 DEV : loss 0.5714263916015625 - score 0.931
2020-04-01 23:04:27,510 BAD EPOCHS (no improvement): 0
2020-04-01 23:04:28,899 ----------------------------------------------------------------------------------------------------
2020-04-01 23:04:41,635 epoch 34 - iter 129/439 - loss 0.74839492 - samples/sec: 152.07
2020-04-01 23:04:37,943 epoch 34 - iter 43/439 - loss 0.82940938 - samples/sec: 152.24
2020-04-01 23:04:36,242 ----------------------------------------------------------------------------------------------------
2020-04-01 23:04:36,243 EPOCH 51 done: loss 0.8737 - lr 0.0050
2020-04-01 23:04:40,211 DEV : loss 0.6020563840866089 - score 0.9296
2020-04-01 23:04:40,309 BAD EPOCHS (no improvement): 3
2020-04-01 23:04:40,379 ----------------------------------------------------------------------------------------------------
2020-04-01 23:04:43,353 epoch 52 - iter 22/220 - loss 0.85854135 - samples/sec: 473.89
2020-04-01 23:04:52,322 epoch 52 - iter 44/220 - loss 0.86461594 - samples/sec: 465.06
2020-04-01 23:04:56,423 epoch 34 - iter 172/439 - loss 0.74530511 - samples/sec: 160.78
2020-04-01 23:04:53,452 epoch 34 - iter 86/439 - loss 0.82313955 - samples/sec: 151.83
2020-04-01 23:05:02,834 epoch 52 - iter 66/220 - loss 0.87265297 - samples/sec: 422.40
2020-04-01 23:05:12,365 epoch 52 - iter 88/220 - loss 0.87609755 - samples/sec: 419.40
2020-04-01 23:05:12,217 epoch 34 - iter 215/439 - loss 0.76361472 - samples/sec: 163.92
2020-04-01 23:05:23,785 epoch 52 - iter 110/220 - loss 0.86485320 - samples/sec: 324.78
2020-04-01 23:05:26,013 epoch 34 - iter 172/439 - loss 0.80431836 - samples/sec: 153.38
2020-04-01 23:05:34,069 epoch 52 - iter 132/220 - loss 0.87268152 - samples/sec: 310.82
2020-04-01 23:05:41,171 epoch 34 - iter 215/439 - loss 0.80452748 - samples/sec: 150.97
2020-04-01 23:05:44,296 epoch 52 - iter 154/220 - loss 0.86552534 - samples/sec: 328.74
2020-04-01 23:05:51,024 epoch 4 - iter 154/220 - loss 1.68751691 - samples/sec: 121.41
2020-04-01 23:05:54,936 epoch 4 - iter 215/439 - loss 2.05463495 - samples/sec: 168.08
2020-04-01 23:05:54,165 epoch 52 - iter 176/220 - loss 0.85419557 - samples/sec: 316.97
2020-04-01 23:05:55,822 epoch 34 - iter 258/439 - loss 0.78867374 - samples/sec: 151.61
2020-04-01 23:06:05,027 epoch 52 - iter 198/220 - loss 0.85376586 - samples/sec: 313.04
2020-04-01 23:06:11,316 epoch 34 - iter 301/439 - loss 0.80431342 - samples/sec: 151.59
2020-04-01 23:06:15,228 epoch 52 - iter 220/220 - loss 0.85887251 - samples/sec: 304.79
2020-04-01 23:06:21,311 ----------------------------------------------------------------------------------------------------
2020-04-01 23:06:21,312 EPOCH 52 done: loss 0.8589 - lr 0.0050
2020-04-01 23:06:26,561 epoch 34 - iter 430/439 - loss 0.77230559 - samples/sec: 156.85
2020-04-01 23:06:26,730 epoch 34 - iter 344/439 - loss 0.79728735 - samples/sec: 150.87
2020-04-01 23:06:25,257 DEV : loss 0.5996717214584351 - score 0.9305
2020-04-01 23:06:25,352 BAD EPOCHS (no improvement): 0
2020-04-01 23:06:26,710 ----------------------------------------------------------------------------------------------------
2020-04-01 23:06:31,396 epoch 53 - iter 22/220 - loss 0.90674307 - samples/sec: 300.79
2020-04-01 23:06:41,413 epoch 53 - iter 44/220 - loss 0.88240877 - samples/sec: 327.38
------------------------------------
2020-04-01 23:06:34,566 EPOCH 34 done: loss 0.7713 - lr 0.0100
2020-04-01 23:06:39,049 DEV : loss 0.6141831278800964 - score 0.9307
2020-04-01 23:06:39,147 BAD EPOCHS (no improvement): 0
2020-04-01 23:06:40,770 ----------------------------------------------------------------------------------------------------
2020-04-01 23:06:41,405 epoch 34 - iter 387/439 - loss 0.79276996 - samples/sec: 159.09
2020-04-01 23:06:49,412 epoch 35 - iter 43/439 - loss 0.73593295 - samples/sec: 159.31
------------------------------------
2020-04-01 23:06:44,835 EPOCH 2 done: loss 1.8517 - lr 0.0100
2020-04-01 23:06:50,976 epoch 53 - iter 66/220 - loss 0.87768360 - samples/sec: 428.23
2020-04-01 23:07:01,525 epoch 53 - iter 88/220 - loss 0.86395155 - samples/sec: 376.91

2020-04-01 23:07:07,307 DEV : loss 1.0049705505371094 - score 0.8981
2020-04-01 23:07:07,742 BAD EPOCHS (no improvement): 0
2020-04-01 23:07:12,019 epoch 53 - iter 110/220 - loss 0.86124028 - samples/sec: 372.27
020-04-01 23:07:04,784 ----------------------------------------------------------------------------------------------------
2020-04-01 23:07:04,785 EPOCH 34 done: loss 0.7943 - lr 0.0100
2020-04-01 23:07:09,258 DEV : loss 0.5777222514152527 - score 0.9324
2020-04-01 23:07:09,355 BAD EPOCHS (no improvement): 0
2020-04-01 23:07:10,727 ----------------------------------------------------------------------------------------------------
2020-04-01 23:07:19,194 epoch 35 - iter 129/439 - loss 0.74504721 - samples/sec: 179.93
2020-04-01 23:07:19,659 epoch 35 - iter 43/439 - loss 0.85053633 - samples/sec: 154.13
2020-04-01 23:07:48,733 epoch 35 - iter 172/439 - loss 0.75009355 - samples/sec: 167.91
2020-04-01 23:07:49,936 epoch 35 - iter 86/439 - loss 0.79379318 - samples/sec: 154.05
2020-04-01 23:08:04,042 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-01 23:08:10,559 epoch 53 - iter 132/220 - loss 0.86406524 - samples/sec: 364.56
2020-04-01 23:08:19,843 epoch 53 - iter 154/220 - loss 0.85971262 - samples/sec: 377.93
020-04-01 23:08:14,488 epoch 35 - iter 215/439 - loss 0.74936500 - samples/sec: 163.44
2020-04-01 23:08:15,097 epoch 35 - iter 129/439 - loss 0.80065861 - samples/sec: 152.89
2020-04-01 23:08:19,433 epoch 3 - iter 43/439 - loss 1.56940344 - samples/sec: 89.47
2020-04-01 23:08:30,701 epoch 53 - iter 176/220 - loss 0.85520296 - samples/sec: 319.44
2020-04-01 23:08:30,376 epoch 35 - iter 172/439 - loss 0.79430309 - samples/sec: 156.61
2020-04-01 23:08:43,483 epoch 53 - iter 198/220 - loss 0.85438022 - samples/sec: 304.99
2020-04-01 23:08:47,120 epoch 35 - iter 301/439 - loss 0.73785349 - samples/sec: 147.63
2020-04-01 23:08:53,844 epoch 53 - iter 220/220 - loss 0.85390587 - samples/sec: 322.67
2020-04-01 23:08:59,803 ----------------------------------------------------------------------------------------------------
2020-04-01 23:08:59,803 EPOCH 53 done: loss 0.8539 - lr 0.0050
2020-04-01 23:09:03,744 DEV : loss 0.5973268747329712 - score 0.9301
2020-04-01 23:09:03,842 BAD EPOCHS (no improvement): 1
2020-04-01 23:09:03,896 ----------------------------------------------------------------------------------------------------
2020-04-01 23:09:08,342 epoch 54 - iter 22/220 - loss 0.85751916 - samples/sec: 316.90
2020-04-01 23:09:17,859 epoch 35 - iter 387/439 - loss 0.74324163 - samples/sec: 155.25
2020-04-01 23:09:18,801 epoch 35 - iter 301/439 - loss 0.78769108 - samples/sec: 155.07
2020-04-01 23:09:19,339 epoch 54 - iter 44/220 - loss 0.84301236 - samples/sec: 327.00
2020-04-01 23:09:30,275 epoch 54 - iter 66/220 - loss 0.84355938 - samples/sec: 290.01

2020-04-01 23:09:34,021 epoch 35 - iter 344/439 - loss 0.78137614 - samples/sec: 151.91
2020-04-01 23:09:41,268 epoch 54 - iter 88/220 - loss 0.84235863 - samples/sec: 294.63
------------------------------------
2020-04-01 23:09:41,738 EPOCH 35 done: loss 0.7426 - lr 0.0100
2020-04-01 23:09:51,059 epoch 54 - iter 110/220 - loss 0.83258400 - samples/sec: 337.46
020-04-01 23:09:46,167 DEV : loss 0.5878394842147827 - score 0.9346
2020-04-01 23:09:46,263 BAD EPOCHS (no improvement): 0
2020-04-01 23:09:47,839 ----------------------------------------------------------------------------------------------------
2020-04-01 23:09:47,714 epoch 35 - iter 387/439 - loss 0.78611117 - samples/sec: 196.40
2020-04-01 23:10:02,168 epoch 54 - iter 132/220 - loss 0.83350892 - samples/sec: 278.78
020-04-01 23:10:02,905 epoch 35 - iter 430/439 - loss 0.77652599 - samples/sec: 163.98
2020-04-01 23:10:12,698 epoch 54 - iter 154/220 - loss 0.83361515 - samples/sec: 318.92
020-04-01 23:10:10,116 epoch 36 - iter 86/439 - loss 0.76681983 - samples/sec: 161.64
2020-04-01 23:10:10,849 ----------------------------------------------------------------------------------------------------
2020-04-01 23:10:10,850 EPOCH 35 done: loss 0.7793 - lr 0.0100
2020-04-01 23:10:22,721 epoch 54 - iter 176/220 - loss 0.83312565 - samples/sec: 321.75
,340 BAD EPOCHS (no improvement): 1
2020-04-01 23:10:15,431 ----------------------------------------------------------------------------------------------------
2020-04-01 23:10:24,852 epoch 36 - iter 129/439 - loss 0.72621273 - samples/sec: 157.98
2020-04-01 23:10:24,533 epoch 36 - iter 43/439 - loss 0.88801463 - samples/sec: 151.25
2020-04-01 23:10:35,110 epoch 54 - iter 198/220 - loss 0.83836145 - samples/sec: 326.87
2020-04-01 23:10:41,226 epoch 36 - iter 172/439 - loss 0.73583288 - samples/sec: 159.86
2020-04-01 23:10:41,370 epoch 36 - iter 86/439 - loss 0.82252281 - samples/sec: 152.15
2020-04-01 23:10:45,608 epoch 54 - iter 220/220 - loss 0.84752581 - samples/sec: 295.76
2020-04-01 23:10:51,772 ----------------------------------------------------------------------------------------------------
2020-04-01 23:10:51,772 EPOCH 54 done: loss 0.8475 - lr 0.0050
2020-04-01 23:10:55,712 DEV : loss 0.5962018370628357 - score 0.9297
2020-04-01 23:10:55,809 BAD EPOCHS (no improvement): 2
2020-04-01 23:10:55,863 ----------------------------------------------------------------------------------------------------
2020-04-01 23:11:00,290 epoch 55 - iter 22/220 - loss 0.84479655 - samples/sec: 318.24

2020-04-01 23:10:56,334 epoch 36 - iter 129/439 - loss 0.79084639 - samples/sec: 151.52
2020-04-01 23:11:10,446 epoch 55 - iter 44/220 - loss 0.85302875 - samples/sec: 340.11

2020-04-01 23:11:11,272 epoch 36 - iter 172/439 - loss 0.79128403 - samples/sec: 153.05
2020-04-01 23:11:21,638 epoch 55 - iter 66/220 - loss 0.83950487 - samples/sec: 311.05
2020-04-01 23:11:32,444 epoch 55 - iter 88/220 - loss 0.87151551 - samples/sec: 306.02

2020-04-01 23:11:26,826 epoch 36 - iter 215/439 - loss 0.80472571 - samples/sec: 153.36
2020-04-01 23:11:42,786 epoch 55 - iter 110/220 - loss 0.86440012 - samples/sec: 300.12
2020-04-01 23:11:41,943 epoch 36 - iter 258/439 - loss 0.79675669 - samples/sec: 148.71
2020-04-01 23:11:53,402 epoch 4 - iter 344/439 - loss 2.02047776 - samples/sec: 166.86
2020-04-01 23:11:53,730 epoch 55 - iter 132/220 - loss 0.86074965 - samples/sec: 308.17
2020-04-01 23:12:03,277 epoch 55 - iter 154/220 - loss 0.86888546 - samples/sec: 341.45
2020-04-01 23:11:57,697 epoch 36 - iter 301/439 - loss 0.78550973 - samples/sec: 152.57
2020-04-01 23:12:13,822 epoch 55 - iter 176/220 - loss 0.86066490 - samples/sec: 328.85
2020-04-01 23:12:12,525 epoch 36 - iter 344/439 - loss 0.77675937 - samples/sec: 153.12
2020-04-01 23:12:18,736 ----------------------------------------------------------------------------------------------------
2020-04-01 23:12:18,736 EPOCH 36 done: loss 0.7405 - lr 0.0100
2020-04-01 23:12:23,211 DEV : loss 0.5928775668144226 - score 0.9313
2020-04-01 23:12:23,308 BAD EPOCHS (no improvement): 1
2020-04-01 23:12:23,322 ----------------------------------------------------------------------------------------------------
2020-04-01 23:12:24,561 epoch 55 - iter 198/220 - loss 0.85994889 - samples/sec: 322.85
2020-04-01 23:12:31,296 epoch 37 - iter 43/439 - loss 0.75957418 - samples/sec: 172.65
2020-04-01 23:12:27,504 epoch 36 - iter 387/439 - loss 0.77906448 - samples/sec: 159.26
2020-04-01 23:12:35,970 epoch 55 - iter 220/220 - loss 0.85519916 - samples/sec: 275.99
2020-04-01 23:12:41,987 ----------------------------------------------------------------------------------------------------
2020-04-01 23:12:41,987 EPOCH 55 done: loss 0.8552 - lr 0.0050
2020-04-01 23:12:45,945 DEV : loss 0.5994859337806702 - score 0.93
2020-04-01 23:12:46,043 BAD EPOCHS (no improvement): 3
2020-04-01 23:12:46,104 ----------------------------------------------------------------------------------------------------
2020-04-01 23:12:50,457 epoch 56 - iter 22/220 - loss 0.79533450 - samples/sec: 323.66
2020-04-01 23:12:50,651 ----------------------------------------------------------------------------------------------------
2020-04-01 23:12:50,652 EPOCH 36 done: loss 0.7730 - lr 0.0100
2020-04-01 23:13:01,209 epoch 56 - iter 44/220 - loss 0.84414409 - samples/sec: 314.41

2020-04-01 23:12:55,057 DEV : loss 0.5695967674255371 - score 0.9312
2020-04-01 23:12:55,152 BAD EPOCHS (no improvement): 2
2020-04-01 23:12:55,183 ----------------------------------------------------------------------------------------------------
2020-04-01 23:13:04,421 epoch 37 - iter 43/439 - loss 0.85949596 - samples/sec: 149.02
2020-04-01 23:13:11,084 epoch 56 - iter 66/220 - loss 0.84900789 - samples/sec: 362.46

2020-04-01 23:13:20,934 epoch 56 - iter 88/220 - loss 0.85603035 - samples/sec: 369.31
2020-04-01 23:13:25,712 epoch 4 - iter 198/220 - loss 1.68305520 - samples/sec: 115.83
2020-04-01 23:13:29,021 epoch 37 - iter 215/439 - loss 0.72812305 - samples/sec: 155.11
2020-04-01 23:13:34,253 epoch 37 - iter 129/439 - loss 0.80044197 - samples/sec: 155.45
2020-04-01 23:13:34,185 epoch 3 - iter 86/439 - loss 1.51892869 - samples/sec: 91.50
2020-04-01 23:13:29,882 epoch 56 - iter 110/220 - loss 0.85973144 - samples/sec: 480.75
2020-04-01 23:13:37,606 epoch 4 - iter 387/439 - loss 2.00768167 - samples/sec: 208.82
2020-04-01 23:13:44,044 epoch 37 - iter 258/439 - loss 0.74015119 - samples/sec: 154.60
2020-04-01 23:13:39,285 epoch 56 - iter 132/220 - loss 0.85142494 - samples/sec: 421.06
2020-04-01 23:13:49,340 epoch 37 - iter 172/439 - loss 0.80509834 - samples/sec: 150.93
2020-04-01 23:13:49,000 epoch 56 - iter 154/220 - loss 0.85908228 - samples/sec: 329.91
2020-04-01 23:13:58,642 epoch 37 - iter 301/439 - loss 0.73870101 - samples/sec: 154.94
2020-04-01 23:14:04,597 epoch 37 - iter 215/439 - loss 0.79772542 - samples/sec: 152.12
2020-04-01 23:13:59,443 epoch 56 - iter 176/220 - loss 0.84456782 - samples/sec: 332.47
2020-04-01 23:14:13,613 epoch 37 - iter 344/439 - loss 0.73991623 - samples/sec: 152.31
2020-04-01 23:14:09,785 epoch 56 - iter 198/220 - loss 0.84368014 - samples/sec: 312.16
2020-04-01 23:14:19,245 epoch 37 - iter 258/439 - loss 0.78754404 - samples/sec: 152.43
2020-04-01 23:14:20,008 epoch 56 - iter 220/220 - loss 0.83848403 - samples/sec: 282.86
2020-04-01 23:14:26,047 ----------------------------------------------------------------------------------------------------
2020-04-01 23:14:26,048 EPOCH 56 done: loss 0.8385 - lr 0.0050
2020-04-01 23:14:28,556 epoch 37 - iter 387/439 - loss 0.74156375 - samples/sec: 149.10
2020-04-01 23:14:34,486 epoch 37 - iter 301/439 - loss 0.78374450 - samples/sec: 149.21
2020-04-01 23:14:30,610 DEV : loss 0.5966566205024719 - score 0.9288
Epoch    56: reducing learning rate of group 0 to 2.5000e-03.
2020-04-01 23:14:30,707 BAD EPOCHS (no improvement): 4
2020-04-01 23:14:30,776 ----------------------------------------------------------------------------------------------------
2020-04-01 23:14:34,985 epoch 57 - iter 22/220 - loss 0.81223166 - samples/sec: 334.74
2020-04-01 23:14:42,641 epoch 37 - iter 430/439 - loss 0.73484531 - samples/sec: 153.23
2020-04-01 23:14:45,014 epoch 57 - iter 44/220 - loss 0.84274446 - samples/sec: 297.93
2020-04-01 23:14:54,184 epoch 57 - iter 66/220 - loss 0.84347022 - samples/sec: 443.48
------------------------------------
2020-04-01 23:14:50,525 EPOCH 37 done: loss 0.7342 - lr 0.0100
2020-04-01 23:14:48,761 epoch 37 - iter 344/439 - loss 0.79289217 - samples/sec: 154.44
2020-04-01 23:15:03,107 epoch 57 - iter 88/220 - loss 0.83629867 - samples/sec: 428.09
,089 BAD EPOCHS (no improvement): 2
2020-04-01 23:14:55,121 ----------------------------------------------------------------------------------------------------
2020-04-01 23:15:04,051 epoch 38 - iter 43/439 - loss 0.72912269 - samples/sec: 154.17
2020-04-01 23:15:03,529 epoch 37 - iter 387/439 - loss 0.78393225 - samples/sec: 154.53
2020-04-01 23:15:12,647 epoch 57 - iter 110/220 - loss 0.83924523 - samples/sec: 422.37
2020-04-01 23:15:22,409 epoch 57 - iter 132/220 - loss 0.83082729 - samples/sec: 428.53
020-04-01 23:15:19,088 epoch 38 - iter 86/439 - loss 0.71986534 - samples/sec: 153.58
2020-04-01 23:15:18,732 epoch 37 - iter 430/439 - loss 0.77961141 - samples/sec: 152.38
2020-04-01 23:15:33,474 epoch 38 - iter 129/439 - loss 0.72621501 - samples/sec: 159.21
2020-04-01 23:15:26,414 ----------------------------------------------------------------------------------------------------
2020-04-01 23:15:26,414 EPOCH 37 done: loss 0.7793 - lr 0.0100
2020-04-01 23:15:30,871 DEV : loss 0.5663135051727295 - score 0.9329
2020-04-01 23:15:30,970 BAD EPOCHS (no improvement): 0
2020-04-01 23:15:32,298 ----------------------------------------------------------------------------------------------------
2020-04-01 23:15:30,852 epoch 57 - iter 154/220 - loss 0.82879923 - samples/sec: 429.77
2020-04-01 23:15:41,513 epoch 38 - iter 43/439 - loss 0.81926616 - samples/sec: 149.40
2020-04-01 23:15:40,752 epoch 57 - iter 176/220 - loss 0.83043538 - samples/sec: 419.09
2020-04-01 23:15:48,362 epoch 38 - iter 172/439 - loss 0.73172106 - samples/sec: 153.26
2020-04-01 23:15:50,012 epoch 57 - iter 198/220 - loss 0.82664429 - samples/sec: 441.98
2020-04-01 23:16:03,398 epoch 38 - iter 215/439 - loss 0.73262093 - samples/sec: 158.14
2020-04-01 23:15:56,499 epoch 38 - iter 86/439 - loss 0.76833610 - samples/sec: 154.33
2020-04-01 23:15:59,746 epoch 57 - iter 220/220 - loss 0.82314282 - samples/sec: 436.50
2020-04-01 23:16:05,923 ----------------------------------------------------------------------------------------------------
2020-04-01 23:16:05,923 EPOCH 57 done: loss 0.8231 - lr 0.0025
2020-04-01 23:16:09,869 DEV : loss 0.5933665633201599 - score 0.9302
2020-04-01 23:16:09,966 BAD EPOCHS (no improvement): 1
2020-04-01 23:16:09,989 ----------------------------------------------------------------------------------------------------
2020-04-01 23:16:13,023 epoch 58 - iter 22/220 - loss 0.89079774 - samples/sec: 464.50
2020-04-01 23:16:22,523 epoch 58 - iter 44/220 - loss 0.86581052 - samples/sec: 419.75

2020-04-01 23:16:31,875 epoch 58 - iter 66/220 - loss 0.84474394 - samples/sec: 434.07

2020-04-01 23:16:26,380 epoch 38 - iter 172/439 - loss 0.73803289 - samples/sec: 152.65
2020-04-01 23:16:40,400 epoch 38 - iter 215/439 - loss 0.74288084 - samples/sec: 159.27
2020-04-01 23:16:40,905 epoch 58 - iter 88/220 - loss 0.84586564 - samples/sec: 430.23
2020-04-01 23:16:46,784 epoch 38 - iter 344/439 - loss 0.74024839 - samples/sec: 149.10
2020-04-01 23:16:50,576 epoch 58 - iter 110/220 - loss 0.83345659 - samples/sec: 426.84
2020-04-01 23:16:57,679 ----------------------------------------------------------------------------------------------------
2020-04-01 23:16:57,680 EPOCH 4 done: loss 1.9923 - lr 0.0100
2020-04-01 23:17:02,431 DEV : loss 1.2282391786575317 - score 0.8862
2020-04-01 23:17:02,527 BAD EPOCHS (no improvement): 0
2020-04-01 23:17:02,040 epoch 38 - iter 387/439 - loss 0.73469918 - samples/sec: 155.01
2020-04-01 23:16:55,974 epoch 38 - iter 258/439 - loss 0.75008668 - samples/sec: 148.08
2020-04-01 23:16:59,865 epoch 58 - iter 132/220 - loss 0.82278403 - samples/sec: 424.11
2020-04-01 23:17:11,175 ----------------------------------------------------------------------------------------------------
2020-04-01 23:17:11,395 epoch 38 - iter 301/439 - loss 0.75564605 - samples/sec: 156.33
2020-04-01 23:17:20,652 epoch 38 - iter 430/439 - loss 0.72862818 - samples/sec: 152.73
2020-04-01 23:17:19,142 epoch 5 - iter 43/439 - loss 1.71386895 - samples/sec: 172.85
2020-04-01 23:17:21,459 epoch 58 - iter 176/220 - loss 0.82313729 - samples/sec: 302.07
2020-04-01 23:17:28,501 ----------------------------------------------------------------------------------------------------
2020-04-01 23:17:28,502 EPOCH 38 done: loss 0.7250 - lr 0.0100
2020-04-01 23:17:32,991 DEV : loss 0.5736426115036011 - score 0.9343
2020-04-01 23:17:33,090 BAD EPOCHS (no improvement): 3
2020-04-01 23:17:33,119 ----------------------------------------------------------------------------------------------------
2020-04-01 23:17:26,145 epoch 38 - iter 344/439 - loss 0.75319483 - samples/sec: 152.62
2020-04-01 23:17:32,126 epoch 58 - iter 198/220 - loss 0.83260278 - samples/sec: 300.69
2020-04-01 23:17:42,125 epoch 39 - iter 43/439 - loss 0.75383163 - samples/sec: 152.86
2020-04-01 23:17:41,256 epoch 38 - iter 387/439 - loss 0.74747294 - samples/sec: 151.22
2020-04-01 23:17:43,199 epoch 58 - iter 220/220 - loss 0.83414435 - samples/sec: 305.68
2020-04-01 23:17:49,943 ----------------------------------------------------------------------------------------------------
2020-04-01 23:17:49,943 EPOCH 58 done: loss 0.8341 - lr 0.0025
2020-04-01 23:17:53,871 DEV : loss 0.5939693450927734 - score 0.9303
2020-04-01 23:17:53,968 BAD EPOCHS (no improvement): 2
2020-04-01 23:17:54,043 ----------------------------------------------------------------------------------------------------
2020-04-01 23:17:58,315 epoch 59 - iter 22/220 - loss 0.82443288 - samples/sec: 329.83
2020-04-01 23:17:57,802 epoch 39 - iter 86/439 - loss 0.73986168 - samples/sec: 151.30
2020-04-01 23:17:56,843 epoch 38 - iter 430/439 - loss 0.74487899 - samples/sec: 152.07
2020-04-01 23:18:04,912 ----------------------------------------------------------------------------------------------------
2020-04-01 23:18:04,912 EPOCH 38 done: loss 0.7451 - lr 0.0100
2020-04-01 23:18:12,665 epoch 39 - iter 129/439 - loss 0.72481637 - samples/sec: 158.70
2020-04-01 23:18:09,379 DEV : loss 0.5651977062225342 - score 0.9341
2020-04-01 23:18:09,476 BAD EPOCHS (no improvement): 0
2020-04-01 23:18:10,889 ----------------------------------------------------------------------------------------------------
2020-04-01 23:18:19,218 epoch 59 - iter 66/220 - loss 0.83544922 - samples/sec: 290.41
2020-04-01 23:18:19,884 epoch 39 - iter 43/439 - loss 0.70162608 - samples/sec: 153.06
2020-04-01 23:18:29,541 epoch 59 - iter 88/220 - loss 0.81751877 - samples/sec: 332.14
2020-04-01 23:18:27,253 epoch 39 - iter 172/439 - loss 0.71131649 - samples/sec: 154.49
2020-04-01 23:18:35,201 epoch 39 - iter 86/439 - loss 0.70209023 - samples/sec: 150.57
2020-04-01 23:18:39,018 epoch 59 - iter 110/220 - loss 0.81491689 - samples/sec: 395.41
2020-04-01 23:18:41,963 epoch 39 - iter 215/439 - loss 0.71004008 - samples/sec: 152.25
2020-04-01 23:18:42,855 epoch 3 - iter 129/439 - loss 1.54370284 - samples/sec: 91.19
2020-04-01 23:18:48,719 epoch 59 - iter 132/220 - loss 0.82081577 - samples/sec: 382.15
2020-04-01 23:18:49,552 epoch 39 - iter 129/439 - loss 0.71998952 - samples/sec: 151.60
2020-04-01 23:18:59,668 epoch 59 - iter 154/220 - loss 0.82995731 - samples/sec: 322.77
2020-04-01 23:19:01,858 epoch 5 - iter 86/439 - loss 1.81896122 - samples/sec: 282.63
2020-04-01 23:18:56,698 epoch 39 - iter 258/439 - loss 0.71952268 - samples/sec: 152.39
2020-04-01 23:19:05,059 epoch 39 - iter 172/439 - loss 0.73389598 - samples/sec: 153.15
2020-04-01 23:19:11,393 epoch 39 - iter 301/439 - loss 0.71628122 - samples/sec: 152.19
2020-04-01 23:19:20,217 epoch 39 - iter 215/439 - loss 0.73180091 - samples/sec: 153.51
2020-04-01 23:19:31,223 epoch 59 - iter 220/220 - loss 0.82773006 - samples/sec: 321.33
2020-04-01 23:19:26,161 epoch 39 - iter 344/439 - loss 0.70924045 - samples/sec: 151.20
2020-04-01 23:19:35,623 epoch 39 - iter 258/439 - loss 0.73099246 - samples/sec: 153.53
2020-04-01 23:19:41,185 epoch 39 - iter 387/439 - loss 0.70939170 - samples/sec: 154.73
-----------------------------------
2020-04-01 23:19:37,043 EPOCH 59 done: loss 0.8277 - lr 0.0025
2020-04-01 23:19:40,957 DEV : loss 0.593960702419281 - score 0.9304
2020-04-01 23:19:41,055 BAD EPOCHS (no improvement): 3
2020-04-01 23:19:41,092 ----------------------------------------------------------------------------------------------------
2020-04-01 23:19:51,473 epoch 39 - iter 301/439 - loss 0.74044351 - samples/sec: 147.33
2020-04-01 23:19:54,739 epoch 60 - iter 44/220 - loss 0.86229699 - samples/sec: 325.84
2020-04-01 23:19:56,288 epoch 39 - iter 430/439 - loss 0.71256332 - samples/sec: 152.74
2020-04-01 23:20:04,363 ----------------------------------------------------------------------------------------------------
2020-04-01 23:20:04,363 EPOCH 39 done: loss 0.7111 - lr 0.0100
2020-04-01 23:20:05,433 epoch 60 - iter 66/220 - loss 0.87777853 - samples/sec: 314.62
2020-04-01 23:20:08,858 DEV : loss 0.5805408358573914 - score 0.9341
Epoch    39: reducing learning rate of group 0 to 5.0000e-03.
2020-04-01 23:20:08,957 BAD EPOCHS (no improvement): 4
2020-04-01 23:20:08,997 ----------------------------------------------------------------------------------------------------
2020-04-01 23:20:08,324 epoch 39 - iter 344/439 - loss 0.73715287 - samples/sec: 161.69
2020-04-01 23:20:16,050 epoch 60 - iter 88/220 - loss 0.85908851 - samples/sec: 326.60
2020-04-01 23:20:23,646 ----------------------------------------------------------------------------------------------------
2020-04-01 23:20:23,646 EPOCH 4 done: loss 1.6724 - lr 0.0100
2020-04-01 23:20:18,032 epoch 40 - iter 43/439 - loss 0.63139581 - samples/sec: 152.36
2020-04-01 23:20:24,351 epoch 39 - iter 387/439 - loss 0.74143488 - samples/sec: 151.70
2020-04-01 23:20:33,112 epoch 40 - iter 86/439 - loss 0.64964940 - samples/sec: 152.73

2020-04-01 23:20:36,927 epoch 60 - iter 132/220 - loss 0.83887133 - samples/sec: 308.98
2020-04-01 23:20:37,906 DEV : loss 1.1233716011047363 - score 0.8829
2020-04-01 23:20:38,313 BAD EPOCHS (no improvement): 0
2020-04-01 23:20:39,596 epoch 39 - iter 430/439 - loss 0.73703205 - samples/sec: 153.23
2020-04-01 23:20:47,370 epoch 40 - iter 129/439 - loss 0.65472501 - samples/sec: 154.23
2020-04-01 23:20:51,298 epoch 5 - iter 129/439 - loss 1.80709747 - samples/sec: 172.24
2020-04-01 23:20:46,853 ----------------------------------------------------------------------------------------------------
2020-04-01 23:20:46,853 EPOCH 39 done: loss 0.7371 - lr 0.0100
2020-04-01 23:20:51,314 DEV : loss 0.5500827431678772 - score 0.934
2020-04-01 23:20:51,411 BAD EPOCHS (no improvement): 1
2020-04-01 23:20:51,506 ----------------------------------------------------------------------------------------------------
2020-04-01 23:21:13,568 epoch 60 - iter 176/220 - loss 0.83112255 - samples/sec: 272.19
2020-04-01 23:21:00,484 epoch 40 - iter 43/439 - loss 0.72334961 - samples/sec: 153.34
2020-04-01 23:21:16,707 epoch 40 - iter 172/439 - loss 0.65830716 - samples/sec: 151.60
2020-04-01 23:21:20,820 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-01 23:21:34,137 epoch 40 - iter 215/439 - loss 0.68539455 - samples/sec: 155.70
2020-04-01 23:21:28,661 epoch 40 - iter 86/439 - loss 0.73215550 - samples/sec: 152.52
020-04-01 23:21:29,313 epoch 60 - iter 198/220 - loss 0.83396588 - samples/sec: 350.94
2020-04-01 23:21:43,481 epoch 40 - iter 129/439 - loss 0.73332859 - samples/sec: 151.29
2020-04-01 23:21:45,680 ----------------------------------------------------------------------------------------------------
2020-04-01 23:21:45,681 EPOCH 60 done: loss 0.8256 - lr 0.0025
2020-04-01 23:21:49,634 DEV : loss 0.5906031131744385 - score 0.9306
2020-04-01 23:21:49,730 BAD EPOCHS (no improvement): 0
2020-04-01 23:21:51,066 ----------------------------------------------------------------------------------------------------
2020-04-01 23:21:55,318 epoch 61 - iter 22/220 - loss 0.81448024 - samples/sec: 331.38
2020-04-01 23:22:05,485 epoch 61 - iter 44/220 - loss 0.84322141 - samples/sec: 348.49

2020-04-01 23:21:58,733 epoch 40 - iter 172/439 - loss 0.72236649 - samples/sec: 151.50
2020-04-01 23:22:14,245 epoch 40 - iter 215/439 - loss 0.72129570 - samples/sec: 151.67
2020-04-01 23:22:26,219 epoch 61 - iter 88/220 - loss 0.82628132 - samples/sec: 344.73

2020-04-01 23:22:36,232 epoch 61 - iter 110/220 - loss 0.82343297 - samples/sec: 328.75
2020-04-01 23:22:29,621 epoch 40 - iter 258/439 - loss 0.71715087 - samples/sec: 153.49
2020-04-01 23:22:46,242 epoch 61 - iter 132/220 - loss 0.82545875 - samples/sec: 333.25
2020-04-01 23:22:56,436 epoch 61 - iter 154/220 - loss 0.82393321 - samples/sec: 356.57
2020-04-01 23:22:58,148 ----------------------------------------------------------------------------------------------------
2020-04-01 23:22:58,149 EPOCH 40 done: loss 0.6903 - lr 0.0050
2020-04-01 23:23:06,005 epoch 61 - iter 176/220 - loss 0.82589779 - samples/sec: 361.63
020-04-01 23:23:02,621 DEV : loss 0.5732871890068054 - score 0.9335
2020-04-01 23:23:02,719 BAD EPOCHS (no improvement): 1
2020-04-01 23:23:02,746 ----------------------------------------------------------------------------------------------------
2020-04-01 23:23:00,008 epoch 40 - iter 344/439 - loss 0.72218906 - samples/sec: 156.74
2020-04-01 23:23:15,245 epoch 61 - iter 198/220 - loss 0.81854743 - samples/sec: 344.59
020-04-01 23:23:15,451 epoch 40 - iter 387/439 - loss 0.73366985 - samples/sec: 154.64
2020-04-01 23:23:24,481 epoch 61 - iter 220/220 - loss 0.82435750 - samples/sec: 442.01
2020-04-01 23:23:29,956 ----------------------------------------------------------------------------------------------------
2020-04-01 23:23:29,956 EPOCH 61 done: loss 0.8244 - lr 0.0025
2020-04-01 23:23:33,909 DEV : loss 0.5921475887298584 - score 0.9303
2020-04-01 23:23:34,008 BAD EPOCHS (no improvement): 1
2020-04-01 23:23:34,103 ----------------------------------------------------------------------------------------------------
2020-04-01 23:23:37,102 epoch 62 - iter 22/220 - loss 0.82354052 - samples/sec: 469.83
2020-04-01 23:23:47,151 epoch 62 - iter 44/220 - loss 0.80375364 - samples/sec: 424.48

2020-04-01 23:23:39,425 ----------------------------------------------------------------------------------------------------
2020-04-01 23:23:39,426 EPOCH 40 done: loss 0.7302 - lr 0.0100
2020-04-01 23:23:43,888 DEV : loss 0.5488343238830566 - score 0.9352
2020-04-01 23:23:43,985 BAD EPOCHS (no improvement): 0
2020-04-01 23:23:45,350 ----------------------------------------------------------------------------------------------------
2020-04-01 23:23:56,712 epoch 62 - iter 66/220 - loss 0.80026305 - samples/sec: 420.69

2020-04-01 23:23:54,742 epoch 41 - iter 43/439 - loss 0.71975821 - samples/sec: 146.59
2020-04-01 23:24:07,809 epoch 62 - iter 88/220 - loss 0.80418231 - samples/sec: 378.94
2020-04-01 23:24:16,131 epoch 3 - iter 172/439 - loss 1.53181745 - samples/sec: 85.05

2020-04-01 23:24:10,337 epoch 41 - iter 86/439 - loss 0.76023212 - samples/sec: 154.01
2020-04-01 23:24:17,307 epoch 62 - iter 110/220 - loss 0.82022508 - samples/sec: 397.45
2020-04-01 23:24:27,550 epoch 62 - iter 132/220 - loss 0.83474305 - samples/sec: 327.63
2020-04-01 23:24:38,332 epoch 62 - iter 154/220 - loss 0.82045618 - samples/sec: 343.91
2020-04-01 23:24:48,911 epoch 62 - iter 176/220 - loss 0.82238302 - samples/sec: 315.31
2020-04-01 23:24:40,893 epoch 41 - iter 172/439 - loss 0.73195169 - samples/sec: 150.00
2020-04-01 23:24:49,499 epoch 5 - iter 215/439 - loss 1.80518613 - samples/sec: 183.21
2020-04-01 23:24:59,224 epoch 62 - iter 198/220 - loss 0.82627157 - samples/sec: 294.18
2020-04-01 23:24:59,685 epoch 41 - iter 344/439 - loss 0.68963447 - samples/sec: 148.41
2020-04-01 23:25:09,902 epoch 62 - iter 220/220 - loss 0.82362215 - samples/sec: 312.90
2020-04-01 23:25:15,907 ----------------------------------------------------------------------------------------------------
2020-04-01 23:25:15,908 EPOCH 62 done: loss 0.8236 - lr 0.0025
2020-04-01 23:25:19,854 DEV : loss 0.5882090330123901 - score 0.9302
2020-04-01 23:25:19,949 BAD EPOCHS (no improvement): 2
2020-04-01 23:25:19,998 ----------------------------------------------------------------------------------------------------
2020-04-01 23:25:23,946 epoch 63 - iter 22/220 - loss 0.81255993 - samples/sec: 356.90
2020-04-01 23:25:34,976 epoch 63 - iter 44/220 - loss 0.82254837 - samples/sec: 315.57

2020-04-01 23:25:38,325 ----------------------------------------------------------------------------------------------------
2020-04-01 23:25:38,325 EPOCH 41 done: loss 0.6837 - lr 0.0050
2020-04-01 23:25:44,863 epoch 63 - iter 66/220 - loss 0.82292772 - samples/sec: 405.25
2,850 BAD EPOCHS (no improvement): 0
2020-04-01 23:25:44,444 ----------------------------------------------------------------------------------------------------
2020-04-01 23:25:42,025 epoch 41 - iter 344/439 - loss 0.71456527 - samples/sec: 154.96
2020-04-01 23:25:54,369 epoch 63 - iter 88/220 - loss 0.82533747 - samples/sec: 433.35
2020-04-01 23:25:58,424 epoch 41 - iter 387/439 - loss 0.71695549 - samples/sec: 152.25
2020-04-01 23:26:03,885 epoch 63 - iter 110/220 - loss 0.81162299 - samples/sec: 429.61
2020-04-01 23:26:13,094 epoch 41 - iter 430/439 - loss 0.71610014 - samples/sec: 160.16
2020-04-01 23:26:13,298 epoch 63 - iter 132/220 - loss 0.82918515 - samples/sec: 422.85
2020-04-01 23:26:22,909 epoch 63 - iter 154/220 - loss 0.82960645 - samples/sec: 424.36
2020-04-01 23:26:21,315 ----------------------------------------------------------------------------------------------------
2020-04-01 23:26:21,316 EPOCH 41 done: loss 0.7210 - lr 0.0100
2020-04-01 23:26:25,797 DEV : loss 0.5615535378456116 - score 0.9335
2020-04-01 23:26:25,894 BAD EPOCHS (no improvement): 1
2020-04-01 23:26:25,967 ----------------------------------------------------------------------------------------------------
2020-04-01 23:26:38,257 epoch 42 - iter 172/439 - loss 0.65914362 - samples/sec: 151.082020-04-01 23:26:32,672 epoch 63 - iter 176/220 - loss 0.82835658 - samples/sec: 388.80
2020-04-01 23:26:43,070 epoch 63 - iter 198/220 - loss 0.82391174 - samples/sec: 329.60
2020-04-01 23:26:53,213 epoch 63 - iter 220/220 - loss 0.82450108 - samples/sec: 351.77
2020-04-01 23:26:59,566 ----------------------------------------------------------------------------------------------------
2020-04-01 23:26:59,566 EPOCH 63 done: loss 0.8245 - lr 0.0025
2020-04-01 23:27:08,769 epoch 42 - iter 258/439 - loss 0.67145109 - samples/sec: 157.19
2020-04-01 23:27:05,892 epoch 42 - iter 129/439 - loss 0.72254345 - samples/sec: 155.03
2020-04-01 23:27:03,521 DEV : loss 0.5907836556434631 - score 0.9311
2020-04-01 23:27:03,619 BAD EPOCHS (no improvement): 0
2020-04-01 23:27:04,816 ----------------------------------------------------------------------------------------------------
2020-04-01 23:27:08,941 epoch 64 - iter 22/220 - loss 0.85585207 - samples/sec: 341.54
2020-04-01 23:27:20,758 epoch 64 - iter 44/220 - loss 0.80624650 - samples/sec: 323.90

2020-04-01 23:27:22,527 epoch 42 - iter 172/439 - loss 0.69981789 - samples/sec: 152.94
2020-04-01 23:27:31,428 epoch 64 - iter 66/220 - loss 0.80592669 - samples/sec: 298.07

2020-04-01 23:27:41,468 epoch 64 - iter 88/220 - loss 0.79428798 - samples/sec: 303.01

2020-04-01 23:27:50,494 epoch 64 - iter 110/220 - loss 0.79410725 - samples/sec: 430.21
2020-04-01 23:27:51,959 epoch 42 - iter 258/439 - loss 0.71531586 - samples/sec: 153.01
2020-04-01 23:28:00,901 epoch 64 - iter 132/220 - loss 0.80234825 - samples/sec: 348.70
2020-04-01 23:28:07,485 epoch 42 - iter 301/439 - loss 0.70868243 - samples/sec: 152.85
2020-04-01 23:28:10,756 epoch 64 - iter 154/220 - loss 0.79993453 - samples/sec: 382.78
-----------------------------------
2020-04-01 23:28:18,104 EPOCH 42 done: loss 0.6729 - lr 0.0050
2020-04-01 23:28:24,774 epoch 5 - iter 301/439 - loss 1.81577019 - samples/sec: 159.85
2020-04-01 23:28:21,654 epoch 64 - iter 176/220 - loss 0.81009206 - samples/sec: 314.60
335 BAD EPOCHS (no improvement): 1
2020-04-01 23:28:23,347 ----------------------------------------------------------------------------------------------------
2020-04-01 23:28:22,282 epoch 42 - iter 344/439 - loss 0.71231770 - samples/sec: 163.00
2020-04-01 23:28:31,742 epoch 64 - iter 198/220 - loss 0.80746261 - samples/sec: 319.37
020-04-01 23:28:37,080 epoch 42 - iter 387/439 - loss 0.70669143 - samples/sec: 152.78
2020-04-01 23:28:41,958 epoch 64 - iter 220/220 - loss 0.80789094 - samples/sec: 330.48
2020-04-01 23:28:47,970 ----------------------------------------------------------------------------------------------------
2020-04-01 23:28:47,970 EPOCH 64 done: loss 0.8079 - lr 0.0025
2020-04-01 23:28:52,540 DEV : loss 0.5904819965362549 - score 0.9301
2020-04-01 23:28:52,639 BAD EPOCHS (no improvement): 1
2020-04-01 23:28:52,681 ----------------------------------------------------------------------------------------------------
2020-04-01 23:28:56,932 epoch 65 - iter 22/220 - loss 0.87575196 - samples/sec: 331.41
2020-04-01 23:29:06,893 epoch 65 - iter 44/220 - loss 0.84949564 - samples/sec: 322.71

2020-04-01 23:29:01,217 ----------------------------------------------------------------------------------------------------
2020-04-01 23:29:01,218 EPOCH 42 done: loss 0.7097 - lr 0.0100
2020-04-01 23:29:05,695 DEV : loss 0.542456865310669 - score 0.9357
2020-04-01 23:29:05,791 BAD EPOCHS (no improvement): 0
2020-04-01 23:29:07,126 ----------------------------------------------------------------------------------------------------
2020-04-01 23:29:16,420 epoch 65 - iter 66/220 - loss 0.82553728 - samples/sec: 383.94

2020-04-01 23:29:16,300 epoch 43 - iter 43/439 - loss 0.73482378 - samples/sec: 150.08
2020-04-01 23:29:27,441 epoch 3 - iter 215/439 - loss 1.50064437 - samples/sec: 88.18
2020-04-01 23:29:25,906 epoch 65 - iter 88/220 - loss 0.81738506 - samples/sec: 401.30
2020-04-01 23:29:36,160 epoch 65 - iter 110/220 - loss 0.79823258 - samples/sec: 337.84
2020-04-01 23:29:31,931 epoch 43 - iter 215/439 - loss 0.68184531 - samples/sec: 156.52
2020-04-01 23:29:31,375 epoch 43 - iter 86/439 - loss 0.71864266 - samples/sec: 152.35
2020-04-01 23:29:56,374 epoch 43 - iter 258/439 - loss 0.67581967 - samples/sec: 157.60
2020-04-01 23:29:55,630 epoch 43 - iter 129/439 - loss 0.70303017 - samples/sec: 149.35
2020-04-01 23:30:15,962 epoch 65 - iter 154/220 - loss 0.79991585 - samples/sec: 313.63
2020-04-01 23:30:26,369 epoch 65 - iter 176/220 - loss 0.80237530 - samples/sec: 302.82
2020-04-01 23:30:20,411 epoch 43 - iter 301/439 - loss 0.67579516 - samples/sec: 152.88
2020-04-01 23:30:19,694 epoch 43 - iter 172/439 - loss 0.69867376 - samples/sec: 150.67
2020-04-01 23:30:35,657 epoch 43 - iter 344/439 - loss 0.67632420 - samples/sec: 151.19
2020-04-01 23:30:35,040 epoch 43 - iter 215/439 - loss 0.68609781 - samples/sec: 150.39
2020-04-01 23:30:47,104 epoch 65 - iter 220/220 - loss 0.80955696 - samples/sec: 356.71
2020-04-01 23:30:53,588 ----------------------------------------------------------------------------------------------------
2020-04-01 23:30:53,588 EPOCH 65 done: loss 0.8096 - lr 0.0025
2020-04-01 23:30:51,267 epoch 43 - iter 387/439 - loss 0.66486684 - samples/sec: 153.81
2020-04-01 23:30:50,647 epoch 43 - iter 258/439 - loss 0.70057293 - samples/sec: 152.48
2020-04-01 23:31:06,173 epoch 43 - iter 301/439 - loss 0.70425305 - samples/sec: 153.11
,592 BAD EPOCHS (no improvement): 2
2020-04-01 23:30:57,626 ----------------------------------------------------------------------------------------------------
2020-04-01 23:31:02,079 epoch 66 - iter 22/220 - loss 0.82008329 - samples/sec: 316.47
2020-04-01 23:31:06,754 epoch 43 - iter 430/439 - loss 0.66664296 - samples/sec: 153.34
2020-04-01 23:31:36,618 epoch 43 - iter 344/439 - loss 0.69762113 - samples/sec: 159.07
2020-04-01 23:31:32,589 epoch 66 - iter 44/220 - loss 0.82394708 - samples/sec: 307.70
2020-04-01 23:31:29,948 ----------------------------------------------------------------------------------------------------
2020-04-01 23:31:29,948 EPOCH 43 done: loss 0.6690 - lr 0.0050
2020-04-01 23:31:34,439 DEV : loss 0.5644075870513916 - score 0.9336
2020-04-01 23:31:34,538 BAD EPOCHS (no improvement): 2
2020-04-01 23:31:34,574 ----------------------------------------------------------------------------------------------------
2020-04-01 23:31:43,699 epoch 44 - iter 43/439 - loss 0.62441937 - samples/sec: 150.87
2020-04-01 23:31:52,706 epoch 66 - iter 88/220 - loss 0.80839879 - samples/sec: 343.18

2020-04-01 23:31:58,122 epoch 44 - iter 86/439 - loss 0.63756229 - samples/sec: 153.37
2020-04-01 23:32:04,450 epoch 66 - iter 110/220 - loss 0.81016095 - samples/sec: 311.40
2020-04-01 23:32:14,861 epoch 66 - iter 132/220 - loss 0.81260338 - samples/sec: 356.78
-----------------------------------
2020-04-01 23:32:15,190 EPOCH 43 done: loss 0.6992 - lr 0.0100
2020-04-01 23:32:12,283 epoch 44 - iter 129/439 - loss 0.66463942 - samples/sec: 165.17
2020-04-01 23:32:25,881 epoch 66 - iter 154/220 - loss 0.80988131 - samples/sec: 302.89
,417 BAD EPOCHS (no improvement): 1
2020-04-01 23:32:20,504 ----------------------------------------------------------------------------------------------------
2020-04-01 23:32:28,919 epoch 44 - iter 43/439 - loss 0.64732246 - samples/sec: 163.58
2020-04-01 23:32:25,735 epoch 44 - iter 172/439 - loss 0.67222304 - samples/sec: 181.74
2020-04-01 23:32:36,662 epoch 5 - iter 387/439 - loss 1.82085635 - samples/sec: 166.37
2020-04-01 23:32:39,411 epoch 44 - iter 215/439 - loss 0.66116782 - samples/sec: 174.72
2020-04-01 23:32:45,629 epoch 66 - iter 198/220 - loss 0.81163531 - samples/sec: 351.02
2020-04-01 23:32:55,998 epoch 66 - iter 220/220 - loss 0.80836848 - samples/sec: 315.37
2020-04-01 23:32:53,879 epoch 44 - iter 258/439 - loss 0.67272799 - samples/sec: 164.69
2020-04-01 23:33:07,441 epoch 44 - iter 301/439 - loss 0.66670467 - samples/sec: 174.77
-----------------------------------
2020-04-01 23:33:02,374 EPOCH 66 done: loss 0.8084 - lr 0.0025
2020-04-01 23:33:06,323 DEV : loss 0.5843347907066345 - score 0.931
2020-04-01 23:33:06,420 BAD EPOCHS (no improvement): 3
2020-04-01 23:33:06,467 ----------------------------------------------------------------------------------------------------
2020-04-01 23:33:10,951 epoch 67 - iter 22/220 - loss 0.79375757 - samples/sec: 314.33

2020-04-01 23:33:20,750 epoch 67 - iter 44/220 - loss 0.79631133 - samples/sec: 366.49

2020-04-01 23:33:21,520 epoch 44 - iter 344/439 - loss 0.66867868 - samples/sec: 170.26
2020-04-01 23:33:30,770 epoch 67 - iter 66/220 - loss 0.78138404 - samples/sec: 321.70

2020-04-01 23:33:41,208 epoch 67 - iter 88/220 - loss 0.79468465 - samples/sec: 340.25

2020-04-01 23:33:50,998 epoch 67 - iter 110/220 - loss 0.78058889 - samples/sec: 434.88
2020-04-01 23:33:51,096 epoch 44 - iter 430/439 - loss 0.67076376 - samples/sec: 161.38
2020-04-01 23:33:58,873 ----------------------------------------------------------------------------------------------------
2020-04-01 23:33:58,874 EPOCH 44 done: loss 0.6702 - lr 0.0050
2020-04-01 23:34:00,271 epoch 67 - iter 132/220 - loss 0.80324866 - samples/sec: 424.08
406 BAD EPOCHS (no improvement): 3
2020-04-01 23:34:03,459 ----------------------------------------------------------------------------------------------------
2020-04-01 23:34:10,032 epoch 67 - iter 154/220 - loss 0.79769139 - samples/sec: 412.55
2020-04-01 23:34:12,421 epoch 45 - iter 43/439 - loss 0.71579536 - samples/sec: 153.61
2020-04-01 23:34:20,609 epoch 67 - iter 176/220 - loss 0.80153708 - samples/sec: 419.84
2020-04-01 23:34:30,162 epoch 67 - iter 198/220 - loss 0.79825592 - samples/sec: 426.81
2020-04-01 23:34:40,573 epoch 67 - iter 220/220 - loss 0.80508851 - samples/sec: 439.54
2020-04-01 23:34:46,479 ----------------------------------------------------------------------------------------------------
2020-04-01 23:34:46,480 EPOCH 67 done: loss 0.8051 - lr 0.0025
2020-04-01 23:34:50,592 DEV : loss 0.5852161049842834 - score 0.9312
2020-04-01 23:34:50,689 BAD EPOCHS (no improvement): 0
2020-04-01 23:34:52,014 ----------------------------------------------------------------------------------------------------
2020-04-01 23:34:56,463 epoch 68 - iter 22/220 - loss 0.80899736 - samples/sec: 316.80
2020-04-01 23:34:58,387 epoch 45 - iter 172/439 - loss 0.67533990 - samples/sec: 161.51
2020-04-01 23:35:00,332 ----------------------------------------------------------------------------------------------------
2020-04-01 23:35:08,445 epoch 45 - iter 43/439 - loss 0.64685998 - samples/sec: 169.71
2020-04-01 23:35:06,623 epoch 68 - iter 44/220 - loss 0.80237845 - samples/sec: 366.36
2020-04-01 23:35:18,440 epoch 3 - iter 258/439 - loss 1.47934839 - samples/sec: 90.66
2020-04-01 23:35:14,362 epoch 45 - iter 215/439 - loss 0.66544645 - samples/sec: 154.46
2020-04-01 23:35:26,805 epoch 68 - iter 88/220 - loss 0.81155300 - samples/sec: 335.85
2020-04-01 23:35:29,053 epoch 45 - iter 258/439 - loss 0.66061140 - samples/sec: 152.24
2020-04-01 23:35:37,415 epoch 68 - iter 110/220 - loss 0.80096934 - samples/sec: 306.09
2020-04-01 23:35:47,662 epoch 68 - iter 132/220 - loss 0.80994560 - samples/sec: 341.75
2020-04-01 23:35:57,659 epoch 68 - iter 154/220 - loss 0.81560093 - samples/sec: 317.36
2020-04-01 23:35:59,197 epoch 45 - iter 344/439 - loss 0.65857453 - samples/sec: 154.00
2020-04-01 23:36:07,995 epoch 68 - iter 176/220 - loss 0.81139301 - samples/sec: 350.73
-----------------------------------
2020-04-01 23:36:02,921 EPOCH 5 done: loss 1.8299 - lr 0.0100
2020-04-01 23:36:07,563 DEV : loss 1.1249427795410156 - score 0.8915
2020-04-01 23:36:07,662 BAD EPOCHS (no improvement): 0
2020-04-01 23:36:16,184 ----------------------------------------------------------------------------------------------------
2020-04-01 23:36:14,232 epoch 45 - iter 387/439 - loss 0.65473537 - samples/sec: 153.19
2020-04-01 23:36:21,994 epoch 68 - iter 198/220 - loss 0.80903774 - samples/sec: 332.62
2020-04-01 23:36:30,128 epoch 45 - iter 430/439 - loss 0.65894856 - samples/sec: 152.29
2020-04-01 23:36:32,980 epoch 68 - iter 220/220 - loss 0.80702296 - samples/sec: 297.55
2020-04-01 23:36:38,929 ----------------------------------------------------------------------------------------------------
2020-04-01 23:36:38,929 EPOCH 68 done: loss 0.8070 - lr 0.0025
2020-04-01 23:36:42,868 DEV : loss 0.5834540128707886 - score 0.9306
2020-04-01 23:36:42,967 BAD EPOCHS (no improvement): 1
2020-04-01 23:36:42,992 ----------------------------------------------------------------------------------------------------
2020-04-01 23:36:47,032 epoch 69 - iter 22/220 - loss 0.75788297 - samples/sec: 348.75
--------------------------------------------------------------
2020-04-01 23:36:57,453 epoch 69 - iter 44/220 - loss 0.75814305 - samples/sec: 301.87
2020-04-01 23:36:57,568 epoch 45 - iter 344/439 - loss 0.68939542 - samples/sec: 153.52
2020-04-01 23:36:53,761 epoch 46 - iter 43/439 - loss 0.67893194 - samples/sec: 144.90
2020-04-01 23:37:09,049 epoch 69 - iter 66/220 - loss 0.75718768 - samples/sec: 331.48
2020-04-01 23:37:19,340 epoch 69 - iter 88/220 - loss 0.77351267 - samples/sec: 336.41

2020-04-01 23:37:29,568 epoch 69 - iter 110/220 - loss 0.78228997 - samples/sec: 347.98
2020-04-01 23:37:24,379 epoch 46 - iter 129/439 - loss 0.67045523 - samples/sec: 157.13
2020-04-01 23:37:40,211 epoch 69 - iter 132/220 - loss 0.78082478 - samples/sec: 351.87
-----------------------------------
2020-04-01 23:37:38,178 EPOCH 45 done: loss 0.6903 - lr 0.0100
2020-04-01 23:37:39,331 epoch 46 - iter 172/439 - loss 0.65207799 - samples/sec: 154.15
2020-04-01 23:37:50,601 epoch 69 - iter 154/220 - loss 0.79517350 - samples/sec: 323.13
,738 BAD EPOCHS (no improvement): 1
2020-04-01 23:37:42,758 ----------------------------------------------------------------------------------------------------
2020-04-01 23:38:00,888 epoch 69 - iter 176/220 - loss 0.79592803 - samples/sec: 364.32
020-04-01 23:37:53,198 epoch 46 - iter 215/439 - loss 0.64247451 - samples/sec: 173.48
2020-04-01 23:38:06,909 epoch 46 - iter 86/439 - loss 0.66055315 - samples/sec: 149.90
2020-04-01 23:38:08,449 epoch 46 - iter 258/439 - loss 0.64746525 - samples/sec: 151.39
2020-04-01 23:38:11,508 epoch 69 - iter 198/220 - loss 0.79697168 - samples/sec: 359.06
2020-04-01 23:38:21,997 epoch 69 - iter 220/220 - loss 0.79746908 - samples/sec: 347.52
2020-04-01 23:38:28,850 ----------------------------------------------------------------------------------------------------
2020-04-01 23:38:28,850 EPOCH 69 done: loss 0.7975 - lr 0.0025
2020-04-01 23:38:32,813 DEV : loss 0.5852981805801392 - score 0.9312
2020-04-01 23:38:32,912 BAD EPOCHS (no improvement): 2
2020-04-01 23:38:34,326 ----------------------------------------------------------------------------------------------------
2020-04-01 23:38:38,050 epoch 70 - iter 22/220 - loss 0.86549085 - samples/sec: 378.50
2020-04-01 23:38:50,054 epoch 70 - iter 44/220 - loss 0.83534242 - samples/sec: 309.82
2020-04-01 23:39:01,177 epoch 70 - iter 66/220 - loss 0.82798541 - samples/sec: 315.29

2020-04-01 23:38:54,918 epoch 46 - iter 387/439 - loss 0.65405234 - samples/sec: 152.41
2020-04-01 23:39:11,496 epoch 70 - iter 88/220 - loss 0.84715793 - samples/sec: 293.70

2020-04-01 23:39:09,584 epoch 46 - iter 430/439 - loss 0.64919473 - samples/sec: 155.53
2020-04-01 23:39:17,505 ----------------------------------------------------------------------------------------------------
2020-04-01 23:39:17,506 EPOCH 46 done: loss 0.6498 - lr 0.0025
2020-04-01 23:39:21,653 epoch 70 - iter 110/220 - loss 0.83891499 - samples/sec: 399.15
2020-04-01 23:39:21,947 DEV : loss 0.5569950938224792 - score 0.9361
2020-04-01 23:39:22,042 BAD EPOCHS (no improvement): 1
2020-04-01 23:39:22,058 ----------------------------------------------------------------------------------------------------
2020-04-01 23:39:31,097 epoch 47 - iter 43/439 - loss 0.61653472 - samples/sec: 152.30
2020-04-01 23:39:32,377 epoch 70 - iter 132/220 - loss 0.82002687 - samples/sec: 289.74
2020-04-01 23:39:43,632 epoch 70 - iter 154/220 - loss 0.80862765 - samples/sec: 350.24
2020-04-01 23:39:53,672 epoch 70 - iter 176/220 - loss 0.80378828 - samples/sec: 338.44
2020-04-01 23:40:04,167 epoch 70 - iter 198/220 - loss 0.80432973 - samples/sec: 366.16
020-04-01 23:40:07,753 epoch 46 - iter 430/439 - loss 0.68761826 - samples/sec: 168.74
2020-04-01 23:40:01,712 epoch 47 - iter 129/439 - loss 0.64595976 - samples/sec: 153.69
2020-04-01 23:40:13,586 epoch 70 - iter 220/220 - loss 0.80296658 - samples/sec: 387.49
2020-04-01 23:40:20,187 ----------------------------------------------------------------------------------------------------
2020-04-01 23:40:20,187 EPOCH 70 done: loss 0.8030 - lr 0.0025
,881 BAD EPOCHS (no improvement): 0
2020-04-01 23:40:21,318 ----------------------------------------------------------------------------------------------------
2020-04-01 23:40:16,001 epoch 47 - iter 172/439 - loss 0.64577756 - samples/sec: 153.46
2020-04-01 23:40:30,105 epoch 47 - iter 43/439 - loss 0.72629636 - samples/sec: 156.69
2020-04-01 23:40:24,159 DEV : loss 0.5776016712188721 - score 0.9318
2020-04-01 23:40:24,256 BAD EPOCHS (no improvement): 0
2020-04-01 23:40:25,551 ----------------------------------------------------------------------------------------------------
2020-04-01 23:40:28,653 epoch 71 - iter 22/220 - loss 0.79869029 - samples/sec: 454.23
2020-04-01 23:40:38,250 epoch 71 - iter 44/220 - loss 0.79358081 - samples/sec: 408.54
2020-04-01 23:40:32,905 epoch 47 - iter 215/439 - loss 0.64538574 - samples/sec: 154.98
2020-04-01 23:40:43,841 epoch 3 - iter 301/439 - loss 1.48452329 - samples/sec: 87.01
2020-04-01 23:40:49,724 epoch 71 - iter 66/220 - loss 0.80082866 - samples/sec: 276.74
2020-04-01 23:40:47,793 epoch 47 - iter 258/439 - loss 0.64346581 - samples/sec: 149.61
2020-04-01 23:41:00,829 epoch 71 - iter 88/220 - loss 0.80930808 - samples/sec: 304.63

2020-04-01 23:41:02,878 epoch 47 - iter 301/439 - loss 0.64737989 - samples/sec: 154.63
2020-04-01 23:41:12,306 epoch 71 - iter 110/220 - loss 0.81198768 - samples/sec: 328.15
2020-04-01 23:41:18,796 epoch 47 - iter 344/439 - loss 0.64613058 - samples/sec: 152.84
2020-04-01 23:41:22,631 epoch 71 - iter 132/220 - loss 0.79762596 - samples/sec: 315.38
2020-04-01 23:41:32,561 epoch 71 - iter 154/220 - loss 0.79879366 - samples/sec: 350.92
2020-04-01 23:41:34,133 epoch 47 - iter 387/439 - loss 0.64677939 - samples/sec: 152.59
2020-04-01 23:41:43,147 epoch 71 - iter 176/220 - loss 0.80299513 - samples/sec: 348.80
2020-04-01 23:41:49,782 epoch 47 - iter 430/439 - loss 0.64902733 - samples/sec: 151.99
2020-04-01 23:41:54,340 epoch 71 - iter 198/220 - loss 0.80374225 - samples/sec: 292.92
020-04-01 23:41:57,837 ----------------------------------------------------------------------------------------------------
2020-04-01 23:41:57,838 EPOCH 47 done: loss 0.6511 - lr 0.0025
2020-04-01 23:42:02,529 epoch 47 - iter 301/439 - loss 0.68914233 - samples/sec: 165.56
2020-04-01 23:42:02,280 DEV : loss 0.5604133009910583 - score 0.9365
2020-04-01 23:42:02,378 BAD EPOCHS (no improvement): 0
2020-04-01 23:42:04,059 ----------------------------------------------------------------------------------------------------
2020-04-01 23:42:05,426 epoch 71 - iter 220/220 - loss 0.80235922 - samples/sec: 303.43
2020-04-01 23:42:12,093 ----------------------------------------------------------------------------------------------------
2020-04-01 23:42:12,094 EPOCH 71 done: loss 0.8024 - lr 0.0025
2020-04-01 23:42:19,394 epoch 47 - iter 344/439 - loss 0.68827035 - samples/sec: 152.63
2020-04-01 23:42:13,162 epoch 48 - iter 43/439 - loss 0.68190980 - samples/sec: 151.26
2020-04-01 23:42:16,010 DEV : loss 0.5811843872070312 - score 0.931
2020-04-01 23:42:16,107 BAD EPOCHS (no improvement): 1
2020-04-01 23:42:16,139 ----------------------------------------------------------------------------------------------------
2020-04-01 23:42:20,470 epoch 72 - iter 22/220 - loss 0.69390022 - samples/sec: 325.37
2020-04-01 23:42:32,317 epoch 72 - iter 44/220 - loss 0.78185968 - samples/sec: 298.56
2020-04-01 23:42:35,247 epoch 47 - iter 387/439 - loss 0.68409330 - samples/sec: 154.17
2020-04-01 23:42:43,250 epoch 72 - iter 66/220 - loss 0.77627436 - samples/sec: 320.69

2020-04-01 23:42:44,029 epoch 48 - iter 129/439 - loss 0.65105586 - samples/sec: 149.74
2020-04-01 23:42:53,565 epoch 72 - iter 88/220 - loss 0.78638240 - samples/sec: 340.15
------------------------------------
2020-04-01 23:42:59,786 EPOCH 47 done: loss 0.6834 - lr 0.0100
2020-04-01 23:42:59,387 epoch 48 - iter 172/439 - loss 0.64561486 - samples/sec: 150.49
2020-04-01 23:43:04,644 epoch 72 - iter 110/220 - loss 0.78102126 - samples/sec: 324.26
338 BAD EPOCHS (no improvement): 1
2020-04-01 23:43:04,408 ----------------------------------------------------------------------------------------------------
2020-04-01 23:43:14,500 epoch 72 - iter 132/220 - loss 0.79484585 - samples/sec: 310.67
020-04-01 23:43:14,414 epoch 48 - iter 215/439 - loss 0.64435332 - samples/sec: 153.45
2020-04-01 23:43:29,741 epoch 48 - iter 86/439 - loss 0.69017587 - samples/sec: 151.35
2020-04-01 23:43:31,061 epoch 48 - iter 258/439 - loss 0.64443522 - samples/sec: 149.46
2020-04-01 23:43:26,116 epoch 72 - iter 154/220 - loss 0.77972311 - samples/sec: 334.10
2020-04-01 23:43:37,441 epoch 72 - iter 176/220 - loss 0.77959209 - samples/sec: 314.98
2020-04-01 23:43:48,230 epoch 72 - iter 198/220 - loss 0.77902711 - samples/sec: 343.09
2020-04-01 23:43:46,431 epoch 48 - iter 301/439 - loss 0.63709388 - samples/sec: 156.75
2020-04-01 23:43:58,214 epoch 72 - iter 220/220 - loss 0.78744695 - samples/sec: 343.78
020-04-01 23:44:00,289 epoch 48 - iter 172/439 - loss 0.67554033 - samples/sec: 151.14
2020-04-01 23:44:01,285 epoch 48 - iter 344/439 - loss 0.63765016 - samples/sec: 156.50
2020-04-01 23:44:04,582 ----------------------------------------------------------------------------------------------------
2020-04-01 23:44:04,582 EPOCH 72 done: loss 0.7874 - lr 0.0025
2020-04-01 23:44:08,482 DEV : loss 0.5835056900978088 - score 0.9315
2020-04-01 23:44:08,580 BAD EPOCHS (no improvement): 2
2020-04-01 23:44:08,593 ----------------------------------------------------------------------------------------------------
2020-04-01 23:44:12,230 epoch 73 - iter 22/220 - loss 0.80652135 - samples/sec: 387.39
2020-04-01 23:44:21,557 epoch 73 - iter 44/220 - loss 0.79636093 - samples/sec: 423.93

2020-04-01 23:44:17,034 epoch 48 - iter 387/439 - loss 0.63690236 - samples/sec: 151.62
2020-04-01 23:44:31,618 epoch 73 - iter 66/220 - loss 0.76457420 - samples/sec: 424.40
2020-04-01 23:44:31,749 epoch 48 - iter 258/439 - loss 0.68571505 - samples/sec: 154.73
2020-04-01 23:44:31,546 epoch 48 - iter 430/439 - loss 0.63610521 - samples/sec: 170.16
2020-04-01 23:44:42,682 epoch 73 - iter 88/220 - loss 0.79415349 - samples/sec: 420.93
------------------------------------
2020-04-01 23:44:40,830 EPOCH 48 done: loss 0.6388 - lr 0.0025
2020-04-01 23:44:52,355 epoch 73 - iter 110/220 - loss 0.78542939 - samples/sec: 427.00
2020-04-01 23:44:45,325 DEV : loss 0.5566175580024719 - score 0.9358
2020-04-01 23:44:45,424 BAD EPOCHS (no improvement): 1
2020-04-01 23:44:45,511 ----------------------------------------------------------------------------------------------------
2020-04-01 23:45:02,237 epoch 73 - iter 132/220 - loss 0.78507072 - samples/sec: 429.93
2020-04-01 23:45:12,563 epoch 73 - iter 154/220 - loss 0.78849000 - samples/sec: 426.83
2020-04-01 23:45:07,114 epoch 49 - iter 86/439 - loss 0.66109950 - samples/sec: 189.28
2020-04-01 23:45:22,490 epoch 73 - iter 176/220 - loss 0.79581400 - samples/sec: 432.25
2020-04-01 23:45:21,465 epoch 49 - iter 129/439 - loss 0.66818039 - samples/sec: 176.77
2020-04-01 23:45:33,753 epoch 73 - iter 198/220 - loss 0.79519215 - samples/sec: 421.33
2020-04-01 23:45:43,198 epoch 73 - iter 220/220 - loss 0.79879839 - samples/sec: 434.69
2020-04-01 23:45:50,786 ----------------------------------------------------------------------------------------------------
2020-04-01 23:45:50,786 EPOCH 73 done: loss 0.7988 - lr 0.0025
2020-04-01 23:45:48,451 DEV : loss 0.5334346890449524 - score 0.9375
2020-04-01 23:45:48,547 BAD EPOCHS (no improvement): 0
2020-04-01 23:45:49,855 ----------------------------------------------------------------------------------------------------
2020-04-01 23:45:50,300 epoch 49 - iter 215/439 - loss 0.65182523 - samples/sec: 175.02
2020-04-01 23:45:55,349 DEV : loss 0.5776796936988831 - score 0.9317
2020-04-01 23:45:55,446 BAD EPOCHS (no improvement): 3
2020-04-01 23:45:55,478 ----------------------------------------------------------------------------------------------------
2020-04-01 23:45:58,533 epoch 74 - iter 22/220 - loss 0.73321962 - samples/sec: 461.23
2020-04-01 23:46:07,932 epoch 74 - iter 44/220 - loss 0.73882607 - samples/sec: 450.06
2020-04-01 23:46:16,049 epoch 3 - iter 344/439 - loss 1.47257864 - samples/sec: 89.87
2020-04-01 23:46:13,565 epoch 49 - iter 86/439 - loss 0.66920575 - samples/sec: 159.09
2020-04-01 23:46:16,076 epoch 49 - iter 301/439 - loss 0.66493890 - samples/sec: 170.45
2020-04-01 23:46:17,138 epoch 74 - iter 66/220 - loss 0.76787003 - samples/sec: 409.58
2020-04-01 23:46:28,030 epoch 74 - iter 88/220 - loss 0.78195137 - samples/sec: 313.81

2020-04-01 23:46:29,741 epoch 49 - iter 344/439 - loss 0.65670447 - samples/sec: 190.61
2020-04-01 23:46:43,195 epoch 74 - iter 110/220 - loss 0.76762406 - samples/sec: 312.14
2020-04-01 23:46:49,092 epoch 49 - iter 172/439 - loss 0.65546892 - samples/sec: 149.48
2020-04-01 23:46:48,196 epoch 49 - iter 387/439 - loss 0.64622484 - samples/sec: 179.26
2020-04-01 23:47:02,124 epoch 49 - iter 430/439 - loss 0.64322401 - samples/sec: 188.21
2020-04-01 23:46:54,493 epoch 74 - iter 132/220 - loss 0.77281048 - samples/sec: 330.83
2020-04-01 23:47:06,011 epoch 74 - iter 154/220 - loss 0.79032698 - samples/sec: 302.11
2020-04-01 23:47:10,231 ----------------------------------------------------------------------------------------------------
2020-04-01 23:47:10,232 EPOCH 49 done: loss 0.6407 - lr 0.0025
2020-04-01 23:47:18,332 epoch 74 - iter 176/220 - loss 0.78735252 - samples/sec: 287.00
2020-04-01 23:47:14,738 DEV : loss 0.5640286207199097 - score 0.9365
2020-04-01 23:47:14,836 BAD EPOCHS (no improvement): 2
2020-04-01 23:47:16,554 ----------------------------------------------------------------------------------------------------
2020-04-01 23:47:28,797 epoch 74 - iter 198/220 - loss 0.78532450 - samples/sec: 331.09
2020-04-01 23:47:39,501 epoch 74 - iter 220/220 - loss 0.78569987 - samples/sec: 325.31
2020-04-01 23:47:39,248 epoch 50 - iter 86/439 - loss 0.63290724 - samples/sec: 163.67
2020-04-01 23:47:46,605 ----------------------------------------------------------------------------------------------------
2020-04-01 23:47:46,605 EPOCH 74 done: loss 0.7857 - lr 0.0025
2020-04-01 23:47:50,554 DEV : loss 0.5711490511894226 - score 0.9334
2020-04-01 23:47:50,651 BAD EPOCHS (no improvement): 0
2020-04-01 23:47:51,935 ----------------------------------------------------------------------------------------------------
2020-04-01 23:47:56,194 epoch 75 - iter 22/220 - loss 0.75062666 - samples/sec: 330.90

2020-04-01 23:48:07,793 epoch 49 - iter 387/439 - loss 0.66109488 - samples/sec: 154.69
2020-04-01 23:48:10,286 epoch 50 - iter 172/439 - loss 0.64836094 - samples/sec: 165.32
2020-04-01 23:48:07,388 epoch 75 - iter 44/220 - loss 0.75325316 - samples/sec: 328.37
2020-04-01 23:48:18,491 epoch 75 - iter 66/220 - loss 0.77392453 - samples/sec: 308.68
2020-04-01 23:48:23,596 epoch 49 - iter 430/439 - loss 0.65946816 - samples/sec: 149.24
2020-04-01 23:48:31,323 ----------------------------------------------------------------------------------------------------
2020-04-01 23:48:31,324 EPOCH 49 done: loss 0.6580 - lr 0.0100
2020-04-01 23:48:25,510 epoch 50 - iter 215/439 - loss 0.63775200 - samples/sec: 153.45
2020-04-01 23:48:28,151 epoch 75 - iter 88/220 - loss 0.76172405 - samples/sec: 357.09
2020-04-01 23:48:39,003 epoch 75 - iter 110/220 - loss 0.77422473 - samples/sec: 294.54
,830 BAD EPOCHS (no improvement): 0
2020-04-01 23:48:37,059 ----------------------------------------------------------------------------------------------------
2020-04-01 23:48:39,782 epoch 50 - iter 258/439 - loss 0.64223283 - samples/sec: 169.29
2020-04-01 23:48:48,950 epoch 75 - iter 132/220 - loss 0.78223876 - samples/sec: 356.69
020-04-01 23:48:54,243 epoch 50 - iter 301/439 - loss 0.64058488 - samples/sec: 160.49
2020-04-01 23:48:59,457 epoch 75 - iter 154/220 - loss 0.77136725 - samples/sec: 323.97
2020-04-01 23:49:10,216 epoch 75 - iter 176/220 - loss 0.77885884 - samples/sec: 330.66
2020-04-01 23:49:20,104 epoch 75 - iter 198/220 - loss 0.78267453 - samples/sec: 356.67
2020-04-01 23:49:22,056 epoch 50 - iter 387/439 - loss 0.63346582 - samples/sec: 158.62
2020-04-01 23:49:30,852 epoch 75 - iter 220/220 - loss 0.78653347 - samples/sec: 355.63
2020-04-01 23:49:36,774 ----------------------------------------------------------------------------------------------------
2020-04-01 23:49:36,775 EPOCH 75 done: loss 0.7865 - lr 0.0025
2020-04-01 23:49:40,734 DEV : loss 0.5687063932418823 - score 0.9331
2020-04-01 23:49:40,833 BAD EPOCHS (no improvement): 1
2020-04-01 23:49:40,920 ----------------------------------------------------------------------------------------------------
2020-04-01 23:49:45,613 epoch 76 - iter 22/220 - loss 0.75191554 - samples/sec: 300.24

2020-04-01 23:49:45,528 ----------------------------------------------------------------------------------------------------
2020-04-01 23:49:45,529 EPOCH 50 done: loss 0.6353 - lr 0.0025
2020-04-01 23:49:49,951 DEV : loss 0.5550058484077454 - score 0.936
2020-04-01 23:49:50,047 BAD EPOCHS (no improvement): 3
2020-04-01 23:49:50,068 ----------------------------------------------------------------------------------------------------
2020-04-01 23:49:56,386 epoch 76 - iter 44/220 - loss 0.73712162 - samples/sec: 309.77

2020-04-01 23:49:58,997 epoch 51 - iter 43/439 - loss 0.62525570 - samples/sec: 154.18
2020-04-01 23:50:06,541 epoch 76 - iter 66/220 - loss 0.74142606 - samples/sec: 324.73
2020-04-01 23:50:16,863 epoch 76 - iter 88/220 - loss 0.76676666 - samples/sec: 333.10

2020-04-01 23:50:30,284 epoch 50 - iter 344/439 - loss 0.65062978 - samples/sec: 150.75
2020-04-01 23:50:29,718 epoch 51 - iter 129/439 - loss 0.63335341 - samples/sec: 150.20
2020-04-01 23:50:27,956 epoch 76 - iter 110/220 - loss 0.77718084 - samples/sec: 330.57
2020-04-01 23:50:44,609 epoch 51 - iter 172/439 - loss 0.65281476 - samples/sec: 155.40
2020-04-01 23:50:38,514 epoch 76 - iter 132/220 - loss 0.78197775 - samples/sec: 296.73
2020-04-01 23:50:45,552 epoch 50 - iter 387/439 - loss 0.65091264 - samples/sec: 150.18
2020-04-01 23:50:48,649 epoch 76 - iter 154/220 - loss 0.78280201 - samples/sec: 333.82
2020-04-01 23:50:59,312 epoch 76 - iter 176/220 - loss 0.77862135 - samples/sec: 318.69
2020-04-01 23:50:59,869 epoch 51 - iter 215/439 - loss 0.64565660 - samples/sec: 153.27
2020-04-01 23:51:09,665 epoch 76 - iter 198/220 - loss 0.78451438 - samples/sec: 331.24
-----------------------------------
2020-04-01 23:51:09,383 EPOCH 50 done: loss 0.6618 - lr 0.0100
2020-04-01 23:51:13,848 DEV : loss 0.5264071226119995 - score 0.9394
2020-04-01 23:51:13,946 BAD EPOCHS (no improvement): 1
2020-04-01 23:51:13,976 ----------------------------------------------------------------------------------------------------
2020-04-01 23:51:14,692 epoch 51 - iter 258/439 - loss 0.63343492 - samples/sec: 158.39
2020-04-01 23:51:19,906 epoch 76 - iter 220/220 - loss 0.78122507 - samples/sec: 327.28
020-04-01 23:51:22,921 epoch 51 - iter 43/439 - loss 0.61715576 - samples/sec: 153.91
2020-04-01 23:51:26,016 ----------------------------------------------------------------------------------------------------
2020-04-01 23:51:26,016 EPOCH 76 done: loss 0.7812 - lr 0.0025
2020-04-01 23:51:29,889 DEV : loss 0.5727930665016174 - score 0.9336
2020-04-01 23:51:29,987 BAD EPOCHS (no improvement): 0
2020-04-01 23:51:31,177 ----------------------------------------------------------------------------------------------------
2020-04-01 23:51:34,727 epoch 77 - iter 22/220 - loss 0.78930591 - samples/sec: 396.97
2020-04-01 23:51:44,286 epoch 77 - iter 44/220 - loss 0.82875150 - samples/sec: 352.19
2020-04-01 23:51:44,785 epoch 51 - iter 344/439 - loss 0.62874525 - samples/sec: 154.56
2020-04-01 23:51:41,218 epoch 3 - iter 387/439 - loss 1.45591950 - samples/sec: 86.45
2020-04-01 23:51:52,716 epoch 51 - iter 129/439 - loss 0.65746423 - samples/sec: 153.15
2020-04-01 23:51:55,322 epoch 77 - iter 66/220 - loss 0.82073419 - samples/sec: 303.93

2020-04-01 23:52:05,608 epoch 77 - iter 88/220 - loss 0.83282869 - samples/sec: 322.06

2020-04-01 23:52:14,560 epoch 51 - iter 430/439 - loss 0.62889682 - samples/sec: 151.14
2020-04-01 23:52:17,101 epoch 77 - iter 110/220 - loss 0.81218840 - samples/sec: 282.72
2020-04-01 23:52:21,685 ----------------------------------------------------------------------------------------------------
2020-04-01 23:52:21,686 EPOCH 51 done: loss 0.6303 - lr 0.0025
2020-04-01 23:52:27,644 epoch 77 - iter 132/220 - loss 0.80714136 - samples/sec: 300.53
g learning rate of group 0 to 1.2500e-03.
2020-04-01 23:52:26,262 BAD EPOCHS (no improvement): 4
2020-04-01 23:52:26,325 ----------------------------------------------------------------------------------------------------
2020-04-01 23:52:37,717 epoch 77 - iter 154/220 - loss 0.79902124 - samples/sec: 322.61
2020-04-01 23:52:35,320 epoch 52 - iter 43/439 - loss 0.64391778 - samples/sec: 153.06
2020-04-01 23:52:47,751 epoch 77 - iter 176/220 - loss 0.80456102 - samples/sec: 343.73
2020-04-01 23:52:50,601 epoch 52 - iter 86/439 - loss 0.63564994 - samples/sec: 150.92
2020-04-01 23:52:57,660 epoch 77 - iter 198/220 - loss 0.80499330 - samples/sec: 324.61
2020-04-01 23:53:07,643 epoch 77 - iter 220/220 - loss 0.80205518 - samples/sec: 342.10
2020-04-01 23:53:13,808 ----------------------------------------------------------------------------------------------------
2020-04-01 23:53:13,809 EPOCH 77 done: loss 0.8021 - lr 0.0025
2020-04-01 23:53:17,752 DEV : loss 0.5722913146018982 - score 0.9319
2020-04-01 23:53:17,847 BAD EPOCHS (no improvement): 1
2020-04-01 23:53:17,882 ----------------------------------------------------------------------------------------------------
2020-04-01 23:53:22,272 epoch 78 - iter 22/220 - loss 0.80319577 - samples/sec: 320.95
2020-04-01 23:53:32,866 epoch 78 - iter 44/220 - loss 0.75756725 - samples/sec: 313.01

2020-04-01 23:53:42,418 epoch 78 - iter 66/220 - loss 0.77155341 - samples/sec: 317.05

2020-04-01 23:53:52,226 epoch 78 - iter 88/220 - loss 0.79339264 - samples/sec: 330.80
------------------------------------
2020-04-01 23:53:46,751 EPOCH 51 done: loss 0.6565 - lr 0.0100
2020-04-01 23:53:51,209 DEV : loss 0.5241388082504272 - score 0.9388
2020-04-01 23:53:51,307 BAD EPOCHS (no improvement): 2
2020-04-01 23:53:51,346 ----------------------------------------------------------------------------------------------------
2020-04-01 23:53:48,474 epoch 52 - iter 258/439 - loss 0.61714824 - samples/sec: 157.81
2020-04-01 23:54:03,033 epoch 78 - iter 110/220 - loss 0.80515074 - samples/sec: 285.86
020-04-01 23:54:03,689 epoch 52 - iter 301/439 - loss 0.62237294 - samples/sec: 152.65
2020-04-01 23:54:13,316 epoch 78 - iter 132/220 - loss 0.79985613 - samples/sec: 327.76
2020-04-01 23:54:23,388 epoch 78 - iter 154/220 - loss 0.79444856 - samples/sec: 316.94
020-04-01 23:54:18,907 epoch 52 - iter 344/439 - loss 0.62780458 - samples/sec: 151.80
2020-04-01 23:54:33,116 epoch 78 - iter 176/220 - loss 0.79944791 - samples/sec: 320.96
2020-04-01 23:54:33,004 epoch 52 - iter 387/439 - loss 0.63241621 - samples/sec: 151.73
2020-04-01 23:54:43,553 epoch 78 - iter 198/220 - loss 0.79051916 - samples/sec: 298.03
-----------------------------------
2020-04-01 23:54:35,915 EPOCH 6 done: loss 1.7336 - lr 0.0100
2020-04-01 23:54:40,675 DEV : loss 1.0697664022445679 - score 0.8983
2020-04-01 23:54:40,773 BAD EPOCHS (no improvement): 0
2020-04-01 23:54:49,554 ----------------------------------------------------------------------------------------------------
2020-04-01 23:54:45,389 epoch 52 - iter 172/439 - loss 0.63656106 - samples/sec: 150.38
2020-04-01 23:54:47,681 epoch 52 - iter 430/439 - loss 0.63610043 - samples/sec: 153.73
2020-04-01 23:54:58,467 epoch 78 - iter 220/220 - loss 0.79181501 - samples/sec: 288.77
2020-04-01 23:54:58,000 epoch 7 - iter 43/439 - loss 1.63135110 - samples/sec: 163.05
2020-04-01 23:55:03,970 epoch 52 - iter 215/439 - loss 0.63502737 - samples/sec: 162.99
2020-04-01 23:54:57,693 ----------------------------------------------------------------------------------------------------
2020-04-01 23:54:57,693 EPOCH 52 done: loss 0.6365 - lr 0.0013
2020-04-01 23:55:02,138 DEV : loss 0.5540027022361755 - score 0.9362
2020-04-01 23:55:02,234 BAD EPOCHS (no improvement): 1
2020-04-01 23:55:02,288 ----------------------------------------------------------------------------------------------------
2020-04-01 23:55:04,550 ----------------------------------------------------------------------------------------------------
2020-04-01 23:55:04,550 EPOCH 78 done: loss 0.7918 - lr 0.0025
2020-04-01 23:55:08,514 DEV : loss 0.5693548917770386 - score 0.9339
2020-04-01 23:55:08,613 BAD EPOCHS (no improvement): 0
2020-04-01 23:55:10,008 ----------------------------------------------------------------------------------------------------
2020-04-01 23:55:14,201 epoch 79 - iter 22/220 - loss 0.78299123 - samples/sec: 336.19
2020-04-01 23:55:24,503 epoch 79 - iter 44/220 - loss 0.76767388 - samples/sec: 304.73

2020-04-01 23:55:25,439 epoch 53 - iter 86/439 - loss 0.62757085 - samples/sec: 153.02
2020-04-01 23:55:21,613 epoch 5 - iter 220/220 - loss 1.49313499 - samples/sec: 127.27
2020-04-01 23:55:34,256 epoch 52 - iter 301/439 - loss 0.64142036 - samples/sec: 151.36
2020-04-01 23:55:35,020 epoch 79 - iter 66/220 - loss 0.75649101 - samples/sec: 310.65
2020-04-01 23:55:45,503 epoch 79 - iter 88/220 - loss 0.76987803 - samples/sec: 318.06

2020-04-01 23:55:49,500 epoch 52 - iter 344/439 - loss 0.64038452 - samples/sec: 151.58
2020-04-01 23:55:55,523 epoch 79 - iter 110/220 - loss 0.79394364 - samples/sec: 326.12
2020-04-01 23:56:04,256 epoch 52 - iter 387/439 - loss 0.64432119 - samples/sec: 151.59
2020-04-01 23:55:55,797 epoch 53 - iter 172/439 - loss 0.62248404 - samples/sec: 151.20
2020-04-01 23:56:05,558 epoch 79 - iter 132/220 - loss 0.79726898 - samples/sec: 336.37
2020-04-01 23:56:10,736 epoch 53 - iter 215/439 - loss 0.62133684 - samples/sec: 152.09
2020-04-01 23:56:15,780 epoch 79 - iter 154/220 - loss 0.79129908 - samples/sec: 313.47
2020-04-01 23:56:18,993 epoch 52 - iter 430/439 - loss 0.64311186 - samples/sec: 153.01
2020-04-01 23:56:26,513 epoch 79 - iter 176/220 - loss 0.78726149 - samples/sec: 290.39
2020-04-01 23:56:26,958 ----------------------------------------------------------------------------------------------------
2020-04-01 23:56:26,959 EPOCH 52 done: loss 0.6428 - lr 0.0100
2020-04-01 23:56:31,410 DEV : loss 0.5213876962661743 - score 0.9377
2020-04-01 23:56:31,507 BAD EPOCHS (no improvement): 3
2020-04-01 23:56:31,527 ----------------------------------------------------------------------------------------------------
2020-04-01 23:56:25,911 epoch 53 - iter 258/439 - loss 0.63183948 - samples/sec: 152.13
2020-04-01 23:56:40,442 epoch 53 - iter 43/439 - loss 0.64970964 - samples/sec: 154.42

2020-04-01 23:56:45,200 epoch 79 - iter 220/220 - loss 0.78641824 - samples/sec: 415.58
2020-04-01 23:56:46,993 epoch 3 - iter 430/439 - loss 1.45145021 - samples/sec: 87.08
2020-04-01 23:56:42,821 epoch 7 - iter 86/439 - loss 1.64283994 - samples/sec: 158.85
2020-04-01 23:56:55,226 epoch 53 - iter 86/439 - loss 0.65058723 - samples/sec: 149.45
2020-04-01 23:56:54,975 epoch 53 - iter 344/439 - loss 0.63051971 - samples/sec: 151.27
2020-04-01 23:56:50,758 ----------------------------------------------------------------------------------------------------
2020-04-01 23:56:50,758 EPOCH 79 done: loss 0.7864 - lr 0.0025
2020-04-01 23:56:54,729 DEV : loss 0.5722447633743286 - score 0.9324
2020-04-01 23:56:54,828 BAD EPOCHS (no improvement): 1
2020-04-01 23:56:54,848 ----------------------------------------------------------------------------------------------------
2020-04-01 23:56:59,073 epoch 80 - iter 22/220 - loss 0.75293231 - samples/sec: 333.44
2020-04-01 23:57:09,911 epoch 53 - iter 129/439 - loss 0.65302772 - samples/sec: 151.87
2020-04-01 23:57:09,636 epoch 53 - iter 387/439 - loss 0.62332467 - samples/sec: 152.12
2020-04-01 23:57:19,806 epoch 80 - iter 66/220 - loss 0.75372806 - samples/sec: 320.73
2020-04-01 23:57:25,276 epoch 53 - iter 172/439 - loss 0.64297903 - samples/sec: 153.97
2020-04-01 23:57:25,268 epoch 53 - iter 430/439 - loss 0.62881198 - samples/sec: 150.06
2020-04-01 23:57:30,474 epoch 80 - iter 88/220 - loss 0.75209961 - samples/sec: 302.42
2020-04-01 23:57:33,330 ----------------------------------------------------------------------------------------------------
2020-04-01 23:57:33,331 EPOCH 53 done: loss 0.6275 - lr 0.0013
2020-04-01 23:57:39,895 epoch 53 - iter 215/439 - loss 0.64080464 - samples/sec: 161.32
2020-04-01 23:57:38,463 DEV : loss 0.5549078583717346 - score 0.9361
2020-04-01 23:57:38,563 BAD EPOCHS (no improvement): 2
2020-04-01 23:57:38,576 ----------------------------------------------------------------------------------------------------
2020-04-01 23:57:40,957 epoch 80 - iter 110/220 - loss 0.78210282 - samples/sec: 335.27
2020-04-01 23:57:55,357 epoch 53 - iter 258/439 - loss 0.64716332 - samples/sec: 154.79
2020-04-01 23:57:47,521 epoch 54 - iter 43/439 - loss 0.69222681 - samples/sec: 153.89
2020-04-01 23:57:51,203 epoch 80 - iter 132/220 - loss 0.79145945 - samples/sec: 318.98
2020-04-01 23:58:01,664 epoch 54 - iter 86/439 - loss 0.64883915 - samples/sec: 153.38
2020-04-01 23:58:10,699 epoch 53 - iter 301/439 - loss 0.65465752 - samples/sec: 151.36
2020-04-01 23:58:12,171 epoch 80 - iter 176/220 - loss 0.80799674 - samples/sec: 326.29
2020-04-01 23:58:16,613 epoch 54 - iter 129/439 - loss 0.64120041 - samples/sec: 150.17
2020-04-01 23:58:23,124 epoch 80 - iter 198/220 - loss 0.80773480 - samples/sec: 312.92
2020-04-01 23:58:26,303 epoch 7 - iter 129/439 - loss 1.65299971 - samples/sec: 235.61
2020-04-01 23:58:26,157 epoch 53 - iter 344/439 - loss 0.65107684 - samples/sec: 148.65
2020-04-01 23:58:32,745 epoch 54 - iter 172/439 - loss 0.63488016 - samples/sec: 148.88
2020-04-01 23:58:33,189 epoch 80 - iter 220/220 - loss 0.80604480 - samples/sec: 342.71
2020-04-01 23:58:38,794 ----------------------------------------------------------------------------------------------------
2020-04-01 23:58:38,794 EPOCH 80 done: loss 0.8060 - lr 0.0025
2020-04-01 23:58:41,475 epoch 53 - iter 387/439 - loss 0.65076210 - samples/sec: 150.71
2020-04-01 23:58:42,760 DEV : loss 0.5729897022247314 - score 0.9318
2020-04-01 23:58:42,858 BAD EPOCHS (no improvement): 2
2020-04-01 23:58:42,902 ----------------------------------------------------------------------------------------------------
2020-04-01 23:58:47,255 epoch 81 - iter 22/220 - loss 0.91182534 - samples/sec: 323.71
2020-04-01 23:58:43,147 ----------------------------------------------------------------------------------------------------
2020-04-01 23:58:43,148 EPOCH 5 done: loss 1.4931 - lr 0.0100
2020-04-01 23:58:47,209 epoch 54 - iter 215/439 - loss 0.63703469 - samples/sec: 153.51
2020-04-01 23:58:58,383 DEV : loss 1.0404720306396484 - score 0.8901
2020-04-01 23:58:58,791 BAD EPOCHS (no improvement): 0
2020-04-01 23:58:57,116 epoch 53 - iter 430/439 - loss 0.65066396 - samples/sec: 152.23
2020-04-01 23:59:04,901 ----------------------------------------------------------------------------------------------------
2020-04-01 23:59:04,902 EPOCH 53 done: loss 0.6500 - lr 0.0100
2020-04-01 23:59:01,519 epoch 54 - iter 258/439 - loss 0.63750329 - samples/sec: 156.62
2020-04-01 23:59:06,772 epoch 81 - iter 66/220 - loss 0.82960131 - samples/sec: 340.04
2020-04-01 23:59:09,390 DEV : loss 0.519869863986969 - score 0.9399
2020-04-01 23:59:09,487 BAD EPOCHS (no improvement): 0
2020-04-01 23:59:12,157 ----------------------------------------------------------------------------------------------------
2020-04-01 23:59:16,527 epoch 54 - iter 301/439 - loss 0.63354801 - samples/sec: 151.47
2020-04-01 23:59:18,893 epoch 81 - iter 88/220 - loss 0.81785555 - samples/sec: 291.55
2020-04-01 23:59:21,176 epoch 54 - iter 43/439 - loss 0.64263656 - samples/sec: 152.65
2020-04-01 23:59:41,273 epoch 81 - iter 110/220 - loss 0.81059118 - samples/sec: 290.56
2020-04-01 23:59:45,544 epoch 54 - iter 86/439 - loss 0.64367395 - samples/sec: 151.39
2020-04-01 23:59:43,842 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-01 23:59:55,052 epoch 6 - iter 22/220 - loss 1.41773171 - samples/sec: 125.68

2020-04-02 00:00:03,694 epoch 81 - iter 154/220 - loss 0.80608958 - samples/sec: 365.68
2020-04-02 00:00:00,827 epoch 54 - iter 129/439 - loss 0.63472001 - samples/sec: 150.73
2020-04-02 00:00:15,542 epoch 81 - iter 176/220 - loss 0.80720796 - samples/sec: 282.72
2020-04-02 00:00:16,837 epoch 54 - iter 172/439 - loss 0.63772360 - samples/sec: 152.02
2020-04-02 00:00:26,358 epoch 81 - iter 198/220 - loss 0.80119092 - samples/sec: 334.02
-----------------------------------
2020-04-02 00:00:25,232 EPOCH 54 done: loss 0.6294 - lr 0.0013
2020-04-02 00:00:29,679 DEV : loss 0.5531099438667297 - score 0.9369
2020-04-02 00:00:29,775 BAD EPOCHS (no improvement): 0
2020-04-02 00:00:37,265 epoch 81 - iter 220/220 - loss 0.79962801 - samples/sec: 316.332020-04-02 00:00:31,416 ----------------------------------------------------------------------------------------------------
2020-04-02 00:00:40,438 epoch 55 - iter 43/439 - loss 0.60669345 - samples/sec: 152.59
2020-04-02 00:00:32,544 epoch 54 - iter 215/439 - loss 0.62649737 - samples/sec: 160.75
2020-04-02 00:00:46,901 epoch 54 - iter 258/439 - loss 0.63750404 - samples/sec: 152.50
-----------------------------------
2020-04-02 00:00:43,318 EPOCH 81 done: loss 0.7996 - lr 0.0025
2020-04-02 00:00:47,906 DEV : loss 0.5693334937095642 - score 0.9324
2020-04-02 00:00:48,005 BAD EPOCHS (no improvement): 3
2020-04-02 00:00:48,074 ----------------------------------------------------------------------------------------------------
2020-04-02 00:00:52,608 epoch 82 - iter 22/220 - loss 0.76007503 - samples/sec: 310.75
2020-04-02 00:01:02,748 epoch 82 - iter 44/220 - loss 0.82113996 - samples/sec: 320.89

2020-04-02 00:01:02,212 epoch 54 - iter 301/439 - loss 0.63897300 - samples/sec: 152.25
2020-04-02 00:01:17,836 epoch 54 - iter 344/439 - loss 0.64203552 - samples/sec: 150.30
2020-04-02 00:01:24,207 epoch 82 - iter 88/220 - loss 0.78886211 - samples/sec: 329.07

2020-04-02 00:01:39,711 epoch 55 - iter 215/439 - loss 0.62170479 - samples/sec: 151.48
2020-04-02 00:01:34,824 epoch 82 - iter 110/220 - loss 0.77867995 - samples/sec: 347.37
2020-04-02 00:01:33,088 epoch 54 - iter 387/439 - loss 0.64140367 - samples/sec: 148.05
2020-04-02 00:01:48,637 epoch 54 - iter 430/439 - loss 0.64777356 - samples/sec: 154.50
2020-04-02 00:01:56,368 epoch 82 - iter 154/220 - loss 0.79848350 - samples/sec: 307.46
2020-04-02 00:01:56,753 ----------------------------------------------------------------------------------------------------
2020-04-02 00:01:56,754 EPOCH 54 done: loss 0.6475 - lr 0.0100
2020-04-02 00:02:10,024 ----------------------------------------------------------------------------------------------------
2020-04-02 00:02:10,024 EPOCH 3 done: loss 1.4502 - lr 0.0100
2020-04-02 00:02:07,176 epoch 82 - iter 176/220 - loss 0.80152037 - samples/sec: 309.52
2020-04-02 00:02:01,939 DEV : loss 0.5105114579200745 - score 0.9399
2020-04-02 00:02:02,037 BAD EPOCHS (no improvement): 1
2020-04-02 00:02:03,406 ----------------------------------------------------------------------------------------------------
2020-04-02 00:02:12,463 epoch 55 - iter 43/439 - loss 0.59803506 - samples/sec: 152.02

2020-04-02 00:02:26,806 epoch 82 - iter 220/220 - loss 0.79621056 - samples/sec: 424.60
2020-04-02 00:02:27,398 epoch 55 - iter 86/439 - loss 0.59446683 - samples/sec: 153.10
2020-04-02 00:02:32,397 DEV : loss 0.8278708457946777 - score 0.9217
2020-04-02 00:02:32,834 BAD EPOCHS (no improvement): 0
2020-04-02 00:02:33,425 ----------------------------------------------------------------------------------------------------
2020-04-02 00:02:33,425 EPOCH 82 done: loss 0.7962 - lr 0.0025
2020-04-02 00:02:38,178 DEV : loss 0.5665610432624817 - score 0.9327
Epoch    82: reducing learning rate of group 0 to 1.2500e-03.
2020-04-02 00:02:38,670 BAD EPOCHS (no improvement): 4
2020-04-02 00:02:39,126 ----------------------------------------------------------------------------------------------------
2020-04-02 00:02:44,208 epoch 83 - iter 22/220 - loss 0.75776651 - samples/sec: 277.28

2020-04-02 00:02:43,341 epoch 55 - iter 129/439 - loss 0.60981839 - samples/sec: 147.34
2020-04-02 00:03:19,736 -----------------------------------------------------------------2020-04-02 00:03:23,797 ----------------------------------------------------------------------------------------------------
2020-04-02 00:03:23,798 EPOCH 55 done: loss 0.6130 - lr 0.0013
2020-04-02 00:03:20,756 epoch 55 - iter 172/439 - loss 0.61863728 - samples/sec: 153.12
2020-04-02 00:03:28,171 epoch 83 - iter 44/220 - loss 0.77621792 - samples/sec: 400.41
8,378 BAD EPOCHS (no improvement): 0
2020-04-02 00:03:29,987 ----------------------------------------------------------------------------------------------------
2020-04-02 00:03:36,124 epoch 4 - iter 43/439 - loss 1.13770450 - samples/sec: 84.02
2020-04-02 00:03:38,941 epoch 56 - iter 43/439 - loss 0.62242392 - samples/sec: 153.75
2020-04-02 00:03:36,060 epoch 55 - iter 215/439 - loss 0.62363430 - samples/sec: 154.58
2020-04-02 00:03:39,535 epoch 83 - iter 66/220 - loss 0.75892845 - samples/sec: 345.72
2020-04-02 00:03:50,587 epoch 83 - iter 88/220 - loss 0.76109424 - samples/sec: 299.08
2020-04-02 00:03:51,220 epoch 55 - iter 258/439 - loss 0.62130607 - samples/sec: 158.93
2020-04-02 00:04:05,425 epoch 6 - iter 44/220 - loss 1.38590930 - samples/sec: 120.54

2020-04-02 00:04:08,776 epoch 56 - iter 129/439 - loss 0.60063153 - samples/sec: 155.70
2020-04-02 00:04:09,362 epoch 83 - iter 132/220 - loss 0.77207451 - samples/sec: 400.10
2020-04-02 00:04:18,694 epoch 83 - iter 154/220 - loss 0.78449626 - samples/sec: 444.16
2020-04-02 00:04:21,450 epoch 55 - iter 344/439 - loss 0.62384524 - samples/sec: 149.30
2020-04-02 00:04:28,219 epoch 83 - iter 176/220 - loss 0.78573625 - samples/sec: 450.10
2020-04-02 00:04:37,787 epoch 83 - iter 198/220 - loss 0.79342823 - samples/sec: 464.33
2020-04-02 00:04:36,542 epoch 55 - iter 387/439 - loss 0.62573730 - samples/sec: 155.68
2020-04-02 00:04:42,237 epoch 7 - iter 258/439 - loss 1.63018596 - samples/sec: 165.70
2020-04-02 00:04:54,287 epoch 56 - iter 258/439 - loss 0.60554478 - samples/sec: 148.78
2020-04-02 00:04:51,642 epoch 55 - iter 430/439 - loss 0.62869106 - samples/sec: 148.53
2020-04-02 00:04:46,763 epoch 83 - iter 220/220 - loss 0.79870408 - samples/sec: 432.28
2020-04-02 00:04:52,420 ----------------------------------------------------------------------------------------------------
2020-04-02 00:04:52,421 EPOCH 83 done: loss 0.7987 - lr 0.0013
2020-04-02 00:04:59,293 ----------------------------------------------------------------------------------------------------
2020-04-02 00:04:59,294 EPOCH 55 done: loss 0.6296 - lr 0.0100
2020-04-02 00:05:03,763 DEV : loss 0.5168473720550537 - score 0.938
2020-04-02 00:05:03,858 BAD EPOCHS (no improvement): 2
2020-04-02 00:05:03,933 ----------------------------------------------------------------------------------------------------
2020-04-02 00:04:56,355 DEV : loss 0.5672868490219116 - score 0.933
2020-04-02 00:04:56,453 BAD EPOCHS (no improvement): 1
2020-04-02 00:04:56,524 ----------------------------------------------------------------------------------------------------
2020-04-02 00:04:59,458 epoch 84 - iter 22/220 - loss 0.79224351 - samples/sec: 480.17
2020-04-02 00:05:08,682 epoch 84 - iter 44/220 - loss 0.78190713 - samples/sec: 383.63

2020-04-02 00:05:13,049 epoch 56 - iter 43/439 - loss 0.57213254 - samples/sec: 151.01
2020-04-02 00:05:18,512 epoch 84 - iter 66/220 - loss 0.77943355 - samples/sec: 425.40

2020-04-02 00:05:27,959 epoch 84 - iter 88/220 - loss 0.77058312 - samples/sec: 425.80
2020-04-02 00:05:38,149 epoch 84 - iter 110/220 - loss 0.77553418 - samples/sec: 423.70
2020-04-02 00:05:44,290 epoch 56 - iter 129/439 - loss 0.60768054 - samples/sec: 151.86
2020-04-02 00:05:47,801 epoch 84 - iter 132/220 - loss 0.77595091 - samples/sec: 427.34
2020-04-02 00:05:56,823 epoch 84 - iter 154/220 - loss 0.76360136 - samples/sec: 422.03
-----------------------------------
2020-04-02 00:06:01,403 EPOCH 56 done: loss 0.6122 - lr 0.0013
2020-04-02 00:05:59,145 epoch 56 - iter 172/439 - loss 0.60054895 - samples/sec: 152.91
2020-04-02 00:06:06,903 epoch 84 - iter 176/220 - loss 0.76563351 - samples/sec: 335.07
75 BAD EPOCHS (no improvement): 1
2020-04-02 00:06:06,004 ----------------------------------------------------------------------------------------------------
2020-04-02 00:06:14,956 epoch 57 - iter 43/439 - loss 0.66794183 - samples/sec: 153.78
2020-04-02 00:06:13,883 epoch 56 - iter 215/439 - loss 0.60035492 - samples/sec: 153.00
2020-04-02 00:06:17,244 epoch 84 - iter 198/220 - loss 0.76570686 - samples/sec: 294.21
2020-04-02 00:06:27,179 epoch 7 - iter 301/439 - loss 1.63992846 - samples/sec: 154.75
2020-04-02 00:06:30,598 epoch 57 - iter 86/439 - loss 0.63152935 - samples/sec: 152.03
2020-04-02 00:06:29,456 epoch 56 - iter 258/439 - loss 0.60828936 - samples/sec: 150.96
2020-04-02 00:06:27,826 epoch 84 - iter 220/220 - loss 0.76958823 - samples/sec: 309.86
2020-04-02 00:06:33,999 ----------------------------------------------------------------------------------------------------
2020-04-02 00:06:34,000 EPOCH 84 done: loss 0.7696 - lr 0.0013
2020-04-02 00:06:37,942 DEV : loss 0.5718793869018555 - score 0.9331
2020-04-02 00:06:38,039 BAD EPOCHS (no improvement): 2
2020-04-02 00:06:38,104 ----------------------------------------------------------------------------------------------------
2020-04-02 00:06:42,942 epoch 85 - iter 22/220 - loss 0.73302293 - samples/sec: 291.26
2020-04-02 00:06:53,984 epoch 85 - iter 44/220 - loss 0.76588884 - samples/sec: 324.02

2020-04-02 00:07:04,018 epoch 85 - iter 66/220 - loss 0.74869395 - samples/sec: 325.37

2020-04-02 00:07:00,084 epoch 56 - iter 344/439 - loss 0.60063562 - samples/sec: 154.38
2020-04-02 00:07:13,999 epoch 85 - iter 88/220 - loss 0.74349283 - samples/sec: 319.74

2020-04-02 00:07:26,088 epoch 85 - iter 110/220 - loss 0.77214065 - samples/sec: 295.22
2020-04-02 00:07:37,004 epoch 85 - iter 132/220 - loss 0.78486039 - samples/sec: 298.99
2020-04-02 00:07:31,840 epoch 56 - iter 430/439 - loss 0.61517210 - samples/sec: 152.43
2020-04-02 00:07:39,509 epoch 6 - iter 66/220 - loss 1.38237324 - samples/sec: 123.71
2020-04-02 00:07:39,968 ----------------------------------------------------------------------------------------------------
2020-04-02 00:07:39,969 EPOCH 56 done: loss 0.6148 - lr 0.0100
2020-04-02 00:07:44,441 DEV : loss 0.5142260193824768 - score 0.9377
2020-04-02 00:07:44,538 BAD EPOCHS (no improvement): 3
2020-04-02 00:07:44,586 ----------------------------------------------------------------------------------------------------
2020-04-02 00:07:47,417 epoch 85 - iter 154/220 - loss 0.77510356 - samples/sec: 298.90
2020-04-02 00:07:53,737 epoch 57 - iter 43/439 - loss 0.61257555 - samples/sec: 150.44
2020-04-02 00:07:58,399 epoch 85 - iter 176/220 - loss 0.77047907 - samples/sec: 326.50
2020-04-02 00:08:15,857 epoch 7 - iter 344/439 - loss 1.62897471 - samples/sec: 165.87

2020-04-02 00:08:19,562 epoch 85 - iter 220/220 - loss 0.77000160 - samples/sec: 318.32
2020-04-02 00:08:25,660 ----------------------------------------------------------------------------------------------------
2020-04-02 00:08:25,660 EPOCH 85 done: loss 0.7700 - lr 0.0013
2020-04-02 00:08:29,580 DEV : loss 0.5674088001251221 - score 0.9338
2020-04-02 00:08:29,676 BAD EPOCHS (no improvement): 3
2020-04-02 00:08:29,729 ----------------------------------------------------------------------------------------------------
2020-04-02 00:08:33,550 epoch 86 - iter 22/220 - loss 0.75378413 - samples/sec: 368.67
2020-04-02 00:08:43,571 epoch 86 - iter 44/220 - loss 0.76237157 - samples/sec: 388.03
------------------------------------
2020-04-02 00:08:41,219 EPOCH 57 done: loss 0.6262 - lr 0.0013
2020-04-02 00:08:45,648 DEV : loss 0.5520374774932861 - score 0.9376
2020-04-02 00:08:45,743 BAD EPOCHS (no improvement): 0
2020-04-02 00:08:39,056 epoch 57 - iter 172/439 - loss 0.62904193 - samples/sec: 150.47
2020-04-02 00:08:47,880 epoch 4 - iter 86/439 - loss 1.28094945 - samples/sec: 82.76
2020-04-02 00:08:54,533 epoch 86 - iter 66/220 - loss 0.75918434 - samples/sec: 323.44
------------------------------------
2020-04-02 00:08:56,319 epoch 58 - iter 43/439 - loss 0.61366085 - samples/sec: 152.69
2020-04-02 00:08:53,705 epoch 57 - iter 215/439 - loss 0.62463799 - samples/sec: 154.90
2020-04-02 00:09:05,086 epoch 86 - iter 88/220 - loss 0.77924184 - samples/sec: 331.07
2020-04-02 00:09:10,974 epoch 58 - iter 86/439 - loss 0.57134646 - samples/sec: 153.56
2020-04-02 00:09:09,070 epoch 57 - iter 258/439 - loss 0.61505510 - samples/sec: 154.88
2020-04-02 00:09:14,942 epoch 86 - iter 110/220 - loss 0.78039252 - samples/sec: 368.36
2020-04-02 00:09:25,029 epoch 57 - iter 301/439 - loss 0.62579541 - samples/sec: 151.42
2020-04-02 00:09:26,694 epoch 58 - iter 129/439 - loss 0.59803339 - samples/sec: 153.36
2020-04-02 00:09:42,254 epoch 86 - iter 132/220 - loss 0.76805401 - samples/sec: 276.06
2020-04-02 00:09:55,148 epoch 57 - iter 344/439 - loss 0.62961410 - samples/sec: 153.91
2020-04-02 00:09:55,212 epoch 58 - iter 172/439 - loss 0.62288108 - samples/sec: 151.82
2020-04-02 00:09:54,202 epoch 86 - iter 154/220 - loss 0.78442771 - samples/sec: 332.68
2020-04-02 00:10:11,047 epoch 57 - iter 387/439 - loss 0.63476176 - samples/sec: 153.73
2020-04-02 00:10:10,994 epoch 58 - iter 215/439 - loss 0.62229512 - samples/sec: 155.24
2020-04-02 00:10:14,988 epoch 86 - iter 198/220 - loss 0.78361721 - samples/sec: 347.95
2020-04-02 00:10:25,897 epoch 58 - iter 258/439 - loss 0.62385925 - samples/sec: 151.90
2020-04-02 00:10:25,222 epoch 86 - iter 220/220 - loss 0.78421055 - samples/sec: 307.24
2020-04-02 00:10:31,349 ----------------------------------------------------------------------------------------------------
2020-04-02 00:10:31,349 EPOCH 86 done: loss 0.7842 - lr 0.0013
2020-04-02 00:10:26,124 epoch 57 - iter 430/439 - loss 0.63461140 - samples/sec: 149.34
2020-04-02 00:10:34,147 ----------------------------------------------------------------------------------------------------
2020-04-02 00:10:34,148 EPOCH 57 done: loss 0.6304 - lr 0.0100
2020-04-02 00:10:38,610 DEV : loss 0.5119253993034363 - score 0.9403
2020-04-02 00:10:38,707 BAD EPOCHS (no improvement): 0
2020-04-02 00:10:39,987 ----------------------------------------------------------------------------------------------------
-------------------------------------------------------------
2020-04-02 00:10:38,820 epoch 87 - iter 22/220 - loss 0.77833243 - samples/sec: 403.73
2020-04-02 00:10:40,513 epoch 58 - iter 301/439 - loss 0.62516819 - samples/sec: 162.54
2020-04-02 00:10:49,465 epoch 87 - iter 44/220 - loss 0.78886121 - samples/sec: 385.89
2020-04-02 00:10:48,901 epoch 58 - iter 43/439 - loss 0.58336043 - samples/sec: 154.46
2020-04-02 00:10:56,200 epoch 58 - iter 344/439 - loss 0.62175709 - samples/sec: 154.29
2020-04-02 00:11:00,427 epoch 87 - iter 66/220 - loss 0.78253901 - samples/sec: 344.81
2020-04-02 00:11:04,783 epoch 58 - iter 86/439 - loss 0.60202253 - samples/sec: 154.73
2020-04-02 00:11:11,091 epoch 58 - iter 387/439 - loss 0.62584358 - samples/sec: 151.45
2020-04-02 00:11:20,437 epoch 58 - iter 129/439 - loss 0.59833979 - samples/sec: 150.92
2020-04-02 00:11:26,287 epoch 58 - iter 430/439 - loss 0.62637892 - samples/sec: 153.75
2020-04-02 00:11:34,247 ----------------------------------------------------------------------------------------------------
2020-04-02 00:11:34,248 EPOCH 58 done: loss 0.6253 - lr 0.0013
2020-04-02 00:11:33,117 epoch 87 - iter 132/220 - loss 0.77539029 - samples/sec: 319.22
2020-04-02 00:11:36,078 epoch 58 - iter 172/439 - loss 0.60349684 - samples/sec: 156.12
2020-04-02 00:11:38,680 DEV : loss 0.5494001507759094 - score 0.9372
2020-04-02 00:11:38,776 BAD EPOCHS (no improvement): 1
2020-04-02 00:11:38,844 ----------------------------------------------------------------------------------------------------
2020-04-02 00:11:51,690 epoch 58 - iter 215/439 - loss 0.60045062 - samples/sec: 152.16
2020-04-02 00:11:50,994 epoch 6 - iter 88/220 - loss 1.36786540 - samples/sec: 124.33
2020-04-02 00:11:47,537 epoch 59 - iter 43/439 - loss 0.58550722 - samples/sec: 158.36
2020-04-02 00:12:01,866 epoch 59 - iter 86/439 - loss 0.62636124 - samples/sec: 165.41

2020-04-02 00:12:04,464 epoch 87 - iter 198/220 - loss 0.76993599 - samples/sec: 310.85
2020-04-02 00:12:07,513 epoch 58 - iter 258/439 - loss 0.60738877 - samples/sec: 150.73
2020-04-02 00:12:17,082 epoch 59 - iter 129/439 - loss 0.62472635 - samples/sec: 153.24
2020-04-02 00:12:22,304 epoch 58 - iter 301/439 - loss 0.60849932 - samples/sec: 155.88
2020-04-02 00:12:21,216 ----------------------------------------------------------------------------------------------------
2020-04-02 00:12:21,216 EPOCH 87 done: loss 0.7779 - lr 0.0006
2020-04-02 00:12:31,948 epoch 59 - iter 172/439 - loss 0.61118937 - samples/sec: 154.07
,292 BAD EPOCHS (no improvement): 1
2020-04-02 00:12:25,332 ----------------------------------------------------------------------------------------------------
2020-04-02 00:12:29,550 epoch 88 - iter 22/220 - loss 0.76847069 - samples/sec: 333.98
2020-04-02 00:12:39,419 epoch 88 - iter 44/220 - loss 0.75939767 - samples/sec: 344.20
2020-04-02 00:12:37,445 epoch 58 - iter 344/439 - loss 0.60959978 - samples/sec: 151.26
2020-04-02 00:12:47,093 epoch 59 - iter 215/439 - loss 0.61280970 - samples/sec: 150.93
2020-04-02 00:12:50,641 epoch 88 - iter 66/220 - loss 0.78584446 - samples/sec: 307.79
2020-04-02 00:12:53,339 epoch 58 - iter 387/439 - loss 0.61096202 - samples/sec: 152.73
2020-04-02 00:13:02,437 epoch 59 - iter 258/439 - loss 0.62203364 - samples/sec: 156.29
2020-04-02 00:13:12,233 epoch 58 - iter 430/439 - loss 0.60668839 - samples/sec: 152.57
2020-04-02 00:13:20,445 ----------------------------------------------------------------------------------------------------
2020-04-02 00:13:20,445 EPOCH 58 done: loss 0.6058 - lr 0.0100
2020-04-02 00:13:24,891 DEV : loss 0.5151935815811157 - score 0.9383
2020-04-02 00:13:24,988 BAD EPOCHS (no improvement): 1
2020-04-02 00:13:25,024 ----------------------------------------------------------------------------------------------------
2020-04-02 00:13:17,941 epoch 59 - iter 301/439 - loss 0.62093414 - samples/sec: 152.99
2020-04-02 00:13:25,435 epoch 88 - iter 132/220 - loss 0.77695566 - samples/sec: 297.53
2020-04-02 00:13:34,090 epoch 59 - iter 43/439 - loss 0.56625403 - samples/sec: 151.85
2020-04-02 00:13:33,923 epoch 59 - iter 344/439 - loss 0.62282742 - samples/sec: 149.96
2020-04-02 00:13:36,217 epoch 88 - iter 154/220 - loss 0.77717212 - samples/sec: 299.72
2020-04-02 00:13:46,616 epoch 88 - iter 176/220 - loss 0.76622694 - samples/sec: 312.10
2020-04-02 00:13:49,277 epoch 59 - iter 86/439 - loss 0.57528503 - samples/sec: 149.86
2020-04-02 00:13:48,983 epoch 59 - iter 387/439 - loss 0.62226175 - samples/sec: 152.95
2020-04-02 00:14:01,529 ----------------------------------------------------------------------------------------------------
2020-04-02 00:14:01,529 EPOCH 7 done: loss 1.6243 - lr 0.0100
2020-04-02 00:13:57,173 epoch 88 - iter 198/220 - loss 0.76937114 - samples/sec: 300.70
2020-04-02 00:14:04,261 epoch 59 - iter 129/439 - loss 0.59469489 - samples/sec: 150.99
2020-04-02 00:14:03,686 epoch 59 - iter 430/439 - loss 0.62200780 - samples/sec: 155.02
2020-04-02 00:14:11,765 ----------------------------------------------------------------------------------------------------
2020-04-02 00:14:11,766 EPOCH 59 done: loss 0.6245 - lr 0.0013
2020-04-02 00:14:16,250 DEV : loss 0.5510221719741821 - score 0.9371
2020-04-02 00:14:16,349 BAD EPOCHS (no improvement): 2
2020-04-02 00:14:16,410 ----------------------------------------------------------------------------------------------------
2020-04-02 00:14:18,065 ----------------------------------------------------------------------------------------------------
2020-04-02 00:14:18,066 EPOCH 88 done: loss 0.7769 - lr 0.0006
2020-04-02 00:14:22,059 DEV : loss 0.5659581422805786 - score 0.9327
2020-04-02 00:14:22,155 BAD EPOCHS (no improvement): 2
2020-04-02 00:14:22,168 ----------------------------------------------------------------------------------------------------
2020-04-02 00:14:19,111 epoch 59 - iter 172/439 - loss 0.60190692 - samples/sec: 157.52
2020-04-02 00:14:25,249 epoch 60 - iter 43/439 - loss 0.60607254 - samples/sec: 155.73
2020-04-02 00:14:34,647 epoch 59 - iter 215/439 - loss 0.61097113 - samples/sec: 150.53
2020-04-02 00:14:33,996 epoch 4 - iter 129/439 - loss 1.28364768 - samples/sec: 87.29
2020-04-02 00:14:35,238 epoch 89 - iter 44/220 - loss 0.77534515 - samples/sec: 357.92
2020-04-02 00:14:39,955 epoch 60 - iter 86/439 - loss 0.61134544 - samples/sec: 151.34
2020-04-02 00:14:46,225 epoch 89 - iter 66/220 - loss 0.78142084 - samples/sec: 307.12
2020-04-02 00:14:49,821 epoch 59 - iter 258/439 - loss 0.60025410 - samples/sec: 154.08
2020-04-02 00:14:55,621 epoch 60 - iter 129/439 - loss 0.63417730 - samples/sec: 153.77
2020-04-02 00:15:04,732 epoch 59 - iter 301/439 - loss 0.60359475 - samples/sec: 152.60
2020-04-02 00:15:06,740 epoch 89 - iter 110/220 - loss 0.77055122 - samples/sec: 314.57
2020-04-02 00:15:10,525 epoch 60 - iter 172/439 - loss 0.62019327 - samples/sec: 153.21
2020-04-02 00:15:17,255 epoch 89 - iter 132/220 - loss 0.77620789 - samples/sec: 294.41
2020-04-02 00:15:19,410 epoch 59 - iter 344/439 - loss 0.60931000 - samples/sec: 155.30
2020-04-02 00:15:25,456 epoch 60 - iter 215/439 - loss 0.61879121 - samples/sec: 154.98
2020-04-02 00:15:34,884 epoch 59 - iter 387/439 - loss 0.61110732 - samples/sec: 151.91
2020-04-02 00:15:40,196 epoch 89 - iter 176/220 - loss 0.76560734 - samples/sec: 268.89
2020-04-02 00:15:36,962 epoch 6 - iter 110/220 - loss 1.38355846 - samples/sec: 124.06
2020-04-02 00:15:40,560 epoch 60 - iter 258/439 - loss 0.61647294 - samples/sec: 154.01
2020-04-02 00:15:51,451 epoch 89 - iter 198/220 - loss 0.77161260 - samples/sec: 312.17
2020-04-02 00:15:49,909 epoch 59 - iter 430/439 - loss 0.61391115 - samples/sec: 155.19
2020-04-02 00:15:56,252 epoch 60 - iter 301/439 - loss 0.61001758 - samples/sec: 154.78
2020-04-02 00:15:58,370 ----------------------------------------------------------------------------------------------------
2020-04-02 00:15:58,371 EPOCH 59 done: loss 0.6128 - lr 0.0100
2020-04-02 00:16:02,821 DEV : loss 0.5197738409042358 - score 0.9407
2020-04-02 00:16:02,918 BAD EPOCHS (no improvement): 0
2020-04-02 00:16:04,277 ----------------------------------------------------------------------------------------------------
2020-04-02 00:16:13,609 epoch 60 - iter 43/439 - loss 0.59140177 - samples/sec: 147.53
------------------------------------
2020-04-02 00:16:09,524 EPOCH 89 done: loss 0.7729 - lr 0.0006
2020-04-02 00:16:13,473 DEV : loss 0.5663239359855652 - score 0.934
2020-04-02 00:16:13,572 BAD EPOCHS (no improvement): 0
2020-04-02 00:16:14,808 ----------------------------------------------------------------------------------------------------
2020-04-02 00:16:11,924 epoch 60 - iter 344/439 - loss 0.61221022 - samples/sec: 153.46
2020-04-02 00:16:19,467 epoch 90 - iter 22/220 - loss 0.84770435 - samples/sec: 302.43
2020-04-02 00:16:27,337 epoch 60 - iter 387/439 - loss 0.61161347 - samples/sec: 156.67
2020-04-02 00:16:30,973 epoch 90 - iter 44/220 - loss 0.80471297 - samples/sec: 301.81
2020-04-02 00:16:29,818 epoch 60 - iter 86/439 - loss 0.59377120 - samples/sec: 153.11
2020-04-02 00:16:45,445 epoch 60 - iter 129/439 - loss 0.58606662 - samples/sec: 151.91
2020-04-02 00:16:42,889 epoch 60 - iter 430/439 - loss 0.61114229 - samples/sec: 151.05
2020-04-02 00:16:53,835 epoch 90 - iter 88/220 - loss 0.79643288 - samples/sec: 272.87
2020-04-02 00:16:51,248 ----------------------------------------------------------------------------------------------------
2020-04-02 00:16:51,249 EPOCH 60 done: loss 0.6108 - lr 0.0013
2020-04-02 00:16:55,751 DEV : loss 0.5520440936088562 - score 0.9369
2020-04-02 00:16:55,850 BAD EPOCHS (no improvement): 3
2020-04-02 00:16:55,899 ----------------------------------------------------------------------------------------------------
2020-04-02 00:17:00,770 epoch 60 - iter 172/439 - loss 0.61147416 - samples/sec: 156.59
2020-04-02 00:17:13,006 epoch 90 - iter 110/220 - loss 0.79178410 - samples/sec: 340.90
2020-04-02 00:17:04,123 epoch 61 - iter 43/439 - loss 0.53449729 - samples/sec: 167.40
2020-04-02 00:17:20,574 epoch 61 - iter 86/439 - loss 0.55633800 - samples/sec: 169.71
2020-04-02 00:17:21,268 epoch 60 - iter 215/439 - loss 0.60219110 - samples/sec: 155.28
2020-04-02 00:17:31,749 epoch 90 - iter 132/220 - loss 0.78822631 - samples/sec: 389.42
2020-04-02 00:17:41,911 epoch 90 - iter 154/220 - loss 0.78612679 - samples/sec: 317.57
2020-04-02 00:17:41,152 epoch 60 - iter 258/439 - loss 0.59609822 - samples/sec: 151.58
2020-04-02 00:17:54,081 epoch 90 - iter 176/220 - loss 0.77323806 - samples/sec: 326.57
2020-04-02 00:18:04,404 epoch 90 - iter 198/220 - loss 0.76368095 - samples/sec: 312.74
2020-04-02 00:17:58,055 epoch 60 - iter 301/439 - loss 0.59724246 - samples/sec: 152.35
2020-04-02 00:18:13,978 epoch 90 - iter 220/220 - loss 0.76500523 - samples/sec: 433.22
2020-04-02 00:18:12,996 epoch 60 - iter 344/439 - loss 0.59441184 - samples/sec: 154.14
2020-04-02 00:18:19,882 ----------------------------------------------------------------------------------------------------
2020-04-02 00:18:19,883 EPOCH 90 done: loss 0.7650 - lr 0.0006
2020-04-02 00:18:23,869 DEV : loss 0.5669061541557312 - score 0.933
2020-04-02 00:18:23,969 BAD EPOCHS (no improvement): 1
2020-04-02 00:18:24,037 ----------------------------------------------------------------------------------------------------
2020-04-02 00:18:28,353 epoch 61 - iter 258/439 - loss 0.63866782 - samples/sec: 151.44
2020-04-02 00:18:27,959 epoch 60 - iter 387/439 - loss 0.59372045 - samples/sec: 154.27
2020-04-02 00:18:43,778 epoch 61 - iter 301/439 - loss 0.64169997 - samples/sec: 155.94
2020-04-02 00:18:43,670 epoch 60 - iter 430/439 - loss 0.59592530 - samples/sec: 151.13
2020-04-02 00:18:48,596 epoch 91 - iter 66/220 - loss 0.76813335 - samples/sec: 303.18
2020-04-02 00:18:51,574 ----------------------------------------------------------------------------------------------------
2020-04-02 00:18:51,574 EPOCH 60 done: loss 0.5985 - lr 0.0100
2020-04-02 00:18:56,047 DEV : loss 0.5043076872825623 - score 0.9404
2020-04-02 00:18:56,145 BAD EPOCHS (no improvement): 1
2020-04-02 00:18:56,193 ----------------------------------------------------------------------------------------------------
2020-04-02 00:18:58,423 epoch 61 - iter 344/439 - loss 0.63743388 - samples/sec: 160.49
2020-04-02 00:19:05,164 epoch 61 - iter 43/439 - loss 0.63604372 - samples/sec: 153.44
2020-04-02 00:19:12,986 epoch 61 - iter 387/439 - loss 0.62781052 - samples/sec: 157.23
2020-04-02 00:19:09,528 epoch 91 - iter 110/220 - loss 0.76319368 - samples/sec: 300.47
2020-04-02 00:19:20,468 epoch 61 - iter 86/439 - loss 0.58155686 - samples/sec: 153.85

2020-04-02 00:19:28,280 epoch 61 - iter 430/439 - loss 0.62395736 - samples/sec: 153.18
2020-04-02 00:19:36,012 ----------------------------------------------------------------------------------------------------
2020-04-02 00:19:36,013 EPOCH 61 done: loss 0.6221 - lr 0.0013
2020-04-02 00:19:36,621 epoch 61 - iter 129/439 - loss 0.57500168 - samples/sec: 159.95
2020-04-02 00:19:41,975 epoch 91 - iter 176/220 - loss 0.76813533 - samples/sec: 303.67
g learning rate of group 0 to 6.2500e-04.
2020-04-02 00:19:40,579 BAD EPOCHS (no improvement): 4
2020-04-02 00:19:40,620 ----------------------------------------------------------------------------------------------------
2020-04-02 00:19:38,042 epoch 6 - iter 132/220 - loss 1.38403801 - samples/sec: 137.44
2020-04-02 00:19:51,996 epoch 91 - iter 198/220 - loss 0.76803702 - samples/sec: 372.412020-04-02 00:19:51,789 epoch 61 - iter 172/439 - loss 0.58563180 - samples/sec: 152.19
2020-04-02 00:20:02,175 epoch 91 - iter 220/220 - loss 0.76943602 - samples/sec: 395.972020-04-02 00:20:07,506 epoch 61 - iter 215/439 - loss 0.59626614 - samples/sec: 150.79
2020-04-02 00:20:13,990 epoch 4 - iter 172/439 - loss 1.32506709 - samples/sec: 93.68

2020-04-02 00:20:08,000 ----------------------------------------------------------------------------------------------------
2020-04-02 00:20:08,001 EPOCH 91 done: loss 0.7694 - lr 0.0006
2020-04-02 00:20:11,838 DEV : loss 0.5668796896934509 - score 0.9333
2020-04-02 00:20:11,938 BAD EPOCHS (no improvement): 2
2020-04-02 00:20:11,990 ----------------------------------------------------------------------------------------------------
2020-04-02 00:20:15,893 epoch 92 - iter 22/220 - loss 0.73000099 - samples/sec: 360.96
2020-04-02 00:20:26,375 epoch 92 - iter 44/220 - loss 0.76983273 - samples/sec: 281.61

2020-04-02 00:20:22,129 epoch 61 - iter 258/439 - loss 0.59374144 - samples/sec: 154.03
2020-04-02 00:20:34,097 epoch 62 - iter 172/439 - loss 0.57572522 - samples/sec: 149.28
2020-04-02 00:20:37,461 epoch 61 - iter 301/439 - loss 0.59903847 - samples/sec: 151.64
2020-04-02 00:20:37,507 epoch 92 - iter 66/220 - loss 0.75856879 - samples/sec: 295.41
2020-04-02 00:20:48,586 epoch 92 - iter 88/220 - loss 0.75829484 - samples/sec: 338.96

2020-04-02 00:20:53,437 epoch 61 - iter 344/439 - loss 0.59893721 - samples/sec: 152.58
2020-04-02 00:20:59,410 epoch 92 - iter 110/220 - loss 0.75528606 - samples/sec: 289.91
2020-04-02 00:21:08,300 epoch 61 - iter 387/439 - loss 0.59894022 - samples/sec: 152.50
2020-04-02 00:21:21,675 epoch 92 - iter 154/220 - loss 0.76284437 - samples/sec: 284.47
2020-04-02 00:21:24,875 epoch 61 - iter 430/439 - loss 0.60376286 - samples/sec: 148.64
2020-04-02 00:21:34,911 epoch 62 - iter 344/439 - loss 0.60691853 - samples/sec: 155.93
2020-04-02 00:21:33,250 ----------------------------------------------------------------------------------------------------
2020-04-02 00:21:33,250 EPOCH 61 done: loss 0.6035 - lr 0.0100
2020-04-02 00:21:37,717 DEV : loss 0.513031005859375 - score 0.9398
2020-04-02 00:21:37,815 BAD EPOCHS (no improvement): 2
2020-04-02 00:21:37,838 ----------------------------------------------------------------------------------------------------
2020-04-02 00:21:46,960 epoch 62 - iter 43/439 - loss 0.64191554 - samples/sec: 150.92

2020-04-02 00:21:50,229 epoch 62 - iter 387/439 - loss 0.60840329 - samples/sec: 151.00
2020-04-02 00:21:53,973 epoch 92 - iter 220/220 - loss 0.76820651 - samples/sec: 334.68
2020-04-02 00:22:05,335 epoch 62 - iter 430/439 - loss 0.61252821 - samples/sec: 151.91
2020-04-02 00:22:01,761 epoch 62 - iter 86/439 - loss 0.62427091 - samples/sec: 153.28
------------------------------------
2020-04-02 00:22:00,522 EPOCH 92 done: loss 0.7682 - lr 0.0006
2020-04-02 00:22:04,477 DEV : loss 0.5654230117797852 - score 0.9343
2020-04-02 00:22:04,577 BAD EPOCHS (no improvement): 0
2020-04-02 00:22:05,907 ----------------------------------------------------------------------------------------------------
2020-04-02 00:22:10,179 epoch 93 - iter 22/220 - loss 0.85069548 - samples/sec: 329.91
------------------------------------
2020-04-02 00:22:13,677 EPOCH 62 done: loss 0.6108 - lr 0.0006
2020-04-02 00:22:17,004 epoch 62 - iter 129/439 - loss 0.59818324 - samples/sec: 157.82
2020-04-02 00:22:21,238 epoch 93 - iter 44/220 - loss 0.81218125 - samples/sec: 283.30
8,254 BAD EPOCHS (no improvement): 1
2020-04-02 00:22:18,302 ----------------------------------------------------------------------------------------------------
2020-04-02 00:22:27,125 epoch 63 - iter 43/439 - loss 0.62056356 - samples/sec: 156.04
2020-04-02 00:22:32,753 epoch 62 - iter 172/439 - loss 0.59715739 - samples/sec: 152.72
2020-04-02 00:22:42,975 epoch 93 - iter 88/220 - loss 0.78070582 - samples/sec: 303.06
2020-04-02 00:22:48,100 epoch 62 - iter 215/439 - loss 0.60790648 - samples/sec: 149.24
2020-04-02 00:22:54,378 epoch 93 - iter 110/220 - loss 0.78211798 - samples/sec: 306.95
2020-04-02 00:23:05,273 epoch 93 - iter 132/220 - loss 0.76969270 - samples/sec: 308.34
2020-04-02 00:23:03,132 epoch 62 - iter 258/439 - loss 0.61061053 - samples/sec: 152.47
2020-04-02 00:23:15,062 epoch 93 - iter 154/220 - loss 0.77092391 - samples/sec: 375.69
2020-04-02 00:23:18,038 epoch 62 - iter 301/439 - loss 0.61137964 - samples/sec: 154.81
2020-04-02 00:23:26,302 epoch 93 - iter 176/220 - loss 0.76674258 - samples/sec: 298.20
2020-04-02 00:23:28,408 epoch 63 - iter 215/439 - loss 0.58941109 - samples/sec: 150.97
2020-04-02 00:23:33,794 epoch 62 - iter 344/439 - loss 0.59838812 - samples/sec: 151.01
2020-04-02 00:23:37,728 epoch 93 - iter 198/220 - loss 0.76748921 - samples/sec: 289.85
2020-04-02 00:23:48,289 epoch 62 - iter 387/439 - loss 0.59744698 - samples/sec: 156.01
2020-04-02 00:23:48,582 epoch 93 - iter 220/220 - loss 0.77355789 - samples/sec: 323.91
2020-04-02 00:23:54,910 ----------------------------------------------------------------------------------------------------
2020-04-02 00:23:54,910 EPOCH 93 done: loss 0.7736 - lr 0.0006
2020-04-02 00:23:58,858 DEV : loss 0.5651721954345703 - score 0.9338
2020-04-02 00:23:582020-04-02 00:24:03,941 epoch 62 - iter 430/439 - loss 0.59453075 - samples/sec: 147.45
------------------------------------------------------------------------
2020-04-02 00:24:03,581 epoch 94 - iter 22/220 - loss 0.80654234 - samples/sec: 306.27
2020-04-02 00:24:15,041 epoch 94 - iter 44/220 - loss 0.79457787 - samples/sec: 296.30

2020-04-02 00:24:12,633 ----------------------------------------------------------------------------------------------------
2020-04-02 00:24:12,634 EPOCH 62 done: loss 0.5946 - lr 0.0100
2020-04-02 00:24:17,087 DEV : loss 0.4973811209201813 - score 0.9393
2020-04-02 00:24:17,184 BAD EPOCHS (no improvement): 3
2020-04-02 00:24:17,227 ----------------------------------------------------------------------------------------------------
2020-04-02 00:24:26,343 epoch 63 - iter 43/439 - loss 0.56007886 - samples/sec: 151.02
2020-04-02 00:24:37,131 epoch 94 - iter 88/220 - loss 0.77411985 - samples/sec: 313.89

2020-04-02 00:24:45,177 epoch 63 - iter 430/439 - loss 0.60768583 - samples/sec: 150.21
2020-04-02 00:24:41,866 epoch 63 - iter 86/439 - loss 0.59738914 - samples/sec: 152.96
2020-04-02 00:24:48,280 epoch 94 - iter 110/220 - loss 0.78288456 - samples/sec: 311.86
-----------------------------------
2020-04-02 00:24:53,134 EPOCH 63 done: loss 0.6080 - lr 0.0006
2020-04-02 00:24:57,614 DEV : loss 0.551612138748169 - score 0.9379
2020-04-02 00:24:57,712 BAD EPOCHS (no improvement): 0
2020-04-02 00:24:56,774 epoch 63 - iter 129/439 - loss 0.59107805 - samples/sec: 155.46
2020-04-02 00:24:58,633 epoch 94 - iter 132/220 - loss 0.77819237 - samples/sec: 340.00
-----------------------------------
2020-04-02 00:25:09,574 epoch 94 - iter 154/220 - loss 0.78959792 - samples/sec: 364.682020-04-02 00:25:13,379 epoch 63 - iter 172/439 - loss 0.58921662 - samples/sec: 151.71
2020-04-02 00:25:19,933 epoch 94 - iter 176/220 - loss 0.78569517 - samples/sec: 330.452020-04-02 00:25:28,002 epoch 63 - iter 215/439 - loss 0.58616363 - samples/sec: 157.16
2020-04-02 00:25:34,882 epoch 4 - iter 215/439 - loss 1.29832210 - samples/sec: 87.75
2020-04-02 00:25:29,192 epoch 94 - iter 198/220 - loss 0.77792698 - samples/sec: 447.38
2020-04-02 00:25:38,792 epoch 94 - iter 220/220 - loss 0.77854502 - samples/sec: 439.11
2020-04-02 00:25:45,193 ----------------------------------------------------------------2020-04-02 00:25:43,351 epoch 63 - iter 258/439 - loss 0.59179713 - samples/sec: 152.59
- lr 0.0006
2020-04-02 00:25:49,140 DEV : loss 0.5650793313980103 - score 0.9337
2020-04-02 00:25:492020-04-02 00:25:58,586 epoch 63 - iter 301/439 - loss 0.58857282 - samples/sec: 153.32
------------------------------------------------------------------------
2020-04-02 00:25:52,279 epoch 95 - iter 22/220 - loss 0.75992152 - samples/sec: 476.78
2020-04-02 00:26:01,589 epoch 95 - iter 44/220 - loss 0.79709008 - samples/sec: 425.14
2020-04-02 00:26:10,746 epoch 95 - iter 66/220 - loss 0.77312444 - samples/sec: 410.20

2020-04-02 00:26:13,623 epoch 63 - iter 344/439 - loss 0.58545473 - samples/sec: 153.55
2020-04-02 00:26:20,150 epoch 95 - iter 88/220 - loss 0.81033227 - samples/sec: 424.62

2020-04-02 00:26:28,619 epoch 63 - iter 387/439 - loss 0.58301936 - samples/sec: 151.50
2020-04-02 00:26:29,622 epoch 95 - iter 110/220 - loss 0.81688828 - samples/sec: 422.75
2020-04-02 00:26:39,130 epoch 95 - iter 132/220 - loss 0.79982217 - samples/sec: 420.16
2020-04-02 00:26:43,801 epoch 63 - iter 430/439 - loss 0.58281662 - samples/sec: 156.07
2020-04-02 00:26:48,824 epoch 95 - iter 154/220 - loss 0.79226288 - samples/sec: 426.94
2020-04-02 00:26:52,264 ----------------------------------------------------------------------------------------------------
2020-04-02 00:26:52,265 EPOCH 63 done: loss 0.5833 - lr 0.0100
2020-04-02 00:26:56,746 DEV : loss 0.5046172738075256 - score 0.941
2020-04-02 00:26:56,844 BAD EPOCHS (no improvement): 0
2020-04-02 00:26:58,160 ----------------------------------------------------------------------------------------------------
2020-04-02 00:26:58,976 epoch 95 - iter 176/220 - loss 0.78180992 - samples/sec: 330.152020-04-02 00:27:07,228 epoch 64 - iter 43/439 - loss 0.53886068 - samples/sec: 151.82
2020-04-02 00:27:08,562 epoch 95 - iter 198/220 - loss 0.78131853 - samples/sec: 349.28
2020-04-02 00:27:18,936 epoch 95 - iter 220/220 - loss 0.77801477 - samples/sec: 367.31
2020-04-02 00:27:25,047 ----------------------------------------------------------------2020-04-02 00:27:22,663 epoch 64 - iter 86/439 - loss 0.54724563 - samples/sec: 152.07
 - lr 0.0006
2020-04-02 00:27:29,006 DEV : loss 0.5641939043998718 - score 0.9334
2020-04-02 00:27:29,104 BAD EPOCHS (no improvement): 3
2020-04-02 00:27:29,148 ----------------------------------------------------------------------------------------------------
2020-04-02 00:27:33,557 epoch 96 - iter 22/220 - loss 0.82044959 - samples/sec: 319.63
----------------------------------------------------------------------------------------------------
2020-04-02 00:27:37,609 epoch 64 - iter 129/439 - loss 0.57438799 - samples/sec: 161.22
2020-04-02 00:27:46,271 epoch 65 - iter 43/439 - loss 0.57674356 - samples/sec: 155.23
2020-04-02 00:27:44,515 epoch 96 - iter 44/220 - loss 0.80106228 - samples/sec: 302.59
2020-04-02 00:27:52,875 epoch 64 - iter 172/439 - loss 0.57960847 - samples/sec: 148.59
2020-04-02 00:28:02,319 epoch 65 - iter 86/439 - loss 0.61723777 - samples/sec: 151.13
2020-04-02 00:28:08,373 epoch 64 - iter 215/439 - loss 0.58686411 - samples/sec: 152.34
2020-04-02 00:28:17,654 epoch 65 - iter 129/439 - loss 0.61268394 - samples/sec: 152.92
2020-04-02 00:28:15,037 epoch 96 - iter 110/220 - loss 0.77861135 - samples/sec: 434.38
2020-04-02 00:28:23,836 epoch 64 - iter 258/439 - loss 0.59902992 - samples/sec: 150.22
2020-04-02 00:28:32,793 epoch 65 - iter 172/439 - loss 0.60398757 - samples/sec: 153.27
2020-04-02 00:28:34,819 epoch 96 - iter 154/220 - loss 0.78951768 - samples/sec: 421.84
2020-04-02 00:28:44,127 epoch 96 - iter 176/220 - loss 0.79261984 - samples/sec: 434.55
2020-04-02 00:28:40,039 epoch 64 - iter 301/439 - loss 0.59390865 - samples/sec: 149.20
2020-04-02 00:28:55,918 epoch 64 - iter 344/439 - loss 0.58410966 - samples/sec: 150.82
2020-04-02 00:29:03,031 epoch 96 - iter 220/220 - loss 0.78463482 - samples/sec: 418.90
2020-04-02 00:29:08,796 ----------------------------------------------------------------------------------------------------
2020-04-02 00:29:08,797 EPOCH 96 done: loss 0.7846 - lr 0.0006
2020-04-02 00:29:13,803 epoch 8 - iter 387/439 - loss 1.54309954 - samples/sec: 166.68
2020-04-02 00:29:17,613 epoch 65 - iter 301/439 - loss 0.59252861 - samples/sec: 154.00
2020-04-02 00:29:11,571 epoch 64 - iter 387/439 - loss 0.58383933 - samples/sec: 150.42
ng learning rate of group 0 to 3.1250e-04.
2020-04-02 00:29:12,819 BAD EPOCHS (no improvement): 4
2020-04-02 00:29:12,919 ----------------------------------------------------------------------------------------------------
2020-04-02 00:29:15,889 epoch 97 - iter 22/220 - loss 0.80148989 - samples/sec: 474.41
2020-04-02 00:29:26,572 epoch 64 - iter 430/439 - loss 0.58166149 - samples/sec: 153.89
2020-04-02 00:29:33,128 epoch 65 - iter 344/439 - loss 0.60107079 - samples/sec: 152.18
2020-04-02 00:29:34,652 ----------------------------------------------------------------------------------------------------
2020-04-02 00:29:34,653 EPOCH 64 done: loss 0.5825 - lr 0.0100
2020-04-02 00:29:39,746 DEV : loss 0.512309193611145 - score 0.9421
2020-04-02 00:29:39,844 BAD EPOCHS (no improvement): 0
2020-04-02 00:29:48,120 epoch 65 - iter 387/439 - loss 0.60308169 - samples/sec: 152.75
2020-04-02 00:29:41,178 ----------------------------------------------------------------------------------------------------
2020-04-02 00:29:50,068 epoch 65 - iter 43/439 - loss 0.60513824 - samples/sec: 154.87
2020-04-02 00:29:56,170 epoch 97 - iter 110/220 - loss 0.79449990 - samples/sec: 350.07
2020-04-02 00:30:05,485 epoch 97 - iter 132/220 - loss 0.78038579 - samples/sec: 358.84
2020-04-02 00:30:05,553 epoch 65 - iter 86/439 - loss 0.61097122 - samples/sec: 149.94
2020-04-02 00:30:11,990 ----------------------------------------------------------------------------------------------------
2020-04-02 00:30:11,991 EPOCH 65 done: loss 0.6109 - lr 0.0006
2020-04-02 00:30:16,488 DEV : loss 0.5508486032485962 - score 0.9362
2020-04-02 00:30:16,587 BAD EPOCHS (no improvement): 2
2020-04-02 00:30:16,614 ----------------------------------------------------------------------------------------------------
2020-04-02 00:30:15,947 epoch 97 - iter 154/220 - loss 0.78781245 - samples/sec: 357.67
2020-04-02 00:30:26,323 epoch 97 - iter 176/220 - loss 0.77487546 - samples/sec: 303.142020-04-02 00:30:20,565 epoch 65 - iter 129/439 - loss 0.59291777 - samples/sec: 160.81
2020-04-02 00:30:35,981 epoch 65 - iter 172/439 - loss 0.60217752 - samples/sec: 149.28
020-04-02 00:30:35,882 epoch 97 - iter 198/220 - loss 0.77148756 - samples/sec: 341.75
2020-04-02 00:30:39,756 epoch 66 - iter 86/439 - loss 0.62615817 - samples/sec: 154.49
2020-04-02 00:30:45,319 epoch 97 - iter 220/220 - loss 0.76765013 - samples/sec: 406.06
2020-04-02 00:30:47,826 epoch 4 - iter 258/439 - loss 1.28677408 - samples/sec: 90.76
2020-04-02 00:30:51,100 -----------------------------------------------------------------2020-04-02 00:30:51,026 epoch 65 - iter 215/439 - loss 0.60137992 - samples/sec: 151.28
 lr 0.0003
2020-04-02 00:30:55,185 DEV : loss 0.565016508102417 - score 0.934
2020-04-02 00:30:55,282 BAD EPOCHS (no improvement): 1
2020-04-02 00:30:55,363 ----------------------------------------------------------------------------------------------------
2020-04-02 00:31:06,456 epoch 65 - iter 258/439 - loss 0.59163082 - samples/sec: 155.58
020-04-02 00:30:59,497 epoch 98 - iter 22/220 - loss 0.73762680 - samples/sec: 340.79
2020-04-02 00:31:09,332 epoch 98 - iter 44/220 - loss 0.78259119 - samples/sec: 337.93
2020-04-02 00:31:10,135 epoch 66 - iter 172/439 - loss 0.60447178 - samples/sec: 157.62
2020-04-02 00:31:19,868 epoch 98 - iter 66/220 - loss 0.79820670 - samples/sec: 307.24

2020-04-02 00:31:21,961 epoch 65 - iter 301/439 - loss 0.58735604 - samples/sec: 151.12
2020-04-02 00:31:38,424 epoch 65 - iter 344/439 - loss 0.58677477 - samples/sec: 153.78
2020-04-02 00:31:42,781 epoch 98 - iter 110/220 - loss 0.77437214 - samples/sec: 273.33
2020-04-02 00:31:55,632 epoch 66 - iter 301/439 - loss 0.61536615 - samples/sec: 153.72
2020-04-02 00:31:53,696 epoch 65 - iter 387/439 - loss 0.58345362 - samples/sec: 152.64
2020-04-02 00:32:08,641 epoch 65 - iter 430/439 - loss 0.58047057 - samples/sec: 152.26
2020-04-02 00:32:13,290 epoch 98 - iter 176/220 - loss 0.76053889 - samples/sec: 327.49
2020-04-02 00:32:16,274 ----------------------------------------------------------------------------------------------------
2020-04-02 00:32:16,275 EPOCH 65 done: loss 0.5823 - lr 0.0100
2020-04-02 00:32:20,737 DEV : loss 0.5012242197990417 - score 0.9411
2020-04-02 00:32:24,831 epoch 66 - iter 387/439 - loss 0.61591657 - samples/sec: 161.98
2020-04-02 00:32:20,834 BAD EPOCHS (no improvement): 1
2020-04-02 00:32:20,875 ----------------------------------------------------------------------------------------------------
2020-04-02 00:32:29,874 epoch 66 - iter 43/439 - loss 0.54698921 - samples/sec: 152.97
2020-04-02 00:32:34,022 epoch 98 - iter 220/220 - loss 0.75852730 - samples/sec: 343.85
2020-04-02 00:32:39,810 ----------------------------------------------------------------------------------------------------
2020-04-02 00:32:39,810 EPOCH 98 done: loss 0.7585 - lr 0.0003
2020-04-02 00:32:44,421 DEV : loss 0.5640518069267273 - score 0.9345
2020-04-02 00:32:44,518 BAD EPOCHS (no improvement): 0
2020-04-02 00:32:46,304 ----------------------------------------------------------------------------------------------------
020-04-02 00:32:46,987 EPOCH 66 done: loss 0.6128 - lr 0.0006
2020-04-02 00:32:44,657 epoch 66 - iter 86/439 - loss 0.54351631 - samples/sec: 153.95
2020-04-02 00:32:53,276 ----------------------------------------------------------------------------------------------------
2020-04-02 00:33:01,598 epoch 9 - iter 43/439 - loss 1.31829334 - samples/sec: 165.48
51,567 BAD EPOCHS (no improvement): 3
2020-04-02 00:32:53,251 ----------------------------------------------------------------------------------------------------
2020-04-02 00:33:02,113 epoch 67 - iter 43/439 - loss 0.64127887 - samples/sec: 155.35
2020-04-02 00:32:50,824 epoch 99 - iter 22/220 - loss 0.77604437 - samples/sec: 311.78
2020-04-02 00:33:04,327 epoch 66 - iter 129/439 - loss 0.55168862 - samples/sec: 152.00
2020-04-02 00:33:17,189 epoch 67 - iter 86/439 - loss 0.62586108 - samples/sec: 153.51
2020-04-02 00:33:14,464 epoch 99 - iter 66/220 - loss 0.79097405 - samples/sec: 297.97
2020-04-02 00:33:19,783 epoch 66 - iter 172/439 - loss 0.56704187 - samples/sec: 152.17
2020-04-02 00:33:32,222 epoch 67 - iter 129/439 - loss 0.64129782 - samples/sec: 149.31
2020-04-02 00:33:24,953 epoch 99 - iter 88/220 - loss 0.77342322 - samples/sec: 295.50
2020-04-02 00:33:34,912 epoch 66 - iter 215/439 - loss 0.58245185 - samples/sec: 156.23
2020-04-02 00:33:35,316 epoch 99 - iter 110/220 - loss 0.77931961 - samples/sec: 332.33
2020-04-02 00:33:47,147 epoch 67 - iter 172/439 - loss 0.62402588 - samples/sec: 154.48
2020-04-02 00:33:50,418 epoch 66 - iter 258/439 - loss 0.57975338 - samples/sec: 149.45
2020-04-02 00:33:46,326 epoch 99 - iter 132/220 - loss 0.77068009 - samples/sec: 302.03
2020-04-02 00:34:02,363 epoch 67 - iter 215/439 - loss 0.62260308 - samples/sec: 153.14
2020-04-02 00:33:56,767 epoch 99 - iter 154/220 - loss 0.77469144 - samples/sec: 328.28
2020-04-02 00:34:12,772 epoch 6 - iter 220/220 - loss 1.35107064 - samples/sec: 130.31

2020-04-02 00:34:06,390 epoch 99 - iter 176/220 - loss 0.76682856 - samples/sec: 328.37
2020-04-02 00:34:20,832 epoch 66 - iter 344/439 - loss 0.58253408 - samples/sec: 148.54
2020-04-02 00:34:17,029 epoch 67 - iter 258/439 - loss 0.61665401 - samples/sec: 152.28
2020-04-02 00:34:16,190 epoch 99 - iter 198/220 - loss 0.75763718 - samples/sec: 334.98
2020-04-02 00:34:31,979 epoch 67 - iter 301/439 - loss 0.61149485 - samples/sec: 154.97
2020-04-02 00:34:26,261 epoch 99 - iter 220/220 - loss 0.76673647 - samples/sec: 321.66
2020-04-02 00:34:32,304 ----------------------------------------------------------------------------------------------------
2020-04-02 00:34:32,304 EPOCH 99 done: loss 0.7667 - lr 0.0003
2020-04-02 00:34:36,041 epoch 66 - iter 387/439 - loss 0.58541507 - samples/sec: 153.52
2020-04-02 00:34:36,258 DEV : loss 0.5639755129814148 - score 0.9347
2020-04-02 00:34:36,356 BAD EPOCHS (no improvement): 0
2020-04-02 00:34:37,680 ----------------------------------------------------------------------------------------------------
2020-04-02 00:34:42,122 epoch 100 - iter 22/220 - loss 0.78895655 - samples/sec: 317.25
2020-04-02 00:34:46,474 epoch 9 - iter 86/439 - loss 1.38612740 - samples/sec: 160.65
2020-04-02 00:34:51,576 epoch 66 - iter 430/439 - loss 0.59028533 - samples/sec: 150.49
2020-04-02 00:34:47,513 epoch 67 - iter 344/439 - loss 0.61382252 - samples/sec: 149.98
2020-04-02 00:34:52,992 epoch 100 - iter 44/220 - loss 0.80882495 - samples/sec: 313.98
2020-04-02 00:34:59,449 ----------------------------------------------------------------------------------------------------
2020-04-02 00:34:59,450 EPOCH 66 done: loss 0.5922 - lr 0.0100
2020-04-02 00:35:02,104 epoch 67 - iter 387/439 - loss 0.61762017 - samples/sec: 157.19
2020-04-02 00:35:03,904 DEV : loss 0.5001153349876404 - score 0.9409
2020-04-02 00:35:04,001 BAD EPOCHS (no improvement): 2
2020-04-02 00:35:04,023 ----------------------------------------------------------------------------------------------------
2020-04-02 00:35:13,090 epoch 67 - iter 43/439 - loss 0.61936609 - samples/sec: 151.83
2020-04-02 00:35:04,138 epoch 100 - iter 66/220 - loss 0.79952257 - samples/sec: 294.04
2020-04-02 00:35:16,926 epoch 67 - iter 430/439 - loss 0.61120263 - samples/sec: 153.78
2020-04-02 00:35:14,538 epoch 100 - iter 88/220 - loss 0.76176271 - samples/sec: 311.82
2020-04-02 00:35:28,754 epoch 67 - iter 86/439 - loss 0.58064342 - samples/sec: 158.31
2020-04-02 00:35:25,499 ----------------------------------------------------------------------------------------------------
2020-04-02 00:35:25,500 EPOCH 67 done: loss 0.6122 - lr 0.0006
2020-04-02 00:35:29,993 DEV : loss 0.5502814054489136 - score 0.9377
Epoch    67: reducing learning rate of group 0 to 3.1250e-04.
2020-04-02 00:35:30,091 BAD EPOCHS (no improvement): 4
2020-04-02 00:35:30,160 ----------------------------------------------------------------------------------------------------
2020-04-02 00:35:26,170 epoch 100 - iter 110/220 - loss 0.77536431 - samples/sec: 296.59
2020-04-02 00:35:39,194 epoch 68 - iter 43/439 - loss 0.64288225 - samples/sec: 152.38
2020-04-02 00:35:37,952 epoch 100 - iter 132/220 - loss 0.77897667 - samples/sec: 293.48
2020-04-02 00:35:44,781 epoch 67 - iter 129/439 - loss 0.61757958 - samples/sec: 153.31
2020-04-02 00:35:48,318 epoch 100 - iter 154/220 - loss 0.77212933 - samples/sec: 350.01
2020-04-02 00:36:00,351 epoch 67 - iter 172/439 - loss 0.60325808 - samples/sec: 150.36
2020-04-02 00:35:54,277 epoch 68 - iter 86/439 - loss 0.60884936 - samples/sec: 156.26
2020-04-02 00:35:57,573 epoch 100 - iter 176/220 - loss 0.77213000 - samples/sec: 424.37
2020-04-02 00:36:04,672 epoch 4 - iter 301/439 - loss 1.26739355 - samples/sec: 88.55
2020-04-02 00:36:08,977 epoch 68 - iter 129/439 - loss 0.60958000 - samples/sec: 157.33
2020-04-02 00:36:07,837 epoch 100 - iter 198/220 - loss 0.76873354 - samples/sec: 383.26
2020-04-02 00:36:15,812 epoch 67 - iter 215/439 - loss 0.59199863 - samples/sec: 153.03
2020-04-02 00:36:18,671 epoch 100 - iter 220/220 - loss 0.76542855 - samples/sec: 315.13
2020-04-02 00:36:30,781 epoch 67 - iter 258/439 - loss 0.60318890 - samples/sec: 155.73
2020-04-02 00:36:24,801 epoch 68 - iter 172/439 - loss 0.62246560 - samples/sec: 146.57
2020-04-02 00:36:25,245 ----------------------------------------------------------------------------------------------------
2020-04-02 00:36:25,246 EPOCH 100 done: loss 0.7654 - lr 0.0003
2020-04-02 00:36:29,205 DEV : loss 0.563457190990448 - score 0.9342
2020-04-02 00:36:29,303 BAD EPOCHS (no improvement): 1
2020-04-02 00:36:29,361 ----------------------------------------------------------------------------------------------------
2020-04-02 00:36:34,206 epoch 101 - iter 22/220 - loss 0.72974502 - samples/sec: 290.79
2020-04-02 00:36:39,769 epoch 68 - iter 215/439 - loss 0.63327194 - samples/sec: 154.84
2020-04-02 00:36:37,786 epoch 9 - iter 129/439 - loss 1.41916905 - samples/sec: 168.42
2020-04-02 00:36:46,510 epoch 67 - iter 301/439 - loss 0.60141438 - samples/sec: 153.58
2020-04-02 00:36:45,129 epoch 101 - iter 44/220 - loss 0.78280925 - samples/sec: 324.47
2020-04-02 00:37:01,616 epoch 67 - iter 344/439 - loss 0.59892791 - samples/sec: 157.02
2020-04-02 00:36:54,797 epoch 68 - iter 258/439 - loss 0.63104056 - samples/sec: 153.24
2020-04-02 00:36:55,518 epoch 101 - iter 66/220 - loss 0.78794308 - samples/sec: 336.33
2020-04-02 00:37:09,672 epoch 68 - iter 301/439 - loss 0.62324098 - samples/sec: 152.46
2020-04-02 00:37:06,179 epoch 101 - iter 88/220 - loss 0.77452740 - samples/sec: 301.50
2020-04-02 00:37:17,184 epoch 67 - iter 387/439 - loss 0.59293700 - samples/sec: 150.01
2020-04-02 00:37:17,247 epoch 101 - iter 110/220 - loss 0.76347254 - samples/sec: 301.03
2020-04-02 00:37:32,024 epoch 67 - iter 430/439 - loss 0.58822556 - samples/sec: 154.88
2020-04-02 00:37:24,822 epoch 68 - iter 344/439 - loss 0.62266294 - samples/sec: 151.89
2020-04-02 00:37:27,800 epoch 101 - iter 132/220 - loss 0.77286204 - samples/sec: 308.41
2020-04-02 00:37:42,581 ----------------------------------------------------------------------------------------------------
2020-04-02 00:37:42,581 EPOCH 6 done: loss 1.3511 - lr 0.0100

2020-04-02 00:37:40,568 epoch 68 - iter 387/439 - loss 0.60858018 - samples/sec: 152.89
2020-04-02 00:37:38,246 epoch 101 - iter 154/220 - loss 0.77034018 - samples/sec: 361.39
2020-04-02 00:37:44,261 DEV : loss 0.5021417737007141 - score 0.9416
2020-04-02 00:37:44,358 BAD EPOCHS (no improvement): 3
2020-04-02 00:37:44,396 ----------------------------------------------------------------------------------------------------
2020-04-02 00:37:53,358 epoch 68 - iter 43/439 - loss 0.57083702 - samples/sec: 153.59
2020-04-02 00:37:47,884 epoch 101 - iter 176/220 - loss 0.76704777 - samples/sec: 400.99
2020-04-02 00:37:56,738 DEV : loss 0.9734504818916321 - score 0.8982
2020-04-02 00:37:57,130 BAD EPOCHS (no improvement): 0
2020-04-02 00:37:55,505 epoch 68 - iter 430/439 - loss 0.60925860 - samples/sec: 152.36
2020-04-02 00:38:02,937 ----------------------------------------------------------------------------------------------------
2020-04-02 00:38:02,937 EPOCH 68 done: loss 0.6060 - lr 0.0003
2020-04-02 00:37:57,070 epoch 101 - iter 198/220 - loss 0.76873097 - samples/sec: 398.35
2020-04-02 00:38:06,241 epoch 101 - iter 220/220 - loss 0.77404789 - samples/sec: 410.83
2020-04-02 00:38:12,545 ----------------------------------------------------------------------------------------------------
2020-04-02 00:38:12,546 EPOCH 101 done: loss 0.7740 - lr 0.0003
2020-04-02 00:38:07,415 DEV : loss 0.5493826866149902 - score 0.9372
2020-04-02 00:38:07,514 BAD EPOCHS (no improvement): 1
2020-04-02 00:38:07,535 ----------------------------------------------------------------------------------------------------
2020-04-02 00:38:22,293 epoch 68 - iter 129/439 - loss 0.56207584 - samples/sec: 150.67
,594 BAD EPOCHS (no improvement): 2
2020-04-02 00:38:16,435 epoch 69 - iter 43/439 - loss 0.50528325 - samples/sec: 154.67
2020-04-02 00:38:37,856 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
- samples/sec: 413.46
2020-04-02 00:38:49,584 epoch 7 - iter 22/220 - loss 1.30430059 - samples/sec: 120.16

2020-04-02 00:38:49,985 epoch 69 - iter 86/439 - loss 0.57073132 - samples/sec: 151.17
2020-04-02 00:38:57,383 epoch 102 - iter 66/220 - loss 0.78030939 - samples/sec: 377.20
2020-04-02 00:39:07,798 epoch 102 - iter 88/220 - loss 0.77822105 - samples/sec: 367.47
2020-04-02 00:39:05,357 epoch 69 - iter 129/439 - loss 0.58324781 - samples/sec: 150.34
2020-04-02 00:39:18,546 epoch 102 - iter 110/220 - loss 0.78354971 - samples/sec: 323.60
020-04-02 00:39:20,480 epoch 69 - iter 172/439 - loss 0.58868750 - samples/sec: 152.48
2020-04-02 00:39:28,932 epoch 102 - iter 132/220 - loss 0.78395288 - samples/sec: 322.96
2020-04-02 00:39:42,553 epoch 102 - iter 154/220 - loss 0.78630376 - samples/sec: 340.08
020-04-02 00:39:35,692 epoch 69 - iter 215/439 - loss 0.60588720 - samples/sec: 149.78
2020-04-02 00:39:51,929 epoch 102 - iter 176/220 - loss 0.78650045 - samples/sec: 377.78
020-04-02 00:39:51,566 epoch 69 - iter 258/439 - loss 0.60411257 - samples/sec: 152.64
2020-04-02 00:40:02,498 epoch 102 - iter 198/220 - loss 0.77796027 - samples/sec: 319.78
2020-04-02 00:40:12,653 epoch 102 - iter 220/220 - loss 0.77365237 - samples/sec: 307.42
020-04-02 00:40:06,465 epoch 69 - iter 301/439 - loss 0.61102134 - samples/sec: 157.85
2020-04-02 00:40:21,126 epoch 68 - iter 430/439 - loss 0.56020906 - samples/sec: 148.20
2020-04-02 00:40:21,782 epoch 69 - iter 344/439 - loss 0.61383825 - samples/sec: 153.02
2020-04-02 00:40:18,399 ----------------------------------------------------------------------------------------------------
2020-04-02 00:40:18,399 EPOCH 102 done: loss 0.7737 - lr 0.0003
2020-04-02 00:40:22,338 DEV : loss 0.5643448233604431 - score 0.9346
2020-04-02 00:40:22,434 BAD EPOCHS (no improvement): 3
2020-04-02 00:40:22,488 ----------------------------------------------------------------------------------------------------
2020-04-02 00:40:27,201 epoch 103 - iter 22/220 - loss 0.80488626 - samples/sec: 298.95
-----------------------------------
2020-04-02 00:40:29,607 EPOCH 68 done: loss 0.5637 - lr 0.0100
2020-04-02 00:40:34,035 DEV : loss 0.4968172609806061 - score 0.9419
Epoch    68: reducing learning rate of group 0 to 5.0000e-03.
2020-04-02 00:40:34,128 BAD EPOCHS (no improvement): 4
2020-04-02 00:40:34,255 ----------------------------------------------------------------------------------------------------
2020-04-02 00:40:37,029 epoch 69 - iter 387/439 - loss 0.60158711 - samples/sec: 160.50
2020-04-02 00:40:38,267 epoch 103 - iter 44/220 - loss 0.77602081 - samples/sec: 305.88
2020-04-02 00:40:43,166 epoch 69 - iter 43/439 - loss 0.62580261 - samples/sec: 154.50
2020-04-02 00:40:51,785 epoch 69 - iter 430/439 - loss 0.60253471 - samples/sec: 156.74
2020-04-02 00:40:49,318 epoch 103 - iter 66/220 - loss 0.75125484 - samples/sec: 292.83
2020-04-02 00:40:59,527 epoch 103 - iter 88/220 - loss 0.77599481 - samples/sec: 375.78
020-04-02 00:41:00,283 ----------------------------------------------------------------------------------------------------
2020-04-02 00:41:00,284 EPOCH 69 done: loss 0.5989 - lr 0.0003
2020-04-02 00:41:04,756 DEV : loss 0.5495927929878235 - score 0.937
2020-04-02 00:41:04,854 BAD EPOCHS (no improvement): 2
2020-04-02 00:41:04,906 ----------------------------------------------------------------------------------------------------
2020-04-02 00:41:08,841 epoch 103 - iter 110/220 - loss 0.75839827 - samples/sec: 425.21
2020-04-02 00:41:13,485 epoch 69 - iter 129/439 - loss 0.56864155 - samples/sec: 151.96
2020-04-02 00:41:13,713 epoch 70 - iter 43/439 - loss 0.57131648 - samples/sec: 156.32
2020-04-02 00:41:18,850 epoch 103 - iter 132/220 - loss 0.75140167 - samples/sec: 436.66
2020-04-02 00:41:29,005 epoch 69 - iter 172/439 - loss 0.55880237 - samples/sec: 150.20
2020-04-02 00:41:29,222 epoch 70 - iter 86/439 - loss 0.59945243 - samples/sec: 152.09
2020-04-02 00:41:28,662 epoch 103 - iter 154/220 - loss 0.75118811 - samples/sec: 396.11
2020-04-02 00:41:41,924 epoch 4 - iter 344/439 - loss 1.25721058 - samples/sec: 88.66
2020-04-02 00:41:37,977 epoch 103 - iter 176/220 - loss 0.76025397 - samples/sec: 397.66
2020-04-02 00:41:47,587 epoch 103 - iter 198/220 - loss 0.76424110 - samples/sec: 344.26
020-04-02 00:41:44,131 epoch 70 - iter 129/439 - loss 0.60443929 - samples/sec: 150.91
2020-04-02 00:41:59,466 epoch 69 - iter 258/439 - loss 0.55365789 - samples/sec: 150.56
2020-04-02 00:41:59,647 epoch 70 - iter 172/439 - loss 0.60886806 - samples/sec: 151.59
2020-04-02 00:41:58,870 epoch 103 - iter 220/220 - loss 0.76340841 - samples/sec: 310.35
2020-04-02 00:42:06,484 ----------------------------------------------------------------------------------------------------
2020-04-02 00:42:06,484 EPOCH 103 done: loss 0.7634 - lr 0.0003
2020-04-02 00:42:10,437 DEV : loss 0.5639015436172485 - score 0.9344
Epoch   103: reducing learning rate of group 0 to 1.5625e-04.
2020-04-02 00:42:10,533 BAD EPOCHS (no improvement): 4
2020-04-02 00:42:10,584 ----------------------------------------------------------------------------------------------------
2020-04-02 00:42:14,612 epoch 104 - iter 22/220 - loss 0.71388939 - samples/sec: 349.81
2020-04-02 00:42:25,172 epoch 104 - iter 44/220 - loss 0.74051387 - samples/sec: 330.64
020-04-02 00:42:16,348 epoch 69 - iter 301/439 - loss 0.55197340 - samples/sec: 149.90
2020-04-02 00:42:16,499 epoch 70 - iter 215/439 - loss 0.61376985 - samples/sec: 150.56
2020-04-02 00:42:35,273 epoch 104 - iter 66/220 - loss 0.76083314 - samples/sec: 335.70
2020-04-02 00:42:31,645 epoch 70 - iter 258/439 - loss 0.61899444 - samples/sec: 153.78
2020-04-02 00:42:46,293 epoch 104 - iter 88/220 - loss 0.76030253 - samples/sec: 285.30
2020-04-02 00:42:46,929 epoch 70 - iter 301/439 - loss 0.61104229 - samples/sec: 152.60
2020-04-02 00:42:57,833 epoch 104 - iter 110/220 - loss 0.76422736 - samples/sec: 320.68
2020-04-02 00:43:08,533 epoch 104 - iter 132/220 - loss 0.77541840 - samples/sec: 305.39
020-04-02 00:43:11,425 ----------------------------------------------------------------------------------------------------
2020-04-02 00:43:11,426 EPOCH 69 done: loss 0.5545 - lr 0.0050
2020-04-02 00:43:15,915 DEV : loss 0.4891326427459717 - score 0.9429
2020-04-02 00:43:16,013 BAD EPOCHS (no improvement): 0
2020-04-02 00:43:17,295 ----------------------------------------------------------------------------------------------------
2020-04-02 00:43:17,893 epoch 70 - iter 387/439 - loss 0.60451728 - samples/sec: 157.23
2020-04-02 00:43:19,844 epoch 104 - iter 154/220 - loss 0.77254100 - samples/sec: 300.43
2020-04-02 00:43:30,060 epoch 104 - iter 176/220 - loss 0.76289777 - samples/sec: 350.64
20-04-02 00:43:32,986 epoch 70 - iter 430/439 - loss 0.60769761 - samples/sec: 153.65
2020-04-02 00:43:41,199 epoch 104 - iter 198/220 - loss 0.77213839 - samples/sec: 300.96
20-04-02 00:43:41,357 ----------------------------------------------------------------------------------------------------
2020-04-02 00:43:41,358 EPOCH 70 done: loss 0.6052 - lr 0.0003
2020-04-02 00:43:51,646 epoch 104 - iter 220/220 - loss 0.77434056 - samples/sec: 337.26
913 BAD EPOCHS (no improvement): 3
2020-04-02 00:43:46,012 ----------------------------------------------------------------------------------------------------
2020-04-02 00:43:57,779 ----------------------------------------------------------------------------------------------------
2020-04-02 00:43:57,779 EPOCH 104 done: loss 0.7743 - lr 0.0002
2020-04-02 00:44:01,729 DEV : loss 0.5647574067115784 - score 0.9344
2020-04-02 00:44:01,828 BAD EPOCHS (no improvement): 1
2020-04-02 00:44:01,876 ----------------------------------------------------------------------------------------------------
2020-04-02 00:44:06,228 epoch 105 - iter 22/220 - loss 0.82009580 - samples/sec: 323.72
2020-04-02 00:44:10,327 epoch 71 - iter 86/439 - loss 0.64181859 - samples/sec: 153.63
2020-04-02 00:44:16,459 epoch 105 - iter 44/220 - loss 0.76845946 - samples/sec: 343.01
2020-04-02 00:44:27,413 epoch 105 - iter 66/220 - loss 0.77327282 - samples/sec: 301.43
2020-04-02 00:44:25,817 epoch 71 - iter 129/439 - loss 0.60673066 - samples/sec: 154.82
2020-04-02 00:44:37,596 epoch 105 - iter 88/220 - loss 0.77219422 - samples/sec: 392.48
2020-04-02 00:44:48,300 epoch 105 - iter 110/220 - loss 0.76992375 - samples/sec: 318.15
2020-04-02 00:44:57,724 epoch 105 - iter 132/220 - loss 0.76761924 - samples/sec: 349.33
020-04-02 00:44:57,003 epoch 71 - iter 215/439 - loss 0.62526646 - samples/sec: 147.80
2020-04-02 00:45:09,174 epoch 105 - iter 154/220 - loss 0.76425957 - samples/sec: 310.69
2020-04-02 00:45:15,079 epoch 70 - iter 344/439 - loss 0.54403237 - samples/sec: 152.26
2020-04-02 00:45:20,136 epoch 105 - iter 176/220 - loss 0.75626427 - samples/sec: 311.10
2020-04-02 00:45:31,031 epoch 105 - iter 198/220 - loss 0.76123489 - samples/sec: 297.57
020-04-02 00:45:28,236 epoch 71 - iter 301/439 - loss 0.62447365 - samples/sec: 149.93
2020-04-02 00:45:41,876 epoch 105 - iter 220/220 - loss 0.76402544 - samples/sec: 366.12
2020-04-02 00:45:47,917 ----------------------------------------------------------------------------------------------------
2020-04-02 00:45:47,918 EPOCH 105 done: loss 0.7640 - lr 0.0002
2020-04-02 00:45:51,866 DEV : loss 0.5646253824234009 - score 0.9342
2020-04-02 00:45:51,962 BAD EPOCHS (no improvement): 2
2020-04-02 00:45:52,006 ----------------------------------------------------------------------------------------------------
2020-04-02 00:45:55,846 epoch 106 - iter 22/220 - loss 0.80259430 - samples/sec: 366.96
2020-04-02 00:46:06,663 epoch 106 - iter 44/220 - loss 0.80091107 - samples/sec: 329.72
020-04-02 00:45:54,575 ----------------------------------------------------------------------------------------------------
2020-04-02 00:45:54,576 EPOCH 70 done: loss 0.5461 - lr 0.0050
2020-04-02 00:45:58,999 DEV : loss 0.4909541606903076 - score 0.9422
2020-04-02 00:45:59,091 BAD EPOCHS (no improvement): 1
2020-04-02 00:45:59,132 ----------------------------------------------------------------------------------------------------
2020-04-02 00:45:59,251 epoch 71 - iter 387/439 - loss 0.61448212 - samples/sec: 161.81
2020-04-02 00:46:10,532 epoch 7 - iter 66/220 - loss 1.24554643 - samples/sec: 123.41
2020-04-02 00:46:08,265 epoch 71 - iter 43/439 - loss 0.49519073 - samples/sec: 150.73
2020-04-02 00:46:23,386 epoch 71 - iter 86/439 - loss 0.53150832 - samples/sec: 151.99
2020-04-02 00:46:14,667 epoch 71 - iter 430/439 - loss 0.61595313 - samples/sec: 155.01
2020-04-02 00:46:22,146 ----------------------------------------------------------------------------------------------------
2020-04-02 00:46:22,146 EPOCH 71 done: loss 0.6153 - lr 0.0003
2020-04-02 00:46:17,196 epoch 106 - iter 66/220 - loss 0.78882091 - samples/sec: 307.34
2020-04-02 00:46:27,788 epoch 106 - iter 88/220 - loss 0.78069093 - samples/sec: 304.03
ng learning rate of group 0 to 1.5625e-04.
2020-04-02 00:46:26,723 BAD EPOCHS (no improvement): 4
2020-04-02 00:46:26,742 ----------------------------------------------------------------------------------------------------
2020-04-02 00:46:37,835 epoch 106 - iter 110/220 - loss 0.77767749 - samples/sec: 356.67
020-04-02 00:46:35,935 epoch 72 - iter 43/439 - loss 0.58620378 - samples/sec: 149.75
2020-04-02 00:46:48,727 epoch 106 - iter 132/220 - loss 0.75934348 - samples/sec: 372.19
2020-04-02 00:47:01,605 epoch 4 - iter 387/439 - loss 1.25162260 - samples/sec: 86.73
2020-04-02 00:46:54,097 epoch 71 - iter 172/439 - loss 0.52013328 - samples/sec: 152.06
2020-04-02 00:46:58,287 epoch 106 - iter 154/220 - loss 0.75698554 - samples/sec: 378.05
2020-04-02 00:47:09,382 epoch 106 - iter 176/220 - loss 0.75396126 - samples/sec: 299.27
020-04-02 00:47:06,277 epoch 72 - iter 129/439 - loss 0.60054021 - samples/sec: 156.31
2020-04-02 00:47:21,355 epoch 72 - iter 172/439 - loss 0.59937544 - samples/sec: 154.41
2020-04-02 00:47:20,432 epoch 106 - iter 198/220 - loss 0.75880317 - samples/sec: 304.99
2020-04-02 00:47:24,025 epoch 71 - iter 258/439 - loss 0.52453570 - samples/sec: 158.10
2020-04-02 00:47:29,737 epoch 106 - iter 220/220 - loss 0.75816069 - samples/sec: 433.51
2020-04-02 00:47:53,639 ----------------------------------------------------------------------------------------------------
2020-04-02 00:47:53,639 EPOCH 106 done: loss 0.7582 - lr 0.0002
2020-04-02 00:47:59,499 epoch 71 - iter 301/439 - loss 0.53287299 - samples/sec: 162.84
2020-04-02 00:47:58,251 DEV : loss 0.5642665028572083 - score 0.9344
2020-04-02 00:47:58,349 BAD EPOCHS (no improvement): 3
2020-04-02 00:47:58,399 ----------------------------------------------------------------------------------------------------
2020-04-02 00:48:02,971 epoch 107 - iter 22/220 - loss 0.75521310 - samples/sec: 308.12
2020-04-02 00:48:07,383 epoch 9 - iter 387/439 - loss 1.43932987 - samples/sec: 161.99
2020-04-02 00:48:13,556 epoch 107 - iter 44/220 - loss 0.74721145 - samples/sec: 312.54
2020-04-02 00:48:06,094 epoch 72 - iter 258/439 - loss 0.59018083 - samples/sec: 152.48
2020-04-02 00:48:23,902 epoch 107 - iter 66/220 - loss 0.77481058 - samples/sec: 319.96
2020-04-02 00:48:28,888 epoch 71 - iter 387/439 - loss 0.54000397 - samples/sec: 154.52
2020-04-02 00:48:34,851 epoch 107 - iter 88/220 - loss 0.78861959 - samples/sec: 307.42
2020-04-02 00:48:35,819 epoch 72 - iter 344/439 - loss 0.60028992 - samples/sec: 175.82
2020-04-02 00:48:45,642 epoch 107 - iter 110/220 - loss 0.78756824 - samples/sec: 334.87
----------------------------------
2020-04-02 00:48:51,569 EPOCH 71 done: loss 0.5409 - lr 0.0050
2020-04-02 00:48:51,419 epoch 72 - iter 387/439 - loss 0.60441252 - samples/sec: 152.20
2020-04-02 00:48:56,100 epoch 107 - iter 132/220 - loss 0.77502109 - samples/sec: 316.62
,076 BAD EPOCHS (no improvement): 0
2020-04-02 00:48:57,376 ----------------------------------------------------------------------------------------------------
2020-04-02 00:49:07,392 epoch 107 - iter 154/220 - loss 0.76862387 - samples/sec: 295.10
20-04-02 00:49:07,544 epoch 72 - iter 430/439 - loss 0.60732356 - samples/sec: 149.06
2020-04-02 00:49:20,706 epoch 72 - iter 86/439 - loss 0.56487798 - samples/sec: 162.68
2020-04-02 00:49:15,824 ----------------------------------------------------------------------------------------------------
2020-04-02 00:49:15,825 EPOCH 72 done: loss 0.6067 - lr 0.0002
2020-04-02 00:49:20,315 DEV : loss 0.5489267110824585 - score 0.9369
2020-04-02 00:49:20,412 BAD EPOCHS (no improvement): 1
2020-04-02 00:49:20,442 ----------------------------------------------------------------------------------------------------
2020-04-02 00:49:17,872 epoch 107 - iter 176/220 - loss 0.76802365 - samples/sec: 344.83
2020-04-02 00:49:29,343 epoch 73 - iter 43/439 - loss 0.54311751 - samples/sec: 154.65
2020-04-02 00:49:28,036 epoch 107 - iter 198/220 - loss 0.77041174 - samples/sec: 327.82
2020-04-02 00:49:39,034 epoch 107 - iter 220/220 - loss 0.76388610 - samples/sec: 308.67
2020-04-02 00:49:45,431 ----------------------------------------------------------------------------------------------------
2020-04-02 00:49:45,432 EPOCH 107 done: loss 0.7639 - lr 0.0002
2020-04-02 00:49:49,361 DEV : loss 0.564339816570282 - score 0.9342
Epoch   107: reducing learning rate of group 0 to 7.8125e-05.
2020-04-02 00:49:49,460 BAD EPOCHS (no improvement): 4
2020-04-02 00:49:49,519 ----------------------------------------------------------------------------------------------------
2020-04-02 00:49:49,519 ----------------------------------------------------------------------------------------------------
2020-04-02 00:49:49,519 learning rate too small - quitting training!
2020-04-02 00:49:49,519 ----------------------------------------------------------------------------------------------------
2020-04-02 00:49:50,742 ----------------------------------------------------------------------------------------------------
2020-04-02 00:49:50,742 Testing using best model ...
2020-04-02 00:49:50,743 loading file log/elmo_s_20200401212730_64/best-model.pt
2020-04-02 00:50:04,200 0.9001	0.9047	0.9024
2020-04-02 00:50:04,200 
MICRO_AVG: acc 0.8222 - f1-score 0.9024
MACRO_AVG: acc 0.8008 - f1-score 0.88575
LOC        tp: 1536 - fp: 133 - fn: 132 - tn: 1536 - precision: 0.9203 - recall: 0.9209 - accuracy: 0.8529 - f1-score: 0.9206
MISC       tp: 559 - fp: 167 - fn: 143 - tn: 559 - precision: 0.7700 - recall: 0.7963 - accuracy: 0.6433 - f1-score: 0.7829
ORG        tp: 1470 - fp: 197 - fn: 191 - tn: 1470 - precision: 0.8818 - recall: 0.8850 - accuracy: 0.7912 - f1-score: 0.8834
PER        tp: 1545 - fp: 70 - fn: 72 - tn: 1545 - precision: 0.9567 - recall: 0.9555 - accuracy: 0.9158 - f1-score: 0.9561
2020-04-02 00:50:04,200 ----------------------------------------------------------------------------------------------------
2020-04-02 00:50:05,000 epoch 72 - iter 215/439 - loss 0.56220324 - samples/sec: 159.94
2020-04-02 00:50:19,249 epoch 72 - iter 258/439 - loss 0.56723873 - samples/sec: 166.33
2020-04-02 00:50:15,509 epoch 73 - iter 172/439 - loss 0.57116332 - samples/sec: 157.71
2020-04-02 00:50:34,246 epoch 72 - iter 301/439 - loss 0.56337419 - samples/sec: 156.74
2020-04-02 00:50:30,617 epoch 73 - iter 215/439 - loss 0.57848439 - samples/sec: 151.73
2020-04-02 00:50:49,453 epoch 72 - iter 344/439 - loss 0.55737375 - samples/sec: 153.05
2020-04-02 00:50:45,989 epoch 73 - iter 258/439 - loss 0.57589012 - samples/sec: 152.40
2020-04-02 00:51:04,140 epoch 72 - iter 387/439 - loss 0.55472826 - samples/sec: 163.82
2020-04-02 00:51:01,066 epoch 73 - iter 301/439 - loss 0.58264693 - samples/sec: 154.09
2020-04-02 00:51:18,748 epoch 72 - iter 430/439 - loss 0.55670770 - samples/sec: 157.11
2020-04-02 00:51:15,821 epoch 73 - iter 344/439 - loss 0.59019790 - samples/sec: 155.20
2020-04-02 00:51:26,715 ----------------------------------------------------------------------------------------------------
2020-04-02 00:51:26,716 EPOCH 72 done: loss 0.5601 - lr 0.0050
2020-04-02 00:51:31,166 DEV : loss 0.49400463700294495 - score 0.9424
2020-04-02 00:51:31,260 BAD EPOCHS (no improvement): 1
2020-04-02 00:51:31,312 ----------------------------------------------------------------------------------------------------
2020-04-02 00:51:30,146 epoch 73 - iter 387/439 - loss 0.58978581 - samples/sec: 161.51
2020-04-02 00:51:39,736 epoch 73 - iter 43/439 - loss 0.56461195 - samples/sec: 163.43
------------------------------------
2020-04-02 00:51:33,387 EPOCH 9 done: loss 1.4487 - lr 0.0100
2020-04-02 00:51:38,132 DEV : loss 0.9446277022361755 - score 0.9101
2020-04-02 00:51:38,230 BAD EPOCHS (no improvement): 0
2020-04-02 00:51:47,013 ----------------------------------------------------------------------------------------------------
2020-04-02 00:51:45,599 epoch 73 - iter 430/439 - loss 0.58728898 - samples/sec: 150.70
2020-04-02 00:51:55,635 ----------------------------------------------------------------------------------------------------
2020-04-02 00:51:55,636 EPOCH 73 done: loss 0.5920 - lr 0.0002
2020-04-02 00:51:55,402 epoch 10 - iter 43/439 - loss 1.42389865 - samples/sec: 164.14
2020-04-02 00:52:00,113 DEV : loss 0.5491862893104553 - score 0.9372
2020-04-02 00:52:00,211 BAD EPOCHS (no improvement): 2
2020-04-02 00:52:00,276 ----------------------------------------------------------------------------------------------------
2020-04-02 00:51:58,598 epoch 73 - iter 86/439 - loss 0.54334176 - samples/sec: 158.77
2020-04-02 00:52:09,408 epoch 74 - iter 43/439 - loss 0.54822583 - samples/sec: 150.74
2020-04-02 00:52:12,546 epoch 73 - iter 129/439 - loss 0.52964808 - samples/sec: 159.55
2020-04-02 00:52:25,229 epoch 74 - iter 86/439 - loss 0.57270294 - samples/sec: 150.44
2020-04-02 00:52:27,432 epoch 73 - iter 172/439 - loss 0.53392037 - samples/sec: 158.27
2020-04-02 00:52:38,946 epoch 4 - iter 430/439 - loss 1.24603746 - samples/sec: 84.88
2020-04-02 00:52:42,631 epoch 73 - iter 215/439 - loss 0.53736928 - samples/sec: 160.38
2020-04-02 00:52:40,789 epoch 74 - iter 129/439 - loss 0.57991549 - samples/sec: 153.92
2020-04-02 00:52:56,290 epoch 74 - iter 172/439 - loss 0.60024926 - samples/sec: 153.74
2020-04-02 00:52:57,997 epoch 73 - iter 258/439 - loss 0.53145923 - samples/sec: 153.89
2020-04-02 00:53:13,149 epoch 73 - iter 301/439 - loss 0.53175305 - samples/sec: 158.08
2020-04-02 00:53:11,561 epoch 74 - iter 215/439 - loss 0.61003185 - samples/sec: 156.22
2020-04-02 00:53:27,287 epoch 74 - iter 258/439 - loss 0.61326555 - samples/sec: 153.41
2020-04-02 00:53:28,874 epoch 73 - iter 344/439 - loss 0.53040419 - samples/sec: 153.21
2020-04-02 00:53:43,469 epoch 73 - iter 387/439 - loss 0.53312298 - samples/sec: 164.84
2020-04-02 00:53:42,293 epoch 74 - iter 301/439 - loss 0.61946998 - samples/sec: 156.79
2020-04-02 00:53:44,511 epoch 10 - iter 86/439 - loss 1.46767911 - samples/sec: 190.17
2020-04-02 00:53:59,858 epoch 7 - iter 110/220 - loss 1.27736137 - samples/sec: 123.35
2020-04-02 00:53:58,536 epoch 73 - iter 430/439 - loss 0.53706704 - samples/sec: 156.34
2020-04-02 00:54:06,681 ----------------------------------------------------------------------------------------------------
2020-04-02 00:54:06,682 EPOCH 73 done: loss 0.5375 - lr 0.0050
2020-04-02 00:53:57,973 epoch 74 - iter 344/439 - loss 0.62038956 - samples/sec: 150.59
2020-04-02 00:54:11,102 DEV : loss 0.4946323335170746 - score 0.9424
2020-04-02 00:54:11,195 BAD EPOCHS (no improvement): 2
2020-04-02 00:54:11,267 ----------------------------------------------------------------------------------------------------
2020-04-02 00:54:12,549 epoch 74 - iter 387/439 - loss 0.61763885 - samples/sec: 162.78
2020-04-02 00:54:19,648 epoch 74 - iter 43/439 - loss 0.52237550 - samples/sec: 164.26
2020-04-02 00:54:34,024 epoch 74 - iter 86/439 - loss 0.57186406 - samples/sec: 156.43
2020-04-02 00:54:28,323 epoch 74 - iter 430/439 - loss 0.61129248 - samples/sec: 154.65
2020-04-02 00:54:37,078 ----------------------------------------------------------------------------------------------------
2020-04-02 00:54:37,079 EPOCH 74 done: loss 0.6136 - lr 0.0002
2020-04-02 00:54:41,574 DEV : loss 0.5490232110023499 - score 0.9367
2020-04-02 00:54:41,673 BAD EPOCHS (no improvement): 3
2020-04-02 00:54:41,731 ----------------------------------------------------------------------------------------------------
2020-04-02 00:54:48,941 epoch 74 - iter 129/439 - loss 0.56460542 - samples/sec: 158.57
2020-04-02 00:54:50,710 epoch 75 - iter 43/439 - loss 0.66843400 - samples/sec: 153.32
2020-04-02 00:55:03,661 epoch 74 - iter 172/439 - loss 0.56269290 - samples/sec: 167.79
2020-04-02 00:55:06,250 epoch 75 - iter 86/439 - loss 0.63622345 - samples/sec: 153.02
2020-04-02 00:55:18,335 epoch 74 - iter 215/439 - loss 0.55869903 - samples/sec: 158.42
2020-04-02 00:55:21,071 epoch 75 - iter 129/439 - loss 0.61684592 - samples/sec: 154.88
2020-04-02 00:55:32,809 epoch 74 - iter 258/439 - loss 0.56375440 - samples/sec: 163.48
2020-04-02 00:55:35,600 epoch 75 - iter 172/439 - loss 0.60967502 - samples/sec: 158.69
2020-04-02 00:55:47,584 epoch 74 - iter 301/439 - loss 0.55383689 - samples/sec: 154.11
2020-04-02 00:55:51,065 epoch 75 - iter 215/439 - loss 0.60040239 - samples/sec: 152.37
2020-04-02 00:56:02,490 epoch 74 - iter 344/439 - loss 0.55402209 - samples/sec: 162.95
2020-04-02 00:56:06,635 epoch 75 - iter 258/439 - loss 0.59398412 - samples/sec: 152.77
2020-04-02 00:56:17,044 epoch 74 - iter 387/439 - loss 0.55461326 - samples/sec: 160.62
2020-04-02 00:56:21,873 epoch 75 - iter 301/439 - loss 0.59522346 - samples/sec: 152.81
2020-04-02 00:56:31,618 epoch 74 - iter 430/439 - loss 0.55164196 - samples/sec: 160.68
2020-04-02 00:56:37,577 epoch 75 - iter 344/439 - loss 0.60136608 - samples/sec: 148.44
2020-04-02 00:56:39,240 ----------------------------------------------------------------------------------------------------
2020-04-02 00:56:39,240 EPOCH 74 done: loss 0.5508 - lr 0.0050
2020-04-02 00:56:43,696 DEV : loss 0.4936267137527466 - score 0.9431
2020-04-02 00:56:43,793 BAD EPOCHS (no improvement): 3
2020-04-02 00:56:43,817 ----------------------------------------------------------------------------------------------------
2020-04-02 00:56:51,954 epoch 75 - iter 43/439 - loss 0.48985124 - samples/sec: 169.20
2020-04-02 00:56:52,420 epoch 75 - iter 387/439 - loss 0.60325263 - samples/sec: 158.67
2020-04-02 00:57:06,546 epoch 75 - iter 86/439 - loss 0.50012814 - samples/sec: 163.12
2020-04-02 00:57:06,870 epoch 75 - iter 430/439 - loss 0.61010730 - samples/sec: 163.72
2020-04-02 00:57:14,217 ----------------------------------------------------------------------------------------------------
2020-04-02 00:57:14,218 EPOCH 75 done: loss 0.6095 - lr 0.0002
2020-04-02 00:57:19,150 epoch 10 - iter 172/439 - loss 1.47077726 - samples/sec: 170.66
2020-04-02 00:57:19,194 epoch 75 - iter 129/439 - loss 0.51981937 - samples/sec: 190.86
2020-04-02 00:57:19,359 DEV : loss 0.5487097501754761 - score 0.937
Epoch    75: reducing learning rate of group 0 to 7.8125e-05.
2020-04-02 00:57:19,456 BAD EPOCHS (no improvement): 4
2020-04-02 00:57:19,501 ----------------------------------------------------------------------------------------------------
2020-04-02 00:57:19,501 ----------------------------------------------------------------------------------------------------
2020-04-02 00:57:19,501 learning rate too small - quitting training!
2020-04-02 00:57:19,501 ----------------------------------------------------------------------------------------------------
2020-04-02 00:57:21,054 ----------------------------------------------------------------------------------------------------
2020-04-02 00:57:21,054 Testing using best model ...
2020-04-02 00:57:21,055 loading file log/elmo_s_20200401213237_512/best-model.pt
2020-04-02 00:57:34,371 epoch 75 - iter 172/439 - loss 0.52010439 - samples/sec: 175.68
2020-04-02 00:57:37,329 0.9034	0.909	0.9062
2020-04-02 00:57:37,329 
MICRO_AVG: acc 0.8285 - f1-score 0.9062
MACRO_AVG: acc 0.8081 - f1-score 0.89065
LOC        tp: 1539 - fp: 119 - fn: 129 - tn: 1539 - precision: 0.9282 - recall: 0.9227 - accuracy: 0.8612 - f1-score: 0.9254
MISC       tp: 561 - fp: 148 - fn: 141 - tn: 561 - precision: 0.7913 - recall: 0.7991 - accuracy: 0.6600 - f1-score: 0.7952
ORG        tp: 1487 - fp: 216 - fn: 174 - tn: 1487 - precision: 0.8732 - recall: 0.8952 - accuracy: 0.7922 - f1-score: 0.8841
PER        tp: 1547 - fp: 66 - fn: 70 - tn: 1547 - precision: 0.9591 - recall: 0.9567 - accuracy: 0.9192 - f1-score: 0.9579
2020-04-02 00:57:37,329 ----------------------------------------------------------------------------------------------------
2020-04-02 00:57:37,720 epoch 7 - iter 132/220 - loss 1.27216569 - samples/sec: 116.08
2020-04-02 00:57:49,025 ----------------------------------------------------------------------------------------------------
2020-04-02 00:57:49,025 EPOCH 4 done: loss 1.2404 - lr 0.0100
2020-04-02 00:57:48,954 epoch 75 - iter 215/439 - loss 0.51196999 - samples/sec: 176.43
2020-04-02 00:58:03,836 epoch 75 - iter 258/439 - loss 0.51891001 - samples/sec: 159.65
2020-04-02 00:58:11,153 DEV : loss 0.7830876111984253 - score 0.9242
2020-04-02 00:58:11,591 BAD EPOCHS (no improvement): 0
2020-04-02 00:58:19,065 epoch 75 - iter 301/439 - loss 0.53434822 - samples/sec: 150.27
2020-04-02 00:58:48,122 epoch 75 - iter 344/439 - loss 0.53976376 - samples/sec: 151.43
2020-04-02 00:58:58,269 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 00:59:09,451 epoch 75 - iter 387/439 - loss 0.53960135 - samples/sec: 157.05
2020-04-02 00:59:15,973 epoch 5 - iter 43/439 - loss 1.07282172 - samples/sec: 77.77
2020-04-02 00:59:24,767 epoch 75 - iter 430/439 - loss 0.54369441 - samples/sec: 149.63
2020-04-02 00:59:32,653 ----------------------------------------------------------------------------------------------------
2020-04-02 00:59:32,654 EPOCH 75 done: loss 0.5415 - lr 0.0050
2020-04-02 00:59:37,676 DEV : loss 0.48718538880348206 - score 0.9436
Epoch    75: reducing learning rate of group 0 to 2.5000e-03.
2020-04-02 00:59:37,769 BAD EPOCHS (no improvement): 4
2020-04-02 00:59:37,858 ----------------------------------------------------------------------------------------------------
2020-04-02 00:59:47,035 epoch 76 - iter 43/439 - loss 0.58346612 - samples/sec: 150.00
2020-04-02 01:00:02,183 epoch 76 - iter 86/439 - loss 0.59150427 - samples/sec: 156.37
2020-04-02 01:00:18,057 epoch 76 - iter 129/439 - loss 0.55400471 - samples/sec: 152.36
2020-04-02 01:00:32,649 epoch 76 - iter 172/439 - loss 0.55708944 - samples/sec: 160.20
2020-04-02 01:00:48,044 epoch 76 - iter 215/439 - loss 0.54031199 - samples/sec: 153.73
2020-04-02 01:01:02,880 epoch 76 - iter 258/439 - loss 0.54981392 - samples/sec: 161.61
2020-04-02 01:01:18,374 epoch 76 - iter 301/439 - loss 0.53717892 - samples/sec: 152.45
2020-04-02 01:01:27,302 epoch 10 - iter 258/439 - loss 1.42552494 - samples/sec: 169.09
2020-04-02 01:01:34,136 epoch 76 - iter 344/439 - loss 0.53266661 - samples/sec: 151.79
2020-04-02 01:01:47,451 epoch 7 - iter 154/220 - loss 1.27597673 - samples/sec: 120.70
2020-04-02 01:01:49,368 epoch 76 - iter 387/439 - loss 0.52969637 - samples/sec: 151.25
2020-04-02 01:02:03,936 epoch 76 - iter 430/439 - loss 0.53162134 - samples/sec: 160.76
2020-04-02 01:02:11,481 ----------------------------------------------------------------------------------------------------
2020-04-02 01:02:11,482 EPOCH 76 done: loss 0.5307 - lr 0.0025
2020-04-02 01:02:15,941 DEV : loss 0.4913417398929596 - score 0.9439
2020-04-02 01:02:16,038 BAD EPOCHS (no improvement): 1
2020-04-02 01:02:16,087 ----------------------------------------------------------------------------------------------------
2020-04-02 01:02:25,281 epoch 77 - iter 43/439 - loss 0.52296250 - samples/sec: 149.72
2020-04-02 01:02:40,231 epoch 77 - iter 86/439 - loss 0.52298780 - samples/sec: 155.74
2020-04-02 01:02:55,081 epoch 77 - iter 129/439 - loss 0.51159860 - samples/sec: 155.66
2020-04-02 01:03:13,264 epoch 10 - iter 301/439 - loss 1.43578543 - samples/sec: 160.08
2020-04-02 01:03:09,457 epoch 77 - iter 172/439 - loss 0.52189471 - samples/sec: 157.52
2020-04-02 01:03:24,135 epoch 77 - iter 215/439 - loss 0.52336333 - samples/sec: 153.85
2020-04-02 01:03:38,357 epoch 77 - iter 258/439 - loss 0.53144021 - samples/sec: 152.11
2020-04-02 01:03:52,936 epoch 77 - iter 301/439 - loss 0.52964479 - samples/sec: 152.51
2020-04-02 01:04:07,638 epoch 77 - iter 344/439 - loss 0.53008364 - samples/sec: 160.29
2020-04-02 01:04:40,345 epoch 5 - iter 86/439 - loss 1.07905628 - samples/sec: 84.45
6
2020-04-02 01:04:53,634 epoch 77 - iter 430/439 - loss 0.52014880 - samples/sec: 152.95
2020-04-02 01:05:01,462 ----------------------------------------------------------------------------------------------------
2020-04-02 01:05:01,463 EPOCH 77 done: loss 0.5204 - lr 0.0025
2020-04-02 01:05:05,844 DEV : loss 0.4935394525527954 - score 0.9423
2020-04-02 01:05:05,936 BAD EPOCHS (no improvement): 2
2020-04-02 01:05:05,970 ----------------------------------------------------------------------------------------------------
2020-04-02 01:05:14,884 epoch 78 - iter 43/439 - loss 0.54508616 - samples/sec: 154.43

2020-04-02 01:05:35,882 epoch 7 - iter 176/220 - loss 1.26198547 - samples/sec: 115.41
2020-04-02 01:05:29,801 epoch 78 - iter 86/439 - loss 0.50854897 - samples/sec: 152.96
2020-04-02 01:05:45,038 epoch 78 - iter 129/439 - loss 0.51319873 - samples/sec: 147.78
2020-04-02 01:06:00,089 epoch 78 - iter 172/439 - loss 0.50658296 - samples/sec: 151.04
2020-04-02 01:06:14,188 epoch 78 - iter 215/439 - loss 0.51366283 - samples/sec: 152.30
2020-04-02 01:06:28,994 epoch 78 - iter 258/439 - loss 0.51185886 - samples/sec: 153.24
2020-04-02 01:06:44,141 epoch 78 - iter 301/439 - loss 0.51615039 - samples/sec: 151.19
2020-04-02 01:06:59,297 epoch 78 - iter 344/439 - loss 0.52664876 - samples/sec: 146.04
2020-04-02 01:07:15,019 epoch 78 - iter 387/439 - loss 0.52911115 - samples/sec: 149.92
2020-04-02 01:07:29,817 epoch 78 - iter 430/439 - loss 0.53038771 - samples/sec: 152.87
2020-04-02 01:07:37,957 ----------------------------------------------------------------------------------------------------
2020-04-02 01:07:37,958 EPOCH 78 done: loss 0.5311 - lr 0.0025
2020-04-02 01:07:42,350 DEV : loss 0.4898799657821655 - score 0.9432
2020-04-02 01:07:42,444 BAD EPOCHS (no improvement): 3
2020-04-02 01:07:42,487 ----------------------------------------------------------------------------------------------------
2020-04-02 01:07:51,567 epoch 79 - iter 43/439 - loss 0.48783060 - samples/sec: 151.61
2020-04-02 01:08:06,524 epoch 79 - iter 86/439 - loss 0.51395126 - samples/sec: 152.77
2020-04-02 01:08:21,636 epoch 79 - iter 129/439 - loss 0.52110877 - samples/sec: 150.80
2020-04-02 01:08:36,800 epoch 79 - iter 172/439 - loss 0.49954474 - samples/sec: 150.29
2020-04-02 01:08:46,586 epoch 10 - iter 430/439 - loss 1.41745571 - samples/sec: 165.87
2020-04-02 01:08:51,853 epoch 79 - iter 215/439 - loss 0.50813987 - samples/sec: 150.64
2020-04-02 01:09:06,883 epoch 79 - iter 258/439 - loss 0.51076207 - samples/sec: 155.39
2020-04-02 01:09:10,928 epoch 7 - iter 198/220 - loss 1.24571084 - samples/sec: 121.44
2020-04-02 01:09:21,463 epoch 79 - iter 301/439 - loss 0.51822146 - samples/sec: 151.86
2020-04-02 01:09:36,913 epoch 79 - iter 344/439 - loss 0.51481133 - samples/sec: 152.26
2020-04-02 01:09:57,346 epoch 5 - iter 129/439 - loss 1.12000178 - samples/sec: 77.39
2020-04-02 01:09:51,759 epoch 79 - iter 387/439 - loss 0.51422732 - samples/sec: 154.14
2020-04-02 01:10:05,403 epoch 79 - iter 430/439 - loss 0.51739872 - samples/sec: 158.75
2020-04-02 01:10:13,233 ----------------------------------------------------------------------------------------------------
2020-04-02 01:10:13,234 EPOCH 79 done: loss 0.5173 - lr 0.0025
2020-04-02 01:10:17,684 DEV : loss 0.48938798904418945 - score 0.9451
2020-04-02 01:10:17,782 BAD EPOCHS (no improvement): 0
2020-04-02 01:10:19,134 ----------------------------------------------------------------------------------------------------
2020-04-02 01:10:28,017 epoch 80 - iter 43/439 - loss 0.50343537 - samples/sec: 154.99
------------------------------------
2020-04-02 01:10:26,168 EPOCH 10 done: loss 1.4260 - lr 0.0100
2020-04-02 01:10:30,828 DEV : loss 0.9174355268478394 - score 0.9112
2020-04-02 01:10:30,925 BAD EPOCHS (no improvement): 0
2020-04-02 01:10:39,517 ----------------------------------------------------------------------------------------------------
2020-04-02 01:10:46,376 epoch 11 - iter 43/439 - loss 1.42382803 - samples/sec: 200.79
2020-04-02 01:10:42,928 epoch 80 - iter 86/439 - loss 0.50059296 - samples/sec: 151.87
2020-04-02 01:10:57,604 epoch 80 - iter 129/439 - loss 0.50793493 - samples/sec: 154.52
2020-04-02 01:11:13,081 epoch 80 - iter 172/439 - loss 0.51675024 - samples/sec: 153.22
2020-04-02 01:11:28,331 epoch 80 - iter 215/439 - loss 0.52116836 - samples/sec: 149.46
2020-04-02 01:11:43,710 epoch 80 - iter 258/439 - loss 0.52670094 - samples/sec: 156.51
2020-04-02 01:11:58,512 epoch 80 - iter 301/439 - loss 0.52430221 - samples/sec: 153.30
2020-04-02 01:12:13,581 epoch 80 - iter 344/439 - loss 0.52497111 - samples/sec: 152.24
2020-04-02 01:12:28,977 epoch 80 - iter 387/439 - loss 0.52494099 - samples/sec: 150.24
2020-04-02 01:12:34,778 epoch 11 - iter 86/439 - loss 1.40727753 - samples/sec: 194.23
2020-04-02 01:12:43,375 epoch 80 - iter 430/439 - loss 0.52511210 - samples/sec: 151.98
2020-04-02 01:12:51,189 ----------------------------------------------------------------------------------------------------
2020-04-02 01:12:51,190 EPOCH 80 done: loss 0.5263 - lr 0.0025
2020-04-02 01:12:55,630 DEV : loss 0.49138370156288147 - score 0.9458
2020-04-02 01:12:55,728 BAD EPOCHS (no improvement): 0
2020-04-02 01:12:57,127 ----------------------------------------------------------------------------------------------------
2020-04-02 01:13:05,627 epoch 81 - iter 43/439 - loss 0.54828245 - samples/sec: 161.98
2020-04-02 01:13:20,943 epoch 81 - iter 86/439 - loss 0.56200405 - samples/sec: 148.64
2020-04-02 01:13:36,031 epoch 81 - iter 129/439 - loss 0.57210922 - samples/sec: 149.39
2020-04-02 01:13:51,447 epoch 81 - iter 172/439 - loss 0.55007024 - samples/sec: 150.86
2020-04-02 01:14:06,377 epoch 81 - iter 215/439 - loss 0.53993329 - samples/sec: 157.55
2020-04-02 01:14:22,754 epoch 11 - iter 129/439 - loss 1.41851707 - samples/sec: 196.44
2020-04-02 01:14:22,403 epoch 81 - iter 258/439 - loss 0.54076130 - samples/sec: 149.54
2020-04-02 01:14:37,207 epoch 81 - iter 301/439 - loss 0.53501767 - samples/sec: 154.62
2020-04-02 01:14:52,308 epoch 81 - iter 344/439 - loss 0.53475011 - samples/sec: 153.09
2020-04-02 01:15:06,555 epoch 81 - iter 387/439 - loss 0.53345431 - samples/sec: 164.25
2020-04-02 01:15:21,315 epoch 81 - iter 430/439 - loss 0.52747871 - samples/sec: 151.87
2020-04-02 01:15:29,573 ----------------------------------------------------------------------------------------------------
2020-04-02 01:15:29,573 EPOCH 81 done: loss 0.5266 - lr 0.0025
2020-04-02 01:15:33,960 DEV : loss 0.48972752690315247 - score 0.9442
2020-04-02 01:15:34,053 BAD EPOCHS (no improvement): 1
2020-04-02 01:15:34,074 ----------------------------------------------------------------------------------------------------
2020-04-02 01:15:42,944 epoch 82 - iter 43/439 - loss 0.50971815 - samples/sec: 155.19
2020-04-02 01:15:57,941 epoch 82 - iter 86/439 - loss 0.49729209 - samples/sec: 150.46
2020-04-02 01:16:08,715 epoch 11 - iter 172/439 - loss 1.38631270 - samples/sec: 176.83
2020-04-02 01:16:15,343 ----------------------------------------------------------------------------------------------------
2020-04-02 01:16:15,343 EPOCH 7 done: loss 1.2438 - lr 0.0100
2020-04-02 01:16:12,449 epoch 82 - iter 129/439 - loss 0.50390928 - samples/sec: 152.15
2020-04-02 01:16:27,689 epoch 82 - iter 172/439 - loss 0.50756265 - samples/sec: 151.86
2020-04-02 01:16:30,079 BAD EPOCHS (no improvement): 0
2020-04-02 01:16:43,002 epoch 82 - iter 215/439 - loss 0.51225618 - samples/sec: 151.68
2020-04-02 01:17:08,011 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 01:17:18,826 epoch 82 - iter 258/439 - loss 0.52231921 - samples/sec: 152.77
2020-04-02 01:17:19,474 epoch 8 - iter 22/220 - loss 1.13600396 - samples/sec: 122.94
2020-04-02 01:17:33,602 epoch 82 - iter 301/439 - loss 0.52332614 - samples/sec: 151.49
2020-04-02 01:17:48,701 epoch 82 - iter 344/439 - loss 0.52220160 - samples/sec: 148.59
2020-04-02 01:18:03,300 epoch 82 - iter 387/439 - loss 0.51863027 - samples/sec: 157.12
2020-04-02 01:18:09,578 epoch 11 - iter 215/439 - loss 1.36144061 - samples/sec: 249.94
2020-04-02 01:18:18,327 epoch 82 - iter 430/439 - loss 0.51895893 - samples/sec: 155.85
2020-04-02 01:18:26,099 ----------------------------------------------------------------------------------------------------
2020-04-02 01:18:26,100 EPOCH 82 done: loss 0.5205 - lr 0.0025
2020-04-02 01:18:30,565 DEV : loss 0.4942484200000763 - score 0.9453
2020-04-02 01:18:30,662 BAD EPOCHS (no improvement): 2
2020-04-02 01:18:30,732 ----------------------------------------------------------------------------------------------------
2020-04-02 01:18:39,717 epoch 83 - iter 43/439 - loss 0.49572128 - samples/sec: 153.21
2020-04-02 01:18:55,072 epoch 83 - iter 86/439 - loss 0.49441124 - samples/sec: 148.59
2020-04-02 01:19:08,816 epoch 83 - iter 129/439 - loss 0.47671750 - samples/sec: 164.50
2020-04-02 01:19:23,981 epoch 83 - iter 172/439 - loss 0.47431986 - samples/sec: 150.46
2020-04-02 01:19:38,209 epoch 83 - iter 215/439 - loss 0.48190189 - samples/sec: 154.08
2020-04-02 01:19:53,211 epoch 83 - iter 258/439 - loss 0.48570219 - samples/sec: 149.57
2020-04-02 01:19:53,389 epoch 11 - iter 258/439 - loss 1.37609135 - samples/sec: 165.08
2020-04-02 01:20:07,412 epoch 83 - iter 301/439 - loss 0.50128304 - samples/sec: 158.46
2020-04-02 01:20:22,645 epoch 83 - iter 344/439 - loss 0.51020541 - samples/sec: 152.27
2020-04-02 01:20:37,085 epoch 83 - iter 387/439 - loss 0.50908914 - samples/sec: 151.30
2020-04-02 01:20:47,349 epoch 8 - iter 44/220 - loss 1.22990621 - samples/sec: 110.76
2020-04-02 01:20:49,096 epoch 5 - iter 215/439 - loss 1.09355829 - samples/sec: 83.45
2020-04-02 01:20:52,053 epoch 83 - iter 430/439 - loss 0.51588383 - samples/sec: 149.14
2020-04-02 01:21:00,006 ----------------------------------------------------------------------------------------------------
2020-04-02 01:21:00,007 EPOCH 83 done: loss 0.5196 - lr 0.0025
2020-04-02 01:21:04,422 DEV : loss 0.4914816617965698 - score 0.9446
2020-04-02 01:21:04,516 BAD EPOCHS (no improvement): 3
2020-04-02 01:21:04,552 ----------------------------------------------------------------------------------------------------
2020-04-02 01:21:13,565 epoch 84 - iter 43/439 - loss 0.48733851 - samples/sec: 152.74
2020-04-02 01:21:29,333 epoch 84 - iter 86/439 - loss 0.51524606 - samples/sec: 148.16
2020-04-02 01:21:36,907 epoch 11 - iter 301/439 - loss 1.37785981 - samples/sec: 175.70
2020-04-02 01:21:43,641 epoch 84 - iter 129/439 - loss 0.50268653 - samples/sec: 153.59
2020-04-02 01:21:59,461 epoch 84 - iter 172/439 - loss 0.51815647 - samples/sec: 148.00
2020-04-02 01:22:14,487 epoch 84 - iter 215/439 - loss 0.52341408 - samples/sec: 154.78
2020-04-02 01:22:29,932 epoch 84 - iter 258/439 - loss 0.52131549 - samples/sec: 151.18
2020-04-02 01:22:45,618 epoch 84 - iter 301/439 - loss 0.52926667 - samples/sec: 150.42
2020-04-02 01:23:01,030 epoch 84 - iter 344/439 - loss 0.53722712 - samples/sec: 150.54
2020-04-02 01:23:16,365 epoch 84 - iter 387/439 - loss 0.53424727 - samples/sec: 151.71
2020-04-02 01:23:24,868 epoch 11 - iter 344/439 - loss 1.36465232 - samples/sec: 164.37
2020-04-02 01:23:31,491 epoch 84 - iter 430/439 - loss 0.52383911 - samples/sec: 151.49
2020-04-02 01:23:39,379 ----------------------------------------------------------------------------------------------------
2020-04-02 01:23:39,380 EPOCH 84 done: loss 0.5236 - lr 0.0025
2020-04-02 01:23:43,763 DEV : loss 0.49143168330192566 - score 0.9432
Epoch    84: reducing learning rate of group 0 to 1.2500e-03.
2020-04-02 01:23:43,857 BAD EPOCHS (no improvement): 4
2020-04-02 01:23:43,869 ----------------------------------------------------------------------------------------------------
2020-04-02 01:23:52,957 epoch 85 - iter 43/439 - loss 0.56667253 - samples/sec: 151.47
2020-04-02 01:24:07,307 epoch 85 - iter 86/439 - loss 0.54339915 - samples/sec: 163.27
2020-04-02 01:24:25,283 epoch 8 - iter 66/220 - loss 1.21672424 - samples/sec: 121.34
2020-04-02 01:24:23,008 epoch 85 - iter 129/439 - loss 0.52589805 - samples/sec: 154.26
2020-04-02 01:24:38,081 epoch 85 - iter 172/439 - loss 0.52987148 - samples/sec: 152.44
2020-04-02 01:24:53,184 epoch 85 - iter 215/439 - loss 0.51953971 - samples/sec: 149.32
2020-04-02 01:25:07,424 epoch 85 - iter 258/439 - loss 0.51271301 - samples/sec: 162.58
2020-04-02 01:25:13,536 epoch 11 - iter 387/439 - loss 1.36413252 - samples/sec: 188.32
2020-04-02 01:25:22,692 epoch 85 - iter 301/439 - loss 0.51720881 - samples/sec: 147.38
2020-04-02 01:25:52,225 epoch 85 - iter 344/439 - loss 0.52168397 - samples/sec: 151.24
2020-04-02 01:26:07,241 epoch 85 - iter 387/439 - loss 0.51674115 - samples/sec: 160.12
2020-04-02 01:26:25,397 epoch 5 - iter 258/439 - loss 1.09654573 - samples/sec: 82.78
2020-04-02 01:26:22,037 epoch 85 - iter 430/439 - loss 0.52159990 - samples/sec: 155.21
2020-04-02 01:26:29,654 ----------------------------------------------------------------------------------------------------
2020-04-02 01:26:29,655 EPOCH 85 done: loss 0.5230 - lr 0.0013
2020-04-02 01:26:34,112 DEV : loss 0.49201199412345886 - score 0.9437
2020-04-02 01:26:34,209 BAD EPOCHS (no improvement): 1
2020-04-02 01:26:34,234 ----------------------------------------------------------------------------------------------------
2020-04-02 01:26:43,241 epoch 86 - iter 43/439 - loss 0.55325555 - samples/sec: 152.84
2020-04-02 01:26:58,233 epoch 86 - iter 86/439 - loss 0.53282695 - samples/sec: 150.96
2020-04-02 01:27:17,153 epoch 11 - iter 430/439 - loss 1.36548913 - samples/sec: 160.32
2020-04-02 01:27:12,987 epoch 86 - iter 129/439 - loss 0.53049658 - samples/sec: 155.33
2020-04-02 01:27:28,106 epoch 86 - iter 172/439 - loss 0.53045618 - samples/sec: 153.54
2020-04-02 01:27:43,342 epoch 86 - iter 215/439 - loss 0.52639008 - samples/sec: 149.22
2020-04-02 01:27:58,525 epoch 86 - iter 258/439 - loss 0.52263898 - samples/sec: 147.87
2020-04-02 01:28:13,661 epoch 86 - iter 301/439 - loss 0.51849060 - samples/sec: 156.43
2020-04-02 01:28:28,736 epoch 86 - iter 344/439 - loss 0.51484081 - samples/sec: 152.98
2020-04-02 01:28:34,682 epoch 8 - iter 88/220 - loss 1.20154461 - samples/sec: 116.28
2020-04-02 01:28:43,433 epoch 86 - iter 387/439 - loss 0.50941113 - samples/sec: 151.42
2020-04-02 01:28:58,474 epoch 86 - iter 430/439 - loss 0.50875663 - samples/sec: 151.16
-----------------------------------
2020-04-02 01:28:56,017 EPOCH 11 done: loss 1.3646 - lr 0.0100
2020-04-02 01:29:05,078 ----------------------------------------------------------------------------------------------------
2020-04-02 01:29:05,078 EPOCH 86 done: loss 0.5096 - lr 0.0013
2020-04-02 01:29:10,006 DEV : loss 0.4903477430343628 - score 0.9445
2020-04-02 01:29:10,103 BAD EPOCHS (no improvement): 2
2020-04-02 01:29:10,154 ----------------------------------------------------------------------------------------------------
2020-04-02 01:29:14,066 epoch 87 - iter 43/439 - loss 0.52167685 - samples/sec: 351.97
2020-04-02 01:29:29,411 epoch 87 - iter 86/439 - loss 0.52388821 - samples/sec: 150.15
2020-04-02 01:29:45,215 epoch 87 - iter 129/439 - loss 0.52116953 - samples/sec: 146.16
2020-04-02 01:30:00,826 epoch 87 - iter 172/439 - loss 0.50904378 - samples/sec: 150.21
2020-04-02 01:30:11,388 epoch 87 - iter 215/439 - loss 0.51089162 - samples/sec: 337.88
2020-04-02 01:30:21,767 epoch 87 - iter 258/439 - loss 0.51006836 - samples/sec: 327.30
2020-04-02 01:30:37,599 epoch 87 - iter 301/439 - loss 0.51034012 - samples/sec: 149.54
2020-04-02 01:30:52,553 epoch 87 - iter 344/439 - loss 0.50892590 - samples/sec: 155.25
2020-04-02 01:31:08,092 epoch 87 - iter 387/439 - loss 0.50471513 - samples/sec: 161.27
2020-04-02 01:31:24,251 epoch 87 - iter 430/439 - loss 0.50647033 - samples/sec: 151.21
2020-04-02 01:31:32,983 ----------------------------------------------------------------------------------------------------
2020-04-02 01:31:32,984 EPOCH 87 done: loss 0.5098 - lr 0.0013
2020-04-02 01:31:37,445 DEV : loss 0.4928915202617645 - score 0.9449
2020-04-02 01:31:37,542 BAD EPOCHS (no improvement): 3
2020-04-02 01:31:37,612 ----------------------------------------------------------------------------------------------------
2020-04-02 01:31:46,711 epoch 88 - iter 43/439 - loss 0.46375653 - samples/sec: 151.29
2020-04-02 01:32:02,087 epoch 88 - iter 86/439 - loss 0.46796338 - samples/sec: 153.55
2020-04-02 01:32:17,912 epoch 88 - iter 129/439 - loss 0.47430535 - samples/sec: 149.88
2020-04-02 01:32:28,435 epoch 88 - iter 172/439 - loss 0.47178820 - samples/sec: 316.04
2020-04-02 01:32:42,359 epoch 88 - iter 215/439 - loss 0.47550154 - samples/sec: 306.63
2020-04-02 01:32:52,857 epoch 88 - iter 258/439 - loss 0.48409065 - samples/sec: 305.66
2020-04-02 01:32:59,883 epoch 12 - iter 129/439 - loss 1.28928945 - samples/sec: 162.27
2020-04-02 01:33:02,119 epoch 88 - iter 301/439 - loss 0.47958550 - samples/sec: 332.34
2020-04-02 01:33:11,925 epoch 88 - iter 344/439 - loss 0.49102067 - samples/sec: 340.13
2020-04-02 01:33:22,035 epoch 88 - iter 387/439 - loss 0.49682665 - samples/sec: 342.20
2020-04-02 01:33:32,570 epoch 88 - iter 430/439 - loss 0.50151511 - samples/sec: 303.69
2020-04-02 01:33:41,477 ----------------------------------------------------------------------------------------------------
2020-04-02 01:33:41,478 EPOCH 88 done: loss 0.5015 - lr 0.0013
2020-04-02 01:33:45,866 DEV : loss 0.4906286895275116 - score 0.9442
Epoch    88: reducing learning rate of group 0 to 6.2500e-04.
2020-04-02 01:33:45,958 BAD EPOCHS (no improvement): 4
2020-04-02 01:33:45,998 ----------------------------------------------------------------------------------------------------
2020-04-02 01:33:55,161 epoch 89 - iter 43/439 - loss 0.57623349 - samples/sec: 150.23
2020-04-02 01:34:08,988 epoch 89 - iter 86/439 - loss 0.55259046 - samples/sec: 171.37
2020-04-02 01:34:19,275 epoch 89 - iter 129/439 - loss 0.55323300 - samples/sec: 307.87
2020-04-02 01:34:29,787 epoch 89 - iter 172/439 - loss 0.53258125 - samples/sec: 334.66
2020-04-02 01:34:40,721 epoch 89 - iter 215/439 - loss 0.52221015 - samples/sec: 309.89
2020-04-02 01:34:44,818 epoch 12 - iter 172/439 - loss 1.31113526 - samples/sec: 176.21
2020-04-02 01:34:50,197 epoch 89 - iter 258/439 - loss 0.51581942 - samples/sec: 309.66
2020-04-02 01:35:00,863 epoch 89 - iter 301/439 - loss 0.50826185 - samples/sec: 308.00
2020-04-02 01:35:10,649 epoch 89 - iter 344/439 - loss 0.50134864 - samples/sec: 331.81
2020-04-02 01:35:21,214 epoch 89 - iter 387/439 - loss 0.50802420 - samples/sec: 312.37
2020-04-02 01:35:31,138 epoch 89 - iter 430/439 - loss 0.51066811 - samples/sec: 325.74
2020-04-02 01:35:37,574 ----------------------------------------------------------------------------------------------------
2020-04-02 01:35:37,574 EPOCH 89 done: loss 0.5103 - lr 0.0006
2020-04-02 01:35:41,894 DEV : loss 0.4895794689655304 - score 0.9431
2020-04-02 01:35:41,990 BAD EPOCHS (no improvement): 1
2020-04-02 01:35:42,020 ----------------------------------------------------------------------------------------------------
2020-04-02 01:35:45,968 epoch 90 - iter 43/439 - loss 0.48911824 - samples/sec: 348.74
2020-04-02 01:35:56,464 epoch 90 - iter 86/439 - loss 0.46714803 - samples/sec: 314.43
2020-04-02 01:36:06,324 epoch 90 - iter 129/439 - loss 0.48374154 - samples/sec: 348.04
2020-04-02 01:36:16,153 epoch 90 - iter 172/439 - loss 0.50988834 - samples/sec: 326.67
2020-04-02 01:36:26,096 epoch 90 - iter 215/439 - loss 0.51395157 - samples/sec: 323.50
2020-04-02 01:36:35,387 epoch 90 - iter 258/439 - loss 0.51588367 - samples/sec: 326.57
2020-04-02 01:36:45,540 epoch 90 - iter 301/439 - loss 0.51714787 - samples/sec: 351.86
2020-04-02 01:36:56,268 epoch 90 - iter 344/439 - loss 0.51477125 - samples/sec: 325.62
2020-04-02 01:37:06,291 epoch 90 - iter 387/439 - loss 0.52088829 - samples/sec: 343.25
2020-04-02 01:37:16,921 epoch 90 - iter 430/439 - loss 0.52275483 - samples/sec: 331.85
2020-04-02 01:37:23,737 ----------------------------------------------------------------------------------------------------
2020-04-02 01:37:23,737 EPOCH 90 done: loss 0.5233 - lr 0.0006
2020-04-02 01:37:28,061 DEV : loss 0.4887349605560303 - score 0.9436
2020-04-02 01:37:28,158 BAD EPOCHS (no improvement): 2
2020-04-02 01:37:28,191 ----------------------------------------------------------------------------------------------------
2020-04-02 01:37:32,167 epoch 91 - iter 43/439 - loss 0.49409898 - samples/sec: 346.23
2020-04-02 01:37:47,154 epoch 91 - iter 86/439 - loss 0.51255502 - samples/sec: 149.80
2020-04-02 01:38:02,527 epoch 91 - iter 129/439 - loss 0.50345846 - samples/sec: 155.58
2020-04-02 01:38:17,765 epoch 91 - iter 172/439 - loss 0.50863273 - samples/sec: 153.31
2020-04-02 01:38:32,826 epoch 91 - iter 215/439 - loss 0.51339861 - samples/sec: 154.00
2020-04-02 01:38:48,427 epoch 91 - iter 258/439 - loss 0.52125752 - samples/sec: 151.01
2020-04-02 01:39:03,200 epoch 91 - iter 301/439 - loss 0.52525485 - samples/sec: 159.41
2020-04-02 01:39:18,161 epoch 91 - iter 344/439 - loss 0.52123608 - samples/sec: 151.87
2020-04-02 01:39:21,161 epoch 8 - iter 154/220 - loss 1.18678950 - samples/sec: 125.03
2020-04-02 01:39:32,865 epoch 91 - iter 387/439 - loss 0.51534275 - samples/sec: 149.27
2020-04-02 01:39:47,977 epoch 91 - iter 430/439 - loss 0.51118808 - samples/sec: 152.19
2020-04-02 01:39:57,806 epoch 12 - iter 301/439 - loss 1.32067651 - samples/sec: 163.24
2020-04-02 01:39:55,568 ----------------------------------------------------------------------------------------------------
2020-04-02 01:39:55,569 EPOCH 91 done: loss 0.5117 - lr 0.0006
2020-04-02 01:40:00,037 DEV : loss 0.4906969666481018 - score 0.9443
2020-04-02 01:40:00,132 BAD EPOCHS (no improvement): 3
2020-04-02 01:40:00,169 ----------------------------------------------------------------------------------------------------
2020-04-02 01:40:08,409 epoch 92 - iter 43/439 - loss 0.47938657 - samples/sec: 167.05
2020-04-02 01:40:23,677 epoch 92 - iter 86/439 - loss 0.50586258 - samples/sec: 149.45
2020-04-02 01:40:38,633 epoch 92 - iter 129/439 - loss 0.51097745 - samples/sec: 151.99
2020-04-02 01:40:52,907 epoch 92 - iter 172/439 - loss 0.51426806 - samples/sec: 159.92
2020-04-02 01:41:07,149 epoch 92 - iter 215/439 - loss 0.51204753 - samples/sec: 166.07
2020-04-02 01:41:22,565 epoch 92 - iter 258/439 - loss 0.52210404 - samples/sec: 153.26
2020-04-02 01:41:37,329 epoch 92 - iter 301/439 - loss 0.52579505 - samples/sec: 154.04
2020-04-02 01:41:41,061 epoch 12 - iter 344/439 - loss 1.30111380 - samples/sec: 165.03
2020-04-02 01:41:51,993 epoch 92 - iter 344/439 - loss 0.51634792 - samples/sec: 152.69
2020-04-02 01:42:06,912 epoch 5 - iter 387/439 - loss 1.08022495 - samples/sec: 84.10
2020-04-02 01:42:05,508 epoch 92 - iter 387/439 - loss 0.50796409 - samples/sec: 174.83
2020-04-02 01:42:20,761 epoch 92 - iter 430/439 - loss 0.50790243 - samples/sec: 149.34
2020-04-02 01:42:28,160 ----------------------------------------------------------------------------------------------------
2020-04-02 01:42:28,161 EPOCH 92 done: loss 0.5094 - lr 0.0006
2020-04-02 01:42:32,613 DEV : loss 0.48861685395240784 - score 0.9434
Epoch    92: reducing learning rate of group 0 to 3.1250e-04.
2020-04-02 01:42:32,711 BAD EPOCHS (no improvement): 4
2020-04-02 01:42:32,722 ----------------------------------------------------------------------------------------------------
2020-04-02 01:42:41,701 epoch 93 - iter 43/439 - loss 0.50429163 - samples/sec: 153.30
2020-04-02 01:42:48,428 epoch 8 - iter 176/220 - loss 1.17614019 - samples/sec: 117.97
2020-04-02 01:42:57,576 epoch 93 - iter 86/439 - loss 0.49993070 - samples/sec: 150.88
2020-04-02 01:43:08,861 epoch 93 - iter 129/439 - loss 0.51599731 - samples/sec: 314.75
2020-04-02 01:43:19,161 epoch 93 - iter 172/439 - loss 0.51115485 - samples/sec: 309.29
2020-04-02 01:43:25,530 epoch 12 - iter 387/439 - loss 1.29199122 - samples/sec: 170.11
2020-04-02 01:43:33,557 epoch 93 - iter 215/439 - loss 0.51433616 - samples/sec: 153.00
2020-04-02 01:43:48,457 epoch 93 - iter 258/439 - loss 0.49553760 - samples/sec: 151.73
2020-04-02 01:44:02,555 epoch 93 - iter 301/439 - loss 0.49820810 - samples/sec: 164.60
2020-04-02 01:44:17,420 epoch 93 - iter 344/439 - loss 0.49621319 - samples/sec: 156.65
2020-04-02 01:44:33,552 epoch 93 - iter 387/439 - loss 0.49935083 - samples/sec: 153.34
2020-04-02 01:44:48,653 epoch 93 - iter 430/439 - loss 0.50276240 - samples/sec: 150.55
2020-04-02 01:44:57,243 ----------------------------------------------------------------------------------------------------
2020-04-02 01:44:57,244 EPOCH 93 done: loss 0.5032 - lr 0.0003
2020-04-02 01:45:01,696 DEV : loss 0.48863840103149414 - score 0.9438
2020-04-02 01:45:01,793 BAD EPOCHS (no improvement): 1
2020-04-02 01:45:01,834 ----------------------------------------------------------------------------------------------------
2020-04-02 01:45:10,668 epoch 94 - iter 43/439 - loss 0.48037972 - samples/sec: 155.83
2020-04-02 01:45:11,463 epoch 12 - iter 430/439 - loss 1.30069137 - samples/sec: 170.04
2020-04-02 01:45:25,689 epoch 94 - iter 86/439 - loss 0.51393241 - samples/sec: 154.63
2020-04-02 01:45:40,974 epoch 94 - iter 129/439 - loss 0.51499056 - samples/sec: 151.43
2020-04-02 01:45:56,725 epoch 94 - iter 172/439 - loss 0.51099697 - samples/sec: 146.76
2020-04-02 01:46:06,727 epoch 94 - iter 215/439 - loss 0.51544437 - samples/sec: 338.10
2020-04-02 01:46:17,489 epoch 94 - iter 258/439 - loss 0.52491892 - samples/sec: 303.72
2020-04-02 01:46:27,565 epoch 94 - iter 301/439 - loss 0.52896524 - samples/sec: 317.72
2020-04-02 01:46:38,263 epoch 94 - iter 344/439 - loss 0.52830874 - samples/sec: 315.51
2020-04-02 01:46:48,670 epoch 94 - iter 387/439 - loss 0.52629383 - samples/sec: 351.36
2020-04-02 01:46:59,609 epoch 94 - iter 430/439 - loss 0.52704685 - samples/sec: 335.96
-----------------------------------
2020-04-02 01:46:52,448 EPOCH 12 done: loss 1.3066 - lr 0.0100
2020-04-02 01:46:57,790 DEV : loss 0.8802516460418701 - score 0.9157
2020-04-02 01:46:57,887 BAD EPOCHS (no improvement): 0
2020-04-02 01:47:06,627 ----------------------------------------------------------------------------------------------------
2020-04-02 01:47:15,383 epoch 13 - iter 43/439 - loss 1.33921336 - samples/sec: 157.26
------------------------------------
2020-04-02 01:47:10,291 EPOCH 94 done: loss 0.5242 - lr 0.0003
2020-04-02 01:47:14,612 DEV : loss 0.4889685809612274 - score 0.9441
2020-04-02 01:47:14,710 BAD EPOCHS (no improvement): 2
2020-04-02 01:47:14,735 ----------------------------------------------------------------------------------------------------
2020-04-02 01:47:18,729 epoch 95 - iter 43/439 - loss 0.48809529 - samples/sec: 344.65
2020-04-02 01:47:26,418 epoch 5 - iter 430/439 - loss 1.08042594 - samples/sec: 83.32
2020-04-02 01:47:29,337 epoch 95 - iter 86/439 - loss 0.49734013 - samples/sec: 333.71
2020-04-02 01:47:40,201 epoch 95 - iter 129/439 - loss 0.49821593 - samples/sec: 328.04
2020-04-02 01:47:50,989 epoch 95 - iter 172/439 - loss 0.51111680 - samples/sec: 329.81
2020-04-02 01:48:02,166 epoch 95 - iter 215/439 - loss 0.51980354 - samples/sec: 309.88
2020-04-02 01:48:13,098 epoch 95 - iter 258/439 - loss 0.51360405 - samples/sec: 340.58
2020-04-02 01:48:23,743 epoch 95 - iter 301/439 - loss 0.50956223 - samples/sec: 327.16
2020-04-02 01:48:33,986 epoch 95 - iter 344/439 - loss 0.50428809 - samples/sec: 337.58
2020-04-02 01:48:44,815 epoch 95 - iter 387/439 - loss 0.49865680 - samples/sec: 302.38
2020-04-02 01:48:59,576 epoch 95 - iter 430/439 - loss 0.49502022 - samples/sec: 158.08
2020-04-02 01:49:06,611 ----------------------------------------------------------------------------------------------------
2020-04-02 01:49:06,611 EPOCH 95 done: loss 0.4933 - lr 0.0003
2020-04-02 01:49:05,804 epoch 13 - iter 86/439 - loss 1.35929842 - samples/sec: 161.03
2020-04-02 01:49:10,904 DEV : loss 0.48903021216392517 - score 0.9443
2020-04-02 01:49:11,002 BAD EPOCHS (no improvement): 3
2020-04-02 01:49:11,068 ----------------------------------------------------------------------------------------------------
2020-04-02 01:49:15,037 epoch 96 - iter 43/439 - loss 0.52469806 - samples/sec: 346.88
2020-04-02 01:49:25,313 epoch 96 - iter 86/439 - loss 0.49757962 - samples/sec: 322.14
2020-04-02 01:49:35,766 epoch 96 - iter 129/439 - loss 0.50447353 - samples/sec: 330.51
2020-04-02 01:49:45,699 epoch 96 - iter 172/439 - loss 0.51026615 - samples/sec: 333.90
2020-04-02 01:49:56,353 epoch 96 - iter 215/439 - loss 0.50662701 - samples/sec: 306.28
2020-04-02 01:50:05,986 epoch 96 - iter 258/439 - loss 0.50147252 - samples/sec: 338.44
2020-04-02 01:50:01,739 epoch 8 - iter 220/220 - loss 1.16727963 - samples/sec: 118.37
2020-04-02 01:50:16,654 epoch 96 - iter 301/439 - loss 0.49311954 - samples/sec: 308.45
2020-04-02 01:50:26,929 epoch 96 - iter 344/439 - loss 0.49030024 - samples/sec: 324.41
2020-04-02 01:50:37,119 epoch 96 - iter 387/439 - loss 0.49025765 - samples/sec: 323.77
2020-04-02 01:50:47,115 epoch 96 - iter 430/439 - loss 0.49396508 - samples/sec: 335.19
2020-04-02 01:50:50,796 epoch 13 - iter 129/439 - loss 1.33323569 - samples/sec: 157.82
2020-04-02 01:50:54,000 ----------------------------------------------------------------------------------------------------
2020-04-02 01:50:54,001 EPOCH 96 done: loss 0.4947 - lr 0.0003
2020-04-02 01:50:58,328 DEV : loss 0.4887675344944 - score 0.9442
Epoch    96: reducing learning rate of group 0 to 1.5625e-04.
2020-04-02 01:50:58,425 BAD EPOCHS (no improvement): 4
2020-04-02 01:50:58,473 ----------------------------------------------------------------------------------------------------
2020-04-02 01:51:02,509 epoch 97 - iter 43/439 - loss 0.47983260 - samples/sec: 341.13
2020-04-02 01:51:13,387 epoch 97 - iter 86/439 - loss 0.51458140 - samples/sec: 334.36
2020-04-02 01:51:37,932 epoch 97 - iter 129/439 - loss 0.51692448 - samples/sec: 148.92
2020-04-02 01:52:00,379 epoch 97 - iter 172/439 - loss 0.51409015 - samples/sec: 149.12
2020-04-02 01:52:11,124 epoch 97 - iter 215/439 - loss 0.51963927 - samples/sec: 303.26
2020-04-02 01:52:20,804 epoch 97 - iter 258/439 - loss 0.52219127 - samples/sec: 348.02
2020-04-02 01:52:30,394 epoch 97 - iter 301/439 - loss 0.51940375 - samples/sec: 325.99
2020-04-02 01:52:39,951 epoch 97 - iter 344/439 - loss 0.51463886 - samples/sec: 333.45
2020-04-02 01:52:49,612 epoch 97 - iter 387/439 - loss 0.51106468 - samples/sec: 323.95
-----------------------------------
2020-04-02 01:52:48,717 EPOCH 5 done: loss 1.0795 - lr 0.0100
2020-04-02 01:52:59,654 epoch 97 - iter 430/439 - loss 0.51549820 - samples/sec: 332.29
2020-04-02 01:53:07,644 ----------------------------------------------------------------------------------------------------
2020-04-02 01:53:07,645 EPOCH 97 done: loss 0.5156 - lr 0.0002
2020-04-02 01:53:12,683 DEV : loss 0.4887518584728241 - score 0.9442
2020-04-02 01:53:12,778 BAD EPOCHS (no improvement): 1
2020-04-02 01:53:12,862 ----------------------------------------------------------------------------------------------------
2020-04-02 01:53:21,924 epoch 98 - iter 43/439 - loss 0.49436674 - samples/sec: 151.90
2020-04-02 01:53:38,192 epoch 98 - iter 86/439 - loss 0.48750210 - samples/sec: 152.52
2020-04-02 01:53:58,923 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 01:54:10,055 ----------------------------------------------------------------------------------------------------
2020-04-02 01:54:10,055 EPOCH 8 done: loss 1.1673 - lr 0.0100
2020-04-02 01:54:14,046 epoch 6 - iter 43/439 - loss 0.93903876 - samples/sec: 91.04
6
2020-04-02 01:54:23,418 epoch 98 - iter 172/439 - loss 0.49457619 - samples/sec: 151.57
2020-04-02 01:54:24,241 DEV : loss 0.8726761341094971 - score 0.9082
2020-04-02 01:54:24,636 BAD EPOCHS (no improvement): 0
2020-04-02 01:54:38,294 epoch 98 - iter 215/439 - loss 0.50890273 - samples/sec: 149.86
2020-04-02 01:55:08,465 epoch 98 - iter 258/439 - loss 0.50806162 - samples/sec: 341.57
2020-04-02 01:55:05,537 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 01:55:23,532 epoch 98 - iter 301/439 - loss 0.50681615 - samples/sec: 151.92
2020-04-02 01:55:17,384 epoch 9 - iter 22/220 - loss 1.19369565 - samples/sec: 118.95
2020-04-02 01:55:27,767 epoch 13 - iter 215/439 - loss 1.31600084 - samples/sec: 163.26
2020-04-02 01:55:38,833 epoch 98 - iter 344/439 - loss 0.50468986 - samples/sec: 150.23
2020-04-02 01:55:54,330 epoch 98 - iter 387/439 - loss 0.49941793 - samples/sec: 149.45
2020-04-02 01:56:08,421 epoch 98 - iter 430/439 - loss 0.49701945 - samples/sec: 162.14
2020-04-02 01:56:16,403 ----------------------------------------------------------------------------------------------------
2020-04-02 01:56:16,404 EPOCH 98 done: loss 0.4963 - lr 0.0002
2020-04-02 01:56:20,795 DEV : loss 0.4886699616909027 - score 0.9442
2020-04-02 01:56:20,889 BAD EPOCHS (no improvement): 2
2020-04-02 01:56:20,950 ----------------------------------------------------------------------------------------------------
2020-04-02 01:56:30,022 epoch 99 - iter 43/439 - loss 0.56259138 - samples/sec: 151.75
2020-04-02 01:56:45,194 epoch 99 - iter 86/439 - loss 0.52744608 - samples/sec: 150.24
2020-04-02 01:57:00,349 epoch 99 - iter 129/439 - loss 0.51955881 - samples/sec: 151.62
2020-04-02 01:57:11,389 epoch 13 - iter 258/439 - loss 1.29782400 - samples/sec: 225.94
2020-04-02 01:57:15,495 epoch 99 - iter 172/439 - loss 0.50747515 - samples/sec: 150.98
2020-04-02 01:57:30,543 epoch 99 - iter 215/439 - loss 0.51657063 - samples/sec: 149.68
2020-04-02 01:57:45,708 epoch 99 - iter 258/439 - loss 0.51265241 - samples/sec: 149.93
2020-04-02 01:58:00,542 epoch 99 - iter 301/439 - loss 0.50497797 - samples/sec: 150.75
2020-04-02 01:58:14,899 epoch 99 - iter 344/439 - loss 0.50561480 - samples/sec: 155.98
2020-04-02 01:58:29,745 epoch 99 - iter 387/439 - loss 0.50584622 - samples/sec: 150.59
2020-04-02 01:58:44,313 epoch 99 - iter 430/439 - loss 0.50376569 - samples/sec: 153.59
2020-04-02 01:58:52,867 ----------------------------------------------------------------------------------------------------
2020-04-02 01:58:52,868 EPOCH 99 done: loss 0.5054 - lr 0.0002
2020-04-02 01:58:57,256 DEV : loss 0.4888545870780945 - score 0.9443
2020-04-02 01:58:57,350 BAD EPOCHS (no improvement): 3
2020-04-02 01:58:57,397 ----------------------------------------------------------------------------------------------------
2020-04-02 01:59:05,430 epoch 100 - iter 43/439 - loss 0.49064431 - samples/sec: 171.37
2020-04-02 01:59:23,378 epoch 100 - iter 86/439 - loss 0.48919362 - samples/sec: 153.53
2020-04-02 01:59:38,098 epoch 100 - iter 129/439 - loss 0.49534131 - samples/sec: 152.68
2020-04-02 01:59:53,048 epoch 100 - iter 172/439 - loss 0.48449685 - samples/sec: 150.18
2020-04-02 02:00:06,821 epoch 100 - iter 215/439 - loss 0.49809421 - samples/sec: 164.29
2020-04-02 02:00:22,109 epoch 100 - iter 258/439 - loss 0.49864156 - samples/sec: 152.67
2020-04-02 02:00:41,243 epoch 13 - iter 344/439 - loss 1.27336844 - samples/sec: 183.94
2020-04-02 02:00:36,657 epoch 100 - iter 301/439 - loss 0.50236307 - samples/sec: 147.96
2020-04-02 02:00:52,027 epoch 100 - iter 344/439 - loss 0.51081445 - samples/sec: 151.19
2020-04-02 02:01:05,576 epoch 100 - iter 387/439 - loss 0.51743161 - samples/sec: 184.65
2020-04-02 02:01:20,518 epoch 100 - iter 430/439 - loss 0.50984496 - samples/sec: 152.31
2020-04-02 02:01:29,081 ----------------------------------------------------------------------------------------------------
2020-04-02 02:01:29,082 EPOCH 100 done: loss 0.5085 - lr 0.0002
2020-04-02 02:01:33,567 DEV : loss 0.48876479268074036 - score 0.9443
Epoch   100: reducing learning rate of group 0 to 7.8125e-05.
2020-04-02 02:01:33,666 BAD EPOCHS (no improvement): 4
2020-04-02 02:01:33,724 ----------------------------------------------------------------------------------------------------
2020-04-02 02:01:33,725 ----------------------------------------------------------------------------------------------------
2020-04-02 02:01:33,725 learning rate too small - quitting training!
2020-04-02 02:01:33,725 ----------------------------------------------------------------------------------------------------
2020-04-02 02:01:34,954 ----------------------------------------------------------------------------------------------------
2020-04-02 02:01:34,954 Testing using best model ...
2020-04-02 02:01:34,955 loading file log/elmo_s_20200401213219_128/best-model.pt
2020-04-02 02:01:51,414 0.9036	0.9109	0.9072
2020-04-02 02:01:51,414 
MICRO_AVG: acc 0.8302 - f1-score 0.9072
MACRO_AVG: acc 0.812 - f1-score 0.893625
LOC        tp: 1535 - fp: 125 - fn: 133 - tn: 1535 - precision: 0.9247 - recall: 0.9203 - accuracy: 0.8561 - f1-score: 0.9225
MISC       tp: 569 - fp: 134 - fn: 133 - tn: 569 - precision: 0.8094 - recall: 0.8105 - accuracy: 0.6806 - f1-score: 0.8099
ORG        tp: 1494 - fp: 222 - fn: 167 - tn: 1494 - precision: 0.8706 - recall: 0.8995 - accuracy: 0.7934 - f1-score: 0.8848
PER        tp: 1547 - fp: 68 - fn: 70 - tn: 1547 - precision: 0.9579 - recall: 0.9567 - accuracy: 0.9181 - f1-score: 0.9573
2020-04-02 02:01:51,414 ----------------------------------------------------------------------------------------------------
2020-04-02 02:02:25,007 epoch 13 - iter 387/439 - loss 1.27138627 - samples/sec: 196.17
2020-04-02 02:04:19,067 epoch 13 - iter 430/439 - loss 1.27651212 - samples/sec: 211.12
2020-04-02 02:05:12,274 epoch 6 - iter 129/439 - loss 0.95844668 - samples/sec: 85.15
2020-04-02 02:05:57,964 ----------------------------------------------------------------------------------------------------
2020-04-02 02:05:57,964 EPOCH 13 done: loss 1.2785 - lr 0.0100
2020-04-02 02:06:02,666 DEV : loss 0.8489771485328674 - score 0.9181
2020-04-02 02:06:02,760 BAD EPOCHS (no improvement): 0
2020-04-02 02:06:11,354 ----------------------------------------------------------------------------------------------------
2020-04-02 02:06:16,177 epoch 14 - iter 43/439 - loss 1.30109763 - samples/sec: 285.57
2020-04-02 02:06:15,366 epoch 9 - iter 88/220 - loss 1.08205019 - samples/sec: 125.35
2020-04-02 02:07:58,914 epoch 14 - iter 86/439 - loss 1.22788594 - samples/sec: 158.85
2020-04-02 02:09:44,434 epoch 9 - iter 110/220 - loss 1.07967140 - samples/sec: 121.02

2020-04-02 02:10:24,305 epoch 6 - iter 172/439 - loss 0.98299403 - samples/sec: 82.55
2020-04-02 02:11:30,263 epoch 14 - iter 172/439 - loss 1.22996537 - samples/sec: 191.75
2020-04-02 02:13:16,351 epoch 14 - iter 215/439 - loss 1.22822984 - samples/sec: 166.14
2020-04-02 02:15:02,720 epoch 14 - iter 258/439 - loss 1.21545060 - samples/sec: 164.04
2020-04-02 02:15:39,137 epoch 6 - iter 215/439 - loss 0.98520016 - samples/sec: 83.31
2020-04-02 02:16:51,691 epoch 14 - iter 301/439 - loss 1.22510023 - samples/sec: 162.93
2020-04-02 02:18:36,485 epoch 14 - iter 344/439 - loss 1.24296997 - samples/sec: 168.11
2020-04-02 02:20:26,369 epoch 9 - iter 176/220 - loss 1.08567982 - samples/sec: 121.87

2020-04-02 02:20:54,197 epoch 6 - iter 258/439 - loss 0.97223476 - samples/sec: 85.54
2020-04-02 02:22:13,001 epoch 14 - iter 430/439 - loss 1.22121620 - samples/sec: 159.10
2020-04-02 02:24:07,686 epoch 9 - iter 198/220 - loss 1.09882911 - samples/sec: 123.07
------------------------------------
2020-04-02 02:23:56,419 EPOCH 14 done: loss 1.2210 - lr 0.0100
2020-04-02 02:24:01,045 DEV : loss 0.8452187776565552 - score 0.9175
2020-04-02 02:24:01,143 BAD EPOCHS (no improvement): 1
2020-04-02 02:24:01,178 ----------------------------------------------------------------------------------------------------
2020-04-02 02:24:05,537 epoch 15 - iter 43/439 - loss 1.14042318 - samples/sec: 315.86
2020-04-02 02:25:56,886 epoch 15 - iter 86/439 - loss 1.15685804 - samples/sec: 162.85
2020-04-02 02:26:22,782 epoch 6 - iter 301/439 - loss 0.97475925 - samples/sec: 86.88
2020-04-02 02:27:48,210 epoch 9 - iter 220/220 - loss 1.08709938 - samples/sec: 125.71

2020-04-02 02:29:35,240 epoch 15 - iter 172/439 - loss 1.19925406 - samples/sec: 164.00
2020-04-02 02:31:23,645 epoch 15 - iter 215/439 - loss 1.21305785 - samples/sec: 179.83
-----------------------------------
2020-04-02 02:31:17,556 EPOCH 9 done: loss 1.0871 - lr 0.0100
2020-04-02 02:31:32,785 DEV : loss 0.8457300066947937 - score 0.9123
2020-04-02 02:31:33,192 BAD EPOCHS (no improvement): 0
2020-04-02 02:31:46,307 epoch 6 - iter 344/439 - loss 0.96070135 - samples/sec: 90.40
2020-04-02 02:32:11,181 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 02:32:22,523 epoch 10 - iter 22/220 - loss 1.03576817 - samples/sec: 124.26
2020-04-02 02:33:14,421 epoch 15 - iter 258/439 - loss 1.21350559 - samples/sec: 175.66
2020-04-02 02:35:05,590 epoch 15 - iter 301/439 - loss 1.22760429 - samples/sec: 164.34
2020-04-02 02:36:09,986 epoch 10 - iter 44/220 - loss 1.03580599 - samples/sec: 125.49
2020-04-02 02:37:00,035 epoch 15 - iter 344/439 - loss 1.21483431 - samples/sec: 174.27
2020-04-02 02:37:38,866 epoch 6 - iter 387/439 - loss 0.95828078 - samples/sec: 79.65
2020-04-02 02:38:47,336 epoch 15 - iter 387/439 - loss 1.20332017 - samples/sec: 175.91
2020-04-02 02:40:06,666 epoch 10 - iter 66/220 - loss 1.03290218 - samples/sec: 119.97
2020-04-02 02:41:03,519 epoch 15 - iter 430/439 - loss 1.20108433 - samples/sec: 192.79
2020-04-02 02:42:45,938 ----------------------------------------------------------------------------------------------------
2020-04-02 02:42:45,938 EPOCH 15 done: loss 1.2004 - lr 0.0100
2020-04-02 02:42:50,559 DEV : loss 0.8224450349807739 - score 0.9192
2020-04-02 02:42:50,654 BAD EPOCHS (no improvement): 0
2020-04-02 02:42:59,379 ----------------------------------------------------------------------------------------------------
2020-04-02 02:43:07,445 epoch 16 - iter 43/439 - loss 1.18161714 - samples/sec: 170.73
2020-04-02 02:43:38,888 epoch 6 - iter 430/439 - loss 0.95711032 - samples/sec: 94.27
2020-04-02 02:44:18,937 epoch 10 - iter 88/220 - loss 1.03672896 - samples/sec: 121.06
2020-04-02 02:44:56,750 epoch 16 - iter 86/439 - loss 1.14487420 - samples/sec: 164.30
2020-04-02 02:46:51,319 epoch 16 - iter 129/439 - loss 1.14522770 - samples/sec: 168.06
2020-04-02 02:48:39,313 epoch 16 - iter 172/439 - loss 1.15661853 - samples/sec: 154.69
2020-04-02 02:48:53,571 ----------------------------------------------------------------------------------------------------
2020-04-02 02:48:53,572 EPOCH 6 done: loss 0.9589 - lr 0.0100
2020-04-02 02:49:15,748 DEV : loss 0.6903554201126099 - score 0.9373
2020-04-02 02:49:16,187 BAD EPOCHS (no improvement): 0
2020-04-02 02:50:01,488 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 02:50:19,200 epoch 7 - iter 43/439 - loss 0.91377940 - samples/sec: 77.73
2020-04-02 02:50:53,944 epoch 16 - iter 215/439 - loss 1.13669309 - samples/sec: 179.41
2020-04-02 02:52:43,437 epoch 16 - iter 258/439 - loss 1.13487746 - samples/sec: 167.98
2020-04-02 02:54:33,233 epoch 16 - iter 301/439 - loss 1.14829993 - samples/sec: 163.12
2020-04-02 02:55:48,455 epoch 10 - iter 154/220 - loss 1.03148145 - samples/sec: 121.36
2020-04-02 02:56:17,340 epoch 16 - iter 344/439 - loss 1.14266036 - samples/sec: 179.71
2020-04-02 02:58:04,957 epoch 16 - iter 387/439 - loss 1.13936816 - samples/sec: 172.23
2020-04-02 02:59:54,103 epoch 16 - iter 430/439 - loss 1.14618812 - samples/sec: 165.98
2020-04-02 03:00:59,695 epoch 7 - iter 129/439 - loss 0.90284043 - samples/sec: 81.13
2020-04-02 03:01:36,164 ----------------------------------------------------------------------------------------------------
2020-04-02 03:01:36,164 EPOCH 16 done: loss 1.1451 - lr 0.0100
2020-04-02 03:01:40,920 DEV : loss 0.8057830333709717 - score 0.9211
2020-04-02 03:01:41,018 BAD EPOCHS (no improvement): 0
2020-04-02 03:01:49,529 ----------------------------------------------------------------------------------------------------
2020-04-02 03:01:57,496 epoch 17 - iter 43/439 - loss 1.16614387 - samples/sec: 172.84
2020-04-02 03:03:07,572 epoch 10 - iter 198/220 - loss 1.03809053 - samples/sec: 120.65
2020-04-02 03:03:44,167 epoch 17 - iter 86/439 - loss 1.13425235 - samples/sec: 171.50
2020-04-02 03:05:30,969 epoch 17 - iter 129/439 - loss 1.12586741 - samples/sec: 173.38
2020-04-02 03:06:20,509 epoch 7 - iter 172/439 - loss 0.89552529 - samples/sec: 88.05
2020-04-02 03:06:46,233 epoch 10 - iter 220/220 - loss 1.03824771 - samples/sec: 110.86
2020-04-02 03:07:19,409 epoch 17 - iter 172/439 - loss 1.07939021 - samples/sec: 160.54
2020-04-02 03:09:03,981 epoch 17 - iter 215/439 - loss 1.09280445 - samples/sec: 271.52
2020-04-02 03:10:12,344 ----------------------------------------------------------------------------------------------------
2020-04-02 03:10:12,345 EPOCH 10 done: loss 1.0382 - lr 0.0100
2020-04-02 03:10:26,812 DEV : loss 0.8087517023086548 - score 0.917
2020-04-02 03:10:27,221 BAD EPOCHS (no improvement): 0
2020-04-02 03:10:39,932 epoch 17 - iter 258/439 - loss 1.10201917 - samples/sec: 292.80
2020-04-02 03:11:01,994 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 03:11:13,674 epoch 11 - iter 22/220 - loss 0.92293568 - samples/sec: 120.64
2020-04-02 03:11:41,813 epoch 7 - iter 215/439 - loss 0.87417732 - samples/sec: 88.28
2020-04-02 03:12:41,787 epoch 17 - iter 301/439 - loss 1.10054545 - samples/sec: 175.19
2020-04-02 03:14:36,165 epoch 11 - iter 44/220 - loss 0.92091282 - samples/sec: 125.65

2020-04-02 03:16:10,706 epoch 17 - iter 387/439 - loss 1.13623388 - samples/sec: 167.03
2020-04-02 03:16:49,254 epoch 7 - iter 258/439 - loss 0.87811867 - samples/sec: 78.43
2020-04-02 03:17:55,675 epoch 17 - iter 430/439 - loss 1.12621061 - samples/sec: 173.07
2020-04-02 03:18:09,780 epoch 11 - iter 66/220 - loss 0.95342857 - samples/sec: 126.11
2020-04-02 03:19:52,725 ----------------------------------------------------------------------------------------------------
2020-04-02 03:19:52,725 EPOCH 17 done: loss 1.1270 - lr 0.0100
2020-04-02 03:19:57,491 DEV : loss 0.7954118251800537 - score 0.9237
2020-04-02 03:19:57,589 BAD EPOCHS (no improvement): 0
2020-04-02 03:20:06,264 ----------------------------------------------------------------------------------------------------
2020-04-02 03:20:14,363 epoch 18 - iter 43/439 - loss 1.04779191 - samples/sec: 170.04
2020-04-02 03:22:16,288 epoch 7 - iter 301/439 - loss 0.87994039 - samples/sec: 87.41

2020-04-02 03:23:32,590 epoch 18 - iter 129/439 - loss 1.06448375 - samples/sec: 297.37
2020-04-02 03:25:16,862 epoch 18 - iter 172/439 - loss 1.09822888 - samples/sec: 158.97
2020-04-02 03:25:41,484 epoch 11 - iter 110/220 - loss 0.93561211 - samples/sec: 121.75
2020-04-02 03:27:21,271 epoch 18 - iter 215/439 - loss 1.08527438 - samples/sec: 168.10
2020-04-02 03:27:47,471 epoch 7 - iter 344/439 - loss 0.87156791 - samples/sec: 79.25
2020-04-02 03:29:37,790 epoch 11 - iter 132/220 - loss 0.94207552 - samples/sec: 125.89
2020-04-02 03:30:53,169 epoch 18 - iter 301/439 - loss 1.08808984 - samples/sec: 182.12
2020-04-02 03:32:35,715 epoch 18 - iter 344/439 - loss 1.08648873 - samples/sec: 172.77
2020-04-02 03:32:58,988 epoch 7 - iter 387/439 - loss 0.87544852 - samples/sec: 80.48
2020-04-02 03:33:07,990 epoch 11 - iter 154/220 - loss 0.95326662 - samples/sec: 108.74
2020-04-02 03:34:19,183 epoch 18 - iter 387/439 - loss 1.08691871 - samples/sec: 155.87
2020-04-02 03:36:01,354 epoch 18 - iter 430/439 - loss 1.09548533 - samples/sec: 167.02
2020-04-02 03:36:35,275 epoch 11 - iter 176/220 - loss 0.95331562 - samples/sec: 121.71
2020-04-02 03:37:43,039 ----------------------------------------------------------------------------------------------------
2020-04-02 03:37:43,039 EPOCH 18 done: loss 1.0926 - lr 0.0100
2020-04-02 03:37:47,811 DEV : loss 0.7802757620811462 - score 0.9229
2020-04-02 03:37:47,907 BAD EPOCHS (no improvement): 1
2020-04-02 03:37:47,957 ----------------------------------------------------------------------------------------------------
2020-04-02 03:37:56,546 epoch 19 - iter 43/439 - loss 1.04732505 - samples/sec: 160.31
2020-04-02 03:38:08,440 epoch 7 - iter 430/439 - loss 0.87596547 - samples/sec: 84.12
2020-04-02 03:39:46,523 epoch 19 - iter 86/439 - loss 1.01889313 - samples/sec: 169.49
2020-04-02 03:40:15,028 epoch 11 - iter 198/220 - loss 0.96203852 - samples/sec: 123.20
2020-04-02 03:41:33,728 epoch 19 - iter 129/439 - loss 1.02861162 - samples/sec: 152.82
2020-04-02 03:43:19,520 epoch 19 - iter 172/439 - loss 1.03202701 - samples/sec: 168.68
-----------------------------------
2020-04-02 03:43:16,837 EPOCH 7 done: loss 0.8778 - lr 0.0100
2020-04-02 03:43:39,527 DEV : loss 0.6389328837394714 - score 0.9388
2020-04-02 03:43:39,965 BAD EPOCHS (no improvement): 0
2020-04-02 03:43:50,333 epoch 11 - iter 220/220 - loss 0.96183049 - samples/sec: 121.12
2020-04-02 03:44:21,055 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 03:44:37,429 epoch 8 - iter 43/439 - loss 0.81780104 - samples/sec: 84.09
2020-04-02 03:45:26,360 epoch 19 - iter 215/439 - loss 1.04295477 - samples/sec: 165.02
2020-04-02 03:47:45,721 ----------------------------------------------------------------------------------------------------
2020-04-02 03:47:45,722 EPOCH 11 done: loss 0.9618 - lr 0.0100
2020-04-02 03:48:00,178 DEV : loss 0.7903637290000916 - score 0.9199
2020-04-02 03:48:00,583 BAD EPOCHS (no improvement): 0
2020-04-02 03:48:43,490 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 03:48:55,429 epoch 12 - iter 22/220 - loss 0.90562836 - samples/sec: 118.03
2020-04-02 03:49:16,276 epoch 19 - iter 301/439 - loss 1.05728221 - samples/sec: 159.30
2020-04-02 03:50:09,105 epoch 8 - iter 86/439 - loss 0.83121804 - samples/sec: 77.12
2020-04-02 03:51:00,105 epoch 19 - iter 344/439 - loss 1.05732969 - samples/sec: 182.75
2020-04-02 03:52:48,721 epoch 19 - iter 387/439 - loss 1.04245820 - samples/sec: 200.76
2020-04-02 03:54:33,035 epoch 19 - iter 430/439 - loss 1.05696174 - samples/sec: 190.19
2020-04-02 03:55:25,913 epoch 8 - iter 129/439 - loss 0.82951151 - samples/sec: 82.34
2020-04-02 03:56:35,917 epoch 12 - iter 66/220 - loss 0.88848664 - samples/sec: 125.43
------------------------------------
2020-04-02 03:56:29,494 EPOCH 19 done: loss 1.0597 - lr 0.0100
2020-04-02 03:56:34,228 DEV : loss 0.7829985022544861 - score 0.9234
2020-04-02 03:56:34,323 BAD EPOCHS (no improvement): 2
2020-04-02 03:56:34,353 ----------------------------------------------------------------------------------------------------
2020-04-02 03:56:42,563 epoch 20 - iter 43/439 - loss 1.06749700 - samples/sec: 167.71
2020-04-02 03:58:26,003 epoch 20 - iter 86/439 - loss 1.07271771 - samples/sec: 189.53
2020-04-02 04:00:37,238 epoch 8 - iter 172/439 - loss 0.80849307 - samples/sec: 82.96


2020-04-02 04:01:46,983 epoch 20 - iter 172/439 - loss 1.03828366 - samples/sec: 201.42
2020-04-02 04:03:39,621 epoch 12 - iter 110/220 - loss 0.90411854 - samples/sec: 120.58
2020-04-02 04:05:18,100 epoch 20 - iter 258/439 - loss 1.03009528 - samples/sec: 200.99
2020-04-02 04:05:51,118 epoch 8 - iter 215/439 - loss 0.80758937 - samples/sec: 86.12
2020-04-02 04:07:03,755 epoch 20 - iter 301/439 - loss 1.03949328 - samples/sec: 238.82
2020-04-02 04:07:13,995 epoch 12 - iter 132/220 - loss 0.91346595 - samples/sec: 117.31
2020-04-02 04:08:52,401 epoch 20 - iter 344/439 - loss 1.02320834 - samples/sec: 194.43
2020-04-02 04:10:47,347 epoch 12 - iter 154/220 - loss 0.92171098 - samples/sec: 120.77
2020-04-02 04:11:06,828 epoch 8 - iter 258/439 - loss 0.81525703 - samples/sec: 90.13
2020-04-02 04:12:20,829 epoch 20 - iter 430/439 - loss 1.03177000 - samples/sec: 169.24
2020-04-02 04:14:15,713 ----------------------------------------------------------------------------------------------------
2020-04-02 04:14:15,713 EPOCH 20 done: loss 1.0290 - lr 0.0100
2020-04-02 04:14:20,395 DEV : loss 0.7596288323402405 - score 0.924
2020-04-02 04:14:20,494 BAD EPOCHS (no improvement): 0
2020-04-02 04:14:34,817 epoch 12 - iter 176/220 - loss 0.92174579 - samples/sec: 123.90
2020-04-02 04:14:29,411 ----------------------------------------------------------------------------------------------------
2020-04-02 04:14:37,862 epoch 21 - iter 43/439 - loss 1.07522585 - samples/sec: 162.95
2020-04-02 04:16:32,008 epoch 8 - iter 301/439 - loss 0.80789277 - samples/sec: 83.58

2020-04-02 04:18:05,565 epoch 21 - iter 129/439 - loss 1.00091632 - samples/sec: 181.14
2020-04-02 04:19:50,229 epoch 21 - iter 172/439 - loss 1.01537312 - samples/sec: 172.61
2020-04-02 04:21:32,628 epoch 21 - iter 215/439 - loss 1.00507345 - samples/sec: 167.55
2020-04-02 04:21:43,859 epoch 8 - iter 344/439 - loss 0.81086433 - samples/sec: 81.08
2020-04-02 04:23:10,022 epoch 21 - iter 258/439 - loss 1.02191836 - samples/sec: 234.77
2020-04-02 04:24:54,926 epoch 21 - iter 301/439 - loss 1.01138119 - samples/sec: 161.18
-----------------------------------
2020-04-02 04:24:47,292 EPOCH 12 done: loss 0.9180 - lr 0.0100
2020-04-02 04:25:01,718 DEV : loss 0.7817736268043518 - score 0.9171
2020-04-02 04:25:02,143 BAD EPOCHS (no improvement): 1
2020-04-02 04:25:02,179 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 04:25:13,291 epoch 13 - iter 22/220 - loss 0.96187664 - samples/sec: 126.79
2020-04-02 04:26:37,163 epoch 21 - iter 344/439 - loss 1.01024945 - samples/sec: 159.60
2020-04-02 04:26:48,060 epoch 8 - iter 387/439 - loss 0.80330719 - samples/sec: 80.03
2020-04-02 04:28:40,829 epoch 13 - iter 44/220 - loss 0.94402639 - samples/sec: 121.00

2020-04-02 04:30:07,415 epoch 21 - iter 430/439 - loss 1.01405289 - samples/sec: 172.71
2020-04-02 04:32:19,095 epoch 13 - iter 66/220 - loss 0.93389724 - samples/sec: 109.24
------------------------------------
2020-04-02 04:32:01,284 EPOCH 21 done: loss 1.0084 - lr 0.0100
2020-04-02 04:32:06,014 DEV : loss 0.776271402835846 - score 0.9237
2020-04-02 04:32:06,111 BAD EPOCHS (no improvement): 1
2020-04-02 04:32:06,147 ----------------------------------------------------------------------------------------------------
2020-04-02 04:32:14,263 epoch 22 - iter 43/439 - loss 1.00288687 - samples/sec: 169.63
2020-04-02 04:33:58,574 epoch 22 - iter 86/439 - loss 0.96021010 - samples/sec: 178.92
2020-04-02 04:35:52,400 epoch 13 - iter 88/220 - loss 0.92061310 - samples/sec: 121.52

2020-04-02 04:37:33,956 epoch 22 - iter 172/439 - loss 0.96849204 - samples/sec: 172.70
-----------------------------------
2020-04-02 04:37:18,872 EPOCH 8 done: loss 0.8034 - lr 0.0100
2020-04-02 04:37:41,099 DEV : loss 0.6153534650802612 - score 0.9408
2020-04-02 04:37:41,539 BAD EPOCHS (no improvement): 0
2020-04-02 04:38:38,449 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 04:38:54,918 epoch 9 - iter 43/439 - loss 0.75056460 - samples/sec: 83.59
2020-04-02 04:39:50,791 epoch 22 - iter 215/439 - loss 0.97752101 - samples/sec: 165.34
2020-04-02 04:40:00,332 epoch 13 - iter 110/220 - loss 0.91031654 - samples/sec: 124.10
2020-04-02 04:41:37,119 epoch 22 - iter 258/439 - loss 1.01184840 - samples/sec: 167.10
2020-04-02 04:43:35,854 epoch 13 - iter 132/220 - loss 0.89515366 - samples/sec: 120.25
2020-04-02 04:44:13,851 epoch 9 - iter 86/439 - loss 0.77303011 - samples/sec: 77.34
2020-04-02 04:45:14,138 epoch 22 - iter 344/439 - loss 1.01596681 - samples/sec: 154.18
2020-04-02 04:47:09,304 epoch 13 - iter 154/220 - loss 0.88592766 - samples/sec: 116.37
2020-04-02 04:48:47,687 epoch 22 - iter 430/439 - loss 1.00706436 - samples/sec: 166.66
2020-04-02 04:49:32,226 epoch 9 - iter 129/439 - loss 0.75717952 - samples/sec: 86.57
2020-04-02 04:50:31,978 ----------------------------------------------------------------------------------------------------
2020-04-02 04:50:31,978 EPOCH 22 done: loss 1.0036 - lr 0.0100
2020-04-02 04:50:37,329 DEV : loss 0.7616667151451111 - score 0.9265
2020-04-02 04:50:37,424 BAD EPOCHS (no improvement): 0
2020-04-02 04:50:52,296 epoch 13 - iter 176/220 - loss 0.88538315 - samples/sec: 122.77
2020-04-02 04:50:46,219 ----------------------------------------------------------------------------------------------------
2020-04-02 04:50:54,523 epoch 23 - iter 43/439 - loss 1.00835358 - samples/sec: 165.82
2020-04-02 04:52:46,616 epoch 23 - iter 86/439 - loss 1.02727778 - samples/sec: 169.52
2020-04-02 04:54:38,385 epoch 23 - iter 129/439 - loss 0.97026764 - samples/sec: 167.77
2020-04-02 04:55:02,193 epoch 9 - iter 172/439 - loss 0.73634648 - samples/sec: 85.39
2020-04-02 04:56:28,980 epoch 23 - iter 172/439 - loss 0.96769740 - samples/sec: 163.00
2020-04-02 04:58:17,815 epoch 23 - iter 215/439 - loss 0.96630982 - samples/sec: 199.12
2020-04-02 05:00:47,021 epoch 9 - iter 215/439 - loss 0.73055467 - samples/sec: 83.35

2020-04-02 05:02:11,447 ----------------------------------------------------------------------------------------------------
2020-04-02 05:02:11,447 EPOCH 13 done: loss 0.8754 - lr 0.0100
2020-04-02 05:02:16,939 epoch 23 - iter 301/439 - loss 0.95408019 - samples/sec: 159.84
2020-04-02 05:02:25,577 DEV : loss 0.7472423911094666 - score 0.924
2020-04-02 05:02:25,968 BAD EPOCHS (no improvement): 0
2020-04-02 05:03:10,240 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 05:03:21,529 epoch 14 - iter 22/220 - loss 0.87876232 - samples/sec: 124.84
2020-04-02 05:04:26,709 epoch 23 - iter 344/439 - loss 0.95590403 - samples/sec: 186.13
2020-04-02 05:06:36,898 epoch 9 - iter 258/439 - loss 0.73690022 - samples/sec: 95.25

2020-04-02 05:07:06,537 epoch 14 - iter 44/220 - loss 0.80246491 - samples/sec: 123.98
2020-04-02 05:08:10,705 epoch 23 - iter 430/439 - loss 0.95270268 - samples/sec: 174.31
2020-04-02 05:09:53,405 ----------------------------------------------------------------------------------------------------
2020-04-02 05:09:53,405 EPOCH 23 done: loss 0.9518 - lr 0.0100
2020-04-02 05:09:58,154 DEV : loss 0.7387256622314453 - score 0.9269
2020-04-02 05:09:58,249 BAD EPOCHS (no improvement): 0
2020-04-02 05:10:25,546 ----------------------------------------------------------------------------------------------------
2020-04-02 05:10:34,149 epoch 24 - iter 43/439 - loss 0.88406528 - samples/sec: 160.07
2020-04-02 05:11:33,363 epoch 14 - iter 66/220 - loss 0.83117372 - samples/sec: 123.75
2020-04-02 05:12:11,209 epoch 9 - iter 301/439 - loss 0.73627684 - samples/sec: 80.89
2020-04-02 05:12:25,688 epoch 24 - iter 86/439 - loss 0.87691561 - samples/sec: 161.98
2020-04-02 05:14:22,319 epoch 24 - iter 129/439 - loss 0.87920847 - samples/sec: 186.43
2020-04-02 05:15:24,003 epoch 14 - iter 88/220 - loss 0.83615703 - samples/sec: 124.79
2020-04-02 05:16:15,232 epoch 24 - iter 172/439 - loss 0.91402890 - samples/sec: 168.83
2020-04-02 05:17:49,818 epoch 9 - iter 344/439 - loss 0.73596681 - samples/sec: 80.10
2020-04-02 05:18:07,728 epoch 24 - iter 215/439 - loss 0.92170716 - samples/sec: 163.12
2020-04-02 05:19:08,611 epoch 14 - iter 110/220 - loss 0.81648653 - samples/sec: 123.32
2020-04-02 05:20:01,001 epoch 24 - iter 258/439 - loss 0.92087590 - samples/sec: 164.79
2020-04-02 05:21:55,232 epoch 24 - iter 301/439 - loss 0.92624311 - samples/sec: 155.95
2020-04-02 05:22:52,478 epoch 14 - iter 132/220 - loss 0.82928373 - samples/sec: 125.65
2020-04-02 05:23:17,946 epoch 9 - iter 387/439 - loss 0.74430695 - samples/sec: 85.99
2020-04-02 05:23:40,794 epoch 24 - iter 344/439 - loss 0.93164701 - samples/sec: 159.84
2020-04-02 05:25:23,587 epoch 24 - iter 387/439 - loss 0.93252026 - samples/sec: 211.62
2020-04-02 05:26:20,757 epoch 14 - iter 154/220 - loss 0.82363936 - samples/sec: 122.22
2020-04-02 05:27:08,748 epoch 24 - iter 430/439 - loss 0.93776678 - samples/sec: 166.58
2020-04-02 05:28:48,048 ----------------------------------------------------------------------------------------------------
2020-04-02 05:28:48,048 EPOCH 24 done: loss 0.9338 - lr 0.0100
2020-04-02 05:28:52,822 DEV : loss 0.724621593952179 - score 0.9282
2020-04-02 05:28:52,919 BAD EPOCHS (no improvement): 0
2020-04-02 05:29:01,594 ----------------------------------------------------------------------------------------------------
2020-04-02 05:29:10,180 epoch 25 - iter 43/439 - loss 0.97521586 - samples/sec: 160.37
2020-04-02 05:29:56,077 epoch 14 - iter 176/220 - loss 0.82992745 - samples/sec: 117.15
2020-04-02 05:31:01,959 epoch 25 - iter 86/439 - loss 0.95044711 - samples/sec: 183.87
2020-04-02 05:32:43,135 epoch 25 - iter 129/439 - loss 0.93623204 - samples/sec: 166.50
2020-04-02 05:33:30,938 epoch 14 - iter 198/220 - loss 0.82887648 - samples/sec: 124.73
-----------------------------------
2020-04-02 05:33:28,355 EPOCH 9 done: loss 0.7431 - lr 0.0100
2020-04-02 05:33:50,498 DEV : loss 0.6077281832695007 - score 0.9414
2020-04-02 05:33:50,928 BAD EPOCHS (no improvement): 0
2020-04-02 05:34:42,533 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 05:34:59,834 epoch 10 - iter 43/439 - loss 0.63223297 - samples/sec: 79.57

2020-04-02 05:36:37,221 epoch 25 - iter 215/439 - loss 0.91589971 - samples/sec: 246.50
2020-04-02 05:37:30,435 epoch 14 - iter 220/220 - loss 0.82523288 - samples/sec: 121.11
2020-04-02 05:38:20,113 epoch 25 - iter 258/439 - loss 0.91231652 - samples/sec: 169.95
2020-04-02 05:40:29,602 ----------------------------------------------------------------------------------------------------
2020-04-02 05:40:29,603 EPOCH 14 done: loss 0.8252 - lr 0.0100
2020-04-02 05:40:44,889 DEV : loss 0.7417137622833252 - score 0.9237
2020-04-02 05:40:45,297 BAD EPOCHS (no improvement): 1
2020-04-02 05:40:45,340 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 05:40:56,870 epoch 15 - iter 22/220 - loss 0.82931948 - samples/sec: 122.19
2020-04-02 05:41:45,859 epoch 25 - iter 344/439 - loss 0.90737077 - samples/sec: 163.69
2020-04-02 05:43:28,881 epoch 25 - iter 387/439 - loss 0.90980783 - samples/sec: 307.09
2020-04-02 05:44:28,027 epoch 15 - iter 44/220 - loss 0.79173221 - samples/sec: 122.42
2020-04-02 05:45:12,400 epoch 25 - iter 430/439 - loss 0.91609947 - samples/sec: 171.57
2020-04-02 05:45:12,660 epoch 10 - iter 129/439 - loss 0.65330565 - samples/sec: 95.70
2020-04-02 05:46:46,437 ----------------------------------------------------------------------------------------------------
2020-04-02 05:46:46,437 EPOCH 25 done: loss 0.9132 - lr 0.0100
2020-04-02 05:46:51,107 DEV : loss 0.7295681834220886 - score 0.9291
2020-04-02 05:46:51,203 BAD EPOCHS (no improvement): 0
2020-04-02 05:47:11,637 ----------------------------------------------------------------------------------------------------
2020-04-02 05:47:20,403 epoch 26 - iter 43/439 - loss 0.91702275 - samples/sec: 157.08
2020-04-02 05:48:08,779 epoch 15 - iter 66/220 - loss 0.80220255 - samples/sec: 132.50
2020-04-02 05:49:04,492 epoch 26 - iter 86/439 - loss 0.85079331 - samples/sec: 158.97
2020-04-02 05:50:43,047 epoch 26 - iter 129/439 - loss 0.87826962 - samples/sec: 196.07
2020-04-02 05:51:31,738 epoch 15 - iter 88/220 - loss 0.82317108 - samples/sec: 118.56
2020-04-02 05:52:25,138 epoch 26 - iter 172/439 - loss 0.87869121 - samples/sec: 168.48
2020-04-02 05:54:07,482 epoch 26 - iter 215/439 - loss 0.86989641 - samples/sec: 178.92
2020-04-02 05:54:53,626 epoch 15 - iter 110/220 - loss 0.82457134 - samples/sec: 139.74
2020-04-02 05:55:27,666 epoch 10 - iter 215/439 - loss 0.69173869 - samples/sec: 89.49
2020-04-02 05:55:46,583 epoch 26 - iter 258/439 - loss 0.89054387 - samples/sec: 167.70
2020-04-02 05:57:34,640 epoch 26 - iter 301/439 - loss 0.88780788 - samples/sec: 175.41
2020-04-02 05:58:24,334 epoch 15 - iter 132/220 - loss 0.80509890 - samples/sec: 123.61
2020-04-02 05:59:16,306 epoch 26 - iter 344/439 - loss 0.89010201 - samples/sec: 162.45
2020-04-02 06:00:52,602 epoch 26 - iter 387/439 - loss 0.88168040 - samples/sec: 201.89
2020-04-02 06:01:43,053 epoch 15 - iter 154/220 - loss 0.79843261 - samples/sec: 118.29
2020-04-02 06:02:31,178 epoch 26 - iter 430/439 - loss 0.89178816 - samples/sec: 164.81
2020-04-02 06:04:05,569 ----------------------------------------------------------------------------------------------------
2020-04-02 06:04:05,569 EPOCH 26 done: loss 0.8951 - lr 0.0100
2020-04-02 06:04:10,346 DEV : loss 0.7190839052200317 - score 0.927
2020-04-02 06:04:10,444 BAD EPOCHS (no improvement): 1
2020-04-02 06:04:10,518 ----------------------------------------------------------------------------------------------------
2020-04-02 06:04:18,660 epoch 27 - iter 43/439 - loss 0.82346733 - samples/sec: 169.11
2020-04-02 06:05:03,094 epoch 15 - iter 176/220 - loss 0.78687888 - samples/sec: 121.53
2020-04-02 06:05:28,715 epoch 10 - iter 301/439 - loss 0.68324314 - samples/sec: 84.14
2020-04-02 06:05:59,247 epoch 27 - iter 86/439 - loss 0.86226766 - samples/sec: 170.51
2020-04-02 06:07:49,875 epoch 27 - iter 129/439 - loss 0.85036693 - samples/sec: 167.32
2020-04-02 06:08:36,648 epoch 15 - iter 198/220 - loss 0.78200778 - samples/sec: 116.69
2020-04-02 06:09:34,309 epoch 27 - iter 172/439 - loss 0.86753075 - samples/sec: 174.28
2020-04-02 06:11:23,858 epoch 27 - iter 215/439 - loss 0.85038620 - samples/sec: 287.68
2020-04-02 06:12:16,259 epoch 15 - iter 220/220 - loss 0.78211858 - samples/sec: 123.28
2020-04-02 06:13:11,150 epoch 27 - iter 258/439 - loss 0.83794876 - samples/sec: 197.67
2020-04-02 06:15:00,386 epoch 27 - iter 301/439 - loss 0.83851322 - samples/sec: 172.13
2020-04-02 06:15:44,261 ----------------------------------------------------------------------------------------------------
2020-04-02 06:15:44,261 EPOCH 15 done: loss 0.7821 - lr 0.0100
2020-04-02 06:16:12,848 epoch 10 - iter 387/439 - loss 0.68648359 - samples/sec: 81.60
9,869 BAD EPOCHS (no improvement): 0
2020-04-02 06:16:43,159 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 06:16:54,755 epoch 16 - iter 22/220 - loss 0.72643433 - samples/sec: 121.50
2020-04-02 06:16:54,346 epoch 27 - iter 344/439 - loss 0.85037880 - samples/sec: 163.05
2020-04-02 06:18:41,645 epoch 27 - iter 387/439 - loss 0.86373066 - samples/sec: 245.15
2020-04-02 06:20:36,974 epoch 16 - iter 44/220 - loss 0.72961680 - samples/sec: 123.54

2020-04-02 06:21:46,282 epoch 10 - iter 430/439 - loss 0.68247273 - samples/sec: 82.06
2020-04-02 06:22:10,222 ----------------------------------------------------------------------------------------------------
2020-04-02 06:22:10,222 EPOCH 27 done: loss 0.8600 - lr 0.0100
2020-04-02 06:22:14,924 DEV : loss 0.7208787202835083 - score 0.928
2020-04-02 06:22:15,020 BAD EPOCHS (no improvement): 2
2020-04-02 06:22:15,055 ----------------------------------------------------------------------------------------------------
2020-04-02 06:22:23,035 epoch 28 - iter 43/439 - loss 0.87647386 - samples/sec: 172.54
2020-04-02 06:24:28,337 epoch 28 - iter 86/439 - loss 0.85231100 - samples/sec: 168.69
2020-04-02 06:24:46,093 epoch 16 - iter 66/220 - loss 0.73104044 - samples/sec: 123.48
2020-04-02 06:26:14,273 epoch 28 - iter 129/439 - loss 0.87197080 - samples/sec: 164.11
2020-04-02 06:27:05,973 ----------------------------------------------------------------------------------------------------
2020-04-02 06:27:05,974 EPOCH 10 done: loss 0.6820 - lr 0.0100
2020-04-02 06:27:28,335 DEV : loss 0.598747193813324 - score 0.9463
2020-04-02 06:27:28,775 BAD EPOCHS (no improvement): 0
2020-04-02 06:28:08,410 epoch 28 - iter 172/439 - loss 0.86913457 - samples/sec: 172.07
2020-04-02 06:28:26,254 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 06:28:44,424 epoch 16 - iter 88/220 - loss 0.75645484 - samples/sec: 119.89
2020-04-02 06:28:42,534 epoch 11 - iter 43/439 - loss 0.66503210 - samples/sec: 84.57
2020-04-02 06:30:02,416 epoch 28 - iter 215/439 - loss 0.87093191 - samples/sec: 183.75
2020-04-02 06:31:42,779 epoch 28 - iter 258/439 - loss 0.87245943 - samples/sec: 169.35
2020-04-02 06:32:03,279 epoch 16 - iter 110/220 - loss 0.74610267 - samples/sec: 151.15
2020-04-02 06:33:43,293 epoch 11 - iter 86/439 - loss 0.67533912 - samples/sec: 78.34

2020-04-02 06:35:15,308 epoch 28 - iter 344/439 - loss 0.86178147 - samples/sec: 193.15
2020-04-02 06:35:39,390 epoch 16 - iter 132/220 - loss 0.75310523 - samples/sec: 121.02
2020-04-02 06:36:57,415 epoch 28 - iter 387/439 - loss 0.87512945 - samples/sec: 169.07
2020-04-02 06:38:40,723 epoch 28 - iter 430/439 - loss 0.86504593 - samples/sec: 168.76
2020-04-02 06:38:57,509 epoch 11 - iter 129/439 - loss 0.69494457 - samples/sec: 87.08
2020-04-02 06:39:05,179 epoch 16 - iter 154/220 - loss 0.74264536 - samples/sec: 130.97
2020-04-02 06:40:19,778 ----------------------------------------------------------------------------------------------------
2020-04-02 06:40:19,778 EPOCH 28 done: loss 0.8630 - lr 0.0100
2020-04-02 06:40:24,520 DEV : loss 0.7139449119567871 - score 0.9303
2020-04-02 06:40:24,617 BAD EPOCHS (no improvement): 0
2020-04-02 06:40:33,209 ----------------------------------------------------------------------------------------------------
2020-04-02 06:40:41,606 epoch 29 - iter 43/439 - loss 0.87355968 - samples/sec: 164.00
2020-04-02 06:43:07,317 epoch 29 - iter 86/439 - loss 0.83572037 - samples/sec: 185.94
2020-04-02 06:43:54,099 epoch 16 - iter 176/220 - loss 0.74723454 - samples/sec: 122.31
2020-04-02 06:46:37,247 epoch 11 - iter 172/439 - loss 0.68393941 - samples/sec: 83.41

2020-04-02 06:49:37,792 epoch 16 - iter 198/220 - loss 0.75244701 - samples/sec: 110.03
2020-04-02 06:51:54,450 epoch 29 - iter 215/439 - loss 0.82797341 - samples/sec: 150.56
2020-04-02 06:54:35,734 epoch 29 - iter 258/439 - loss 0.82834388 - samples/sec: 175.78
2020-04-02 06:55:14,997 epoch 16 - iter 220/220 - loss 0.75546939 - samples/sec: 122.60
2020-04-02 06:57:08,744 epoch 29 - iter 301/439 - loss 0.83282086 - samples/sec: 170.94
2020-04-02 06:59:49,609 ----------------------------------------------------------------------------------------------------
2020-04-02 06:59:49,609 EPOCH 16 done: loss 0.7555 - lr 0.0100
2020-04-02 07:00:04,006 DEV : loss 0.7215655446052551 - score 0.9296
2020-04-02 07:00:04,415 BAD EPOCHS (no improvement): 0
2020-04-02 07:00:40,721 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 07:00:52,049 epoch 17 - iter 22/220 - loss 0.68252954 - samples/sec: 124.41
2020-04-02 07:01:33,101 epoch 29 - iter 387/439 - loss 0.83618899 - samples/sec: 178.01
2020-04-02 07:01:34,687 epoch 11 - iter 258/439 - loss 0.67155161 - samples/sec: 83.41
2020-04-02 07:03:23,106 epoch 29 - iter 430/439 - loss 0.83756923 - samples/sec: 160.65
2020-04-02 07:05:04,524 ----------------------------------------------------------------------------------------------------
2020-04-02 07:05:04,524 EPOCH 29 done: loss 0.8359 - lr 0.0100
2020-04-02 07:05:09,159 DEV : loss 0.7118620276451111 - score 0.9287
2020-04-02 07:05:09,254 BAD EPOCHS (no improvement): 1
2020-04-02 07:05:09,323 ----------------------------------------------------------------------------------------------------
2020-04-02 07:05:17,054 epoch 30 - iter 43/439 - loss 0.78715522 - samples/sec: 178.09
2020-04-02 07:07:01,852 epoch 30 - iter 86/439 - loss 0.85595806 - samples/sec: 183.73
2020-04-02 07:08:44,201 epoch 17 - iter 66/220 - loss 0.72824700 - samples/sec: 134.56
2020-04-02 07:09:11,913 epoch 30 - iter 129/439 - loss 0.86368461 - samples/sec: 186.57
2020-04-02 07:11:05,078 epoch 30 - iter 172/439 - loss 0.83853205 - samples/sec: 167.44
2020-04-02 07:12:51,798 epoch 30 - iter 215/439 - loss 0.82921602 - samples/sec: 168.70
2020-04-02 07:14:43,706 epoch 30 - iter 258/439 - loss 0.82997447 - samples/sec: 176.95
2020-04-02 07:16:35,368 epoch 30 - iter 301/439 - loss 0.82507915 - samples/sec: 170.20
2020-04-02 07:18:23,420 epoch 30 - iter 344/439 - loss 0.82200365 - samples/sec: 164.04
2020-04-02 07:19:56,978 epoch 17 - iter 132/220 - loss 0.72618207 - samples/sec: 115.36
2020-04-02 07:20:14,255 epoch 30 - iter 387/439 - loss 0.81965431 - samples/sec: 171.37
2020-04-02 07:22:18,182 epoch 30 - iter 430/439 - loss 0.82095200 - samples/sec: 167.73
2020-04-02 07:23:58,194 ----------------------------------------------------------------------------------------------------
2020-04-02 07:23:58,194 EPOCH 30 done: loss 0.8192 - lr 0.0100
2020-04-02 07:24:02,922 DEV : loss 0.6994922161102295 - score 0.9299
2020-04-02 07:24:03,018 BAD EPOCHS (no improvement): 2
2020-04-02 07:24:03,090 ----------------------------------------------------------------------------------------------------
2020-04-02 07:24:11,048 epoch 31 - iter 43/439 - loss 0.83754544 - samples/sec: 173.01
2020-04-02 07:25:58,443 epoch 31 - iter 86/439 - loss 0.85976236 - samples/sec: 218.61
2020-04-02 07:27:48,121 epoch 31 - iter 129/439 - loss 0.83311883 - samples/sec: 171.12
2020-04-02 07:28:52,952 ----------------------------------------------------------------------------------------------------
2020-04-02 07:28:52,952 EPOCH 11 done: loss 0.6455 - lr 0.0100
2020-04-02 07:29:15,205 DEV : loss 0.5947575569152832 - score 0.9442
2020-04-02 07:29:15,644 BAD EPOCHS (no improvement): 1
2020-04-02 07:29:15,693 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 07:29:33,303 epoch 31 - iter 172/439 - loss 0.82998142 - samples/sec: 174.90
2020-04-02 07:31:21,167 epoch 31 - iter 215/439 - loss 0.83555016 - samples/sec: 166.62
2020-04-02 07:33:06,364 epoch 31 - iter 258/439 - loss 0.81231317 - samples/sec: 164.97
2020-04-02 07:34:53,622 epoch 31 - iter 301/439 - loss 0.80487234 - samples/sec: 158.92
2020-04-02 07:34:48,775 epoch 12 - iter 86/439 - loss 0.56908930 - samples/sec: 85.72
2020-04-02 07:36:39,583 epoch 31 - iter 344/439 - loss 0.80532483 - samples/sec: 230.65
2020-04-02 07:38:22,993 epoch 31 - iter 387/439 - loss 0.81349358 - samples/sec: 283.96
-----------------------------------
2020-04-02 07:38:04,670 EPOCH 17 done: loss 0.7424 - lr 0.0100
2020-04-02 07:38:18,854 DEV : loss 0.7113832235336304 - score 0.9302
2020-04-02 07:38:19,253 BAD EPOCHS (no improvement): 0
2020-04-02 07:38:58,675 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 07:39:10,171 epoch 18 - iter 22/220 - loss 0.75036057 - samples/sec: 122.58
2020-04-02 07:40:22,399 epoch 31 - iter 430/439 - loss 0.81264214 - samples/sec: 182.32
2020-04-02 07:40:20,624 epoch 12 - iter 129/439 - loss 0.58408278 - samples/sec: 82.65
2020-04-02 07:42:00,611 ----------------------------------------------------------------------------------------------------
2020-04-02 07:42:00,611 EPOCH 31 done: loss 0.8156 - lr 0.0100
2020-04-02 07:42:05,390 DEV : loss 0.6972277760505676 - score 0.9294
2020-04-02 07:42:05,486 BAD EPOCHS (no improvement): 3
2020-04-02 07:42:05,545 ----------------------------------------------------------------------------------------------------
2020-04-02 07:42:14,246 epoch 32 - iter 43/439 - loss 0.84299557 - samples/sec: 158.25
2020-04-02 07:42:43,681 epoch 18 - iter 44/220 - loss 0.69163156 - samples/sec: 115.90
2020-04-02 07:43:59,202 epoch 32 - iter 86/439 - loss 0.77067528 - samples/sec: 176.25
2020-04-02 07:45:55,702 epoch 32 - iter 129/439 - loss 0.77585488 - samples/sec: 214.89
2020-04-02 07:45:49,924 epoch 12 - iter 172/439 - loss 0.58304167 - samples/sec: 86.32
2020-04-02 07:46:40,412 epoch 18 - iter 66/220 - loss 0.69402431 - samples/sec: 119.39
2020-04-02 07:47:38,740 epoch 32 - iter 172/439 - loss 0.78616410 - samples/sec: 241.99
2020-04-02 07:49:22,573 epoch 32 - iter 215/439 - loss 0.79529696 - samples/sec: 178.62
2020-04-02 07:50:08,952 epoch 18 - iter 88/220 - loss 0.67226190 - samples/sec: 124.49
2020-04-02 07:51:06,435 epoch 32 - iter 258/439 - loss 0.81267146 - samples/sec: 185.83
2020-04-02 07:52:50,158 epoch 32 - iter 301/439 - loss 0.80741083 - samples/sec: 195.32
2020-04-02 07:53:37,990 epoch 18 - iter 110/220 - loss 0.68291365 - samples/sec: 121.52
2020-04-02 07:54:32,747 epoch 32 - iter 344/439 - loss 0.80274451 - samples/sec: 178.58
2020-04-02 07:56:15,427 epoch 32 - iter 387/439 - loss 0.79607900 - samples/sec: 165.88
2020-04-02 07:57:05,899 epoch 18 - iter 132/220 - loss 0.69363053 - samples/sec: 124.86
2020-04-02 07:58:00,988 epoch 32 - iter 430/439 - loss 0.79535250 - samples/sec: 163.89
2020-04-02 07:59:36,171 ----------------------------------------------------------------------------------------------------
2020-04-02 07:59:36,171 EPOCH 32 done: loss 0.7975 - lr 0.0100
2020-04-02 07:59:40,752 DEV : loss 0.6928383708000183 - score 0.931
2020-04-02 07:59:40,848 BAD EPOCHS (no improvement): 0
2020-04-02 07:59:49,507 ----------------------------------------------------------------------------------------------------
2020-04-02 07:59:57,546 epoch 33 - iter 43/439 - loss 0.78078272 - samples/sec: 171.30
2020-04-02 08:00:35,715 epoch 18 - iter 154/220 - loss 0.69405072 - samples/sec: 119.13
2020-04-02 08:01:09,253 epoch 12 - iter 301/439 - loss 0.58545086 - samples/sec: 80.98
2020-04-02 08:01:41,509 epoch 33 - iter 86/439 - loss 0.74014840 - samples/sec: 162.00
2020-04-02 08:03:28,248 epoch 33 - iter 129/439 - loss 0.72491345 - samples/sec: 166.68
2020-04-02 08:04:07,193 epoch 18 - iter 176/220 - loss 0.69084467 - samples/sec: 122.47
2020-04-02 08:05:13,665 epoch 33 - iter 172/439 - loss 0.75369269 - samples/sec: 166.55
2020-04-02 08:06:25,010 epoch 12 - iter 344/439 - loss 0.59070089 - samples/sec: 93.46
2020-04-02 08:07:21,046 epoch 33 - iter 215/439 - loss 0.77555259 - samples/sec: 163.87
2020-04-02 08:08:04,597 epoch 18 - iter 198/220 - loss 0.69771604 - samples/sec: 116.76
2020-04-02 08:09:13,597 epoch 33 - iter 258/439 - loss 0.77133470 - samples/sec: 165.99
2020-04-02 08:11:02,666 epoch 33 - iter 301/439 - loss 0.77197450 - samples/sec: 166.14
2020-04-02 08:11:44,189 epoch 18 - iter 220/220 - loss 0.70263443 - samples/sec: 155.59
2020-04-02 08:12:08,901 epoch 12 - iter 387/439 - loss 0.59363112 - samples/sec: 81.32
2020-04-02 08:12:50,596 epoch 33 - iter 344/439 - loss 0.77478026 - samples/sec: 179.18
2020-04-02 08:14:41,125 epoch 33 - iter 387/439 - loss 0.76939743 - samples/sec: 181.73
2020-04-02 08:15:15,024 ----------------------------------------------------------------------------------------------------
2020-04-02 08:15:15,024 EPOCH 18 done: loss 0.7026 - lr 0.0100
2020-04-02 08:15:29,234 DEV : loss 0.6860486268997192 - score 0.9327
2020-04-02 08:15:29,646 BAD EPOCHS (no improvement): 0
2020-04-02 08:16:09,781 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 08:16:21,132 epoch 19 - iter 22/220 - loss 0.67742758 - samples/sec: 124.15
2020-04-02 08:16:47,029 epoch 33 - iter 430/439 - loss 0.76765996 - samples/sec: 163.90
2020-04-02 08:17:49,463 epoch 12 - iter 430/439 - loss 0.59257545 - samples/sec: 97.08
2020-04-02 08:18:32,004 ----------------------------------------------------------------------------------------------------
2020-04-02 08:18:32,004 EPOCH 33 done: loss 0.7651 - lr 0.0100
2020-04-02 08:18:37,360 DEV : loss 0.6838279962539673 - score 0.9321
2020-04-02 08:18:37,453 BAD EPOCHS (no improvement): 0
2020-04-02 08:18:46,133 ----------------------------------------------------------------------------------------------------
2020-04-02 08:18:54,546 epoch 34 - iter 43/439 - loss 0.68756449 - samples/sec: 163.68
2020-04-02 08:20:43,949 epoch 34 - iter 86/439 - loss 0.76075576 - samples/sec: 195.82
2020-04-02 08:22:37,627 epoch 34 - iter 129/439 - loss 0.78462799 - samples/sec: 164.20
2020-04-02 08:23:09,876 ----------------------------------------------------------------------------------------------------
2020-04-02 08:23:09,876 EPOCH 12 done: loss 0.5913 - lr 0.0100
2020-04-02 08:23:32,011 DEV : loss 0.5611104369163513 - score 0.9461
2020-04-02 08:23:32,452 BAD EPOCHS (no improvement): 2
2020-04-02 08:23:32,487 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 08:23:46,246 epoch 13 - iter 43/439 - loss 0.59016861 - samples/sec: 100.05
2020-04-02 08:23:53,827 epoch 19 - iter 66/220 - loss 0.67069404 - samples/sec: 120.58
2020-04-02 08:24:27,278 epoch 34 - iter 172/439 - loss 0.75662546 - samples/sec: 163.64
2020-04-02 08:26:19,200 epoch 34 - iter 215/439 - loss 0.75220312 - samples/sec: 158.13
2020-04-02 08:27:38,445 epoch 19 - iter 88/220 - loss 0.66543382 - samples/sec: 115.54
2020-04-02 08:28:12,875 epoch 34 - iter 258/439 - loss 0.75305086 - samples/sec: 168.52
2020-04-02 08:29:22,680 epoch 13 - iter 86/439 - loss 0.55638203 - samples/sec: 84.38
2020-04-02 08:30:09,567 epoch 34 - iter 301/439 - loss 0.74949464 - samples/sec: 163.41
2020-04-02 08:32:00,752 epoch 34 - iter 344/439 - loss 0.75783108 - samples/sec: 163.23
2020-04-02 08:33:52,211 epoch 34 - iter 387/439 - loss 0.76509423 - samples/sec: 169.92
2020-04-02 08:34:57,145 epoch 13 - iter 129/439 - loss 0.58525262 - samples/sec: 80.74
2020-04-02 08:35:17,123 epoch 19 - iter 132/220 - loss 0.67236347 - samples/sec: 119.36
2020-04-02 08:35:45,975 epoch 34 - iter 430/439 - loss 0.76249711 - samples/sec: 170.30
2020-04-02 08:37:31,795 ----------------------------------------------------------------------------------------------------
2020-04-02 08:37:31,796 EPOCH 34 done: loss 0.7614 - lr 0.0100
2020-04-02 08:37:36,560 DEV : loss 0.6904889345169067 - score 0.9323
2020-04-02 08:37:36,658 BAD EPOCHS (no improvement): 0
2020-04-02 08:37:45,347 ----------------------------------------------------------------------------------------------------
2020-04-02 08:37:53,608 epoch 35 - iter 43/439 - loss 0.84848968 - samples/sec: 166.69
2020-04-02 08:39:48,418 epoch 35 - iter 86/439 - loss 0.83090893 - samples/sec: 171.93

2020-04-02 08:40:32,053 epoch 13 - iter 172/439 - loss 0.55732617 - samples/sec: 87.77
2020-04-02 08:41:41,218 epoch 35 - iter 129/439 - loss 0.78544780 - samples/sec: 170.19
2020-04-02 08:42:56,959 epoch 19 - iter 176/220 - loss 0.67655292 - samples/sec: 123.18
2020-04-02 08:43:35,981 epoch 35 - iter 172/439 - loss 0.77608610 - samples/sec: 160.94
2020-04-02 08:45:27,015 epoch 35 - iter 215/439 - loss 0.78458229 - samples/sec: 173.41
2020-04-02 08:46:06,453 epoch 13 - iter 215/439 - loss 0.57771594 - samples/sec: 84.52
2020-04-02 08:46:42,433 epoch 19 - iter 198/220 - loss 0.67144578 - samples/sec: 120.54
2020-04-02 08:47:19,369 epoch 35 - iter 258/439 - loss 0.77694427 - samples/sec: 162.58
2020-04-02 08:49:11,000 epoch 35 - iter 301/439 - loss 0.76527742 - samples/sec: 171.87
2020-04-02 08:50:25,059 epoch 19 - iter 220/220 - loss 0.67583700 - samples/sec: 120.41
2020-04-02 08:51:05,090 epoch 35 - iter 344/439 - loss 0.76445362 - samples/sec: 173.71
2020-04-02 08:51:40,035 epoch 13 - iter 258/439 - loss 0.57762441 - samples/sec: 82.27
2020-04-02 08:52:51,799 epoch 35 - iter 387/439 - loss 0.75856061 - samples/sec: 203.68
2020-04-02 08:54:11,700 ----------------------------------------------------------------------------------------------------
2020-04-02 08:54:11,701 EPOCH 19 done: loss 0.6758 - lr 0.0100
2020-04-02 08:54:26,932 DEV : loss 0.6853516697883606 - score 0.9341
2020-04-02 08:54:27,339 BAD EPOCHS (no improvement): 0
2020-04-02 08:55:10,864 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 08:55:23,117 epoch 20 - iter 22/220 - loss 0.67688421 - samples/sec: 115.01
2020-04-02 08:56:54,026 ----------------------------------------------------------------------------------------------------
2020-04-02 08:56:54,026 EPOCH 35 done: loss 0.7496 - lr 0.0100
2020-04-02 08:56:58,775 DEV : loss 0.6826223134994507 - score 0.9308
2020-04-02 08:56:58,868 BAD EPOCHS (no improvement): 1
2020-04-02 08:56:58,903 ----------------------------------------------------------------------------------------------------
2020-04-02 08:57:07,147 epoch 36 - iter 43/439 - loss 0.73431724 - samples/sec: 167.01
2020-04-02 08:57:30,327 epoch 13 - iter 301/439 - loss 0.56895352 - samples/sec: 85.55
2020-04-02 08:58:55,490 epoch 36 - iter 86/439 - loss 0.71185782 - samples/sec: 167.26
2020-04-02 09:00:37,265 epoch 36 - iter 129/439 - loss 0.72351493 - samples/sec: 181.28
2020-04-02 09:03:08,040 epoch 13 - iter 344/439 - loss 0.57298786 - samples/sec: 79.54

2020-04-02 09:03:14,387 epoch 20 - iter 66/220 - loss 0.63386464 - samples/sec: 122.14
2020-04-02 09:04:48,204 epoch 36 - iter 215/439 - loss 0.72488653 - samples/sec: 168.64
2020-04-02 09:07:04,633 epoch 20 - iter 88/220 - loss 0.62697719 - samples/sec: 126.15

2020-04-02 09:08:52,117 epoch 13 - iter 387/439 - loss 0.57508496 - samples/sec: 78.40

2020-04-02 09:10:57,269 epoch 20 - iter 110/220 - loss 0.62091598 - samples/sec: 120.21
2020-04-02 09:12:33,110 epoch 36 - iter 387/439 - loss 0.72908614 - samples/sec: 154.51
2020-04-02 09:14:38,763 epoch 13 - iter 430/439 - loss 0.57473970 - samples/sec: 84.35

2020-04-02 09:14:52,632 epoch 20 - iter 132/220 - loss 0.62602178 - samples/sec: 122.44
2020-04-02 09:16:20,060 ----------------------------------------------------------------------------------------------------
2020-04-02 09:16:20,060 EPOCH 36 done: loss 0.7322 - lr 0.0100
2020-04-02 09:16:24,828 DEV : loss 0.6846714615821838 - score 0.9327
2020-04-02 09:16:24,926 BAD EPOCHS (no improvement): 0
2020-04-02 09:16:33,768 ----------------------------------------------------------------------------------------------------
2020-04-02 09:16:42,595 epoch 37 - iter 43/439 - loss 0.63819521 - samples/sec: 156.00
2020-04-02 09:18:40,733 epoch 20 - iter 154/220 - loss 0.63597877 - samples/sec: 130.28
2020-04-02 09:20:24,241 epoch 37 - iter 129/439 - loss 0.66312847 - samples/sec: 162.45
-----------------------------------
2020-04-02 09:20:02,206 EPOCH 13 done: loss 0.5745 - lr 0.0100
2020-04-02 09:20:24,914 DEV : loss 0.568153440952301 - score 0.9476
2020-04-02 09:20:25,353 BAD EPOCHS (no improvement): 0
2020-04-02 09:21:19,737 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 09:21:36,515 epoch 14 - iter 43/439 - loss 0.50366005 - samples/sec: 82.06
2020-04-02 09:22:24,249 epoch 20 - iter 176/220 - loss 0.63531013 - samples/sec: 115.29
2020-04-02 09:22:36,903 epoch 37 - iter 172/439 - loss 0.66730397 - samples/sec: 169.03
2020-04-02 09:24:19,588 epoch 37 - iter 215/439 - loss 0.68045273 - samples/sec: 211.06
2020-04-02 09:26:04,904 epoch 37 - iter 258/439 - loss 0.69274715 - samples/sec: 164.30
2020-04-02 09:26:48,409 epoch 14 - iter 86/439 - loss 0.51104498 - samples/sec: 80.92
2020-04-02 09:27:53,620 epoch 37 - iter 301/439 - loss 0.70813333 - samples/sec: 179.44
2020-04-02 09:29:46,012 epoch 37 - iter 344/439 - loss 0.70739507 - samples/sec: 171.95
2020-04-02 09:31:38,078 epoch 37 - iter 387/439 - loss 0.70570161 - samples/sec: 168.13
2020-04-02 09:32:20,144 epoch 14 - iter 129/439 - loss 0.51075081 - samples/sec: 83.81
2020-04-02 09:33:03,822 ----------------------------------------------------------------------------------------------------
2020-04-02 09:33:03,822 EPOCH 20 done: loss 0.6399 - lr 0.0100
2020-04-02 09:33:18,148 DEV : loss 0.6811580061912537 - score 0.9323
2020-04-02 09:33:27,257 epoch 37 - iter 430/439 - loss 0.70996891 - samples/sec: 164.57
-------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 09:33:29,574 epoch 21 - iter 22/220 - loss 0.63308096 - samples/sec: 128.51
2020-04-02 09:35:14,028 ----------------------------------------------------------------------------------------------------
2020-04-02 09:35:14,029 EPOCH 37 done: loss 0.7091 - lr 0.0100
2020-04-02 09:35:18,749 DEV : loss 0.677095353603363 - score 0.933
2020-04-02 09:35:18,844 BAD EPOCHS (no improvement): 0
2020-04-02 09:35:27,628 ----------------------------------------------------------------------------------------------------
2020-04-02 09:35:36,302 epoch 38 - iter 43/439 - loss 0.74414059 - samples/sec: 158.75
2020-04-02 09:37:22,200 epoch 38 - iter 86/439 - loss 0.69547595 - samples/sec: 155.10
2020-04-02 09:37:44,374 epoch 14 - iter 172/439 - loss 0.53528297 - samples/sec: 85.37
2020-04-02 09:39:09,999 epoch 38 - iter 129/439 - loss 0.69417131 - samples/sec: 316.44
2020-04-02 09:41:43,934 epoch 21 - iter 66/220 - loss 0.60965935 - samples/sec: 122.36

2020-04-02 09:43:23,078 epoch 38 - iter 215/439 - loss 0.70469594 - samples/sec: 166.21
2020-04-02 09:43:43,081 epoch 14 - iter 215/439 - loss 0.53653270 - samples/sec: 85.75
2020-04-02 09:45:21,110 epoch 21 - iter 88/220 - loss 0.61744718 - samples/sec: 121.22

2020-04-02 09:47:01,698 epoch 38 - iter 301/439 - loss 0.71320043 - samples/sec: 160.80
2020-04-02 09:48:59,879 epoch 21 - iter 110/220 - loss 0.60551111 - samples/sec: 142.33
2020-04-02 09:49:05,821 epoch 14 - iter 258/439 - loss 0.51830236 - samples/sec: 83.22
2020-04-02 09:50:40,337 epoch 38 - iter 387/439 - loss 0.71209166 - samples/sec: 171.56
2020-04-02 09:52:43,862 epoch 21 - iter 132/220 - loss 0.59919112 - samples/sec: 122.36
2020-04-02 09:54:17,568 ----------------------------------------------------------------------------------------------------
2020-04-02 09:54:17,568 EPOCH 38 done: loss 0.7175 - lr 0.0100
2020-04-02 09:54:22,312 DEV : loss 0.6857771277427673 - score 0.9346
2020-04-02 09:54:22,411 BAD EPOCHS (no improvement): 0
2020-04-02 09:54:31,323 ----------------------------------------------------------------------------------------------------
2020-04-02 09:54:39,320 epoch 39 - iter 43/439 - loss 0.76046788 - samples/sec: 172.20
2020-04-02 09:54:37,673 epoch 14 - iter 301/439 - loss 0.50891988 - samples/sec: 86.68
2020-04-02 09:56:23,279 epoch 21 - iter 154/220 - loss 0.60067558 - samples/sec: 121.86
2020-04-02 09:58:11,556 epoch 39 - iter 129/439 - loss 0.67924394 - samples/sec: 170.98
2020-04-02 10:00:04,662 epoch 21 - iter 176/220 - loss 0.60528591 - samples/sec: 109.05
2020-04-02 10:01:50,349 epoch 39 - iter 215/439 - loss 0.66760555 - samples/sec: 185.69
2020-04-02 10:03:45,028 epoch 21 - iter 198/220 - loss 0.61137658 - samples/sec: 122.04
2020-04-02 10:05:24,116 epoch 39 - iter 301/439 - loss 0.68582601 - samples/sec: 159.43
2020-04-02 10:05:19,602 epoch 14 - iter 387/439 - loss 0.51373984 - samples/sec: 78.94
2020-04-02 10:07:15,396 epoch 39 - iter 344/439 - loss 0.69528232 - samples/sec: 162.71
2020-04-02 10:09:04,685 epoch 39 - iter 387/439 - loss 0.69487493 - samples/sec: 167.87
2020-04-02 10:10:49,253 epoch 39 - iter 430/439 - loss 0.69337230 - samples/sec: 154.72
-----------------------------------
2020-04-02 10:10:26,384 EPOCH 21 done: loss 0.6103 - lr 0.0100
2020-04-02 10:10:40,782 DEV : loss 0.6728362441062927 - score 0.9342
2020-04-02 10:10:40,930 epoch 14 - iter 430/439 - loss 0.51853963 - samples/sec: 83.28
2020-04-02 10:10:41,189 BAD EPOCHS (no improvement): 0
2020-04-02 10:11:25,978 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 10:11:36,685 epoch 22 - iter 22/220 - loss 0.59020837 - samples/sec: 131.64
2020-04-02 10:12:47,421 ----------------------------------------------------------------------------------------------------
2020-04-02 10:12:47,421 EPOCH 39 done: loss 0.6920 - lr 0.0100
2020-04-02 10:12:52,148 DEV : loss 0.6893383860588074 - score 0.9331
2020-04-02 10:12:52,243 BAD EPOCHS (no improvement): 1
2020-04-02 10:12:52,302 ----------------------------------------------------------------------------------------------------
2020-04-02 10:13:00,794 epoch 40 - iter 43/439 - loss 0.58314787 - samples/sec: 162.14
2020-04-02 10:14:46,543 epoch 40 - iter 86/439 - loss 0.64904641 - samples/sec: 161.83
2020-04-02 10:15:08,189 epoch 22 - iter 44/220 - loss 0.62006114 - samples/sec: 119.77
2020-04-02 10:15:49,143 ----------------------------------------------------------------------------------------------------
2020-04-02 10:15:49,143 EPOCH 14 done: loss 0.5189 - lr 0.0100
2020-04-02 10:16:11,347 DEV : loss 0.5831729769706726 - score 0.9482
2020-04-02 10:16:11,786 BAD EPOCHS (no improvement): 0
2020-04-02 10:16:32,498 epoch 40 - iter 129/439 - loss 0.67154788 - samples/sec: 165.33
2020-04-02 10:17:09,673 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 10:17:25,266 epoch 15 - iter 43/439 - loss 0.44442141 - samples/sec: 88.30
2020-04-02 10:18:30,721 epoch 40 - iter 172/439 - loss 0.68186123 - samples/sec: 174.39
2020-04-02 10:20:09,280 epoch 40 - iter 215/439 - loss 0.67687859 - samples/sec: 172.33
2020-04-02 10:21:48,424 epoch 40 - iter 258/439 - loss 0.68237834 - samples/sec: 166.64
2020-04-02 10:22:32,959 epoch 15 - iter 86/439 - loss 0.47468875 - samples/sec: 88.31
2020-04-02 10:22:58,258 epoch 22 - iter 88/220 - loss 0.60081590 - samples/sec: 125.10
2020-04-02 10:23:29,073 epoch 40 - iter 301/439 - loss 0.67376999 - samples/sec: 155.66
2020-04-02 10:25:14,469 epoch 40 - iter 344/439 - loss 0.67059322 - samples/sec: 169.65
2020-04-02 10:26:27,231 epoch 22 - iter 110/220 - loss 0.61622271 - samples/sec: 111.94
2020-04-02 10:26:58,139 epoch 40 - iter 387/439 - loss 0.66603490 - samples/sec: 175.99
2020-04-02 10:27:48,903 epoch 15 - iter 129/439 - loss 0.48388697 - samples/sec: 85.80
2020-04-02 10:28:56,534 epoch 40 - iter 430/439 - loss 0.67973390 - samples/sec: 160.45
2020-04-02 10:30:34,073 ----------------------------------------------------------------------------------------------------
2020-04-02 10:30:34,074 EPOCH 40 done: loss 0.6802 - lr 0.0100
2020-04-02 10:30:38,849 DEV : loss 0.6822118759155273 - score 0.9336
2020-04-02 10:30:38,946 BAD EPOCHS (no improvement): 2
2020-04-02 10:30:39,035 ----------------------------------------------------------------------------------------------------
2020-04-02 10:30:47,938 epoch 41 - iter 43/439 - loss 0.69928164 - samples/sec: 154.67
2020-04-02 10:32:46,819 epoch 15 - iter 172/439 - loss 0.47124619 - samples/sec: 91.94
2020-04-02 10:33:34,768 epoch 22 - iter 154/220 - loss 0.61029387 - samples/sec: 123.03
2020-04-02 10:34:10,923 epoch 41 - iter 129/439 - loss 0.65757557 - samples/sec: 168.36
2020-04-02 10:35:53,394 epoch 41 - iter 172/439 - loss 0.66358038 - samples/sec: 161.98
2020-04-02 10:37:04,351 epoch 22 - iter 176/220 - loss 0.61326594 - samples/sec: 120.97
2020-04-02 10:37:37,793 epoch 41 - iter 215/439 - loss 0.65828094 - samples/sec: 159.36
2020-04-02 10:37:54,662 epoch 15 - iter 215/439 - loss 0.47505739 - samples/sec: 85.28
2020-04-02 10:39:19,900 epoch 41 - iter 258/439 - loss 0.66104340 - samples/sec: 167.78
2020-04-02 10:40:33,252 epoch 22 - iter 198/220 - loss 0.60775508 - samples/sec: 123.27
2020-04-02 10:41:04,294 epoch 41 - iter 301/439 - loss 0.67063742 - samples/sec: 168.20
2020-04-02 10:42:57,999 epoch 15 - iter 258/439 - loss 0.47476566 - samples/sec: 85.25

2020-04-02 10:43:58,757 epoch 22 - iter 220/220 - loss 0.60502827 - samples/sec: 124.18
2020-04-02 10:44:30,196 epoch 41 - iter 387/439 - loss 0.67370720 - samples/sec: 232.15
2020-04-02 10:46:21,166 epoch 41 - iter 430/439 - loss 0.67796962 - samples/sec: 156.82
2020-04-02 10:47:29,071 ----------------------------------------------------------------------------------------------------
2020-04-02 10:47:29,071 EPOCH 22 done: loss 0.6050 - lr 0.0100
2020-04-02 10:47:43,574 DEV : loss 0.6751622557640076 - score 0.9352
2020-04-02 10:47:43,980 BAD EPOCHS (no improvement): 0
2020-04-02 10:48:22,986 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
20-04-02 10:48:22,500 DEV : loss 0.6795617341995239 - score 0.9333
2020-04-02 10:48:22,597 BAD EPOCHS (no improvement): 3
2020-04-02 10:48:22,987 ----------------------------------------------------------------------------------------------------
2020-04-02 10:48:34,443 epoch 23 - iter 22/220 - loss 0.54683335 - samples/sec: 123.01
2020-04-02 10:48:31,415 epoch 42 - iter 43/439 - loss 0.71025931 - samples/sec: 163.40
2020-04-02 10:50:22,071 epoch 42 - iter 86/439 - loss 0.68430726 - samples/sec: 169.11
2020-04-02 10:52:14,409 epoch 23 - iter 44/220 - loss 0.56108037 - samples/sec: 109.78

2020-04-02 10:53:57,092 epoch 42 - iter 172/439 - loss 0.68273916 - samples/sec: 162.97
2020-04-02 10:55:46,611 epoch 23 - iter 66/220 - loss 0.56472955 - samples/sec: 124.64

2020-04-02 10:57:33,760 epoch 42 - iter 258/439 - loss 0.68495461 - samples/sec: 164.17
2020-04-02 10:59:33,184 epoch 23 - iter 88/220 - loss 0.56822204 - samples/sec: 128.79
2020-04-02 10:59:26,831 epoch 42 - iter 301/439 - loss 0.67202974 - samples/sec: 159.60
2020-04-02 11:01:17,928 epoch 42 - iter 344/439 - loss 0.66821044 - samples/sec: 159.66
2020-04-02 11:03:23,926 epoch 23 - iter 110/220 - loss 0.56585572 - samples/sec: 127.52
2020-04-02 11:05:11,504 epoch 42 - iter 430/439 - loss 0.66617368 - samples/sec: 169.60
2020-04-02 11:07:14,138 epoch 23 - iter 132/220 - loss 0.57231037 - samples/sec: 123.59
-----------------------------------
2020-04-02 11:06:57,537 EPOCH 42 done: loss 0.6680 - lr 0.0100
2020-04-02 11:07:02,328 DEV : loss 0.6824474334716797 - score 0.9331
Epoch    42: reducing learning rate of group 0 to 5.0000e-03.
2020-04-02 11:07:02,424 BAD EPOCHS (no improvement): 4
2020-04-02 11:07:02,489 ----------------------------------------------------------------------------------------------------
2020-04-02 11:07:10,194 epoch 43 - iter 43/439 - loss 0.61083620 - samples/sec: 178.75
2020-04-02 11:08:59,362 epoch 43 - iter 86/439 - loss 0.63585723 - samples/sec: 165.99
2020-04-02 11:10:08,055 ----------------------------------------------------------------------------------------------------
2020-04-02 11:10:08,055 EPOCH 15 done: loss 0.4955 - lr 0.0100
2020-04-02 11:10:30,191 DEV : loss 0.5595209002494812 - score 0.9474
2020-04-02 11:10:30,632 BAD EPOCHS (no improvement): 1
2020-04-02 11:10:30,666 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 11:10:47,834 epoch 16 - iter 43/439 - loss 0.47814712 - samples/sec: 80.19
2020-04-02 11:10:47,582 epoch 43 - iter 129/439 - loss 0.62054531 - samples/sec: 173.54
2020-04-02 11:10:53,627 epoch 23 - iter 154/220 - loss 0.56671422 - samples/sec: 122.52
2020-04-02 11:12:33,153 epoch 43 - iter 172/439 - loss 0.62576110 - samples/sec: 165.36
2020-04-02 11:14:40,239 epoch 23 - iter 176/220 - loss 0.57419001 - samples/sec: 121.58
2020-04-02 11:16:16,269 epoch 43 - iter 258/439 - loss 0.64504135 - samples/sec: 162.38
2020-04-02 11:18:16,595 epoch 23 - iter 198/220 - loss 0.57251243 - samples/sec: 118.62
2020-04-02 11:19:49,435 epoch 43 - iter 344/439 - loss 0.65348337 - samples/sec: 166.47
2020-04-02 11:21:54,430 epoch 23 - iter 220/220 - loss 0.57533638 - samples/sec: 128.33
2020-04-02 11:23:28,303 epoch 43 - iter 430/439 - loss 0.64538847 - samples/sec: 156.37
2020-04-02 11:25:35,392 ----------------------------------------------------------------------------------------------------
2020-04-02 11:25:35,392 EPOCH 23 done: loss 0.5753 - lr 0.0100
2020-04-02 11:25:21,540 DEV : loss 0.6745314598083496 - score 0.935
2020-04-02 11:25:21,636 BAD EPOCHS (no improvement): 0
2020-04-02 11:25:29,974 ----------------------------------------------------------------------------------------------------
2020-04-02 11:25:38,621 epoch 44 - iter 43/439 - loss 0.64245275 - samples/sec: 159.25
2020-04-02 11:25:49,544 DEV : loss 0.6619340181350708 - score 0.9376
2020-04-02 11:25:49,937 BAD EPOCHS (no improvement): 0
2020-04-02 11:26:22,857 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 11:26:33,774 epoch 24 - iter 22/220 - loss 0.59239570 - samples/sec: 129.09
2020-04-02 11:27:25,952 epoch 16 - iter 172/439 - loss 0.50877447 - samples/sec: 81.54
2020-04-02 11:27:49,659 epoch 44 - iter 86/439 - loss 0.60995486 - samples/sec: 164.34
2020-04-02 11:29:45,612 epoch 44 - iter 129/439 - loss 0.63108529 - samples/sec: 164.76
2020-04-02 11:30:23,184 epoch 24 - iter 44/220 - loss 0.57746526 - samples/sec: 125.48
2020-04-02 11:31:52,124 epoch 44 - iter 172/439 - loss 0.63299454 - samples/sec: 170.70
2020-04-02 11:33:41,482 epoch 44 - iter 215/439 - loss 0.62233859 - samples/sec: 275.01
2020-04-02 11:34:44,261 epoch 24 - iter 66/220 - loss 0.58227929 - samples/sec: 122.58
2020-04-02 11:35:33,416 epoch 44 - iter 258/439 - loss 0.61844255 - samples/sec: 168.80
2020-04-02 11:37:24,193 epoch 44 - iter 301/439 - loss 0.61938516 - samples/sec: 161.61
2020-04-02 11:38:27,962 epoch 24 - iter 88/220 - loss 0.58241371 - samples/sec: 120.00
2020-04-02 11:38:45,290 epoch 16 - iter 258/439 - loss 0.48628782 - samples/sec: 82.75
2020-04-02 11:39:19,907 epoch 44 - iter 344/439 - loss 0.61985033 - samples/sec: 163.65
2020-04-02 11:41:12,068 epoch 44 - iter 387/439 - loss 0.61914486 - samples/sec: 163.59
2020-04-02 11:42:16,304 epoch 24 - iter 110/220 - loss 0.57527226 - samples/sec: 154.73
2020-04-02 11:43:06,598 epoch 44 - iter 430/439 - loss 0.61393226 - samples/sec: 208.42
2020-04-02 11:44:53,665 ----------------------------------------------------------------------------------------------------
2020-04-02 11:44:53,665 EPOCH 44 done: loss 0.6136 - lr 0.0050
2020-04-02 11:44:59,056 DEV : loss 0.6806424856185913 - score 0.936
2020-04-02 11:44:59,152 BAD EPOCHS (no improvement): 0
2020-04-02 11:45:07,039 ----------------------------------------------------------------------------------------------------
2020-04-02 11:45:15,208 epoch 45 - iter 43/439 - loss 0.64776206 - samples/sec: 168.55
2020-04-02 11:46:12,454 epoch 24 - iter 132/220 - loss 0.56890567 - samples/sec: 121.53
2020-04-02 11:47:09,784 epoch 45 - iter 86/439 - loss 0.66137702 - samples/sec: 168.67
2020-04-02 11:49:05,112 epoch 45 - iter 129/439 - loss 0.64292662 - samples/sec: 164.04
2020-04-02 11:50:06,545 epoch 16 - iter 344/439 - loss 0.48092693 - samples/sec: 89.26

2020-04-02 11:50:59,689 epoch 45 - iter 172/439 - loss 0.63557075 - samples/sec: 175.12
2020-04-02 11:52:54,748 epoch 45 - iter 215/439 - loss 0.63176405 - samples/sec: 171.31
2020-04-02 11:53:56,088 epoch 24 - iter 176/220 - loss 0.56419962 - samples/sec: 121.00
2020-04-02 11:54:44,528 epoch 45 - iter 258/439 - loss 0.62220756 - samples/sec: 168.87
2020-04-02 11:55:42,642 epoch 16 - iter 387/439 - loss 0.47711914 - samples/sec: 86.79
2020-04-02 11:56:37,628 epoch 45 - iter 301/439 - loss 0.61618940 - samples/sec: 160.68
2020-04-02 11:57:44,006 epoch 24 - iter 198/220 - loss 0.57292227 - samples/sec: 122.00
2020-04-02 11:58:32,000 epoch 45 - iter 344/439 - loss 0.61468185 - samples/sec: 158.55
2020-04-02 12:00:41,464 epoch 45 - iter 387/439 - loss 0.61820307 - samples/sec: 163.10
2020-04-02 12:01:51,899 epoch 24 - iter 220/220 - loss 0.56924891 - samples/sec: 125.66
2020-04-02 12:02:39,208 epoch 45 - iter 430/439 - loss 0.61676369 - samples/sec: 167.07
2020-04-02 12:04:29,033 ----------------------------------------------------------------------------------------------------
2020-04-02 12:04:29,033 EPOCH 45 done: loss 0.6156 - lr 0.0050
2020-04-02 12:04:33,762 DEV : loss 0.6809647679328918 - score 0.9354
2020-04-02 12:04:33,857 BAD EPOCHS (no improvement): 1
2020-04-02 12:04:33,921 ----------------------------------------------------------------------------------------------------
2020-04-02 12:04:41,694 epoch 46 - iter 43/439 - loss 0.63254917 - samples/sec: 177.14
2020-04-02 12:05:39,778 ----------------------------------------------------------------------------------------------------
2020-04-02 12:05:39,778 EPOCH 24 done: loss 0.5692 - lr 0.0100
2020-04-02 12:05:55,026 DEV : loss 0.6641486287117004 - score 0.936
2020-04-02 12:05:55,435 BAD EPOCHS (no improvement): 1
2020-04-02 12:05:55,472 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 12:06:06,671 epoch 25 - iter 22/220 - loss 0.53789136 - samples/sec: 125.80
2020-04-02 12:06:38,895 epoch 46 - iter 86/439 - loss 0.61226827 - samples/sec: 163.36
2020-04-02 12:07:12,842 ----------------------------------------------------------------------------------------------------
2020-04-02 12:07:12,842 EPOCH 16 done: loss 0.4742 - lr 0.0100
2020-04-02 12:07:36,300 DEV : loss 0.5528343319892883 - score 0.9476
2020-04-02 12:07:36,740 BAD EPOCHS (no improvement): 2
2020-04-02 12:07:36,783 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 12:07:52,198 epoch 17 - iter 43/439 - loss 0.37664134 - samples/sec: 89.31
2020-04-02 12:08:30,845 epoch 46 - iter 129/439 - loss 0.59925240 - samples/sec: 174.46
2020-04-02 12:10:22,651 epoch 46 - iter 172/439 - loss 0.59298480 - samples/sec: 163.44
2020-04-02 12:12:12,995 epoch 46 - iter 215/439 - loss 0.59458023 - samples/sec: 175.10
2020-04-02 12:13:20,535 epoch 17 - iter 86/439 - loss 0.41025592 - samples/sec: 90.36
2020-04-02 12:13:39,154 epoch 25 - iter 66/220 - loss 0.51846458 - samples/sec: 126.62
2020-04-02 12:14:08,030 epoch 46 - iter 258/439 - loss 0.59622460 - samples/sec: 161.82
2020-04-02 12:16:01,273 epoch 46 - iter 301/439 - loss 0.60343340 - samples/sec: 153.24
2020-04-02 12:17:52,193 epoch 46 - iter 344/439 - loss 0.59994499 - samples/sec: 296.86
2020-04-02 12:18:56,145 epoch 17 - iter 129/439 - loss 0.43939980 - samples/sec: 82.92
2020-04-02 12:19:40,463 epoch 46 - iter 387/439 - loss 0.59861835 - samples/sec: 154.41
2020-04-02 12:21:24,775 epoch 46 - iter 430/439 - loss 0.59919104 - samples/sec: 157.13
2020-04-02 12:23:00,430 ----------------------------------------------------------------------------------------------------
2020-04-02 12:23:00,430 EPOCH 46 done: loss 0.5977 - lr 0.0050
2020-04-02 12:23:05,060 DEV : loss 0.6670848727226257 - score 0.9338
2020-04-02 12:23:05,157 BAD EPOCHS (no improvement): 2
2020-04-02 12:23:05,202 ----------------------------------------------------------------------------------------------------
2020-04-02 12:23:09,466 epoch 47 - iter 43/439 - loss 0.59068202 - samples/sec: 322.96
2020-04-02 12:24:09,242 epoch 17 - iter 172/439 - loss 0.45004471 - samples/sec: 82.80
2020-04-02 12:24:37,290 epoch 25 - iter 132/220 - loss 0.52448328 - samples/sec: 121.27
2020-04-02 12:24:55,177 epoch 47 - iter 86/439 - loss 0.57223186 - samples/sec: 156.36
2020-04-02 12:26:42,361 epoch 47 - iter 129/439 - loss 0.55734905 - samples/sec: 171.86
2020-04-02 12:28:23,978 epoch 47 - iter 172/439 - loss 0.56731132 - samples/sec: 178.81
2020-04-02 12:29:24,555 epoch 17 - iter 215/439 - loss 0.44645370 - samples/sec: 82.44
2020-04-02 12:30:09,150 epoch 47 - iter 215/439 - loss 0.59142703 - samples/sec: 166.26
2020-04-02 12:31:56,096 epoch 47 - iter 258/439 - loss 0.58299763 - samples/sec: 167.07
2020-04-02 12:33:44,596 epoch 47 - iter 301/439 - loss 0.58564140 - samples/sec: 167.25
2020-04-02 12:34:39,191 epoch 17 - iter 258/439 - loss 0.43976641 - samples/sec: 98.82
2020-04-02 12:35:27,831 epoch 47 - iter 344/439 - loss 0.58155873 - samples/sec: 156.38
2020-04-02 12:37:14,314 epoch 47 - iter 387/439 - loss 0.58646072 - samples/sec: 165.59
2020-04-02 12:39:01,209 epoch 47 - iter 430/439 - loss 0.58447222 - samples/sec: 175.58
2020-04-02 12:39:44,393 epoch 17 - iter 301/439 - loss 0.43800543 - samples/sec: 88.44
2020-04-02 12:40:37,176 ----------------------------------------------------------------------------------------------------
2020-04-02 12:40:37,176 EPOCH 47 done: loss 0.5909 - lr 0.0050
2020-04-02 12:40:41,924 DEV : loss 0.670686662197113 - score 0.9335
2020-04-02 12:40:42,020 BAD EPOCHS (no improvement): 3
2020-04-02 12:40:42,090 ----------------------------------------------------------------------------------------------------
2020-04-02 12:40:50,109 epoch 48 - iter 43/439 - loss 0.55138021 - samples/sec: 171.68
2020-04-02 12:42:34,677 epoch 48 - iter 86/439 - loss 0.59485638 - samples/sec: 155.37
------------------------------------
2020-04-02 12:42:11,494 EPOCH 25 done: loss 0.5428 - lr 0.0100
2020-04-02 12:42:25,965 DEV : loss 0.6555036902427673 - score 0.9375
2020-04-02 12:42:26,371 BAD EPOCHS (no improvement): 2
2020-04-02 12:42:26,400 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 12:42:37,595 epoch 26 - iter 22/220 - loss 0.56145173 - samples/sec: 125.84
2020-04-02 12:44:20,698 epoch 48 - iter 129/439 - loss 0.59666937 - samples/sec: 159.77
2020-04-02 12:44:52,381 epoch 17 - iter 344/439 - loss 0.44045043 - samples/sec: 80.41
2020-04-02 12:46:00,680 epoch 48 - iter 172/439 - loss 0.58618702 - samples/sec: 169.28
2020-04-02 12:46:03,616 epoch 26 - iter 44/220 - loss 0.51666789 - samples/sec: 129.53
2020-04-02 12:47:52,612 epoch 48 - iter 215/439 - loss 0.58993903 - samples/sec: 160.27
2020-04-02 12:49:39,209 epoch 26 - iter 66/220 - loss 0.53181021 - samples/sec: 122.87

2020-04-02 12:51:20,030 epoch 48 - iter 301/439 - loss 0.58673449 - samples/sec: 170.36
2020-04-02 12:53:14,321 epoch 26 - iter 88/220 - loss 0.53363375 - samples/sec: 125.01

2020-04-02 12:54:25,006 epoch 17 - iter 430/439 - loss 0.44742601 - samples/sec: 84.30
2020-04-02 12:54:48,624 epoch 48 - iter 387/439 - loss 0.57905670 - samples/sec: 214.82
2020-04-02 12:56:44,699 epoch 26 - iter 110/220 - loss 0.54226065 - samples/sec: 124.63
2020-04-02 12:58:19,193 ----------------------------------------------------------------------------------------------------
2020-04-02 12:58:19,194 EPOCH 48 done: loss 0.5866 - lr 0.0050
2020-04-02 12:58:23,943 DEV : loss 0.6686232089996338 - score 0.9361
2020-04-02 12:58:24,037 BAD EPOCHS (no improvement): 0
2020-04-02 12:58:32,948 ----------------------------------------------------------------------------------------------------
2020-04-02 12:58:41,799 epoch 49 - iter 43/439 - loss 0.55293697 - samples/sec: 155.58
2020-04-02 12:59:26,657 ----------------------------------------------------------------------------------------------------
2020-04-02 12:59:26,657 EPOCH 17 done: loss 0.4442 - lr 0.0100
2020-04-02 12:59:48,946 DEV : loss 0.5538303852081299 - score 0.9497
2020-04-02 12:59:49,384 BAD EPOCHS (no improvement): 0
2020-04-02 13:00:52,605 epoch 26 - iter 132/220 - loss 0.53074144 - samples/sec: 125.20
-----------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 13:01:05,474 epoch 18 - iter 43/439 - loss 0.42478129 - samples/sec: 78.25
2020-04-02 13:02:35,754 epoch 49 - iter 129/439 - loss 0.60595818 - samples/sec: 167.00
2020-04-02 13:04:24,228 epoch 49 - iter 172/439 - loss 0.59964539 - samples/sec: 169.22
2020-04-02 13:04:30,327 epoch 26 - iter 154/220 - loss 0.53169341 - samples/sec: 118.08
2020-04-02 13:06:09,522 epoch 49 - iter 215/439 - loss 0.59093037 - samples/sec: 172.71
2020-04-02 13:08:08,608 epoch 26 - iter 176/220 - loss 0.52751251 - samples/sec: 122.39
2020-04-02 13:09:42,024 epoch 49 - iter 301/439 - loss 0.58865713 - samples/sec: 172.39
2020-04-02 13:11:27,066 epoch 49 - iter 344/439 - loss 0.59639457 - samples/sec: 155.84
2020-04-02 13:11:36,626 epoch 26 - iter 198/220 - loss 0.53269109 - samples/sec: 123.86
2020-04-02 13:13:11,104 epoch 49 - iter 387/439 - loss 0.59517082 - samples/sec: 172.30
2020-04-02 13:15:11,723 epoch 26 - iter 220/220 - loss 0.52881066 - samples/sec: 112.11
2020-04-02 13:16:09,709 epoch 18 - iter 172/439 - loss 0.42254456 - samples/sec: 85.69
2020-04-02 13:16:36,465 ----------------------------------------------------------------------------------------------------
2020-04-02 13:16:36,465 EPOCH 49 done: loss 0.5934 - lr 0.0050
2020-04-02 13:16:41,175 DEV : loss 0.6577353477478027 - score 0.9353
2020-04-02 13:16:41,273 BAD EPOCHS (no improvement): 1
2020-04-02 13:16:41,346 ----------------------------------------------------------------------------------------------------
2020-04-02 13:16:49,675 epoch 50 - iter 43/439 - loss 0.56483012 - samples/sec: 165.31
2020-04-02 13:18:33,943 epoch 50 - iter 86/439 - loss 0.55872151 - samples/sec: 165.57
------------------------------------
2020-04-02 13:18:31,668 EPOCH 26 done: loss 0.5288 - lr 0.0100
2020-04-02 13:18:46,063 DEV : loss 0.6695820689201355 - score 0.9344
2020-04-02 13:18:46,470 BAD EPOCHS (no improvement): 3
2020-04-02 13:18:46,515 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 13:18:57,531 epoch 27 - iter 22/220 - loss 0.53095205 - samples/sec: 127.90
2020-04-02 13:20:14,304 epoch 50 - iter 129/439 - loss 0.56334442 - samples/sec: 169.33
2020-04-02 13:21:06,852 epoch 18 - iter 215/439 - loss 0.42439844 - samples/sec: 92.27
2020-04-02 13:21:57,662 epoch 50 - iter 172/439 - loss 0.57737580 - samples/sec: 174.93
2020-04-02 13:22:57,913 epoch 27 - iter 44/220 - loss 0.51911271 - samples/sec: 124.22
2020-04-02 13:23:51,504 epoch 50 - iter 215/439 - loss 0.58595089 - samples/sec: 160.15
2020-04-02 13:25:31,916 epoch 50 - iter 258/439 - loss 0.58757710 - samples/sec: 170.31
2020-04-02 13:26:18,784 epoch 27 - iter 66/220 - loss 0.50526115 - samples/sec: 120.05
2020-04-02 13:26:37,227 epoch 50 - iter 301/439 - loss 0.57904604 - samples/sec: 168.90
2020-04-02 13:28:18,816 epoch 50 - iter 344/439 - loss 0.58507998 - samples/sec: 172.69
2020-04-02 13:30:02,399 epoch 50 - iter 387/439 - loss 0.58263017 - samples/sec: 159.99
2020-04-02 13:31:49,305 epoch 50 - iter 430/439 - loss 0.58227549 - samples/sec: 163.93
2020-04-02 13:33:38,555 ----------------------------------------------------------------------------------------------------
2020-04-02 13:33:38,555 EPOCH 50 done: loss 0.5825 - lr 0.0050
2020-04-02 13:33:43,201 DEV : loss 0.6565419435501099 - score 0.9373
2020-04-02 13:33:43,300 BAD EPOCHS (no improvement): 0
2020-04-02 13:33:52,165 ----------------------------------------------------------------------------------------------------
2020-04-02 13:34:00,496 epoch 51 - iter 43/439 - loss 0.55916863 - samples/sec: 165.29
2020-04-02 13:35:42,507 epoch 51 - iter 86/439 - loss 0.55847713 - samples/sec: 162.27
2020-04-02 13:36:47,884 epoch 18 - iter 344/439 - loss 0.42662672 - samples/sec: 84.39
2020-04-02 13:37:05,706 epoch 27 - iter 132/220 - loss 0.49521189 - samples/sec: 121.97
2020-04-02 13:37:24,773 epoch 51 - iter 129/439 - loss 0.56814413 - samples/sec: 161.87
2020-04-02 13:39:05,843 epoch 51 - iter 172/439 - loss 0.56287087 - samples/sec: 176.69
2020-04-02 13:40:45,477 epoch 51 - iter 215/439 - loss 0.57272343 - samples/sec: 162.15
2020-04-02 13:41:48,161 epoch 18 - iter 387/439 - loss 0.42584861 - samples/sec: 86.68
2020-04-02 13:42:25,705 epoch 51 - iter 258/439 - loss 0.56417360 - samples/sec: 203.65
2020-04-02 13:44:08,215 epoch 51 - iter 301/439 - loss 0.56751278 - samples/sec: 168.37
2020-04-02 13:45:51,422 epoch 51 - iter 344/439 - loss 0.56744137 - samples/sec: 156.12
2020-04-02 13:46:51,303 epoch 18 - iter 430/439 - loss 0.43250845 - samples/sec: 84.37
2020-04-02 13:47:26,451 epoch 27 - iter 198/220 - loss 0.49531158 - samples/sec: 118.49
2020-04-02 13:47:37,410 epoch 51 - iter 387/439 - loss 0.56902021 - samples/sec: 171.79
2020-04-02 13:49:18,627 epoch 51 - iter 430/439 - loss 0.56876325 - samples/sec: 170.61
2020-04-02 13:50:56,439 ----------------------------------------------------------------------------------------------------
2020-04-02 13:50:56,439 EPOCH 51 done: loss 0.5674 - lr 0.0050
2020-04-02 13:51:01,206 DEV : loss 0.6553439497947693 - score 0.9376
2020-04-02 13:51:01,306 BAD EPOCHS (no improvement): 0
2020-04-02 13:51:10,251 ----------------------------------------------------------------------------------------------------
2020-04-02 13:51:17,577 epoch 52 - iter 43/439 - loss 0.62183307 - samples/sec: 187.97
2020-04-02 13:51:48,984 ----------------------------------------------------------------------------------------------------
2020-04-02 13:51:48,984 EPOCH 18 done: loss 0.4320 - lr 0.0100
2020-04-02 13:52:11,194 DEV : loss 0.5670223832130432 - score 0.9501
2020-04-02 13:52:11,632 BAD EPOCHS (no improvement): 0
2020-04-02 13:52:57,502 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 13:53:14,879 epoch 19 - iter 43/439 - loss 0.38955659 - samples/sec: 79.23
2020-04-02 13:53:27,674 epoch 52 - iter 86/439 - loss 0.58114411 - samples/sec: 167.53
2020-04-02 13:55:11,411 epoch 52 - iter 129/439 - loss 0.56866525 - samples/sec: 174.96
-----------------------------------
2020-04-02 13:54:41,710 EPOCH 27 done: loss 0.5032 - lr 0.0100
2020-04-02 13:54:56,080 DEV : loss 0.6607418656349182 - score 0.9367
Epoch    27: reducing learning rate of group 0 to 5.0000e-03.
2020-04-02 13:54:56,492 BAD EPOCHS (no improvement): 4
2020-04-02 13:54:56,557 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 13:55:07,492 epoch 28 - iter 22/220 - loss 0.46780521 - samples/sec: 128.84
2020-04-02 13:56:51,733 epoch 52 - iter 172/439 - loss 0.57573628 - samples/sec: 167.59
2020-04-02 13:58:24,104 epoch 52 - iter 215/439 - loss 0.57839503 - samples/sec: 170.92
2020-04-02 13:59:09,142 epoch 28 - iter 44/220 - loss 0.47599577 - samples/sec: 124.24
2020-04-02 14:00:24,006 epoch 52 - iter 258/439 - loss 0.57631055 - samples/sec: 169.67
2020-04-02 14:02:04,462 epoch 52 - iter 301/439 - loss 0.57246733 - samples/sec: 172.16
2020-04-02 14:02:35,272 epoch 28 - iter 66/220 - loss 0.48580883 - samples/sec: 121.01
2020-04-02 14:03:28,754 epoch 19 - iter 129/439 - loss 0.39941634 - samples/sec: 94.72
2020-04-02 14:03:43,920 epoch 52 - iter 344/439 - loss 0.57417451 - samples/sec: 173.72
2020-04-02 14:05:22,451 epoch 52 - iter 387/439 - loss 0.56942181 - samples/sec: 243.84
2020-04-02 14:05:54,662 epoch 28 - iter 88/220 - loss 0.47500849 - samples/sec: 122.49
2020-04-02 14:06:59,844 epoch 52 - iter 430/439 - loss 0.57523155 - samples/sec: 169.40
2020-04-02 14:08:35,892 ----------------------------------------------------------------------------------------------------
2020-04-02 14:08:35,893 EPOCH 52 done: loss 0.5750 - lr 0.0050
2020-04-02 14:08:40,676 DEV : loss 0.6544925570487976 - score 0.9363
2020-04-02 14:08:40,771 BAD EPOCHS (no improvement): 1
2020-04-02 14:08:40,817 ----------------------------------------------------------------------------------------------------
2020-04-02 14:08:49,180 epoch 53 - iter 43/439 - loss 0.58820119 - samples/sec: 164.63
2020-04-02 14:09:17,598 epoch 28 - iter 110/220 - loss 0.46445453 - samples/sec: 122.62
2020-04-02 14:10:31,510 epoch 53 - iter 86/439 - loss 0.57870126 - samples/sec: 181.82
2020-04-02 14:12:10,901 epoch 53 - iter 129/439 - loss 0.55383260 - samples/sec: 178.40
2020-04-02 14:12:42,348 epoch 28 - iter 132/220 - loss 0.45831327 - samples/sec: 124.99
2020-04-02 14:13:30,362 epoch 19 - iter 215/439 - loss 0.40338904 - samples/sec: 80.79
2020-04-02 14:13:52,694 epoch 53 - iter 172/439 - loss 0.53684861 - samples/sec: 189.45
2020-04-02 14:15:34,350 epoch 53 - iter 215/439 - loss 0.53679391 - samples/sec: 168.99
2020-04-02 14:16:08,325 epoch 28 - iter 154/220 - loss 0.46230722 - samples/sec: 121.47
2020-04-02 14:17:23,083 epoch 53 - iter 258/439 - loss 0.55095784 - samples/sec: 171.05
2020-04-02 14:18:41,048 epoch 19 - iter 258/439 - loss 0.40116824 - samples/sec: 79.34
2020-04-02 14:19:05,754 epoch 53 - iter 301/439 - loss 0.55719572 - samples/sec: 194.55
2020-04-02 14:19:53,260 epoch 28 - iter 176/220 - loss 0.46700201 - samples/sec: 118.38
2020-04-02 14:21:08,532 epoch 53 - iter 344/439 - loss 0.56092239 - samples/sec: 184.01
2020-04-02 14:22:53,797 epoch 53 - iter 387/439 - loss 0.55933069 - samples/sec: 163.43
2020-04-02 14:23:22,513 epoch 28 - iter 198/220 - loss 0.46925870 - samples/sec: 121.39
2020-04-02 14:24:03,328 epoch 19 - iter 301/439 - loss 0.39602405 - samples/sec: 84.17
2020-04-02 14:24:36,397 epoch 53 - iter 430/439 - loss 0.56017008 - samples/sec: 169.22
2020-04-02 14:26:09,483 ----------------------------------------------------------------------------------------------------
2020-04-02 14:26:09,483 EPOCH 53 done: loss 0.5603 - lr 0.0050
2020-04-02 14:26:14,080 DEV : loss 0.6571458578109741 - score 0.9376
2020-04-02 14:26:14,176 BAD EPOCHS (no improvement): 2
2020-04-02 14:26:23,078 ----------------------------------------------------------------------------------------------------
2020-04-02 14:26:31,215 epoch 54 - iter 43/439 - loss 0.56162480 - samples/sec: 169.24
2020-04-02 14:26:50,714 epoch 28 - iter 220/220 - loss 0.46566387 - samples/sec: 119.13
2020-04-02 14:28:13,493 epoch 54 - iter 86/439 - loss 0.55873569 - samples/sec: 194.38
2020-04-02 14:29:10,388 epoch 19 - iter 344/439 - loss 0.39805316 - samples/sec: 90.89
2020-04-02 14:30:03,276 ----------------------------------------------------------------------------------------------------
2020-04-02 14:30:03,277 EPOCH 28 done: loss 0.4657 - lr 0.0050
2020-04-02 14:30:18,369 DEV : loss 0.6485780477523804 - score 0.938
2020-04-02 14:30:18,763 BAD EPOCHS (no improvement): 0
2020-04-02 14:30:59,099 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 14:31:10,427 epoch 29 - iter 22/220 - loss 0.49204735 - samples/sec: 124.41
2020-04-02 14:31:55,435 epoch 54 - iter 172/439 - loss 0.58641408 - samples/sec: 173.86
2020-04-02 14:33:35,541 epoch 54 - iter 215/439 - loss 0.57434633 - samples/sec: 180.83
2020-04-02 14:34:27,317 epoch 19 - iter 387/439 - loss 0.39949568 - samples/sec: 86.15
2020-04-02 14:34:34,998 epoch 29 - iter 44/220 - loss 0.47242368 - samples/sec: 120.90
2020-04-02 14:35:20,330 epoch 54 - iter 258/439 - loss 0.57167545 - samples/sec: 157.74
2020-04-02 14:37:02,214 epoch 54 - iter 301/439 - loss 0.56787712 - samples/sec: 323.70
2020-04-02 14:38:48,316 epoch 54 - iter 344/439 - loss 0.57171116 - samples/sec: 165.22
2020-04-02 14:39:41,197 epoch 19 - iter 430/439 - loss 0.40786132 - samples/sec: 83.33
2020-04-02 14:40:35,737 epoch 54 - iter 387/439 - loss 0.57070934 - samples/sec: 166.99
2020-04-02 14:42:22,501 epoch 54 - iter 430/439 - loss 0.56587862 - samples/sec: 166.72
2020-04-02 14:44:04,017 ----------------------------------------------------------------------------------------------------
2020-04-02 14:44:04,018 EPOCH 54 done: loss 0.5644 - lr 0.0050
2020-04-02 14:44:09,334 DEV : loss 0.6506288647651672 - score 0.9371
2020-04-02 14:44:09,429 BAD EPOCHS (no improvement): 3
2020-04-02 14:44:09,481 ----------------------------------------------------------------------------------------------------
2020-04-02 14:44:18,147 epoch 55 - iter 43/439 - loss 0.55851767 - samples/sec: 158.89
2020-04-02 14:44:49,404 ----------------------------------------------------------------------------------------------------
2020-04-02 14:44:49,404 EPOCH 19 done: loss 0.4075 - lr 0.0100
2020-04-02 14:45:11,708 DEV : loss 0.5309402346611023 - score 0.9507
2020-04-02 14:45:12,155 BAD EPOCHS (no improvement): 0
2020-04-02 14:45:22,446 epoch 29 - iter 110/220 - loss 0.45518466 - samples/sec: 121.83
2020-04-02 14:46:03,942 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 14:46:21,099 epoch 20 - iter 43/439 - loss 0.38271578 - samples/sec: 80.24
2020-04-02 14:46:32,838 epoch 55 - iter 86/439 - loss 0.56870081 - samples/sec: 174.58
2020-04-02 14:48:23,264 epoch 55 - iter 129/439 - loss 0.55924513 - samples/sec: 164.56
2020-04-02 14:49:29,813 epoch 29 - iter 132/220 - loss 0.45736161 - samples/sec: 123.52
2020-04-02 14:50:11,050 epoch 55 - iter 172/439 - loss 0.55352755 - samples/sec: 180.11
2020-04-02 14:51:55,888 epoch 55 - iter 215/439 - loss 0.54011063 - samples/sec: 174.11
2020-04-02 14:53:01,859 epoch 29 - iter 154/220 - loss 0.46825957 - samples/sec: 123.22
2020-04-02 14:53:38,353 epoch 55 - iter 258/439 - loss 0.53747573 - samples/sec: 154.86
2020-04-02 14:55:25,284 epoch 55 - iter 301/439 - loss 0.53875274 - samples/sec: 291.62
2020-04-02 14:56:39,703 epoch 29 - iter 176/220 - loss 0.46891289 - samples/sec: 111.93
2020-04-02 14:57:11,079 epoch 55 - iter 344/439 - loss 0.54637094 - samples/sec: 180.67
2020-04-02 14:59:01,406 epoch 55 - iter 387/439 - loss 0.54932012 - samples/sec: 158.73
2020-04-02 15:00:52,127 epoch 55 - iter 430/439 - loss 0.55004343 - samples/sec: 184.11
2020-04-02 15:02:36,446 ----------------------------------------------------------------------------------------------------
2020-04-02 15:02:36,446 EPOCH 55 done: loss 0.5479 - lr 0.0050
2020-04-02 15:02:41,232 DEV : loss 0.6548258066177368 - score 0.9384
2020-04-02 15:02:41,329 BAD EPOCHS (no improvement): 0
2020-04-02 15:02:50,388 ----------------------------------------------------------------------------------------------------
2020-04-02 15:02:59,077 epoch 56 - iter 43/439 - loss 0.54529115 - samples/sec: 158.47
2020-04-02 15:04:10,283 epoch 29 - iter 220/220 - loss 0.47681641 - samples/sec: 123.39
2020-04-02 15:04:50,552 epoch 56 - iter 86/439 - loss 0.53658417 - samples/sec: 174.94
2020-04-02 15:06:47,363 epoch 56 - iter 129/439 - loss 0.52257438 - samples/sec: 273.29
2020-04-02 15:07:52,793 ----------------------------------------------------------------------------------------------------
2020-04-02 15:07:52,794 EPOCH 29 done: loss 0.4768 - lr 0.0050
2020-04-02 15:08:11,380 epoch 20 - iter 215/439 - loss 0.39025300 - samples/sec: 81.77
7,630 BAD EPOCHS (no improvement): 1
2020-04-02 15:08:07,704 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 15:08:19,182 epoch 30 - iter 22/220 - loss 0.43015688 - samples/sec: 122.74
2020-04-02 15:08:35,225 epoch 56 - iter 172/439 - loss 0.52793977 - samples/sec: 164.95
2020-04-02 15:10:29,883 epoch 56 - iter 215/439 - loss 0.54883258 - samples/sec: 172.11
2020-04-02 15:12:19,996 epoch 56 - iter 258/439 - loss 0.55021398 - samples/sec: 162.73
2020-04-02 15:14:10,811 epoch 56 - iter 301/439 - loss 0.55404760 - samples/sec: 164.57
2020-04-02 15:15:58,324 epoch 56 - iter 344/439 - loss 0.55037719 - samples/sec: 195.61
2020-04-02 15:17:47,335 epoch 56 - iter 387/439 - loss 0.54099143 - samples/sec: 176.64
2020-04-02 15:19:36,751 epoch 56 - iter 430/439 - loss 0.54353957 - samples/sec: 164.08
020-04-02 15:19:29,342 epoch 30 - iter 88/220 - loss 0.44232443 - samples/sec: 121.39
2020-04-02 15:21:20,181 ----------------------------------------------------------------------------------------------------
2020-04-02 15:21:20,181 EPOCH 56 done: loss 0.5425 - lr 0.0050
2020-04-02 15:21:24,885 DEV : loss 0.6595699191093445 - score 0.937
2020-04-02 15:21:24,980 BAD EPOCHS (no improvement): 1
2020-04-02 15:21:25,029 ----------------------------------------------------------------------------------------------------
2020-04-02 15:21:33,821 epoch 57 - iter 43/439 - loss 0.53346333 - samples/sec: 156.61
2020-04-02 15:23:19,939 epoch 57 - iter 86/439 - loss 0.52670491 - samples/sec: 170.97

2020-04-02 15:24:24,475 epoch 20 - iter 344/439 - loss 0.39582780 - samples/sec: 99.06
2020-04-02 15:25:06,580 epoch 57 - iter 129/439 - loss 0.52540092 - samples/sec: 161.57
2020-04-02 15:26:52,743 epoch 57 - iter 172/439 - loss 0.54628436 - samples/sec: 173.24
2020-04-02 15:28:38,528 epoch 57 - iter 215/439 - loss 0.54178840 - samples/sec: 170.93
2020-04-02 15:29:35,464 epoch 20 - iter 387/439 - loss 0.38949414 - samples/sec: 91.78
2020-04-02 15:30:12,596 epoch 30 - iter 154/220 - loss 0.45850881 - samples/sec: 109.79
2020-04-02 15:30:21,031 epoch 57 - iter 258/439 - loss 0.53665273 - samples/sec: 159.20
2020-04-02 15:32:04,752 epoch 57 - iter 301/439 - loss 0.54320074 - samples/sec: 168.25
2020-04-02 15:33:50,443 epoch 57 - iter 344/439 - loss 0.54696889 - samples/sec: 172.40
2020-04-02 15:34:49,655 epoch 20 - iter 430/439 - loss 0.38664324 - samples/sec: 82.71
2020-04-02 15:35:43,340 epoch 57 - iter 387/439 - loss 0.54948603 - samples/sec: 161.06
2020-04-02 15:37:29,803 epoch 57 - iter 430/439 - loss 0.54774965 - samples/sec: 169.69
2020-04-02 15:39:05,149 ----------------------------------------------------------------------------------------------------
2020-04-02 15:39:05,149 EPOCH 57 done: loss 0.5474 - lr 0.0050
2020-04-02 15:39:09,780 DEV : loss 0.6470632553100586 - score 0.9371
2020-04-02 15:39:09,878 BAD EPOCHS (no improvement): 2
2020-04-02 15:39:09,928 ----------------------------------------------------------------------------------------------------
2020-04-02 15:39:14,100 epoch 58 - iter 43/439 - loss 0.52097127 - samples/sec: 330.10
2020-04-02 15:39:50,935 ----------------------------------------------------------------------------------------------------
2020-04-02 15:39:50,935 EPOCH 20 done: loss 0.3869 - lr 0.0100
2020-04-02 15:40:13,210 DEV : loss 0.5606935620307922 - score 0.9499
2020-04-02 15:40:13,647 BAD EPOCHS (no improvement): 1
2020-04-02 15:40:13,693 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 15:40:30,010 epoch 21 - iter 43/439 - loss 0.32437196 - samples/sec: 84.37
2020-04-02 15:40:56,807 epoch 58 - iter 86/439 - loss 0.49256422 - samples/sec: 163.28

2020-04-02 15:42:43,483 epoch 58 - iter 129/439 - loss 0.51613213 - samples/sec: 163.71
2020-04-02 15:44:30,978 epoch 58 - iter 172/439 - loss 0.51400752 - samples/sec: 165.46
-----------------------------------
2020-04-02 15:44:10,132 EPOCH 30 done: loss 0.4550 - lr 0.0050
2020-04-02 15:44:24,449 DEV : loss 0.6516648530960083 - score 0.9389
2020-04-02 15:44:24,857 BAD EPOCHS (no improvement): 0
2020-04-02 15:45:05,808 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 15:45:17,286 epoch 31 - iter 22/220 - loss 0.43102105 - samples/sec: 122.78
2020-04-02 15:45:51,502 epoch 21 - iter 86/439 - loss 0.33897208 - samples/sec: 78.79
2020-04-02 15:46:31,521 epoch 58 - iter 215/439 - loss 0.52563776 - samples/sec: 166.99
2020-04-02 15:48:10,204 epoch 58 - iter 258/439 - loss 0.52122318 - samples/sec: 174.10
2020-04-02 15:49:18,777 epoch 31 - iter 44/220 - loss 0.47566180 - samples/sec: 125.43
2020-04-02 15:50:05,870 epoch 58 - iter 301/439 - loss 0.51538485 - samples/sec: 162.43
2020-04-02 15:51:14,659 epoch 21 - iter 129/439 - loss 0.35831923 - samples/sec: 82.71
2020-04-02 15:51:52,126 epoch 58 - iter 344/439 - loss 0.52474407 - samples/sec: 154.10
2020-04-02 15:53:02,058 epoch 31 - iter 66/220 - loss 0.47232326 - samples/sec: 119.74
2020-04-02 15:53:51,695 epoch 58 - iter 387/439 - loss 0.52998635 - samples/sec: 162.86
2020-04-02 15:55:41,181 epoch 58 - iter 430/439 - loss 0.53306540 - samples/sec: 175.46
2020-04-02 15:56:42,363 epoch 31 - iter 88/220 - loss 0.45581807 - samples/sec: 110.94
2020-04-02 15:57:19,153 ----------------------------------------------------------------------------------------------------
2020-04-02 15:57:19,153 EPOCH 58 done: loss 0.5370 - lr 0.0050
2020-04-02 15:57:23,869 DEV : loss 0.6464316844940186 - score 0.938
2020-04-02 15:57:23,967 BAD EPOCHS (no improvement): 3
2020-04-02 15:57:24,024 ----------------------------------------------------------------------------------------------------
2020-04-02 15:57:32,050 epoch 59 - iter 43/439 - loss 0.54733605 - samples/sec: 171.55
2020-04-02 15:59:26,405 epoch 59 - iter 86/439 - loss 0.51254581 - samples/sec: 169.69
2020-04-02 16:00:25,792 epoch 31 - iter 110/220 - loss 0.45282924 - samples/sec: 127.67
2020-04-02 16:01:19,038 epoch 59 - iter 129/439 - loss 0.52058879 - samples/sec: 183.24
2020-04-02 16:02:24,099 epoch 21 - iter 215/439 - loss 0.36839732 - samples/sec: 84.27
2020-04-02 16:03:10,736 epoch 59 - iter 172/439 - loss 0.52148120 - samples/sec: 157.94
2020-04-02 16:04:15,597 epoch 31 - iter 132/220 - loss 0.44240508 - samples/sec: 120.55
2020-04-02 16:05:01,959 epoch 59 - iter 215/439 - loss 0.52890947 - samples/sec: 174.18
2020-04-02 16:06:55,752 epoch 59 - iter 258/439 - loss 0.52824385 - samples/sec: 166.47
2020-04-02 16:08:05,180 epoch 31 - iter 154/220 - loss 0.44133536 - samples/sec: 121.80
2020-04-02 16:08:48,769 epoch 59 - iter 301/439 - loss 0.52302302 - samples/sec: 160.96
2020-04-02 16:10:43,637 epoch 59 - iter 344/439 - loss 0.52092137 - samples/sec: 173.40
2020-04-02 16:11:54,724 epoch 31 - iter 176/220 - loss 0.44789329 - samples/sec: 120.59
2020-04-02 16:12:37,484 epoch 59 - iter 387/439 - loss 0.52533894 - samples/sec: 162.10
2020-04-02 16:13:39,835 epoch 21 - iter 301/439 - loss 0.36522222 - samples/sec: 87.23
2020-04-02 16:14:30,250 epoch 59 - iter 430/439 - loss 0.52748143 - samples/sec: 174.51
2020-04-02 16:15:41,880 epoch 31 - iter 198/220 - loss 0.44873432 - samples/sec: 122.04
2020-04-02 16:16:14,008 ----------------------------------------------------------------------------------------------------
2020-04-02 16:16:14,009 EPOCH 59 done: loss 0.5274 - lr 0.0050
2020-04-02 16:16:18,776 DEV : loss 0.6546809077262878 - score 0.9379
Epoch    59: reducing learning rate of group 0 to 2.5000e-03.
2020-04-02 16:16:18,873 BAD EPOCHS (no improvement): 4
2020-04-02 16:16:18,946 ----------------------------------------------------------------------------------------------------
2020-04-02 16:16:26,749 epoch 60 - iter 43/439 - loss 0.52336215 - samples/sec: 176.44
2020-04-02 16:18:19,318 epoch 60 - iter 86/439 - loss 0.55539369 - samples/sec: 243.73
2020-04-02 16:19:28,200 epoch 31 - iter 220/220 - loss 0.44974020 - samples/sec: 122.65
2020-04-02 16:20:02,562 epoch 60 - iter 129/439 - loss 0.53631511 - samples/sec: 294.37
2020-04-02 16:21:51,847 epoch 60 - iter 172/439 - loss 0.55437782 - samples/sec: 158.29
2020-04-02 16:22:54,452 ----------------------------------------------------------------------------------------------------
2020-04-02 16:22:54,453 EPOCH 31 done: loss 0.4497 - lr 0.0050
2020-04-02 16:23:08,834 DEV : loss 0.6427021622657776 - score 0.9391
2020-04-02 16:23:09,240 BAD EPOCHS (no improvement): 0
2020-04-02 16:23:47,877 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 16:23:56,378 epoch 60 - iter 215/439 - loss 0.55177557 - samples/sec: 182.13
2020-04-02 16:23:59,324 epoch 32 - iter 22/220 - loss 0.40844236 - samples/sec: 123.11
2020-04-02 16:24:51,591 epoch 21 - iter 387/439 - loss 0.37008443 - samples/sec: 86.36
2020-04-02 16:25:44,868 epoch 60 - iter 258/439 - loss 0.54927712 - samples/sec: 169.10
2020-04-02 16:28:16,021 epoch 32 - iter 44/220 - loss 0.45604936 - samples/sec: 123.74

2020-04-02 16:30:11,600 epoch 60 - iter 344/439 - loss 0.55332057 - samples/sec: 178.52
2020-04-02 16:31:06,613 epoch 21 - iter 430/439 - loss 0.36862893 - samples/sec: 86.73
2020-04-02 16:31:59,831 epoch 60 - iter 387/439 - loss 0.54438665 - samples/sec: 154.95
2020-04-02 16:32:25,595 epoch 32 - iter 66/220 - loss 0.44646884 - samples/sec: 121.70
2020-04-02 16:33:44,724 epoch 60 - iter 430/439 - loss 0.54153395 - samples/sec: 172.88
2020-04-02 16:35:24,674 ----------------------------------------------------------------------------------------------------
2020-04-02 16:35:24,675 EPOCH 60 done: loss 0.5421 - lr 0.0025
2020-04-02 16:35:29,301 DEV : loss 0.6524718403816223 - score 0.9372
2020-04-02 16:35:29,395 BAD EPOCHS (no improvement): 1
2020-04-02 16:35:29,490 ----------------------------------------------------------------------------------------------------
2020-04-02 16:35:36,672 epoch 61 - iter 43/439 - loss 0.50460027 - samples/sec: 191.72
2020-04-02 16:35:58,066 epoch 32 - iter 88/220 - loss 0.44191194 - samples/sec: 123.34
2020-04-02 16:36:04,581 ----------------------------------------------------------------------------------------------------
2020-04-02 16:36:04,581 EPOCH 21 done: loss 0.3690 - lr 0.0100
2020-04-02 16:36:26,792 DEV : loss 0.5450133681297302 - score 0.9508
2020-04-02 16:36:27,222 BAD EPOCHS (no improvement): 0
2020-04-02 16:37:45,941 epoch 61 - iter 86/439 - loss 0.51809468 - samples/sec: 158.14
------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 16:37:39,706 epoch 22 - iter 43/439 - loss 0.31375418 - samples/sec: 85.97
2020-04-02 16:39:26,637 epoch 61 - iter 129/439 - loss 0.53038544 - samples/sec: 162.27
2020-04-02 16:40:00,932 epoch 32 - iter 110/220 - loss 0.44812027 - samples/sec: 120.93
2020-04-02 16:41:17,554 epoch 61 - iter 172/439 - loss 0.52326309 - samples/sec: 170.39
2020-04-02 16:42:59,618 epoch 61 - iter 215/439 - loss 0.52109389 - samples/sec: 160.66
2020-04-02 16:43:26,553 epoch 32 - iter 132/220 - loss 0.44095086 - samples/sec: 117.38
2020-04-02 16:44:41,911 epoch 61 - iter 258/439 - loss 0.52210753 - samples/sec: 158.85
2020-04-02 16:46:27,303 epoch 61 - iter 301/439 - loss 0.52354603 - samples/sec: 158.12
2020-04-02 16:46:57,071 epoch 32 - iter 154/220 - loss 0.44255944 - samples/sec: 123.76
2020-04-02 16:48:13,282 epoch 61 - iter 344/439 - loss 0.52743419 - samples/sec: 161.43
2020-04-02 16:49:57,670 epoch 61 - iter 387/439 - loss 0.52236654 - samples/sec: 172.65
2020-04-02 16:50:29,876 epoch 32 - iter 176/220 - loss 0.44336161 - samples/sec: 114.72
2020-04-02 16:51:44,340 epoch 61 - iter 430/439 - loss 0.51942096 - samples/sec: 165.45
2020-04-02 16:53:23,289 ----------------------------------------------------------------------------------------------------
2020-04-02 16:53:23,289 EPOCH 61 done: loss 0.5175 - lr 0.0025
2020-04-02 16:53:28,064 DEV : loss 0.6578823924064636 - score 0.9376
2020-04-02 16:53:28,162 BAD EPOCHS (no improvement): 2
2020-04-02 16:53:28,202 ----------------------------------------------------------------------------------------------------
2020-04-02 16:53:36,648 epoch 62 - iter 43/439 - loss 0.49412811 - samples/sec: 163.01
2020-04-02 16:54:05,539 epoch 32 - iter 198/220 - loss 0.44161024 - samples/sec: 123.25
2020-04-02 16:55:27,134 epoch 62 - iter 86/439 - loss 0.48057772 - samples/sec: 161.75
2020-04-02 16:57:14,377 epoch 62 - iter 129/439 - loss 0.49899836 - samples/sec: 167.71
2020-04-02 16:57:40,609 epoch 32 - iter 220/220 - loss 0.44533335 - samples/sec: 125.32
2020-04-02 16:58:39,753 epoch 22 - iter 215/439 - loss 0.35724539 - samples/sec: 78.53
2020-04-02 16:59:02,302 epoch 62 - iter 172/439 - loss 0.50996018 - samples/sec: 167.06
2020-04-02 17:00:52,534 epoch 62 - iter 215/439 - loss 0.50729787 - samples/sec: 161.98
2020-04-02 17:01:09,815 ----------------------------------------------------------------------------------------------------
2020-04-02 17:01:09,815 EPOCH 32 done: loss 0.4453 - lr 0.0050
2020-04-02 17:01:24,264 DEV : loss 0.6446845531463623 - score 0.939
2020-04-02 17:01:24,672 BAD EPOCHS (no improvement): 1
2020-04-02 17:01:24,721 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 17:01:37,338 epoch 33 - iter 22/220 - loss 0.44129029 - samples/sec: 111.65
2020-04-02 17:02:42,858 epoch 62 - iter 258/439 - loss 0.50566125 - samples/sec: 165.21
2020-04-02 17:04:27,114 epoch 62 - iter 301/439 - loss 0.50906022 - samples/sec: 163.25
2020-04-02 17:05:11,690 epoch 33 - iter 44/220 - loss 0.43064440 - samples/sec: 125.25
2020-04-02 17:06:14,356 epoch 62 - iter 344/439 - loss 0.50708052 - samples/sec: 177.44
2020-04-02 17:08:02,482 epoch 62 - iter 387/439 - loss 0.51225243 - samples/sec: 175.39
2020-04-02 17:08:50,656 epoch 33 - iter 66/220 - loss 0.42796336 - samples/sec: 123.09
2020-04-02 17:09:27,144 epoch 22 - iter 301/439 - loss 0.34651270 - samples/sec: 83.81
2020-04-02 17:09:51,044 epoch 62 - iter 430/439 - loss 0.51173630 - samples/sec: 167.34
2020-04-02 17:11:29,485 ----------------------------------------------------------------------------------------------------
2020-04-02 17:11:29,485 EPOCH 62 done: loss 0.5104 - lr 0.0025
2020-04-02 17:11:34,224 DEV : loss 0.6498653888702393 - score 0.9377
2020-04-02 17:11:34,321 BAD EPOCHS (no improvement): 3
2020-04-02 17:11:34,363 ----------------------------------------------------------------------------------------------------
2020-04-02 17:11:42,663 epoch 63 - iter 43/439 - loss 0.44570224 - samples/sec: 165.87
2020-04-02 17:12:19,925 epoch 33 - iter 88/220 - loss 0.43155880 - samples/sec: 117.04
2020-04-02 17:13:24,963 epoch 63 - iter 86/439 - loss 0.50603785 - samples/sec: 152.90
2020-04-02 17:14:31,032 epoch 22 - iter 344/439 - loss 0.34656759 - samples/sec: 84.24
2020-04-02 17:15:01,767 epoch 63 - iter 129/439 - loss 0.51401106 - samples/sec: 259.45
2020-04-02 17:15:40,939 epoch 33 - iter 110/220 - loss 0.42671716 - samples/sec: 120.07
2020-04-02 17:16:41,996 epoch 63 - iter 172/439 - loss 0.52325280 - samples/sec: 167.48
2020-04-02 17:18:24,733 epoch 63 - iter 215/439 - loss 0.51310835 - samples/sec: 176.18
2020-04-02 17:19:07,222 epoch 33 - iter 132/220 - loss 0.43139531 - samples/sec: 119.13
2020-04-02 17:19:32,500 epoch 22 - iter 387/439 - loss 0.35707082 - samples/sec: 81.87
2020-04-02 17:20:06,735 epoch 63 - iter 258/439 - loss 0.52273117 - samples/sec: 179.76
2020-04-02 17:21:48,411 epoch 63 - iter 301/439 - loss 0.51726124 - samples/sec: 158.09
2020-04-02 17:22:32,045 epoch 33 - iter 154/220 - loss 0.43252538 - samples/sec: 119.54
2020-04-02 17:23:28,518 epoch 63 - iter 344/439 - loss 0.51543854 - samples/sec: 183.07
2020-04-02 17:25:06,706 epoch 63 - iter 387/439 - loss 0.50989374 - samples/sec: 179.32
2020-04-02 17:25:59,794 epoch 33 - iter 176/220 - loss 0.42819213 - samples/sec: 122.74
2020-04-02 17:26:55,273 epoch 63 - iter 430/439 - loss 0.51391186 - samples/sec: 157.68
2020-04-02 17:28:28,699 ----------------------------------------------------------------------------------------------------
2020-04-02 17:28:28,700 EPOCH 63 done: loss 0.5119 - lr 0.0025
2020-04-02 17:28:33,464 DEV : loss 0.6545779705047607 - score 0.9379
Epoch    63: reducing learning rate of group 0 to 1.2500e-03.
2020-04-02 17:28:33,561 BAD EPOCHS (no improvement): 4
2020-04-02 17:28:33,623 ----------------------------------------------------------------------------------------------------
2020-04-02 17:28:41,937 epoch 64 - iter 43/439 - loss 0.47176972 - samples/sec: 165.62
2020-04-02 17:29:23,603 epoch 33 - iter 198/220 - loss 0.42973031 - samples/sec: 123.44
-----------------------------------
2020-04-02 17:29:23,442 EPOCH 22 done: loss 0.3591 - lr 0.0100
2020-04-02 17:29:46,194 DEV : loss 0.552781343460083 - score 0.9512
2020-04-02 17:29:46,633 BAD EPOCHS (no improvement): 0
2020-04-02 17:30:49,046 epoch 64 - iter 86/439 - loss 0.48525544 - samples/sec: 167.18
------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 17:30:49,525 epoch 23 - iter 43/439 - loss 0.32909996 - samples/sec: 80.42
2020-04-02 17:32:53,483 epoch 64 - iter 129/439 - loss 0.48960718 - samples/sec: 214.84
2020-04-02 17:33:38,483 epoch 33 - iter 220/220 - loss 0.43245562 - samples/sec: 122.88
2020-04-02 17:34:33,705 epoch 64 - iter 172/439 - loss 0.50835753 - samples/sec: 194.27
2020-04-02 17:36:43,603 ----------------------------------------------------------------------------------------------------
2020-04-02 17:36:43,604 EPOCH 33 done: loss 0.4325 - lr 0.0050
2020-04-02 17:36:57,958 DEV : loss 0.6370768547058105 - score 0.9384
2020-04-02 17:36:58,371 BAD EPOCHS (no improvement): 2
2020-04-02 17:36:58,426 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 17:37:11,478 epoch 34 - iter 22/220 - loss 0.50599365 - samples/sec: 107.93
2020-04-02 17:37:52,898 epoch 64 - iter 258/439 - loss 0.51944381 - samples/sec: 187.03
2020-04-02 17:39:27,287 epoch 64 - iter 301/439 - loss 0.51062613 - samples/sec: 213.03
2020-04-02 17:41:28,355 epoch 23 - iter 129/439 - loss 0.35094151 - samples/sec: 80.67

2020-04-02 17:43:03,370 epoch 64 - iter 387/439 - loss 0.51476622 - samples/sec: 213.51
2020-04-02 17:44:51,504 epoch 64 - iter 430/439 - loss 0.52024007 - samples/sec: 164.40
2020-04-02 17:46:31,728 epoch 23 - iter 172/439 - loss 0.35206175 - samples/sec: 88.99
------------------------------------
2020-04-02 17:46:26,920 EPOCH 64 done: loss 0.5196 - lr 0.0013
2020-04-02 17:46:31,672 DEV : loss 0.651780366897583 - score 0.9373
2020-04-02 17:46:31,771 BAD EPOCHS (no improvement): 1
2020-04-02 17:46:31,855 ----------------------------------------------------------------------------------------------------
2020-04-02 17:46:39,743 epoch 65 - iter 43/439 - loss 0.50754918 - samples/sec: 174.56
2020-04-02 17:48:20,221 epoch 65 - iter 86/439 - loss 0.48514316 - samples/sec: 172.18
2020-04-02 17:49:58,366 epoch 65 - iter 129/439 - loss 0.49880786 - samples/sec: 164.55
2020-04-02 17:51:40,193 epoch 65 - iter 172/439 - loss 0.49799793 - samples/sec: 168.61
2020-04-02 17:53:19,309 epoch 65 - iter 215/439 - loss 0.50484710 - samples/sec: 289.97
2020-04-02 17:54:59,528 epoch 65 - iter 258/439 - loss 0.49314135 - samples/sec: 168.22
2020-04-02 17:56:39,100 epoch 65 - iter 301/439 - loss 0.49916246 - samples/sec: 171.66
2020-04-02 17:58:16,203 epoch 65 - iter 344/439 - loss 0.50337551 - samples/sec: 184.02
2020-04-02 17:59:52,922 epoch 65 - iter 387/439 - loss 0.50229947 - samples/sec: 169.31
2020-04-02 18:01:31,886 epoch 65 - iter 430/439 - loss 0.50590188 - samples/sec: 179.85
2020-04-02 18:03:02,110 ----------------------------------------------------------------------------------------------------
2020-04-02 18:03:02,111 EPOCH 65 done: loss 0.5073 - lr 0.0013
2020-04-02 18:03:07,482 DEV : loss 0.6541504263877869 - score 0.9376
2020-04-02 18:03:07,577 BAD EPOCHS (no improvement): 2
2020-04-02 18:03:07,637 ----------------------------------------------------------------------------------------------------
2020-04-02 18:03:15,602 epoch 66 - iter 43/439 - loss 0.48420237 - samples/sec: 172.87
2020-04-02 18:04:31,417 epoch 34 - iter 198/220 - loss 0.42713992 - samples/sec: 119.84
2020-04-02 18:04:50,606 epoch 66 - iter 86/439 - loss 0.52712268 - samples/sec: 174.46
2020-04-02 18:06:34,070 epoch 66 - iter 129/439 - loss 0.52793306 - samples/sec: 178.22
2020-04-02 18:08:12,502 epoch 66 - iter 172/439 - loss 0.51000691 - samples/sec: 209.14
2020-04-02 18:09:52,590 epoch 66 - iter 215/439 - loss 0.51236619 - samples/sec: 197.29
2020-04-02 18:11:36,099 epoch 66 - iter 258/439 - loss 0.51397935 - samples/sec: 179.06
-----------------------------------
2020-04-02 18:11:09,414 EPOCH 34 done: loss 0.4277 - lr 0.0050
2020-04-02 18:11:23,780 DEV : loss 0.6393803358078003 - score 0.941
2020-04-02 18:11:24,173 BAD EPOCHS (no improvement): 0
2020-04-02 18:12:05,296 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 18:12:16,525 epoch 35 - iter 22/220 - loss 0.40614067 - samples/sec: 125.51
2020-04-02 18:13:56,381 epoch 66 - iter 301/439 - loss 0.50928004 - samples/sec: 167.72
2020-04-02 18:15:55,301 epoch 66 - iter 344/439 - loss 0.51446572 - samples/sec: 179.39
2020-04-02 18:16:47,350 epoch 23 - iter 430/439 - loss 0.34765650 - samples/sec: 83.65
2020-04-02 18:17:36,548 epoch 66 - iter 387/439 - loss 0.50842653 - samples/sec: 173.35
2020-04-02 18:19:52,721 epoch 35 - iter 66/220 - loss 0.43210249 - samples/sec: 126.33

2020-04-02 18:20:44,950 ----------------------------------------------------------------------------------------------------
2020-04-02 18:20:44,950 EPOCH 66 done: loss 0.5026 - lr 0.0013
2020-04-02 18:20:49,606 DEV : loss 0.6539003849029541 - score 0.9377
2020-04-02 18:20:49,703 BAD EPOCHS (no improvement): 3
2020-04-02 18:20:49,770 ----------------------------------------------------------------------------------------------------
2020-04-02 18:20:57,539 epoch 67 - iter 43/439 - loss 0.51362325 - samples/sec: 177.23
2020-04-02 18:21:27,226 ----------------------------------------------------------------------------------------------------
2020-04-02 18:21:27,226 EPOCH 23 done: loss 0.3486 - lr 0.0100
2020-04-02 18:21:49,395 DEV : loss 0.5286727547645569 - score 0.9531
2020-04-02 18:21:49,826 BAD EPOCHS (no improvement): 0
2020-04-02 18:22:35,673 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 18:22:52,126 epoch 24 - iter 43/439 - loss 0.34075570 - samples/sec: 83.68
2020-04-02 18:23:06,023 epoch 67 - iter 86/439 - loss 0.51910835 - samples/sec: 166.61
2020-04-02 18:23:39,839 epoch 35 - iter 88/220 - loss 0.42737704 - samples/sec: 126.94
2020-04-02 18:24:40,027 epoch 67 - iter 129/439 - loss 0.53093430 - samples/sec: 173.41
2020-04-02 18:26:24,536 epoch 67 - iter 172/439 - loss 0.53937868 - samples/sec: 167.00
2020-04-02 18:27:04,317 epoch 35 - iter 110/220 - loss 0.42427827 - samples/sec: 122.38
2020-04-02 18:28:06,599 epoch 67 - iter 215/439 - loss 0.53061033 - samples/sec: 166.68
2020-04-02 18:29:52,962 epoch 67 - iter 258/439 - loss 0.52048643 - samples/sec: 161.71
2020-04-02 18:30:34,726 epoch 35 - iter 132/220 - loss 0.41278578 - samples/sec: 123.29
2020-04-02 18:31:37,392 epoch 67 - iter 301/439 - loss 0.52144785 - samples/sec: 181.30
2020-04-02 18:33:24,430 epoch 67 - iter 344/439 - loss 0.52162649 - samples/sec: 163.86
2020-04-02 18:34:04,365 epoch 35 - iter 154/220 - loss 0.41189598 - samples/sec: 121.08
2020-04-02 18:35:09,043 epoch 67 - iter 387/439 - loss 0.51868471 - samples/sec: 167.94
2020-04-02 18:36:53,972 epoch 67 - iter 430/439 - loss 0.51671990 - samples/sec: 175.83
2020-04-02 18:37:36,342 epoch 35 - iter 176/220 - loss 0.41473909 - samples/sec: 120.80
2020-04-02 18:38:14,956 epoch 24 - iter 172/439 - loss 0.32866172 - samples/sec: 76.97
2020-04-02 18:38:33,001 ----------------------------------------------------------------------------------------------------
2020-04-02 18:38:33,001 EPOCH 67 done: loss 0.5176 - lr 0.0013
2020-04-02 18:38:37,658 DEV : loss 0.6568608283996582 - score 0.9377
Epoch    67: reducing learning rate of group 0 to 6.2500e-04.
2020-04-02 18:38:37,754 BAD EPOCHS (no improvement): 4
2020-04-02 18:38:37,818 ----------------------------------------------------------------------------------------------------
2020-04-02 18:38:46,033 epoch 68 - iter 43/439 - loss 0.54093837 - samples/sec: 167.59
2020-04-02 18:40:34,275 epoch 68 - iter 86/439 - loss 0.52941001 - samples/sec: 178.61
2020-04-02 18:41:08,974 epoch 35 - iter 198/220 - loss 0.41290042 - samples/sec: 124.49
2020-04-02 18:42:14,796 epoch 68 - iter 129/439 - loss 0.51366775 - samples/sec: 166.59
2020-04-02 18:44:00,999 epoch 68 - iter 172/439 - loss 0.51545130 - samples/sec: 161.11
2020-04-02 18:44:37,532 epoch 35 - iter 220/220 - loss 0.41448501 - samples/sec: 122.61
2020-04-02 18:45:46,103 epoch 68 - iter 215/439 - loss 0.51672758 - samples/sec: 173.55
2020-04-02 18:47:32,164 epoch 68 - iter 258/439 - loss 0.51842554 - samples/sec: 169.49
2020-04-02 18:47:58,101 ----------------------------------------------------------------------------------------------------
2020-04-02 18:47:58,101 EPOCH 35 done: loss 0.4145 - lr 0.0050
2020-04-02 18:48:13,323 DEV : loss 0.632704496383667 - score 0.9407
2020-04-02 18:48:13,733 BAD EPOCHS (no improvement): 1
2020-04-02 18:48:13,792 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 18:48:25,161 epoch 36 - iter 22/220 - loss 0.40511919 - samples/sec: 123.92
2020-04-02 18:48:38,252 epoch 24 - iter 258/439 - loss 0.33242347 - samples/sec: 88.32
2020-04-02 18:49:13,746 epoch 68 - iter 301/439 - loss 0.52178402 - samples/sec: 162.50
2020-04-02 18:50:54,792 epoch 68 - iter 344/439 - loss 0.52535869 - samples/sec: 290.65
2020-04-02 18:51:55,430 epoch 36 - iter 44/220 - loss 0.39341936 - samples/sec: 122.24
2020-04-02 18:52:41,651 epoch 68 - iter 387/439 - loss 0.52432095 - samples/sec: 164.27
2020-04-02 18:54:26,398 epoch 68 - iter 430/439 - loss 0.51620625 - samples/sec: 176.35
2020-04-02 18:55:28,474 epoch 36 - iter 66/220 - loss 0.38776427 - samples/sec: 120.45
2020-04-02 18:56:06,760 ----------------------------------------------------------------------------------------------------
2020-04-02 18:56:06,760 EPOCH 68 done: loss 0.5182 - lr 0.0006
2020-04-02 18:56:11,404 DEV : loss 0.6518074870109558 - score 0.9377
2020-04-02 18:56:11,501 BAD EPOCHS (no improvement): 1
2020-04-02 18:56:11,585 ----------------------------------------------------------------------------------------------------
2020-04-02 18:56:18,568 epoch 69 - iter 43/439 - loss 0.50246241 - samples/sec: 197.18
2020-04-02 18:58:07,096 epoch 69 - iter 86/439 - loss 0.47563523 - samples/sec: 165.71
2020-04-02 18:59:14,173 epoch 36 - iter 88/220 - loss 0.39038945 - samples/sec: 130.50
2020-04-02 19:00:02,150 epoch 69 - iter 129/439 - loss 0.50065404 - samples/sec: 176.14
2020-04-02 19:01:45,461 epoch 69 - iter 172/439 - loss 0.49890702 - samples/sec: 164.33
2020-04-02 19:02:43,366 epoch 36 - iter 110/220 - loss 0.39481583 - samples/sec: 121.90
2020-04-02 19:03:25,936 epoch 69 - iter 215/439 - loss 0.50233870 - samples/sec: 169.48
2020-04-02 19:04:12,707 epoch 24 - iter 387/439 - loss 0.32997929 - samples/sec: 82.71
2020-04-02 19:05:07,919 epoch 69 - iter 258/439 - loss 0.49687126 - samples/sec: 169.00
2020-04-02 19:06:17,284 epoch 36 - iter 132/220 - loss 0.40057927 - samples/sec: 120.27
2020-04-02 19:06:58,899 epoch 69 - iter 301/439 - loss 0.49553219 - samples/sec: 166.15
2020-04-02 19:08:42,746 epoch 69 - iter 344/439 - loss 0.50007769 - samples/sec: 159.49
2020-04-02 19:09:26,760 epoch 24 - iter 430/439 - loss 0.32799377 - samples/sec: 81.14
2020-04-02 19:09:43,683 epoch 36 - iter 154/220 - loss 0.40954016 - samples/sec: 124.11
2020-04-02 19:10:24,765 epoch 69 - iter 387/439 - loss 0.50223797 - samples/sec: 164.73
2020-04-02 19:12:07,894 epoch 69 - iter 430/439 - loss 0.50199835 - samples/sec: 170.64
2020-04-02 19:13:13,161 epoch 36 - iter 176/220 - loss 0.40598389 - samples/sec: 123.31
2020-04-02 19:13:46,841 ----------------------------------------------------------------------------------------------------
2020-04-02 19:13:46,841 EPOCH 69 done: loss 0.5014 - lr 0.0006
2020-04-02 19:13:51,597 DEV : loss 0.6554862856864929 - score 0.938
2020-04-02 19:13:51,693 BAD EPOCHS (no improvement): 2
2020-04-02 19:13:51,747 ----------------------------------------------------------------------------------------------------
2020-04-02 19:14:00,424 epoch 70 - iter 43/439 - loss 0.47650370 - samples/sec: 158.66
2020-04-02 19:14:23,599 ----------------------------------------------------------------------------------------------------
2020-04-02 19:14:23,599 EPOCH 24 done: loss 0.3281 - lr 0.0100
2020-04-02 19:14:45,722 DEV : loss 0.5714348554611206 - score 0.9496
2020-04-02 19:14:46,153 BAD EPOCHS (no improvement): 1
2020-04-02 19:14:46,200 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 19:15:02,432 epoch 25 - iter 43/439 - loss 0.31026592 - samples/sec: 84.81
2020-04-02 19:15:39,593 epoch 70 - iter 86/439 - loss 0.48885953 - samples/sec: 169.20
2020-04-02 19:16:39,816 epoch 36 - iter 198/220 - loss 0.40676697 - samples/sec: 121.28
2020-04-02 19:17:23,236 epoch 70 - iter 129/439 - loss 0.52012829 - samples/sec: 212.60
2020-04-02 19:19:07,945 epoch 70 - iter 172/439 - loss 0.50848478 - samples/sec: 163.12
2020-04-02 19:20:11,439 epoch 36 - iter 220/220 - loss 0.40751852 - samples/sec: 119.35
2020-04-02 19:20:51,360 epoch 70 - iter 215/439 - loss 0.50617401 - samples/sec: 163.38
2020-04-02 19:22:37,839 epoch 70 - iter 258/439 - loss 0.50123892 - samples/sec: 164.48
2020-04-02 19:23:34,160 ----------------------------------------------------------------------------------------------------
2020-04-02 19:23:34,160 EPOCH 36 done: loss 0.4075 - lr 0.0050
2020-04-02 19:23:49,259 DEV : loss 0.6302979588508606 - score 0.9411
2020-04-02 19:23:49,654 BAD EPOCHS (no improvement): 0
2020-04-02 19:24:33,368 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 19:24:45,048 epoch 37 - iter 22/220 - loss 0.35879464 - samples/sec: 120.67
2020-04-02 19:25:44,217 epoch 25 - iter 129/439 - loss 0.30133411 - samples/sec: 83.36
2020-04-02 19:26:23,294 epoch 70 - iter 344/439 - loss 0.50051774 - samples/sec: 169.19
2020-04-02 19:28:19,156 epoch 37 - iter 44/220 - loss 0.36833363 - samples/sec: 127.17

2020-04-02 19:29:58,055 epoch 70 - iter 430/439 - loss 0.50038908 - samples/sec: 166.34
2020-04-02 19:31:01,778 epoch 25 - iter 172/439 - loss 0.29377707 - samples/sec: 81.07
2020-04-02 19:31:39,565 ----------------------------------------------------------------------------------------------------
2020-04-02 19:31:39,565 EPOCH 70 done: loss 0.5010 - lr 0.0006
2020-04-02 19:31:44,242 DEV : loss 0.654689371585846 - score 0.938
2020-04-02 19:31:44,341 BAD EPOCHS (no improvement): 3
2020-04-02 19:31:44,375 ----------------------------------------------------------------------------------------------------
2020-04-02 19:31:51,965 epoch 71 - iter 43/439 - loss 0.45567892 - samples/sec: 181.40
2020-04-02 19:31:54,842 epoch 37 - iter 66/220 - loss 0.38942020 - samples/sec: 121.20
2020-04-02 19:33:40,957 epoch 71 - iter 86/439 - loss 0.45345980 - samples/sec: 172.77
2020-04-02 19:35:34,598 epoch 37 - iter 88/220 - loss 0.40296595 - samples/sec: 124.37

2020-04-02 19:36:24,009 epoch 25 - iter 215/439 - loss 0.29555334 - samples/sec: 85.90
2020-04-02 19:37:22,121 epoch 71 - iter 172/439 - loss 0.48241067 - samples/sec: 181.04
2020-04-02 19:39:17,484 epoch 37 - iter 110/220 - loss 0.41280790 - samples/sec: 120.23
2020-04-02 19:40:58,873 epoch 71 - iter 258/439 - loss 0.48504977 - samples/sec: 169.35
2020-04-02 19:41:41,856 epoch 25 - iter 258/439 - loss 0.30117364 - samples/sec: 97.31
2020-04-02 19:42:40,915 epoch 71 - iter 301/439 - loss 0.49155612 - samples/sec: 163.48
2020-04-02 19:42:46,205 epoch 37 - iter 132/220 - loss 0.41548103 - samples/sec: 121.73
2020-04-02 19:44:23,247 epoch 71 - iter 344/439 - loss 0.49701005 - samples/sec: 160.19
2020-04-02 19:46:31,438 epoch 37 - iter 154/220 - loss 0.41918159 - samples/sec: 118.05
2020-04-02 19:47:01,249 epoch 25 - iter 301/439 - loss 0.30688125 - samples/sec: 80.27
2020-04-02 19:48:09,447 epoch 71 - iter 430/439 - loss 0.49671916 - samples/sec: 174.82
2020-04-02 19:50:03,632 epoch 37 - iter 176/220 - loss 0.41135547 - samples/sec: 112.15
-----------------------------------
2020-04-02 19:49:48,426 EPOCH 71 done: loss 0.4974 - lr 0.0006
2020-04-02 19:49:53,128 DEV : loss 0.6571632027626038 - score 0.9378
Epoch    71: reducing learning rate of group 0 to 3.1250e-04.
2020-04-02 19:49:53,223 BAD EPOCHS (no improvement): 4
2020-04-02 19:49:53,288 ----------------------------------------------------------------------------------------------------
2020-04-02 19:50:01,273 epoch 72 - iter 43/439 - loss 0.52784592 - samples/sec: 172.46
2020-04-02 19:51:47,621 epoch 72 - iter 86/439 - loss 0.53692128 - samples/sec: 171.13
2020-04-02 19:52:13,475 epoch 25 - iter 344/439 - loss 0.31222183 - samples/sec: 78.74
2020-04-02 19:53:36,688 epoch 37 - iter 198/220 - loss 0.40915046 - samples/sec: 119.46
2020-04-02 19:55:18,349 epoch 72 - iter 172/439 - loss 0.52287683 - samples/sec: 181.80
2020-04-02 19:57:03,105 epoch 37 - iter 220/220 - loss 0.40609128 - samples/sec: 121.06
2020-04-02 19:57:16,484 epoch 25 - iter 387/439 - loss 0.30864740 - samples/sec: 87.19
2020-04-02 19:58:46,168 epoch 72 - iter 258/439 - loss 0.50653158 - samples/sec: 174.82
2020-04-02 20:00:28,369 epoch 72 - iter 301/439 - loss 0.50365658 - samples/sec: 177.03
-----------------------------------
2020-04-02 20:00:23,216 EPOCH 37 done: loss 0.4061 - lr 0.0050
2020-04-02 20:00:37,616 DEV : loss 0.6472018361091614 - score 0.9404
2020-04-02 20:00:38,027 BAD EPOCHS (no improvement): 1
2020-04-02 20:00:38,097 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 20:00:49,570 epoch 38 - iter 22/220 - loss 0.36440867 - samples/sec: 122.80
2020-04-02 20:02:28,700 epoch 25 - iter 430/439 - loss 0.30800512 - samples/sec: 86.09

2020-04-02 20:03:53,262 epoch 72 - iter 387/439 - loss 0.50430310 - samples/sec: 164.24
2020-04-02 20:04:54,150 epoch 38 - iter 44/220 - loss 0.38353694 - samples/sec: 118.71
2020-04-02 20:05:33,792 epoch 72 - iter 430/439 - loss 0.50688520 - samples/sec: 159.38
2020-04-02 20:07:17,184 ----------------------------------------------------------------------------------------------------
2020-04-02 20:07:17,184 EPOCH 25 done: loss 0.3076 - lr 0.0100
2020-04-02 20:07:12,478 DEV : loss 0.6538199782371521 - score 0.938
2020-04-02 20:07:12,573 BAD EPOCHS (no improvement): 1
2020-04-02 20:07:12,634 ----------------------------------------------------------------------------------------------------
2020-04-02 20:07:20,738 epoch 73 - iter 43/439 - loss 0.49097503 - samples/sec: 169.91
2020-04-02 20:07:39,342 DEV : loss 0.5365236401557922 - score 0.9533
2020-04-02 20:07:39,778 BAD EPOCHS (no improvement): 0
2020-04-02 20:08:33,194 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 20:08:50,737 epoch 26 - iter 43/439 - loss 0.35152804 - samples/sec: 78.47
2020-04-02 20:09:31,411 epoch 73 - iter 86/439 - loss 0.52544612 - samples/sec: 157.78
2020-04-02 20:11:11,649 epoch 73 - iter 129/439 - loss 0.50756914 - samples/sec: 213.71
2020-04-02 20:12:00,210 epoch 38 - iter 88/220 - loss 0.38986845 - samples/sec: 119.92
2020-04-02 20:12:52,564 epoch 73 - iter 172/439 - loss 0.49917902 - samples/sec: 165.44
2020-04-02 20:13:50,245 epoch 26 - iter 86/439 - loss 0.31123248 - samples/sec: 83.26
2020-04-02 20:14:36,007 epoch 73 - iter 215/439 - loss 0.49970183 - samples/sec: 161.39
2020-04-02 20:15:22,254 epoch 38 - iter 110/220 - loss 0.39295949 - samples/sec: 123.59
2020-04-02 20:16:14,519 epoch 73 - iter 258/439 - loss 0.49815034 - samples/sec: 165.95
2020-04-02 20:17:55,326 epoch 73 - iter 301/439 - loss 0.50064342 - samples/sec: 170.33
2020-04-02 20:18:45,874 epoch 26 - iter 129/439 - loss 0.32317127 - samples/sec: 91.92

2020-04-02 20:19:39,031 epoch 73 - iter 344/439 - loss 0.49481057 - samples/sec: 163.47
2020-04-02 20:21:21,842 epoch 73 - iter 387/439 - loss 0.48876152 - samples/sec: 177.33
2020-04-02 20:22:16,906 epoch 38 - iter 154/220 - loss 0.39352838 - samples/sec: 124.21
2020-04-02 20:23:07,371 epoch 73 - iter 430/439 - loss 0.49009009 - samples/sec: 176.16
2020-04-02 20:23:56,961 epoch 26 - iter 172/439 - loss 0.30313883 - samples/sec: 81.75
2020-04-02 20:24:48,284 ----------------------------------------------------------------------------------------------------
2020-04-02 20:24:48,285 EPOCH 73 done: loss 0.4879 - lr 0.0003
2020-04-02 20:24:53,063 DEV : loss 0.6550470590591431 - score 0.9381
2020-04-02 20:24:53,160 BAD EPOCHS (no improvement): 2
2020-04-02 20:24:53,196 ----------------------------------------------------------------------------------------------------
2020-04-02 20:25:01,902 epoch 74 - iter 43/439 - loss 0.52793111 - samples/sec: 158.14
2020-04-02 20:25:49,830 epoch 38 - iter 176/220 - loss 0.39369327 - samples/sec: 111.11
2020-04-02 20:26:45,076 epoch 74 - iter 86/439 - loss 0.53452304 - samples/sec: 177.53
2020-04-02 20:28:29,087 epoch 74 - iter 129/439 - loss 0.50178499 - samples/sec: 159.01
2020-04-02 20:29:10,337 epoch 26 - iter 215/439 - loss 0.29647864 - samples/sec: 88.07
2020-04-02 20:29:22,259 epoch 38 - iter 198/220 - loss 0.39562352 - samples/sec: 117.86
2020-04-02 20:30:18,212 epoch 74 - iter 172/439 - loss 0.49995655 - samples/sec: 152.78
2020-04-02 20:32:07,735 epoch 74 - iter 215/439 - loss 0.49796553 - samples/sec: 162.59
2020-04-02 20:33:07,698 epoch 38 - iter 220/220 - loss 0.39877313 - samples/sec: 119.83
2020-04-02 20:34:06,037 epoch 74 - iter 258/439 - loss 0.49314646 - samples/sec: 163.58
2020-04-02 20:34:40,954 epoch 26 - iter 258/439 - loss 0.29631891 - samples/sec: 83.38
2020-04-02 20:35:50,935 epoch 74 - iter 301/439 - loss 0.49190501 - samples/sec: 173.34
2020-04-02 20:36:28,100 ----------------------------------------------------------------------------------------------------
2020-04-02 20:36:28,100 EPOCH 38 done: loss 0.3988 - lr 0.0050
2020-04-02 20:36:42,452 DEV : loss 0.632810115814209 - score 0.9425
2020-04-02 20:36:42,858 BAD EPOCHS (no improvement): 0
2020-04-02 20:37:15,069 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 20:37:26,329 epoch 39 - iter 22/220 - loss 0.40433416 - samples/sec: 125.15
2020-04-02 20:37:53,265 epoch 74 - iter 344/439 - loss 0.48502699 - samples/sec: 161.60
2020-04-02 20:39:39,599 epoch 74 - iter 387/439 - loss 0.48496139 - samples/sec: 168.33
2020-04-02 20:40:09,644 epoch 26 - iter 301/439 - loss 0.30159808 - samples/sec: 81.81
2020-04-02 20:40:53,253 epoch 39 - iter 44/220 - loss 0.39125751 - samples/sec: 131.40
2020-04-02 20:41:17,604 epoch 74 - iter 430/439 - loss 0.49482919 - samples/sec: 296.68
2020-04-02 20:42:55,131 ----------------------------------------------------------------------------------------------------
2020-04-02 20:42:55,132 EPOCH 74 done: loss 0.4956 - lr 0.0003
2020-04-02 20:43:00,114 DEV : loss 0.6551597118377686 - score 0.9382
2020-04-02 20:43:00,231 BAD EPOCHS (no improvement): 3
2020-04-02 20:43:00,302 ----------------------------------------------------------------------------------------------------
2020-04-02 20:43:07,673 epoch 75 - iter 43/439 - loss 0.47452475 - samples/sec: 186.80
2020-04-02 20:44:22,293 epoch 39 - iter 66/220 - loss 0.38304397 - samples/sec: 118.29
2020-04-02 20:44:51,522 epoch 75 - iter 86/439 - loss 0.49905924 - samples/sec: 164.15
2020-04-02 20:45:15,039 epoch 26 - iter 344/439 - loss 0.30202928 - samples/sec: 81.37
2020-04-02 20:46:32,115 epoch 75 - iter 129/439 - loss 0.49414256 - samples/sec: 174.56
2020-04-02 20:48:12,791 epoch 75 - iter 172/439 - loss 0.50236869 - samples/sec: 170.45
2020-04-02 20:49:58,599 epoch 75 - iter 215/439 - loss 0.50642448 - samples/sec: 169.19
2020-04-02 20:50:17,928 epoch 26 - iter 387/439 - loss 0.29748497 - samples/sec: 85.84
2020-04-02 20:51:15,893 epoch 39 - iter 110/220 - loss 0.40057846 - samples/sec: 118.10
2020-04-02 20:51:40,824 epoch 75 - iter 258/439 - loss 0.49125296 - samples/sec: 160.84
2020-04-02 20:53:23,379 epoch 75 - iter 301/439 - loss 0.48871153 - samples/sec: 157.45
2020-04-02 20:55:02,985 epoch 75 - iter 344/439 - loss 0.48985347 - samples/sec: 165.89
2020-04-02 20:55:17,443 epoch 26 - iter 430/439 - loss 0.29451655 - samples/sec: 83.88
2020-04-02 20:56:47,586 epoch 75 - iter 387/439 - loss 0.48414953 - samples/sec: 164.85
2020-04-02 20:58:34,972 epoch 75 - iter 430/439 - loss 0.49015084 - samples/sec: 151.48
2020-04-02 21:00:17,846 ----------------------------------------------------------------------------------------------------
2020-04-02 21:00:17,846 EPOCH 26 done: loss 0.2946 - lr 0.0100
2020-04-02 21:00:17,469 DEV : loss 0.6548476815223694 - score 0.938
Epoch    75: reducing learning rate of group 0 to 1.5625e-04.
2020-04-02 21:00:17,563 BAD EPOCHS (no improvement): 4
2020-04-02 21:00:17,598 ----------------------------------------------------------------------------------------------------
2020-04-02 21:00:25,443 epoch 76 - iter 43/439 - loss 0.53593493 - samples/sec: 175.50
2020-04-02 21:00:40,075 DEV : loss 0.5543223023414612 - score 0.952
2020-04-02 21:00:40,509 BAD EPOCHS (no improvement): 1
2020-04-02 21:00:40,590 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 21:00:56,649 epoch 27 - iter 43/439 - loss 0.32418615 - samples/sec: 85.72
2020-04-02 21:01:37,617 epoch 39 - iter 176/220 - loss 0.38737929 - samples/sec: 120.90
2020-04-02 21:02:09,289 epoch 76 - iter 86/439 - loss 0.51709277 - samples/sec: 156.84
2020-04-02 21:03:55,885 epoch 76 - iter 129/439 - loss 0.51946385 - samples/sec: 170.09
2020-04-02 21:05:38,471 epoch 76 - iter 172/439 - loss 0.51829082 - samples/sec: 283.00
2020-04-02 21:06:12,083 epoch 27 - iter 86/439 - loss 0.30356413 - samples/sec: 82.26
2020-04-02 21:07:26,938 epoch 76 - iter 215/439 - loss 0.51309869 - samples/sec: 177.46
2020-04-02 21:09:10,780 epoch 76 - iter 258/439 - loss 0.50260919 - samples/sec: 169.75
2020-04-02 21:11:23,677 epoch 27 - iter 129/439 - loss 0.28812687 - samples/sec: 83.98

2020-04-02 21:12:06,491 ----------------------------------------------------------------------------------------------------
2020-04-02 21:12:06,491 EPOCH 39 done: loss 0.3916 - lr 0.0050
2020-04-02 21:12:20,538 DEV : loss 0.645031750202179 - score 0.9412
2020-04-02 21:12:20,931 BAD EPOCHS (no improvement): 1
2020-04-02 21:12:20,996 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 21:12:32,300 epoch 40 - iter 22/220 - loss 0.38452754 - samples/sec: 124.63
2020-04-02 21:12:41,520 epoch 76 - iter 344/439 - loss 0.51340955 - samples/sec: 166.38
2020-04-02 21:14:23,311 epoch 76 - iter 387/439 - loss 0.50777814 - samples/sec: 218.35
2020-04-02 21:16:39,135 epoch 27 - iter 172/439 - loss 0.29101295 - samples/sec: 80.14

2020-04-02 21:17:48,107 ----------------------------------------------------------------------------------------------------
2020-04-02 21:17:48,107 EPOCH 76 done: loss 0.5066 - lr 0.0002
2020-04-02 21:17:52,766 DEV : loss 0.6547896862030029 - score 0.9378
2020-04-02 21:17:52,860 BAD EPOCHS (no improvement): 1
2020-04-02 21:17:52,923 ----------------------------------------------------------------------------------------------------
2020-04-02 21:17:59,654 epoch 77 - iter 43/439 - loss 0.46425006 - samples/sec: 204.56
2020-04-02 21:19:48,421 epoch 40 - iter 66/220 - loss 0.38438170 - samples/sec: 118.74
2020-04-02 21:19:58,524 epoch 77 - iter 86/439 - loss 0.46990666 - samples/sec: 161.39
2020-04-02 21:21:51,521 epoch 77 - iter 129/439 - loss 0.48064519 - samples/sec: 162.45
2020-04-02 21:22:12,764 epoch 27 - iter 215/439 - loss 0.28868205 - samples/sec: 85.23
2020-04-02 21:23:39,164 epoch 77 - iter 172/439 - loss 0.47948581 - samples/sec: 182.98
2020-04-02 21:25:31,272 epoch 77 - iter 215/439 - loss 0.49705964 - samples/sec: 170.60
2020-04-02 21:27:20,712 epoch 77 - iter 258/439 - loss 0.49701160 - samples/sec: 163.06
2020-04-02 21:27:39,317 epoch 27 - iter 258/439 - loss 0.28893371 - samples/sec: 81.31
2020-04-02 21:29:09,489 epoch 77 - iter 301/439 - loss 0.49837249 - samples/sec: 179.69
2020-04-02 21:30:57,977 epoch 40 - iter 132/220 - loss 0.37857858 - samples/sec: 123.81
2020-04-02 21:32:49,148 epoch 77 - iter 387/439 - loss 0.49535011 - samples/sec: 170.61
2020-04-02 21:33:05,695 epoch 27 - iter 301/439 - loss 0.28725109 - samples/sec: 82.73
2020-04-02 21:34:41,531 epoch 77 - iter 430/439 - loss 0.49344361 - samples/sec: 159.75
2020-04-02 21:36:24,826 ----------------------------------------------------------------------------------------------------
2020-04-02 21:36:24,827 EPOCH 77 done: loss 0.4943 - lr 0.0002
2020-04-02 21:36:29,607 DEV : loss 0.6542506217956543 - score 0.9375
2020-04-02 21:36:29,704 BAD EPOCHS (no improvement): 2
2020-04-02 21:36:29,755 ----------------------------------------------------------------------------------------------------
2020-04-02 21:36:36,843 epoch 78 - iter 43/439 - loss 0.50185518 - samples/sec: 194.24
2020-04-02 21:38:30,108 epoch 78 - iter 86/439 - loss 0.50641689 - samples/sec: 175.15

2020-04-02 21:38:35,224 epoch 27 - iter 344/439 - loss 0.28874568 - samples/sec: 84.78
2020-04-02 21:40:20,144 epoch 78 - iter 129/439 - loss 0.49893667 - samples/sec: 177.13
2020-04-02 21:42:04,860 epoch 40 - iter 198/220 - loss 0.38079456 - samples/sec: 118.60
2020-04-02 21:42:11,576 epoch 78 - iter 172/439 - loss 0.49725244 - samples/sec: 165.57
2020-04-02 21:44:05,006 epoch 27 - iter 387/439 - loss 0.29090998 - samples/sec: 85.16

2020-04-02 21:45:49,165 epoch 78 - iter 258/439 - loss 0.49480368 - samples/sec: 173.94
2020-04-02 21:47:38,257 epoch 78 - iter 301/439 - loss 0.48724488 - samples/sec: 170.83
2020-04-02 21:49:20,308 epoch 78 - iter 344/439 - loss 0.48973859 - samples/sec: 171.54
-----------------------------------
2020-04-02 21:49:03,378 EPOCH 40 done: loss 0.3812 - lr 0.0050
2020-04-02 21:49:17,581 DEV : loss 0.6355410814285278 - score 0.9406
2020-04-02 21:49:17,978 BAD EPOCHS (no improvement): 2
2020-04-02 21:49:17,990 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 21:49:18,195 epoch 27 - iter 430/439 - loss 0.29228448 - samples/sec: 82.90
2020-04-02 21:49:28,282 epoch 41 - iter 22/220 - loss 0.34163722 - samples/sec: 136.89
2020-04-02 21:51:03,323 epoch 78 - iter 387/439 - loss 0.49019415 - samples/sec: 170.92
2020-04-02 21:52:56,657 epoch 41 - iter 44/220 - loss 0.36963499 - samples/sec: 120.53

2020-04-02 21:54:06,052 ----------------------------------------------------------------------------------------------------
2020-04-02 21:54:06,053 EPOCH 27 done: loss 0.2923 - lr 0.0100
2020-04-02 21:54:29,344 DEV : loss 0.5487464070320129 - score 0.9514
2020-04-02 21:54:29,785 BAD EPOCHS (no improvement): 2
2020-04-02 21:54:29,852 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
20-04-02 21:54:32,136 ----------------------------------------------------------------------------------------------------
2020-04-02 21:54:39,976 epoch 79 - iter 43/439 - loss 0.44665377 - samples/sec: 175.64
2020-04-02 21:54:45,969 epoch 28 - iter 43/439 - loss 0.25856184 - samples/sec: 85.42
2020-04-02 21:56:28,647 epoch 79 - iter 86/439 - loss 0.44495319 - samples/sec: 162.02
2020-04-02 21:58:18,572 epoch 79 - iter 129/439 - loss 0.48100894 - samples/sec: 163.15
2020-04-02 22:00:06,343 epoch 79 - iter 172/439 - loss 0.48711017 - samples/sec: 153.95
2020-04-02 22:01:55,344 epoch 79 - iter 215/439 - loss 0.48800558 - samples/sec: 165.32
2020-04-02 22:03:52,659 epoch 41 - iter 110/220 - loss 0.37167111 - samples/sec: 118.55
2020-04-02 22:05:25,461 epoch 28 - iter 129/439 - loss 0.26691447 - samples/sec: 83.10
2020-04-02 22:05:51,468 epoch 79 - iter 301/439 - loss 0.49512245 - samples/sec: 166.76
2020-04-02 22:07:49,130 epoch 41 - iter 132/220 - loss 0.37632663 - samples/sec: 123.77
2020-04-02 22:09:30,194 epoch 79 - iter 387/439 - loss 0.49440638 - samples/sec: 164.04
2020-04-02 22:10:41,249 epoch 28 - iter 172/439 - loss 0.27368948 - samples/sec: 83.92
2020-04-02 22:11:31,523 epoch 41 - iter 154/220 - loss 0.37361411 - samples/sec: 122.58
2020-04-02 22:13:03,139 ----------------------------------------------------------------------------------------------------
2020-04-02 22:13:03,140 EPOCH 79 done: loss 0.4960 - lr 0.0002
2020-04-02 22:13:07,898 DEV : loss 0.654213547706604 - score 0.9375
Epoch    79: reducing learning rate of group 0 to 7.8125e-05.
2020-04-02 22:13:07,995 BAD EPOCHS (no improvement): 4
2020-04-02 22:13:08,060 ----------------------------------------------------------------------------------------------------
2020-04-02 22:13:08,060 ----------------------------------------------------------------------------------------------------
2020-04-02 22:13:08,060 learning rate too small - quitting training!
2020-04-02 22:13:08,060 ----------------------------------------------------------------------------------------------------
2020-04-02 22:13:15,984 ----------------------------------------------------------------------------------------------------
2020-04-02 22:13:15,984 Testing using best model ...
2020-04-02 22:13:15,987 loading file log/bert_20200401215932_64/best-model.pt
2020-04-02 22:13:27,447 0.9013	0.9017	0.9015
2020-04-02 22:13:27,447 
MICRO_AVG: acc 0.8207 - f1-score 0.9015
MACRO_AVG: acc 0.8004 - f1-score 0.885475
LOC        tp: 1531 - fp: 153 - fn: 137 - tn: 1531 - precision: 0.9091 - recall: 0.9179 - accuracy: 0.8407 - f1-score: 0.9135
MISC       tp: 551 - fp: 145 - fn: 151 - tn: 551 - precision: 0.7917 - recall: 0.7849 - accuracy: 0.6505 - f1-score: 0.7883
ORG        tp: 1451 - fp: 204 - fn: 210 - tn: 1451 - precision: 0.8767 - recall: 0.8736 - accuracy: 0.7780 - f1-score: 0.8751
PER        tp: 1560 - fp: 56 - fn: 57 - tn: 1560 - precision: 0.9653 - recall: 0.9647 - accuracy: 0.9325 - f1-score: 0.9650
2020-04-02 22:13:27,447 ----------------------------------------------------------------------------------------------------
2020-04-02 22:15:39,541 epoch 28 - iter 215/439 - loss 0.27230737 - samples/sec: 88.27

2020-04-02 22:18:53,095 epoch 41 - iter 198/220 - loss 0.37312659 - samples/sec: 122.96
2020-04-02 22:20:41,796 epoch 28 - iter 258/439 - loss 0.27102511 - samples/sec: 84.27
2020-04-02 22:22:27,420 epoch 41 - iter 220/220 - loss 0.37052772 - samples/sec: 124.93
2020-04-02 22:25:50,165 ----------------------------------------------------------------------------------------------------
2020-04-02 22:25:50,166 EPOCH 41 done: loss 0.3705 - lr 0.0050
2020-04-02 22:26:04,435 DEV : loss 0.6373939514160156 - score 0.9421
2020-04-02 22:26:04,831 BAD EPOCHS (no improvement): 3
2020-04-02 22:26:04,857 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 22:26:16,526 epoch 42 - iter 22/220 - loss 0.39826739 - samples/sec: 120.73
2020-04-02 22:29:54,932 epoch 28 - iter 344/439 - loss 0.27831631 - samples/sec: 83.04
2020-04-02 22:33:24,110 epoch 42 - iter 66/220 - loss 0.36091860 - samples/sec: 119.09
2020-04-02 22:35:16,420 epoch 28 - iter 387/439 - loss 0.28207174 - samples/sec: 82.11
2020-04-02 22:37:01,572 epoch 42 - iter 88/220 - loss 0.36684754 - samples/sec: 121.41
2020-04-02 22:40:41,858 epoch 42 - iter 110/220 - loss 0.36369100 - samples/sec: 109.61
2020-04-02 22:44:17,760 epoch 42 - iter 132/220 - loss 0.37067518 - samples/sec: 128.52
2020-04-02 22:45:41,618 ----------------------------------------------------------------------------------------------------
2020-04-02 22:45:41,618 EPOCH 28 done: loss 0.2799 - lr 0.0100
2020-04-02 22:46:03,955 DEV : loss 0.5432841777801514 - score 0.9559
2020-04-02 22:46:04,395 BAD EPOCHS (no improvement): 0
2020-04-02 22:47:02,697 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 22:47:19,834 epoch 29 - iter 43/439 - loss 0.28918027 - samples/sec: 80.35
2020-04-02 22:47:27,214 epoch 42 - iter 154/220 - loss 0.37227483 - samples/sec: 132.44
2020-04-02 22:51:09,848 epoch 42 - iter 176/220 - loss 0.37125998 - samples/sec: 120.67
2020-04-02 22:52:52,425 epoch 29 - iter 86/439 - loss 0.26418197 - samples/sec: 84.99
2020-04-02 22:54:51,153 epoch 42 - iter 198/220 - loss 0.36737009 - samples/sec: 120.16
2020-04-02 22:58:27,644 epoch 42 - iter 220/220 - loss 0.37373299 - samples/sec: 120.50
2020-04-02 23:03:17,671 epoch 29 - iter 172/439 - loss 0.26366785 - samples/sec: 91.14
------------------------------------
2020-04-02 23:02:34,965 EPOCH 42 done: loss 0.3737 - lr 0.0050
2020-04-02 23:02:49,371 DEV : loss 0.6297463774681091 - score 0.9419
Epoch    42: reducing learning rate of group 0 to 2.5000e-03.
2020-04-02 23:02:49,781 BAD EPOCHS (no improvement): 4
2020-04-02 23:02:49,818 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 23:03:01,013 epoch 43 - iter 22/220 - loss 0.36036608 - samples/sec: 125.85
2020-04-02 23:06:38,261 epoch 43 - iter 44/220 - loss 0.35118759 - samples/sec: 132.67
2020-04-02 23:08:45,825 epoch 29 - iter 215/439 - loss 0.26720001 - samples/sec: 80.49
2020-04-02 23:09:59,011 epoch 43 - iter 66/220 - loss 0.36500263 - samples/sec: 121.50
2020-04-02 23:13:43,688 epoch 43 - iter 88/220 - loss 0.36887955 - samples/sec: 120.39
2020-04-02 23:14:03,819 epoch 29 - iter 258/439 - loss 0.26810221 - samples/sec: 91.25
2020-04-02 23:17:14,067 epoch 43 - iter 110/220 - loss 0.37375590 - samples/sec: 113.91
2020-04-02 23:19:21,031 epoch 29 - iter 301/439 - loss 0.26966043 - samples/sec: 92.58
2020-04-02 23:20:51,888 epoch 43 - iter 132/220 - loss 0.36771050 - samples/sec: 122.35
2020-04-02 23:24:32,577 epoch 29 - iter 344/439 - loss 0.27686968 - samples/sec: 81.33

2020-04-02 23:28:00,117 epoch 43 - iter 176/220 - loss 0.36962413 - samples/sec: 128.81
2020-04-02 23:29:48,526 epoch 29 - iter 387/439 - loss 0.27638530 - samples/sec: 85.11
2020-04-02 23:31:23,448 epoch 43 - iter 198/220 - loss 0.37565752 - samples/sec: 122.31
2020-04-02 23:34:57,851 epoch 29 - iter 430/439 - loss 0.27962340 - samples/sec: 84.54

2020-04-02 23:38:17,895 ----------------------------------------------------------------------------------------------------
2020-04-02 23:38:17,895 EPOCH 43 done: loss 0.3740 - lr 0.0025
2020-04-02 23:38:32,246 DEV : loss 0.6296858787536621 - score 0.9417
2020-04-02 23:38:32,655 BAD EPOCHS (no improvement): 1
2020-04-02 23:38:32,717 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 23:38:44,397 epoch 44 - iter 22/220 - loss 0.36495003 - samples/sec: 120.62
2020-04-02 23:39:52,777 ----------------------------------------------------------------------------------------------------
2020-04-02 23:39:52,777 EPOCH 29 done: loss 0.2783 - lr 0.0100
2020-04-02 23:40:14,995 DEV : loss 0.5555154085159302 - score 0.9547
2020-04-02 23:40:15,435 BAD EPOCHS (no improvement): 1
2020-04-02 23:40:15,528 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-02 23:40:31,563 epoch 30 - iter 43/439 - loss 0.26707286 - samples/sec: 85.87
2020-04-02 23:42:02,854 epoch 44 - iter 44/220 - loss 0.35898856 - samples/sec: 152.33
2020-04-02 23:45:29,524 epoch 44 - iter 66/220 - loss 0.34785737 - samples/sec: 120.25
2020-04-02 23:45:36,409 epoch 30 - iter 86/439 - loss 0.26398704 - samples/sec: 82.35
2020-04-02 23:48:26,837 epoch 44 - iter 88/220 - loss 0.35401140 - samples/sec: 122.94
2020-04-02 23:50:38,810 epoch 30 - iter 129/439 - loss 0.26183922 - samples/sec: 81.12
2020-04-02 23:51:48,741 epoch 44 - iter 110/220 - loss 0.35653228 - samples/sec: 113.03
2020-04-02 23:55:20,698 epoch 44 - iter 132/220 - loss 0.35430933 - samples/sec: 121.24
2020-04-02 23:55:42,966 epoch 30 - iter 172/439 - loss 0.26216323 - samples/sec: 92.79
2020-04-02 23:58:23,382 epoch 44 - iter 154/220 - loss 0.36030062 - samples/sec: 118.64
2020-04-03 00:00:43,097 epoch 30 - iter 215/439 - loss 0.26238840 - samples/sec: 84.11
2020-04-03 00:01:44,600 epoch 44 - iter 176/220 - loss 0.36321634 - samples/sec: 120.52
2020-04-03 00:05:43,904 epoch 30 - iter 258/439 - loss 0.26611776 - samples/sec: 82.16

2020-04-03 00:08:27,919 epoch 44 - iter 220/220 - loss 0.35259804 - samples/sec: 128.98
2020-04-03 00:10:42,357 epoch 30 - iter 301/439 - loss 0.26335100 - samples/sec: 83.36
2020-04-03 00:11:36,940 ----------------------------------------------------------------------------------------------------
2020-04-03 00:11:36,940 EPOCH 44 done: loss 0.3526 - lr 0.0025
2020-04-03 00:11:51,169 DEV : loss 0.6379472017288208 - score 0.9418
2020-04-03 00:11:51,581 BAD EPOCHS (no improvement): 2
2020-04-03 00:11:51,620 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 00:12:03,492 epoch 45 - iter 22/220 - loss 0.35403710 - samples/sec: 118.66
2020-04-03 00:15:41,566 epoch 30 - iter 344/439 - loss 0.25929842 - samples/sec: 83.75
2020-04-03 00:18:55,316 epoch 45 - iter 66/220 - loss 0.36065601 - samples/sec: 123.22
2020-04-03 00:20:53,502 epoch 30 - iter 387/439 - loss 0.26371745 - samples/sec: 84.85
2020-04-03 00:22:30,323 epoch 45 - iter 88/220 - loss 0.35377739 - samples/sec: 122.25
2020-04-03 00:26:10,855 epoch 45 - iter 110/220 - loss 0.35270313 - samples/sec: 113.48
2020-04-03 00:29:31,117 epoch 45 - iter 132/220 - loss 0.34559996 - samples/sec: 125.18
2020-04-03 00:30:40,671 ----------------------------------------------------------------------------------------------------
2020-04-03 00:30:40,671 EPOCH 30 done: loss 0.2629 - lr 0.0100
2020-04-03 00:31:02,945 DEV : loss 0.5399788022041321 - score 0.954
2020-04-03 00:31:03,384 BAD EPOCHS (no improvement): 2
2020-04-03 00:31:03,460 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 00:31:20,191 epoch 31 - iter 43/439 - loss 0.24716508 - samples/sec: 82.29
2020-04-03 00:32:52,806 epoch 45 - iter 154/220 - loss 0.34409129 - samples/sec: 122.19
2020-04-03 00:36:18,652 epoch 45 - iter 176/220 - loss 0.34723169 - samples/sec: 122.44
2020-04-03 00:39:57,445 epoch 31 - iter 129/439 - loss 0.23796823 - samples/sec: 81.45

2020-04-03 00:43:05,310 epoch 45 - iter 220/220 - loss 0.34895658 - samples/sec: 130.86
2020-04-03 00:44:17,340 epoch 31 - iter 172/439 - loss 0.23866880 - samples/sec: 86.56
2020-04-03 00:46:16,410 ----------------------------------------------------------------------------------------------------
2020-04-03 00:46:16,410 EPOCH 45 done: loss 0.3490 - lr 0.0025
2020-04-03 00:46:30,711 DEV : loss 0.6234472393989563 - score 0.9421
2020-04-03 00:46:31,121 BAD EPOCHS (no improvement): 3
2020-04-03 00:46:31,158 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 00:46:42,534 epoch 46 - iter 22/220 - loss 0.40854416 - samples/sec: 123.84
2020-04-03 00:48:42,193 epoch 31 - iter 215/439 - loss 0.24931365 - samples/sec: 80.96
2020-04-03 00:50:09,147 epoch 46 - iter 44/220 - loss 0.39752669 - samples/sec: 130.24
2020-04-03 00:53:35,640 epoch 46 - iter 66/220 - loss 0.37027859 - samples/sec: 123.65
2020-04-03 00:57:32,338 epoch 31 - iter 301/439 - loss 0.25033396 - samples/sec: 79.94
2020-04-03 01:00:37,466 epoch 46 - iter 110/220 - loss 0.36871658 - samples/sec: 116.72
2020-04-03 01:02:13,783 epoch 31 - iter 344/439 - loss 0.25239000 - samples/sec: 84.81
2020-04-03 01:04:03,109 epoch 46 - iter 132/220 - loss 0.36202733 - samples/sec: 151.58
2020-04-03 01:07:32,669 epoch 46 - iter 154/220 - loss 0.35901003 - samples/sec: 123.73
2020-04-03 01:11:29,891 epoch 31 - iter 430/439 - loss 0.25581411 - samples/sec: 80.70

2020-04-03 01:14:32,591 epoch 46 - iter 198/220 - loss 0.35480885 - samples/sec: 121.31
2020-04-03 01:16:03,129 ----------------------------------------------------------------------------------------------------
2020-04-03 01:16:03,129 EPOCH 31 done: loss 0.2573 - lr 0.0100
2020-04-03 01:16:25,371 DEV : loss 0.5365515351295471 - score 0.9561
2020-04-03 01:16:25,805 BAD EPOCHS (no improvement): 0
2020-04-03 01:17:17,522 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 01:17:34,774 epoch 32 - iter 43/439 - loss 0.20562915 - samples/sec: 79.80
2020-04-03 01:18:09,531 epoch 46 - iter 220/220 - loss 0.35446887 - samples/sec: 128.81
2020-04-03 01:21:18,371 ----------------------------------------------------------------------------------------------------
2020-04-03 01:21:18,371 EPOCH 46 done: loss 0.3545 - lr 0.0025
2020-04-03 01:21:45,964 epoch 32 - iter 86/439 - loss 0.21137962 - samples/sec: 81.58
33,178 BAD EPOCHS (no improvement): 0
2020-04-03 01:22:16,555 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 01:22:28,374 epoch 47 - iter 22/220 - loss 0.34102896 - samples/sec: 119.24
2020-04-03 01:25:55,686 epoch 47 - iter 44/220 - loss 0.35977156 - samples/sec: 111.34
2020-04-03 01:26:52,981 epoch 32 - iter 129/439 - loss 0.24164466 - samples/sec: 83.44
2020-04-03 01:29:14,069 epoch 47 - iter 66/220 - loss 0.35825905 - samples/sec: 118.85
2020-04-03 01:31:53,709 epoch 32 - iter 172/439 - loss 0.24059277 - samples/sec: 84.27
2020-04-03 01:32:35,294 epoch 47 - iter 88/220 - loss 0.35152985 - samples/sec: 123.94
2020-04-03 01:35:57,162 epoch 47 - iter 110/220 - loss 0.35542351 - samples/sec: 117.53
2020-04-03 01:36:43,202 epoch 32 - iter 215/439 - loss 0.24871281 - samples/sec: 92.08
2020-04-03 01:39:20,033 epoch 47 - iter 132/220 - loss 0.35279222 - samples/sec: 118.11
2020-04-03 01:41:41,659 epoch 32 - iter 258/439 - loss 0.25021764 - samples/sec: 80.44
2020-04-03 01:42:36,512 epoch 47 - iter 154/220 - loss 0.35018265 - samples/sec: 122.39
2020-04-03 01:46:32,018 epoch 32 - iter 301/439 - loss 0.24456947 - samples/sec: 83.50

2020-04-03 01:49:15,468 epoch 47 - iter 198/220 - loss 0.34913172 - samples/sec: 121.46
2020-04-03 01:51:36,483 epoch 32 - iter 344/439 - loss 0.23906796 - samples/sec: 85.25
2020-04-03 01:52:38,845 epoch 47 - iter 220/220 - loss 0.34972826 - samples/sec: 161.05
2020-04-03 01:55:55,001 ----------------------------------------------------------------------------------------------------
2020-04-03 01:55:55,001 EPOCH 47 done: loss 0.3497 - lr 0.0025
2020-04-03 01:56:09,382 DEV : loss 0.6294155120849609 - score 0.9435
2020-04-03 01:56:09,788 BAD EPOCHS (no improvement): 0
2020-04-03 01:56:41,179 epoch 32 - iter 387/439 - loss 0.24169007 - samples/sec: 81.16
2020-04-03 01:56:51,300 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 01:57:03,161 epoch 48 - iter 22/220 - loss 0.31090064 - samples/sec: 118.81
2020-04-03 02:00:28,881 epoch 48 - iter 44/220 - loss 0.34156268 - samples/sec: 118.23
2020-04-03 02:01:46,372 epoch 32 - iter 430/439 - loss 0.24072239 - samples/sec: 85.90
2020-04-03 02:03:56,261 epoch 48 - iter 66/220 - loss 0.34815031 - samples/sec: 116.48
2020-04-03 02:06:46,286 ----------------------------------------------------------------------------------------------------
2020-04-03 02:06:46,286 EPOCH 32 done: loss 0.2406 - lr 0.0100
2020-04-03 02:07:01,345 epoch 48 - iter 88/220 - loss 0.35128146 - samples/sec: 122.30
2020-04-03 02:07:09,470 DEV : loss 0.5594916343688965 - score 0.9559
2020-04-03 02:07:09,909 BAD EPOCHS (no improvement): 1
2020-04-03 02:07:09,953 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 02:07:26,752 epoch 33 - iter 43/439 - loss 0.21703126 - samples/sec: 81.95
2020-04-03 02:10:21,934 epoch 48 - iter 110/220 - loss 0.34603180 - samples/sec: 124.03
2020-04-03 02:12:30,040 epoch 33 - iter 86/439 - loss 0.22979931 - samples/sec: 87.39
2020-04-03 02:13:45,688 epoch 48 - iter 132/220 - loss 0.34015333 - samples/sec: 116.28
2020-04-03 02:17:15,402 epoch 48 - iter 154/220 - loss 0.33774936 - samples/sec: 119.10
2020-04-03 02:17:31,494 epoch 33 - iter 129/439 - loss 0.23191251 - samples/sec: 95.41
2020-04-03 02:20:34,328 epoch 48 - iter 176/220 - loss 0.34596207 - samples/sec: 155.94
2020-04-03 02:22:34,765 epoch 33 - iter 172/439 - loss 0.23687071 - samples/sec: 80.52
2020-04-03 02:23:58,925 epoch 48 - iter 198/220 - loss 0.34116138 - samples/sec: 118.88
2020-04-03 02:27:21,564 epoch 48 - iter 220/220 - loss 0.34116079 - samples/sec: 127.69
2020-04-03 02:27:35,366 epoch 33 - iter 215/439 - loss 0.23090539 - samples/sec: 81.58
2020-04-03 02:30:42,699 ----------------------------------------------------------------------------------------------------
2020-04-03 02:30:42,699 EPOCH 48 done: loss 0.3412 - lr 0.0025
2020-04-03 02:30:57,877 DEV : loss 0.633277416229248 - score 0.9422
2020-04-03 02:30:58,272 BAD EPOCHS (no improvement): 1
2020-04-03 02:30:58,338 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 02:31:10,041 epoch 49 - iter 22/220 - loss 0.29346742 - samples/sec: 120.39
2020-04-03 02:32:39,265 epoch 33 - iter 258/439 - loss 0.22534102 - samples/sec: 89.37
2020-04-03 02:34:33,714 epoch 49 - iter 44/220 - loss 0.29954018 - samples/sec: 123.37
2020-04-03 02:38:00,798 epoch 49 - iter 66/220 - loss 0.32087771 - samples/sec: 126.16
2020-04-03 02:41:25,617 epoch 49 - iter 88/220 - loss 0.33070080 - samples/sec: 123.48
2020-04-03 02:42:57,278 epoch 33 - iter 344/439 - loss 0.23014395 - samples/sec: 84.59
2020-04-03 02:44:58,998 epoch 49 - iter 110/220 - loss 0.32840684 - samples/sec: 117.26
2020-04-03 02:47:58,144 epoch 33 - iter 387/439 - loss 0.23169137 - samples/sec: 90.66
2020-04-03 02:48:23,272 epoch 49 - iter 132/220 - loss 0.32755932 - samples/sec: 121.12
2020-04-03 02:51:49,918 epoch 49 - iter 154/220 - loss 0.33297511 - samples/sec: 120.13
2020-04-03 02:52:58,308 epoch 33 - iter 430/439 - loss 0.23450103 - samples/sec: 82.70
2020-04-03 02:55:14,954 epoch 49 - iter 176/220 - loss 0.33363516 - samples/sec: 120.69
2020-04-03 02:57:55,874 ----------------------------------------------------------------------------------------------------
2020-04-03 02:57:55,875 EPOCH 33 done: loss 0.2360 - lr 0.0100
2020-04-03 02:58:19,270 DEV : loss 0.5238422751426697 - score 0.9559
2020-04-03 02:58:19,710 BAD EPOCHS (no improvement): 2
2020-04-03 02:58:19,781 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 02:58:35,173 epoch 34 - iter 43/439 - loss 0.23867587 - samples/sec: 89.44
2020-04-03 02:58:43,166 epoch 49 - iter 198/220 - loss 0.33446291 - samples/sec: 121.96
2020-04-03 03:02:08,662 epoch 49 - iter 220/220 - loss 0.33255131 - samples/sec: 119.44
2020-04-03 03:03:35,909 epoch 34 - iter 86/439 - loss 0.22502387 - samples/sec: 97.08
2020-04-03 03:05:20,117 ----------------------------------------------------------------------------------------------------
2020-04-03 03:05:20,117 EPOCH 49 done: loss 0.3326 - lr 0.0025
2020-04-03 03:05:35,415 DEV : loss 0.6324671506881714 - score 0.9422
2020-04-03 03:05:35,823 BAD EPOCHS (no improvement): 2
2020-04-03 03:05:35,888 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 03:05:47,473 epoch 50 - iter 22/220 - loss 0.35359903 - samples/sec: 121.62
2020-04-03 03:08:31,155 epoch 34 - iter 129/439 - loss 0.22137011 - samples/sec: 83.07
2020-04-03 03:09:10,118 epoch 50 - iter 44/220 - loss 0.35686690 - samples/sec: 119.43
2020-04-03 03:12:42,161 epoch 50 - iter 66/220 - loss 0.35820880 - samples/sec: 119.46
2020-04-03 03:13:42,181 epoch 34 - iter 172/439 - loss 0.21074811 - samples/sec: 77.11
2020-04-03 03:16:16,314 epoch 50 - iter 88/220 - loss 0.34280222 - samples/sec: 117.45
2020-04-03 03:18:55,743 epoch 34 - iter 215/439 - loss 0.21706261 - samples/sec: 83.16
2020-04-03 03:19:48,193 epoch 50 - iter 110/220 - loss 0.34875989 - samples/sec: 117.80
2020-04-03 03:23:23,918 epoch 50 - iter 132/220 - loss 0.34473565 - samples/sec: 120.79
2020-04-03 03:24:14,940 epoch 34 - iter 258/439 - loss 0.22505487 - samples/sec: 84.10
2020-04-03 03:26:58,077 epoch 50 - iter 154/220 - loss 0.34252149 - samples/sec: 124.16
2020-04-03 03:29:40,570 epoch 34 - iter 301/439 - loss 0.22567835 - samples/sec: 80.74
2020-04-03 03:30:37,733 epoch 50 - iter 176/220 - loss 0.34876505 - samples/sec: 121.91
2020-04-03 03:34:08,557 epoch 50 - iter 198/220 - loss 0.34609409 - samples/sec: 124.17
2020-04-03 03:34:51,156 epoch 34 - iter 344/439 - loss 0.22649537 - samples/sec: 82.82
2020-04-03 03:37:34,392 epoch 50 - iter 220/220 - loss 0.34691381 - samples/sec: 124.73
2020-04-03 03:40:04,298 epoch 34 - iter 387/439 - loss 0.22970307 - samples/sec: 81.14
2020-04-03 03:40:57,654 ----------------------------------------------------------------------------------------------------
2020-04-03 03:40:57,654 EPOCH 50 done: loss 0.3469 - lr 0.0025
2020-04-03 03:41:12,959 DEV : loss 0.6354248523712158 - score 0.9419
2020-04-03 03:41:13,369 BAD EPOCHS (no improvement): 3
2020-04-03 03:41:13,415 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 03:41:24,781 epoch 51 - iter 22/220 - loss 0.33775285 - samples/sec: 123.96
2020-04-03 03:45:21,287 epoch 34 - iter 430/439 - loss 0.22558608 - samples/sec: 85.68
2020-04-03 03:48:36,580 epoch 51 - iter 66/220 - loss 0.34108715 - samples/sec: 119.01
2020-04-03 03:50:22,811 ----------------------------------------------------------------------------------------------------
2020-04-03 03:50:22,811 EPOCH 34 done: loss 0.2241 - lr 0.0100
2020-04-03 03:50:45,217 DEV : loss 0.5379167199134827 - score 0.9569
2020-04-03 03:50:45,831 BAD EPOCHS (no improvement): 0
2020-04-03 03:51:34,428 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 03:51:51,119 epoch 35 - iter 43/439 - loss 0.23637951 - samples/sec: 82.48
2020-04-03 03:52:22,573 epoch 51 - iter 88/220 - loss 0.34043886 - samples/sec: 121.81
2020-04-03 03:55:56,554 epoch 51 - iter 110/220 - loss 0.34381090 - samples/sec: 119.74
2020-04-03 03:57:02,428 epoch 35 - iter 86/439 - loss 0.22946387 - samples/sec: 81.38
2020-04-03 03:59:21,087 epoch 51 - iter 132/220 - loss 0.34451481 - samples/sec: 122.99
2020-04-03 04:02:05,034 epoch 35 - iter 129/439 - loss 0.23482928 - samples/sec: 88.30
2020-04-03 04:02:44,236 epoch 51 - iter 154/220 - loss 0.34533680 - samples/sec: 126.90
2020-04-03 04:06:10,665 epoch 51 - iter 176/220 - loss 0.34102840 - samples/sec: 123.31
2020-04-03 04:07:06,864 epoch 35 - iter 172/439 - loss 0.22572484 - samples/sec: 84.12
2020-04-03 04:09:32,275 epoch 51 - iter 198/220 - loss 0.34265523 - samples/sec: 116.68
2020-04-03 04:12:00,124 epoch 35 - iter 215/439 - loss 0.22613514 - samples/sec: 95.92
2020-04-03 04:12:52,797 epoch 51 - iter 220/220 - loss 0.33958841 - samples/sec: 120.04
2020-04-03 04:16:33,930 ----------------------------------------------------------------------------------------------------
2020-04-03 04:16:33,930 EPOCH 51 done: loss 0.3396 - lr 0.0025
2020-04-03 04:16:49,083 DEV : loss 0.6300770044326782 - score 0.942
Epoch    51: reducing learning rate of group 0 to 1.2500e-03.
2020-04-03 04:16:49,475 BAD EPOCHS (no improvement): 4
2020-04-03 04:16:49,529 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 04:17:01,427 epoch 52 - iter 22/220 - loss 0.33391921 - samples/sec: 118.41
2020-04-03 04:17:26,058 epoch 35 - iter 258/439 - loss 0.22947604 - samples/sec: 83.21
2020-04-03 04:20:35,586 epoch 52 - iter 44/220 - loss 0.34401996 - samples/sec: 123.44
2020-04-03 04:22:44,232 epoch 35 - iter 301/439 - loss 0.23699873 - samples/sec: 80.69
2020-04-03 04:24:12,428 epoch 52 - iter 66/220 - loss 0.33225347 - samples/sec: 121.98
2020-04-03 04:28:03,712 epoch 35 - iter 344/439 - loss 0.23574039 - samples/sec: 81.82
2020-04-03 04:31:27,365 epoch 52 - iter 110/220 - loss 0.34007822 - samples/sec: 120.04
2020-04-03 04:33:25,973 epoch 35 - iter 387/439 - loss 0.23362140 - samples/sec: 83.95
2020-04-03 04:35:07,850 epoch 52 - iter 132/220 - loss 0.33794899 - samples/sec: 120.81
2020-04-03 04:38:54,271 epoch 35 - iter 430/439 - loss 0.23163923 - samples/sec: 84.79

2020-04-03 04:42:22,186 epoch 52 - iter 176/220 - loss 0.33579944 - samples/sec: 125.00
2020-04-03 04:44:09,408 ----------------------------------------------------------------------------------------------------
2020-04-03 04:44:09,408 EPOCH 35 done: loss 0.2306 - lr 0.0100
2020-04-03 04:44:31,763 DEV : loss 0.5417052507400513 - score 0.9568
2020-04-03 04:44:32,200 BAD EPOCHS (no improvement): 1
2020-04-03 04:44:32,264 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 04:44:50,192 epoch 36 - iter 43/439 - loss 0.22825625 - samples/sec: 76.79
2020-04-03 04:45:57,259 epoch 52 - iter 198/220 - loss 0.34182590 - samples/sec: 122.63
2020-04-03 04:49:36,880 epoch 52 - iter 220/220 - loss 0.34259729 - samples/sec: 125.44
2020-04-03 04:50:15,763 epoch 36 - iter 86/439 - loss 0.24410491 - samples/sec: 87.81
2020-04-03 04:52:29,676 ----------------------------------------------------------------------------------------------------
2020-04-03 04:52:29,676 EPOCH 52 done: loss 0.3426 - lr 0.0013
2020-04-03 04:52:44,839 DEV : loss 0.6318085789680481 - score 0.942
2020-04-03 04:52:45,234 BAD EPOCHS (no improvement): 1
2020-04-03 04:52:45,259 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 04:52:56,574 epoch 53 - iter 22/220 - loss 0.34081674 - samples/sec: 124.51
2020-04-03 04:55:38,484 epoch 36 - iter 129/439 - loss 0.22927050 - samples/sec: 86.97
2020-04-03 04:56:32,037 epoch 53 - iter 44/220 - loss 0.35748590 - samples/sec: 121.52
2020-04-03 05:00:15,869 epoch 53 - iter 66/220 - loss 0.33771055 - samples/sec: 123.17
2020-04-03 05:01:04,486 epoch 36 - iter 172/439 - loss 0.21845367 - samples/sec: 83.12
2020-04-03 05:04:04,018 epoch 53 - iter 88/220 - loss 0.32152358 - samples/sec: 131.40
2020-04-03 05:06:49,287 epoch 36 - iter 215/439 - loss 0.21392123 - samples/sec: 85.83
2020-04-03 05:07:51,723 epoch 53 - iter 110/220 - loss 0.32096191 - samples/sec: 119.28
2020-04-03 05:11:38,544 epoch 53 - iter 132/220 - loss 0.32280713 - samples/sec: 122.25
2020-04-03 05:12:29,518 epoch 36 - iter 258/439 - loss 0.21342269 - samples/sec: 83.43
2020-04-03 05:14:55,955 epoch 53 - iter 154/220 - loss 0.32827410 - samples/sec: 120.61
2020-04-03 05:18:40,145 epoch 53 - iter 176/220 - loss 0.32934058 - samples/sec: 127.93
2020-04-03 05:22:20,038 epoch 53 - iter 198/220 - loss 0.33433197 - samples/sec: 122.25
2020-04-03 05:23:23,115 epoch 36 - iter 344/439 - loss 0.21281895 - samples/sec: 82.68
2020-04-03 05:25:34,782 epoch 53 - iter 220/220 - loss 0.33220204 - samples/sec: 118.11
2020-04-03 05:28:55,569 ----------------------------------------------------------------------------------------------------
2020-04-03 05:28:55,569 EPOCH 53 done: loss 0.3322 - lr 0.0013
2020-04-03 05:29:10,872 DEV : loss 0.6341032385826111 - score 0.9419
2020-04-03 05:29:11,284 BAD EPOCHS (no improvement): 2
2020-04-03 05:29:11,331 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 05:29:22,933 epoch 54 - iter 22/220 - loss 0.32932382 - samples/sec: 121.43
2020-04-03 05:33:03,356 epoch 54 - iter 44/220 - loss 0.34927444 - samples/sec: 118.05
2020-04-03 05:34:01,501 epoch 36 - iter 430/439 - loss 0.20996686 - samples/sec: 87.58
2020-04-03 05:36:33,372 epoch 54 - iter 66/220 - loss 0.33805838 - samples/sec: 120.58
2020-04-03 05:39:02,868 ----------------------------------------------------------------------------------------------------
2020-04-03 05:39:02,869 EPOCH 36 done: loss 0.2104 - lr 0.0100
2020-04-03 05:39:25,105 DEV : loss 0.5538637042045593 - score 0.9551
2020-04-03 05:39:25,544 BAD EPOCHS (no improvement): 2
2020-04-03 05:39:25,582 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 05:39:42,573 epoch 37 - iter 43/439 - loss 0.22277294 - samples/sec: 81.02
2020-04-03 05:40:03,211 epoch 54 - iter 88/220 - loss 0.33063112 - samples/sec: 116.83
2020-04-03 05:43:45,083 epoch 54 - iter 110/220 - loss 0.32798535 - samples/sec: 118.49
2020-04-03 05:45:09,029 epoch 37 - iter 86/439 - loss 0.21228675 - samples/sec: 80.27
2020-04-03 05:46:46,853 epoch 54 - iter 132/220 - loss 0.33123983 - samples/sec: 117.04
2020-04-03 05:50:23,202 epoch 54 - iter 154/220 - loss 0.32681557 - samples/sec: 126.44
2020-04-03 05:50:26,883 epoch 37 - iter 129/439 - loss 0.20811210 - samples/sec: 85.73
2020-04-03 05:53:48,910 epoch 54 - iter 176/220 - loss 0.32577848 - samples/sec: 131.93
2020-04-03 05:55:34,777 epoch 37 - iter 172/439 - loss 0.21031518 - samples/sec: 83.94
2020-04-03 05:57:16,009 epoch 54 - iter 198/220 - loss 0.32414482 - samples/sec: 120.22
2020-04-03 06:00:50,390 epoch 54 - iter 220/220 - loss 0.32813324 - samples/sec: 121.86
2020-04-03 06:04:11,774 ----------------------------------------------------------------------------------------------------
2020-04-03 06:04:11,774 EPOCH 54 done: loss 0.3281 - lr 0.0013
2020-04-03 06:04:27,068 DEV : loss 0.637591540813446 - score 0.9418
2020-04-03 06:04:27,477 BAD EPOCHS (no improvement): 3
2020-04-03 06:04:27,548 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 06:04:39,001 epoch 55 - iter 22/220 - loss 0.33107576 - samples/sec: 123.03
2020-04-03 06:05:59,727 epoch 37 - iter 258/439 - loss 0.21181793 - samples/sec: 90.57
2020-04-03 06:08:15,620 epoch 55 - iter 44/220 - loss 0.32285874 - samples/sec: 119.30
2020-04-03 06:11:21,146 epoch 37 - iter 301/439 - loss 0.20877146 - samples/sec: 83.73
2020-04-03 06:11:53,024 epoch 55 - iter 66/220 - loss 0.32945917 - samples/sec: 125.56
2020-04-03 06:15:30,819 epoch 55 - iter 88/220 - loss 0.33366408 - samples/sec: 119.69
2020-04-03 06:16:41,499 epoch 37 - iter 344/439 - loss 0.20927727 - samples/sec: 81.10
2020-04-03 06:19:11,710 epoch 55 - iter 110/220 - loss 0.33020331 - samples/sec: 121.71
2020-04-03 06:22:06,369 epoch 37 - iter 387/439 - loss 0.20763983 - samples/sec: 85.39
2020-04-03 06:22:47,393 epoch 55 - iter 132/220 - loss 0.33374983 - samples/sec: 120.91
2020-04-03 06:26:24,247 epoch 55 - iter 154/220 - loss 0.32962636 - samples/sec: 122.67
2020-04-03 06:27:22,056 epoch 37 - iter 430/439 - loss 0.20822444 - samples/sec: 83.10
2020-04-03 06:29:57,568 epoch 55 - iter 176/220 - loss 0.32722525 - samples/sec: 122.60
2020-04-03 06:32:22,299 ----------------------------------------------------------------------------------------------------
2020-04-03 06:32:22,299 EPOCH 37 done: loss 0.2073 - lr 0.0100
2020-04-03 06:32:44,730 DEV : loss 0.5545207858085632 - score 0.9542
2020-04-03 06:32:45,169 BAD EPOCHS (no improvement): 3
2020-04-03 06:32:45,238 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 06:33:01,796 epoch 38 - iter 43/439 - loss 0.21868004 - samples/sec: 83.14
2020-04-03 06:33:27,020 epoch 55 - iter 198/220 - loss 0.32979365 - samples/sec: 122.52
2020-04-03 06:37:09,265 epoch 55 - iter 220/220 - loss 0.32725093 - samples/sec: 110.38
2020-04-03 06:38:24,663 epoch 38 - iter 86/439 - loss 0.20720724 - samples/sec: 81.09
2020-04-03 06:40:32,769 ----------------------------------------------------------------------------------------------------
2020-04-03 06:40:32,769 EPOCH 55 done: loss 0.3273 - lr 0.0013
2020-04-03 06:40:47,146 DEV : loss 0.6339432597160339 - score 0.9426
Epoch    55: reducing learning rate of group 0 to 6.2500e-04.
2020-04-03 06:40:47,553 BAD EPOCHS (no improvement): 4
2020-04-03 06:40:47,634 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 06:40:58,614 epoch 56 - iter 22/220 - loss 0.31607237 - samples/sec: 128.31
2020-04-03 06:45:16,477 epoch 38 - iter 129/439 - loss 0.20882754 - samples/sec: 84.39
2020-04-03 06:47:23,428 epoch 56 - iter 44/220 - loss 0.31821675 - samples/sec: 126.72
2020-04-03 06:53:01,159 epoch 38 - iter 172/439 - loss 0.20571308 - samples/sec: 83.23
2020-04-03 06:57:45,344 epoch 56 - iter 88/220 - loss 0.32109868 - samples/sec: 124.33
2020-04-03 06:59:16,922 epoch 38 - iter 215/439 - loss 0.20444619 - samples/sec: 85.19
2020-04-03 07:01:07,723 epoch 56 - iter 110/220 - loss 0.32452272 - samples/sec: 118.46
2020-04-03 07:03:50,866 epoch 38 - iter 258/439 - loss 0.20858117 - samples/sec: 82.31
2020-04-03 07:04:37,708 epoch 56 - iter 132/220 - loss 0.32514441 - samples/sec: 123.20
2020-04-03 07:08:17,149 epoch 38 - iter 301/439 - loss 0.20744127 - samples/sec: 94.29

2020-04-03 07:11:23,107 epoch 56 - iter 176/220 - loss 0.33412298 - samples/sec: 115.08
2020-04-03 07:12:56,235 epoch 38 - iter 344/439 - loss 0.20839223 - samples/sec: 83.35
2020-04-03 07:14:44,893 epoch 56 - iter 198/220 - loss 0.33460278 - samples/sec: 125.49
2020-04-03 07:17:38,031 epoch 38 - iter 387/439 - loss 0.20779474 - samples/sec: 81.34
2020-04-03 07:18:09,872 epoch 56 - iter 220/220 - loss 0.33299721 - samples/sec: 115.46
2020-04-03 07:22:08,113 epoch 38 - iter 430/439 - loss 0.20625538 - samples/sec: 87.86
------------------------------------
2020-04-03 07:21:30,566 EPOCH 56 done: loss 0.3330 - lr 0.0006
2020-04-03 07:21:44,885 DEV : loss 0.6321485638618469 - score 0.9426
2020-04-03 07:21:45,295 BAD EPOCHS (no improvement): 1
2020-04-03 07:21:45,330 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 07:21:56,515 epoch 57 - iter 22/220 - loss 0.35393248 - samples/sec: 125.95
2020-04-03 07:25:15,778 epoch 57 - iter 44/220 - loss 0.32097851 - samples/sec: 118.96
2020-04-03 07:26:50,372 ----------------------------------------------------------------------------------------------------
2020-04-03 07:26:50,372 EPOCH 38 done: loss 0.2074 - lr 0.0100
2020-04-03 07:27:12,659 DEV : loss 0.5549178719520569 - score 0.9556
Epoch    38: reducing learning rate of group 0 to 5.0000e-03.
2020-04-03 07:27:13,100 BAD EPOCHS (no improvement): 4
2020-04-03 07:27:13,156 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 07:27:28,788 epoch 39 - iter 43/439 - loss 0.19925705 - samples/sec: 88.07
2020-04-03 07:28:31,644 epoch 57 - iter 66/220 - loss 0.30791381 - samples/sec: 122.19
2020-04-03 07:31:51,303 epoch 57 - iter 88/220 - loss 0.31764174 - samples/sec: 124.13
2020-04-03 07:32:20,259 epoch 39 - iter 86/439 - loss 0.18738979 - samples/sec: 85.86
2020-04-03 07:35:07,636 epoch 57 - iter 110/220 - loss 0.31013654 - samples/sec: 121.26
2020-04-03 07:37:13,574 epoch 39 - iter 129/439 - loss 0.18434670 - samples/sec: 80.99
2020-04-03 07:38:23,149 epoch 57 - iter 132/220 - loss 0.31414758 - samples/sec: 119.98
2020-04-03 07:42:03,718 epoch 39 - iter 172/439 - loss 0.18017217 - samples/sec: 85.14

2020-04-03 07:44:59,111 epoch 57 - iter 176/220 - loss 0.31181683 - samples/sec: 121.71
2020-04-03 07:47:00,107 epoch 39 - iter 215/439 - loss 0.18612439 - samples/sec: 83.96
2020-04-03 07:48:16,820 epoch 57 - iter 198/220 - loss 0.31587564 - samples/sec: 108.48
2020-04-03 07:51:49,129 epoch 39 - iter 258/439 - loss 0.18293982 - samples/sec: 84.03

2020-04-03 07:54:44,145 ----------------------------------------------------------------------------------------------------
2020-04-03 07:54:44,145 EPOCH 57 done: loss 0.3186 - lr 0.0006
2020-04-03 07:54:58,450 DEV : loss 0.6311081051826477 - score 0.9422
2020-04-03 07:54:58,860 BAD EPOCHS (no improvement): 2
2020-04-03 07:54:58,911 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 07:55:10,546 epoch 58 - iter 22/220 - loss 0.37737264 - samples/sec: 121.09
2020-04-03 07:56:40,231 epoch 39 - iter 301/439 - loss 0.18355402 - samples/sec: 81.03
2020-04-03 07:58:31,926 epoch 58 - iter 44/220 - loss 0.36700815 - samples/sec: 123.73
2020-04-03 08:01:52,977 epoch 58 - iter 66/220 - loss 0.35917916 - samples/sec: 120.75
2020-04-03 08:05:20,596 epoch 58 - iter 88/220 - loss 0.36290780 - samples/sec: 114.00
2020-04-03 08:06:52,419 epoch 39 - iter 387/439 - loss 0.19023001 - samples/sec: 80.18
2020-04-03 08:08:53,741 epoch 58 - iter 110/220 - loss 0.36445378 - samples/sec: 121.97
2020-04-03 08:12:23,989 epoch 58 - iter 132/220 - loss 0.35687778 - samples/sec: 125.16
2020-04-03 08:15:49,776 epoch 58 - iter 154/220 - loss 0.35326864 - samples/sec: 131.44
2020-04-03 08:16:47,441 ----------------------------------------------------------------------------------------------------
2020-04-03 08:16:47,442 EPOCH 39 done: loss 0.1871 - lr 0.0050
2020-04-03 08:17:09,835 DEV : loss 0.5514012575149536 - score 0.9583
2020-04-03 08:17:10,267 BAD EPOCHS (no improvement): 0
2020-04-03 08:18:00,181 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 08:18:16,580 epoch 40 - iter 43/439 - loss 0.14449440 - samples/sec: 83.95
2020-04-03 08:19:32,001 epoch 58 - iter 176/220 - loss 0.34567079 - samples/sec: 120.30
2020-04-03 08:23:22,386 epoch 40 - iter 86/439 - loss 0.15889721 - samples/sec: 86.14

2020-04-03 08:26:43,845 epoch 58 - iter 220/220 - loss 0.34377693 - samples/sec: 112.59
2020-04-03 08:28:55,024 epoch 40 - iter 129/439 - loss 0.15935841 - samples/sec: 88.19
2020-04-03 08:30:13,263 ----------------------------------------------------------------------------------------------------
2020-04-03 08:30:13,263 EPOCH 58 done: loss 0.3438 - lr 0.0006
2020-04-03 08:30:27,631 DEV : loss 0.6308870911598206 - score 0.9429
2020-04-03 08:30:28,040 BAD EPOCHS (no improvement): 3
2020-04-03 08:30:28,082 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 08:30:39,793 epoch 59 - iter 22/220 - loss 0.32141760 - samples/sec: 120.30
2020-04-03 08:34:27,697 epoch 40 - iter 172/439 - loss 0.16642211 - samples/sec: 77.62
2020-04-03 08:38:23,315 epoch 59 - iter 66/220 - loss 0.32161317 - samples/sec: 119.15
2020-04-03 08:40:11,244 epoch 40 - iter 215/439 - loss 0.16428198 - samples/sec: 81.04
2020-04-03 08:41:28,488 epoch 59 - iter 88/220 - loss 0.32349878 - samples/sec: 119.61
2020-04-03 08:45:55,559 epoch 40 - iter 258/439 - loss 0.16502455 - samples/sec: 87.35

2020-04-03 08:49:19,760 epoch 59 - iter 132/220 - loss 0.32718374 - samples/sec: 117.43
2020-04-03 08:51:37,309 epoch 40 - iter 301/439 - loss 0.16724863 - samples/sec: 98.42
2020-04-03 08:52:53,747 epoch 59 - iter 154/220 - loss 0.32519520 - samples/sec: 123.93
2020-04-03 08:56:51,234 epoch 59 - iter 176/220 - loss 0.32860180 - samples/sec: 122.95
2020-04-03 08:57:30,462 epoch 40 - iter 344/439 - loss 0.17164149 - samples/sec: 84.12
2020-04-03 09:00:32,108 epoch 59 - iter 198/220 - loss 0.32828438 - samples/sec: 112.36
2020-04-03 09:03:02,019 epoch 40 - iter 387/439 - loss 0.17329427 - samples/sec: 80.26
2020-04-03 09:04:08,745 epoch 59 - iter 220/220 - loss 0.32581654 - samples/sec: 153.20
2020-04-03 09:07:28,821 ----------------------------------------------------------------------------------------------------
2020-04-03 09:07:28,822 EPOCH 59 done: loss 0.3258 - lr 0.0006
2020-04-03 09:07:43,296 DEV : loss 0.630721926689148 - score 0.9422
Epoch    59: reducing learning rate of group 0 to 3.1250e-04.
2020-04-03 09:07:43,700 BAD EPOCHS (no improvement): 4
2020-04-03 09:07:43,733 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 09:07:55,019 epoch 60 - iter 22/220 - loss 0.30951823 - samples/sec: 124.84
2020-04-03 09:08:09,635 epoch 40 - iter 430/439 - loss 0.17397777 - samples/sec: 84.97
2020-04-03 09:11:27,832 epoch 60 - iter 44/220 - loss 0.32413261 - samples/sec: 124.45
2020-04-03 09:13:14,915 ----------------------------------------------------------------------------------------------------
2020-04-03 09:13:14,915 EPOCH 40 done: loss 0.1736 - lr 0.0050
2020-04-03 09:13:38,183 DEV : loss 0.552790105342865 - score 0.9575
2020-04-03 09:13:38,624 BAD EPOCHS (no improvement): 1
2020-04-03 09:13:38,656 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 09:13:54,923 epoch 41 - iter 43/439 - loss 0.15817565 - samples/sec: 84.64
2020-04-03 09:14:19,724 epoch 60 - iter 66/220 - loss 0.31653479 - samples/sec: 123.76
2020-04-03 09:17:56,423 epoch 60 - iter 88/220 - loss 0.31750213 - samples/sec: 122.57
2020-04-03 09:19:17,662 epoch 41 - iter 86/439 - loss 0.18522287 - samples/sec: 78.92
2020-04-03 09:21:32,266 epoch 60 - iter 110/220 - loss 0.31681089 - samples/sec: 122.12
2020-04-03 09:24:52,558 epoch 41 - iter 129/439 - loss 0.18524830 - samples/sec: 82.86

2020-04-03 09:28:35,662 epoch 60 - iter 154/220 - loss 0.32177917 - samples/sec: 122.72
2020-04-03 09:30:23,053 epoch 41 - iter 172/439 - loss 0.18320060 - samples/sec: 79.49
2020-04-03 09:32:34,620 epoch 60 - iter 176/220 - loss 0.32142261 - samples/sec: 118.89
2020-04-03 09:35:41,898 epoch 60 - iter 198/220 - loss 0.32365103 - samples/sec: 121.44
2020-04-03 09:39:12,747 epoch 60 - iter 220/220 - loss 0.32172893 - samples/sec: 126.98
2020-04-03 09:39:52,766 epoch 41 - iter 258/439 - loss 0.18218166 - samples/sec: 83.65
2020-04-03 09:42:18,400 ----------------------------------------------------------------------------------------------------
2020-04-03 09:42:18,401 EPOCH 60 done: loss 0.3217 - lr 0.0003
2020-04-03 09:42:32,769 DEV : loss 0.6331615447998047 - score 0.9422
2020-04-03 09:42:33,179 BAD EPOCHS (no improvement): 1
2020-04-03 09:42:33,220 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 09:42:44,368 epoch 61 - iter 22/220 - loss 0.34071355 - samples/sec: 126.38
2020-04-03 09:44:13,255 epoch 41 - iter 301/439 - loss 0.18219486 - samples/sec: 85.36
2020-04-03 09:46:06,052 epoch 61 - iter 44/220 - loss 0.34221305 - samples/sec: 127.08
2020-04-03 09:49:24,499 epoch 61 - iter 66/220 - loss 0.33666257 - samples/sec: 154.05
2020-04-03 09:52:54,916 epoch 61 - iter 88/220 - loss 0.31968003 - samples/sec: 119.71
2020-04-03 09:53:30,045 epoch 41 - iter 387/439 - loss 0.18197683 - samples/sec: 86.32
2020-04-03 09:56:30,045 epoch 61 - iter 110/220 - loss 0.32258065 - samples/sec: 123.52
2020-04-03 09:58:21,820 epoch 41 - iter 430/439 - loss 0.18112364 - samples/sec: 78.90
2020-04-03 09:59:58,570 epoch 61 - iter 132/220 - loss 0.32122338 - samples/sec: 124.10
2020-04-03 10:02:49,555 ----------------------------------------------------------------------------------------------------
2020-04-03 10:02:49,555 EPOCH 41 done: loss 0.1817 - lr 0.0050
2020-04-03 10:03:11,731 DEV : loss 0.5621703863143921 - score 0.9577
2020-04-03 10:03:12,171 BAD EPOCHS (no improvement): 2
2020-04-03 10:03:12,193 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 10:03:20,932 epoch 61 - iter 154/220 - loss 0.32583223 - samples/sec: 120.94
2020-04-03 10:03:27,303 epoch 42 - iter 43/439 - loss 0.18397414 - samples/sec: 91.11
2020-04-03 10:06:45,254 epoch 61 - iter 176/220 - loss 0.32052158 - samples/sec: 118.00
2020-04-03 10:08:20,707 epoch 42 - iter 86/439 - loss 0.17105263 - samples/sec: 83.94
2020-04-03 10:10:11,721 epoch 61 - iter 198/220 - loss 0.32321150 - samples/sec: 120.84
2020-04-03 10:12:48,288 epoch 42 - iter 129/439 - loss 0.16335124 - samples/sec: 82.93
2020-04-03 10:13:52,536 epoch 61 - iter 220/220 - loss 0.32363778 - samples/sec: 123.13
2020-04-03 10:17:43,029 epoch 42 - iter 172/439 - loss 0.16753783 - samples/sec: 88.12
------------------------------------
2020-04-03 10:17:25,476 EPOCH 61 done: loss 0.3236 - lr 0.0003
2020-04-03 10:17:39,967 DEV : loss 0.6327773928642273 - score 0.9421
2020-04-03 10:17:40,375 BAD EPOCHS (no improvement): 2
2020-04-03 10:17:40,410 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 10:17:51,623 epoch 62 - iter 22/220 - loss 0.33806723 - samples/sec: 125.64
2020-04-03 10:21:32,762 epoch 62 - iter 44/220 - loss 0.32899096 - samples/sec: 122.11
2020-04-03 10:23:07,844 epoch 42 - iter 215/439 - loss 0.16880678 - samples/sec: 80.44
2020-04-03 10:25:22,940 epoch 62 - iter 66/220 - loss 0.33354675 - samples/sec: 121.05
2020-04-03 10:28:50,675 epoch 62 - iter 88/220 - loss 0.33035531 - samples/sec: 125.56
2020-04-03 10:32:28,452 epoch 62 - iter 110/220 - loss 0.32804223 - samples/sec: 116.44
2020-04-03 10:33:47,863 epoch 42 - iter 301/439 - loss 0.17126428 - samples/sec: 81.80
2020-04-03 10:36:10,088 epoch 62 - iter 132/220 - loss 0.33294041 - samples/sec: 122.79
2020-04-03 10:39:49,250 epoch 62 - iter 154/220 - loss 0.33269359 - samples/sec: 123.62
2020-04-03 10:43:17,921 epoch 62 - iter 176/220 - loss 0.32673643 - samples/sec: 125.27
2020-04-03 10:44:27,595 epoch 42 - iter 387/439 - loss 0.17579395 - samples/sec: 82.50
2020-04-03 10:46:51,793 epoch 62 - iter 198/220 - loss 0.32428209 - samples/sec: 116.20
2020-04-03 10:49:46,125 epoch 42 - iter 430/439 - loss 0.17483572 - samples/sec: 94.63
2020-04-03 10:50:30,348 epoch 62 - iter 220/220 - loss 0.32318865 - samples/sec: 107.14
2020-04-03 10:56:29,714 ----------------------------------------------------------------------------------------------------
2020-04-03 10:56:29,714 EPOCH 62 done: loss 0.3232 - lr 0.0003
2020-04-03 10:56:44,121 DEV : loss 0.6336550712585449 - score 0.9422
2020-04-03 10:56:44,530 BAD EPOCHS (no improvement): 3
2020-04-03 10:56:44,602 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 10:56:56,219 epoch 63 - iter 22/220 - loss 0.32692058 - samples/sec: 121.27
2020-04-03 10:57:21,694 ----------------------------------------------------------------------------------------------------
2020-04-03 10:57:21,694 EPOCH 42 done: loss 0.1752 - lr 0.0050
2020-04-03 10:57:44,007 DEV : loss 0.5572935938835144 - score 0.9564
2020-04-03 10:57:44,447 BAD EPOCHS (no improvement): 3
2020-04-03 10:57:44,478 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 10:58:00,444 epoch 43 - iter 43/439 - loss 0.17516193 - samples/sec: 86.23
2020-04-03 11:00:25,447 epoch 63 - iter 44/220 - loss 0.32938877 - samples/sec: 121.66
2020-04-03 11:03:14,804 epoch 43 - iter 86/439 - loss 0.17209828 - samples/sec: 91.76
2020-04-03 11:03:22,455 epoch 63 - iter 66/220 - loss 0.33192372 - samples/sec: 122.34
2020-04-03 11:06:55,700 epoch 63 - iter 88/220 - loss 0.33087351 - samples/sec: 117.58
2020-04-03 11:08:24,206 epoch 43 - iter 129/439 - loss 0.16795605 - samples/sec: 88.52
2020-04-03 11:10:22,413 epoch 63 - iter 110/220 - loss 0.32968675 - samples/sec: 122.58
2020-04-03 11:13:39,580 epoch 43 - iter 172/439 - loss 0.17010134 - samples/sec: 84.27

2020-04-03 11:17:10,372 epoch 63 - iter 154/220 - loss 0.32962710 - samples/sec: 126.99
2020-04-03 11:18:49,485 epoch 43 - iter 215/439 - loss 0.16682594 - samples/sec: 91.03
2020-04-03 11:20:34,861 epoch 63 - iter 176/220 - loss 0.33095101 - samples/sec: 119.68
2020-04-03 11:23:47,144 epoch 63 - iter 198/220 - loss 0.33035464 - samples/sec: 131.93
2020-04-03 11:23:50,341 epoch 43 - iter 258/439 - loss 0.16592599 - samples/sec: 81.58
2020-04-03 11:27:04,576 epoch 63 - iter 220/220 - loss 0.32591362 - samples/sec: 111.27
2020-04-03 11:30:33,178 epoch 43 - iter 301/439 - loss 0.16879301 - samples/sec: 87.27
2020-04-03 11:31:56,561 ----------------------------------------------------------------------------------------------------
2020-04-03 11:31:56,562 EPOCH 63 done: loss 0.3259 - lr 0.0003
2020-04-03 11:32:10,695 DEV : loss 0.6351829171180725 - score 0.9425
Epoch    63: reducing learning rate of group 0 to 1.5625e-04.
2020-04-03 11:32:11,091 BAD EPOCHS (no improvement): 4
2020-04-03 11:32:11,136 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 11:32:22,860 epoch 64 - iter 22/220 - loss 0.33722435 - samples/sec: 120.19
2020-04-03 11:34:58,729 epoch 43 - iter 344/439 - loss 0.16761828 - samples/sec: 80.76
2020-04-03 11:35:55,064 epoch 64 - iter 44/220 - loss 0.31960374 - samples/sec: 121.14
2020-04-03 11:39:38,821 epoch 43 - iter 387/439 - loss 0.16691602 - samples/sec: 77.34
2020-04-03 11:43:04,096 epoch 64 - iter 88/220 - loss 0.33185008 - samples/sec: 123.86
2020-04-03 11:44:35,221 epoch 43 - iter 430/439 - loss 0.16912799 - samples/sec: 81.32
2020-04-03 11:46:34,074 epoch 64 - iter 110/220 - loss 0.33486625 - samples/sec: 120.24
2020-04-03 11:49:11,164 ----------------------------------------------------------------------------------------------------
2020-04-03 11:49:11,164 EPOCH 43 done: loss 0.1700 - lr 0.0050
2020-04-03 11:49:33,367 DEV : loss 0.5553451180458069 - score 0.9569
Epoch    43: reducing learning rate of group 0 to 2.5000e-03.
2020-04-03 11:49:33,806 BAD EPOCHS (no improvement): 4
2020-04-03 11:49:33,866 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 11:49:50,338 epoch 44 - iter 43/439 - loss 0.16615017 - samples/sec: 83.57
2020-04-03 11:49:54,438 epoch 64 - iter 132/220 - loss 0.33882483 - samples/sec: 126.67
2020-04-03 11:53:32,488 epoch 64 - iter 154/220 - loss 0.33256079 - samples/sec: 125.04
2020-04-03 11:54:24,018 epoch 44 - iter 86/439 - loss 0.16331423 - samples/sec: 83.02
2020-04-03 11:57:01,229 epoch 64 - iter 176/220 - loss 0.33092511 - samples/sec: 157.64
2020-04-03 11:59:21,952 epoch 44 - iter 129/439 - loss 0.16586076 - samples/sec: 79.36
2020-04-03 12:00:46,016 epoch 64 - iter 198/220 - loss 0.33092111 - samples/sec: 130.98
2020-04-03 12:04:19,366 epoch 64 - iter 220/220 - loss 0.33224615 - samples/sec: 120.95
2020-04-03 12:08:25,421 epoch 44 - iter 215/439 - loss 0.16440546 - samples/sec: 86.01
------------------------------------
2020-04-03 12:07:43,110 EPOCH 64 done: loss 0.3322 - lr 0.0002
2020-04-03 12:07:57,488 DEV : loss 0.6355127096176147 - score 0.9421
2020-04-03 12:07:57,898 BAD EPOCHS (no improvement): 1
2020-04-03 12:07:57,952 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 12:08:09,241 epoch 65 - iter 22/220 - loss 0.33000293 - samples/sec: 124.80
2020-04-03 12:11:43,795 epoch 65 - iter 44/220 - loss 0.31766044 - samples/sec: 128.27
2020-04-03 12:13:14,192 epoch 44 - iter 258/439 - loss 0.16497580 - samples/sec: 84.10
2020-04-03 12:15:08,624 epoch 65 - iter 66/220 - loss 0.32516087 - samples/sec: 150.31
2020-04-03 12:17:55,805 epoch 44 - iter 301/439 - loss 0.16691999 - samples/sec: 84.84
2020-04-03 12:18:39,531 epoch 65 - iter 88/220 - loss 0.32744735 - samples/sec: 131.39
2020-04-03 12:22:21,450 epoch 44 - iter 344/439 - loss 0.16584248 - samples/sec: 91.78

2020-04-03 12:25:40,173 epoch 65 - iter 132/220 - loss 0.33516038 - samples/sec: 119.59
2020-04-03 12:27:32,459 epoch 44 - iter 387/439 - loss 0.16249256 - samples/sec: 85.93
2020-04-03 12:29:12,128 epoch 65 - iter 154/220 - loss 0.33330824 - samples/sec: 129.71
2020-04-03 12:32:55,529 epoch 44 - iter 430/439 - loss 0.16515380 - samples/sec: 84.27

2020-04-03 12:36:19,871 epoch 65 - iter 198/220 - loss 0.32945598 - samples/sec: 137.09
2020-04-03 12:37:59,001 ----------------------------------------------------------------------------------------------------
2020-04-03 12:37:59,001 EPOCH 44 done: loss 0.1636 - lr 0.0025
2020-04-03 12:38:22,319 DEV : loss 0.5562849044799805 - score 0.9583
2020-04-03 12:38:22,760 BAD EPOCHS (no improvement): 1
2020-04-03 12:39:12,597 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 12:39:29,354 epoch 45 - iter 43/439 - loss 0.16379007 - samples/sec: 82.16
2020-04-03 12:40:15,463 epoch 65 - iter 220/220 - loss 0.33214423 - samples/sec: 163.39
2020-04-03 12:43:54,341 ----------------------------------------------------------------------------------------------------
2020-04-03 12:43:54,342 EPOCH 65 done: loss 0.3321 - lr 0.0002
2020-04-03 12:44:09,595 DEV : loss 0.6366487145423889 - score 0.9424
2020-04-03 12:44:10,003 BAD EPOCHS (no improvement): 2
2020-04-03 12:44:10,043 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 12:44:20,475 epoch 66 - iter 22/220 - loss 0.26938521 - samples/sec: 135.04
2020-04-03 12:44:57,765 epoch 45 - iter 86/439 - loss 0.16597695 - samples/sec: 89.33
2020-04-03 12:47:54,957 epoch 66 - iter 44/220 - loss 0.27595979 - samples/sec: 117.97
2020-04-03 12:50:14,210 epoch 45 - iter 129/439 - loss 0.17615153 - samples/sec: 88.47
2020-04-03 12:51:26,805 epoch 66 - iter 66/220 - loss 0.30936135 - samples/sec: 135.29
2020-04-03 12:54:58,552 epoch 66 - iter 88/220 - loss 0.31514141 - samples/sec: 134.84
2020-04-03 12:55:25,720 epoch 45 - iter 172/439 - loss 0.16732411 - samples/sec: 82.62
2020-04-03 12:58:32,509 epoch 66 - iter 110/220 - loss 0.31321418 - samples/sec: 133.46
2020-04-03 13:00:49,059 epoch 45 - iter 215/439 - loss 0.16835462 - samples/sec: 82.45
2020-04-03 13:02:08,168 epoch 66 - iter 132/220 - loss 0.31786648 - samples/sec: 123.98
2020-04-03 13:05:40,249 epoch 66 - iter 154/220 - loss 0.31778659 - samples/sec: 134.18
2020-04-03 13:06:00,959 epoch 45 - iter 258/439 - loss 0.16840856 - samples/sec: 86.83
2020-04-03 13:09:08,194 epoch 66 - iter 176/220 - loss 0.31761447 - samples/sec: 157.76
2020-04-03 13:11:17,020 epoch 45 - iter 301/439 - loss 0.16933325 - samples/sec: 91.26
2020-04-03 13:13:10,147 epoch 66 - iter 198/220 - loss 0.31557920 - samples/sec: 125.30
2020-04-03 13:15:24,860 epoch 66 - iter 220/220 - loss 0.31640062 - samples/sec: 124.14
2020-04-03 13:18:11,405 ----------------------------------------------------------------------------------------------------
2020-04-03 13:18:11,406 EPOCH 66 done: loss 0.3164 - lr 0.0002
2020-04-03 13:18:26,752 DEV : loss 0.6352291107177734 - score 0.9419
2020-04-03 13:18:27,161 BAD EPOCHS (no improvement): 3
2020-04-03 13:18:27,307 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 13:18:40,159 epoch 45 - iter 387/439 - loss 0.16423105 - samples/sec: 86.70
2020-04-03 13:21:19,059 epoch 67 - iter 44/220 - loss 0.37348355 - samples/sec: 117.88
2020-04-03 13:22:29,869 epoch 45 - iter 430/439 - loss 0.16420601 - samples/sec: 83.97
2020-04-03 13:23:29,506 epoch 67 - iter 66/220 - loss 0.35525991 - samples/sec: 127.40
2020-04-03 13:26:19,142 epoch 67 - iter 88/220 - loss 0.35137135 - samples/sec: 153.71
------------------------------------
2020-04-03 13:26:12,238 EPOCH 45 done: loss 0.1641 - lr 0.0025
2020-04-03 13:26:35,418 DEV : loss 0.56026691198349 - score 0.9588
2020-04-03 13:26:35,855 BAD EPOCHS (no improvement): 0
2020-04-03 13:27:22,176 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 13:27:38,850 epoch 46 - iter 43/439 - loss 0.13939323 - samples/sec: 82.57
2020-04-03 13:27:45,851 epoch 67 - iter 110/220 - loss 0.34061426 - samples/sec: 127.57
2020-04-03 13:30:50,843 epoch 67 - iter 132/220 - loss 0.33759180 - samples/sec: 124.23
2020-04-03 13:31:14,960 epoch 46 - iter 86/439 - loss 0.16458782 - samples/sec: 86.28
2020-04-03 13:32:54,363 epoch 67 - iter 154/220 - loss 0.33782410 - samples/sec: 125.98
2020-04-03 13:35:15,639 epoch 67 - iter 176/220 - loss 0.33342375 - samples/sec: 122.06
2020-04-03 13:38:15,610 epoch 67 - iter 198/220 - loss 0.33700640 - samples/sec: 128.08
2020-04-03 13:38:45,179 epoch 46 - iter 172/439 - loss 0.16706295 - samples/sec: 84.24
2020-04-03 13:40:29,167 epoch 67 - iter 220/220 - loss 0.33417207 - samples/sec: 127.61
2020-04-03 13:42:44,559 ----------------------------------------------------------------------------------------------------
2020-04-03 13:42:44,560 EPOCH 67 done: loss 0.3342 - lr 0.0002
2020-04-03 13:42:50,376 epoch 46 - iter 215/439 - loss 0.15914832 - samples/sec: 80.48
2020-04-03 13:42:59,751 DEV : loss 0.6357910633087158 - score 0.9424
Epoch    67: reducing learning rate of group 0 to 7.8125e-05.
2020-04-03 13:43:00,158 BAD EPOCHS (no improvement): 4
2020-04-03 13:43:00,202 ----------------------------------------------------------------------------------------------------
2020-04-03 13:43:00,202 ----------------------------------------------------------------------------------------------------
2020-04-03 13:43:00,202 learning rate too small - quitting training!
2020-04-03 13:43:00,202 ----------------------------------------------------------------------------------------------------
2020-04-03 13:43:40,073 ----------------------------------------------------------------------------------------------------
2020-04-03 13:43:40,073 Testing using best model ...
2020-04-03 13:43:40,077 loading file log/mix_xfe_20200401204553_256/best-model.pt
Traceback (most recent call last):
  File "train.py", line 127, in <module>
    
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/trainers/trainer.py", line 553, in train
    final_score = self.final_test(base_path, mini_batch_chunk_size, num_workers)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/trainers/trainer.py", line 601, in final_test
    embedding_storage_mode="none",
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/models/sequence_tagger_model.py", line 412, in evaluate
    features = self.forward(batch)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/models/sequence_tagger_model.py", line 498, in forward
    self.embeddings.embed(sentences)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/embeddings.py", line 177, in embed
    embedding.embed(sentences)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/embeddings.py", line 96, in embed
    self._add_embeddings_internal(sentences)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/embeddings.py", line 2157, in _add_embeddings_internal
    self.word_embeddings[token.text], local_embedding
RuntimeError: Expected object of device type cuda but got device type cpu for argument #2 'other' in call to _th_min
2020-04-03 13:44:41,774 epoch 46 - iter 258/439 - loss 0.16175647 - samples/sec: 80.41
2020-04-03 13:46:05,992 epoch 46 - iter 301/439 - loss 0.16706679 - samples/sec: 85.17
2020-04-03 13:47:28,775 epoch 46 - iter 344/439 - loss 0.16914123 - samples/sec: 86.39
2020-04-03 13:48:49,168 epoch 46 - iter 387/439 - loss 0.16487888 - samples/sec: 85.99
2020-04-03 13:50:15,311 epoch 46 - iter 430/439 - loss 0.16454695 - samples/sec: 81.60
2020-04-03 13:51:26,106 ----------------------------------------------------------------------------------------------------
2020-04-03 13:51:26,106 EPOCH 46 done: loss 0.1636 - lr 0.0025
2020-04-03 13:51:49,361 DEV : loss 0.5648012757301331 - score 0.9581
2020-04-03 13:51:49,797 BAD EPOCHS (no improvement): 1
2020-04-03 13:51:49,814 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 13:52:05,589 epoch 47 - iter 43/439 - loss 0.17897561 - samples/sec: 87.26
2020-04-03 13:53:26,999 epoch 47 - iter 86/439 - loss 0.14318523 - samples/sec: 83.96
2020-04-03 13:54:49,626 epoch 47 - iter 129/439 - loss 0.13772377 - samples/sec: 81.59
2020-04-03 13:56:13,298 epoch 47 - iter 172/439 - loss 0.13930534 - samples/sec: 84.49
2020-04-03 13:57:34,835 epoch 47 - iter 215/439 - loss 0.14233067 - samples/sec: 85.05
2020-04-03 13:58:53,242 epoch 47 - iter 258/439 - loss 0.14230290 - samples/sec: 97.30
2020-04-03 14:00:13,557 epoch 47 - iter 301/439 - loss 0.14198917 - samples/sec: 84.70
2020-04-03 14:01:36,283 epoch 47 - iter 344/439 - loss 0.14447512 - samples/sec: 88.04
2020-04-03 14:03:00,613 epoch 47 - iter 387/439 - loss 0.14643030 - samples/sec: 81.77
2020-04-03 14:04:22,857 epoch 47 - iter 430/439 - loss 0.14573551 - samples/sec: 84.25
2020-04-03 14:05:32,432 ----------------------------------------------------------------------------------------------------
2020-04-03 14:05:32,432 EPOCH 47 done: loss 0.1481 - lr 0.0025
2020-04-03 14:05:54,618 DEV : loss 0.5652573108673096 - score 0.959
2020-04-03 14:05:55,059 BAD EPOCHS (no improvement): 0
2020-04-03 14:06:41,063 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 14:06:57,543 epoch 48 - iter 43/439 - loss 0.18174542 - samples/sec: 83.55
2020-04-03 14:08:22,041 epoch 48 - iter 86/439 - loss 0.16321518 - samples/sec: 83.31
2020-04-03 14:09:45,940 epoch 48 - iter 129/439 - loss 0.15543073 - samples/sec: 81.82
2020-04-03 14:11:08,046 epoch 48 - iter 172/439 - loss 0.15043115 - samples/sec: 84.81
2020-04-03 14:12:28,426 epoch 48 - iter 215/439 - loss 0.15219413 - samples/sec: 82.74
2020-04-03 14:13:48,320 epoch 48 - iter 258/439 - loss 0.15233006 - samples/sec: 82.60
2020-04-03 14:15:10,957 epoch 48 - iter 301/439 - loss 0.14801140 - samples/sec: 83.57
2020-04-03 14:16:50,961 epoch 48 - iter 344/439 - loss 0.14889901 - samples/sec: 83.72
2020-04-03 14:18:13,222 epoch 48 - iter 387/439 - loss 0.14824798 - samples/sec: 94.80
2020-04-03 14:19:35,634 epoch 48 - iter 430/439 - loss 0.14752330 - samples/sec: 88.91
2020-04-03 14:20:45,954 ----------------------------------------------------------------------------------------------------
2020-04-03 14:20:45,954 EPOCH 48 done: loss 0.1477 - lr 0.0025
2020-04-03 14:21:08,083 DEV : loss 0.5653989911079407 - score 0.9577
2020-04-03 14:21:08,520 BAD EPOCHS (no improvement): 1
2020-04-03 14:21:08,543 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 14:21:22,879 epoch 49 - iter 43/439 - loss 0.13638041 - samples/sec: 96.03
2020-04-03 14:22:44,055 epoch 49 - iter 86/439 - loss 0.13999961 - samples/sec: 84.38
2020-04-03 14:24:07,891 epoch 49 - iter 129/439 - loss 0.14469932 - samples/sec: 82.44
2020-04-03 14:25:30,457 epoch 49 - iter 172/439 - loss 0.14114828 - samples/sec: 81.23
2020-04-03 14:26:50,511 epoch 49 - iter 215/439 - loss 0.14757993 - samples/sec: 96.79
2020-04-03 14:28:15,976 epoch 49 - iter 258/439 - loss 0.14768721 - samples/sec: 83.23
2020-04-03 14:29:39,828 epoch 49 - iter 301/439 - loss 0.14544114 - samples/sec: 80.94
2020-04-03 14:31:02,046 epoch 49 - iter 344/439 - loss 0.14393983 - samples/sec: 82.59
2020-04-03 14:32:23,363 epoch 49 - iter 387/439 - loss 0.14606377 - samples/sec: 84.44
2020-04-03 14:33:42,014 epoch 49 - iter 430/439 - loss 0.14691433 - samples/sec: 92.36
2020-04-03 14:34:50,521 ----------------------------------------------------------------------------------------------------
2020-04-03 14:34:50,521 EPOCH 49 done: loss 0.1474 - lr 0.0025
2020-04-03 14:35:12,723 DEV : loss 0.5699984431266785 - score 0.9578
2020-04-03 14:35:13,162 BAD EPOCHS (no improvement): 2
2020-04-03 14:35:13,178 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 14:35:28,841 epoch 50 - iter 43/439 - loss 0.15171066 - samples/sec: 87.89
2020-04-03 14:36:49,693 epoch 50 - iter 86/439 - loss 0.13836477 - samples/sec: 80.89
2020-04-03 14:38:09,936 epoch 50 - iter 129/439 - loss 0.14444303 - samples/sec: 81.38
2020-04-03 14:39:29,639 epoch 50 - iter 172/439 - loss 0.14386583 - samples/sec: 85.54
2020-04-03 14:40:45,106 epoch 50 - iter 215/439 - loss 0.14835442 - samples/sec: 87.37
2020-04-03 14:42:09,824 epoch 50 - iter 258/439 - loss 0.14935611 - samples/sec: 87.31
2020-04-03 14:43:27,275 epoch 50 - iter 301/439 - loss 0.15045792 - samples/sec: 77.10
2020-04-03 14:44:45,563 epoch 50 - iter 344/439 - loss 0.15099882 - samples/sec: 85.99
2020-04-03 14:46:00,033 epoch 50 - iter 387/439 - loss 0.15202544 - samples/sec: 86.40
2020-04-03 14:47:20,711 epoch 50 - iter 430/439 - loss 0.14978343 - samples/sec: 85.48
2020-04-03 14:48:23,426 ----------------------------------------------------------------------------------------------------
2020-04-03 14:48:23,427 EPOCH 50 done: loss 0.1491 - lr 0.0025
2020-04-03 14:48:45,756 DEV : loss 0.5707640647888184 - score 0.9573
2020-04-03 14:48:46,197 BAD EPOCHS (no improvement): 3
2020-04-03 14:48:46,203 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 14:49:02,582 epoch 51 - iter 43/439 - loss 0.12437731 - samples/sec: 84.05
2020-04-03 14:50:17,480 epoch 51 - iter 86/439 - loss 0.12989815 - samples/sec: 88.35
2020-04-03 14:51:34,342 epoch 51 - iter 129/439 - loss 0.14375194 - samples/sec: 87.72
2020-04-03 14:52:52,121 epoch 51 - iter 172/439 - loss 0.14278310 - samples/sec: 88.98
2020-04-03 14:54:14,052 epoch 51 - iter 215/439 - loss 0.14688068 - samples/sec: 90.84
2020-04-03 14:55:36,422 epoch 51 - iter 258/439 - loss 0.14641540 - samples/sec: 81.36
2020-04-03 14:56:53,634 epoch 51 - iter 301/439 - loss 0.14712533 - samples/sec: 83.23
2020-04-03 14:58:13,369 epoch 51 - iter 344/439 - loss 0.14701387 - samples/sec: 87.77
2020-04-03 14:59:30,185 epoch 51 - iter 387/439 - loss 0.14764255 - samples/sec: 81.31
2020-04-03 15:00:49,648 epoch 51 - iter 430/439 - loss 0.14639159 - samples/sec: 86.22
2020-04-03 15:01:53,861 ----------------------------------------------------------------------------------------------------
2020-04-03 15:01:53,862 EPOCH 51 done: loss 0.1464 - lr 0.0025
2020-04-03 15:02:17,036 DEV : loss 0.5720375776290894 - score 0.9566
Epoch    51: reducing learning rate of group 0 to 1.2500e-03.
2020-04-03 15:02:17,475 BAD EPOCHS (no improvement): 4
2020-04-03 15:02:17,490 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 15:02:34,019 epoch 52 - iter 43/439 - loss 0.15666413 - samples/sec: 83.28
2020-04-03 15:03:55,521 epoch 52 - iter 86/439 - loss 0.15217151 - samples/sec: 85.32
2020-04-03 15:05:11,213 epoch 52 - iter 129/439 - loss 0.15033282 - samples/sec: 91.33
2020-04-03 15:06:25,660 epoch 52 - iter 172/439 - loss 0.15242189 - samples/sec: 83.87
2020-04-03 15:07:48,859 epoch 52 - iter 215/439 - loss 0.15014354 - samples/sec: 83.68
2020-04-03 15:09:07,761 epoch 52 - iter 258/439 - loss 0.14685242 - samples/sec: 84.33
2020-04-03 15:10:27,331 epoch 52 - iter 301/439 - loss 0.14467653 - samples/sec: 83.61
2020-04-03 15:11:46,053 epoch 52 - iter 344/439 - loss 0.14698424 - samples/sec: 96.63
2020-04-03 15:13:05,557 epoch 52 - iter 387/439 - loss 0.14464959 - samples/sec: 79.99
2020-04-03 15:14:24,312 epoch 52 - iter 430/439 - loss 0.14587205 - samples/sec: 82.40
2020-04-03 15:15:33,196 ----------------------------------------------------------------------------------------------------
2020-04-03 15:15:33,196 EPOCH 52 done: loss 0.1460 - lr 0.0013
2020-04-03 15:15:55,431 DEV : loss 0.5664426684379578 - score 0.9576
2020-04-03 15:15:55,869 BAD EPOCHS (no improvement): 1
2020-04-03 15:15:55,892 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 15:16:11,934 epoch 53 - iter 43/439 - loss 0.12124995 - samples/sec: 85.82
2020-04-03 15:17:29,604 epoch 53 - iter 86/439 - loss 0.14056951 - samples/sec: 79.84
2020-04-03 15:18:44,575 epoch 53 - iter 129/439 - loss 0.14421309 - samples/sec: 84.47
2020-04-03 15:20:04,961 epoch 53 - iter 172/439 - loss 0.13908489 - samples/sec: 85.09
2020-04-03 15:21:20,038 epoch 53 - iter 215/439 - loss 0.14269179 - samples/sec: 95.45
2020-04-03 15:22:41,461 epoch 53 - iter 258/439 - loss 0.14399305 - samples/sec: 82.71
2020-04-03 15:23:59,507 epoch 53 - iter 301/439 - loss 0.14770837 - samples/sec: 86.05
2020-04-03 15:25:17,499 epoch 53 - iter 344/439 - loss 0.14925321 - samples/sec: 79.08
2020-04-03 15:26:37,019 epoch 53 - iter 387/439 - loss 0.14841805 - samples/sec: 81.22
2020-04-03 15:27:51,147 epoch 53 - iter 430/439 - loss 0.14968014 - samples/sec: 81.56
2020-04-03 15:28:58,967 ----------------------------------------------------------------------------------------------------
2020-04-03 15:28:58,967 EPOCH 53 done: loss 0.1508 - lr 0.0013
2020-04-03 15:29:21,179 DEV : loss 0.5640120506286621 - score 0.957
2020-04-03 15:29:21,617 BAD EPOCHS (no improvement): 2
2020-04-03 15:29:21,668 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 15:29:37,623 epoch 54 - iter 43/439 - loss 0.15138539 - samples/sec: 86.29
2020-04-03 15:30:59,602 epoch 54 - iter 86/439 - loss 0.15293570 - samples/sec: 81.88
2020-04-03 15:32:16,435 epoch 54 - iter 129/439 - loss 0.15401709 - samples/sec: 86.87
2020-04-03 15:33:35,435 epoch 54 - iter 172/439 - loss 0.14628655 - samples/sec: 83.15
2020-04-03 15:34:51,629 epoch 54 - iter 215/439 - loss 0.14816266 - samples/sec: 87.83
2020-04-03 15:36:06,846 epoch 54 - iter 258/439 - loss 0.14781336 - samples/sec: 88.28
2020-04-03 15:37:22,937 epoch 54 - iter 301/439 - loss 0.14541844 - samples/sec: 82.17
2020-04-03 15:38:44,927 epoch 54 - iter 344/439 - loss 0.14837498 - samples/sec: 80.41
2020-04-03 15:40:03,650 epoch 54 - iter 387/439 - loss 0.14956583 - samples/sec: 82.22
2020-04-03 15:41:21,072 epoch 54 - iter 430/439 - loss 0.14883901 - samples/sec: 91.52
2020-04-03 15:42:26,323 ----------------------------------------------------------------------------------------------------
2020-04-03 15:42:26,323 EPOCH 54 done: loss 0.1484 - lr 0.0013
2020-04-03 15:42:48,510 DEV : loss 0.5674638152122498 - score 0.9576
2020-04-03 15:42:48,954 BAD EPOCHS (no improvement): 3
2020-04-03 15:42:48,961 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 15:43:02,683 epoch 55 - iter 43/439 - loss 0.13416673 - samples/sec: 100.32
2020-04-03 15:44:19,820 epoch 55 - iter 86/439 - loss 0.12823826 - samples/sec: 81.47
2020-04-03 15:45:37,774 epoch 55 - iter 129/439 - loss 0.13868811 - samples/sec: 84.00
2020-04-03 15:46:58,545 epoch 55 - iter 172/439 - loss 0.14823050 - samples/sec: 95.29
2020-04-03 15:48:17,574 epoch 55 - iter 215/439 - loss 0.14909681 - samples/sec: 82.24
2020-04-03 15:49:49,350 epoch 55 - iter 258/439 - loss 0.14599551 - samples/sec: 83.25
2020-04-03 15:51:05,450 epoch 55 - iter 301/439 - loss 0.14395829 - samples/sec: 91.26
2020-04-03 15:52:26,261 epoch 55 - iter 344/439 - loss 0.14232563 - samples/sec: 87.34
2020-04-03 15:53:53,823 epoch 55 - iter 387/439 - loss 0.13956202 - samples/sec: 93.04
2020-04-03 15:55:18,116 epoch 55 - iter 430/439 - loss 0.13767788 - samples/sec: 79.97
2020-04-03 15:56:25,990 ----------------------------------------------------------------------------------------------------
2020-04-03 15:56:25,990 EPOCH 55 done: loss 0.1370 - lr 0.0013
2020-04-03 15:56:48,294 DEV : loss 0.5703366994857788 - score 0.9578
Epoch    55: reducing learning rate of group 0 to 6.2500e-04.
2020-04-03 15:56:48,736 BAD EPOCHS (no improvement): 4
2020-04-03 15:56:48,758 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 15:57:05,225 epoch 56 - iter 43/439 - loss 0.14836579 - samples/sec: 83.60
2020-04-03 15:58:24,376 epoch 56 - iter 86/439 - loss 0.14240889 - samples/sec: 83.31
2020-04-03 15:59:39,505 epoch 56 - iter 129/439 - loss 0.13880702 - samples/sec: 88.31
2020-04-03 16:01:01,759 epoch 56 - iter 172/439 - loss 0.13850796 - samples/sec: 82.72
2020-04-03 16:02:16,239 epoch 56 - iter 215/439 - loss 0.13751623 - samples/sec: 90.12
2020-04-03 16:03:34,450 epoch 56 - iter 258/439 - loss 0.13741163 - samples/sec: 87.23
2020-04-03 16:04:50,520 epoch 56 - iter 301/439 - loss 0.13903443 - samples/sec: 95.35
2020-04-03 16:06:12,791 epoch 56 - iter 344/439 - loss 0.14053316 - samples/sec: 86.01
2020-04-03 16:07:36,836 epoch 56 - iter 387/439 - loss 0.13957710 - samples/sec: 86.17
2020-04-03 16:09:03,346 epoch 56 - iter 430/439 - loss 0.13786203 - samples/sec: 89.66
2020-04-03 16:10:13,227 ----------------------------------------------------------------------------------------------------
2020-04-03 16:10:13,228 EPOCH 56 done: loss 0.1371 - lr 0.0006
2020-04-03 16:10:35,313 DEV : loss 0.5700700879096985 - score 0.9579
2020-04-03 16:10:35,752 BAD EPOCHS (no improvement): 1
2020-04-03 16:10:35,785 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 16:10:51,772 epoch 57 - iter 43/439 - loss 0.11386070 - samples/sec: 86.12
2020-04-03 16:12:18,148 epoch 57 - iter 86/439 - loss 0.11494578 - samples/sec: 84.97
2020-04-03 16:13:41,178 epoch 57 - iter 129/439 - loss 0.13103704 - samples/sec: 91.78
2020-04-03 16:15:05,482 epoch 57 - iter 172/439 - loss 0.13382249 - samples/sec: 95.59
2020-04-03 16:16:26,625 epoch 57 - iter 215/439 - loss 0.13182473 - samples/sec: 82.51
2020-04-03 16:17:51,116 epoch 57 - iter 258/439 - loss 0.13245444 - samples/sec: 83.54
2020-04-03 16:19:18,049 epoch 57 - iter 301/439 - loss 0.13382455 - samples/sec: 86.05
2020-04-03 16:20:42,329 epoch 57 - iter 344/439 - loss 0.13591714 - samples/sec: 86.77
2020-04-03 16:22:05,558 epoch 57 - iter 387/439 - loss 0.13760583 - samples/sec: 82.12
2020-04-03 16:23:28,904 epoch 57 - iter 430/439 - loss 0.13597178 - samples/sec: 81.64
2020-04-03 16:24:38,038 ----------------------------------------------------------------------------------------------------
2020-04-03 16:24:38,038 EPOCH 57 done: loss 0.1355 - lr 0.0006
2020-04-03 16:25:00,329 DEV : loss 0.5675865411758423 - score 0.9571
2020-04-03 16:25:00,758 BAD EPOCHS (no improvement): 2
2020-04-03 16:25:00,773 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 16:25:16,659 epoch 58 - iter 43/439 - loss 0.13721964 - samples/sec: 86.66
2020-04-03 16:26:43,360 epoch 58 - iter 86/439 - loss 0.13595836 - samples/sec: 86.68
2020-04-03 16:28:06,464 epoch 58 - iter 129/439 - loss 0.13269799 - samples/sec: 81.06
2020-04-03 16:29:25,658 epoch 58 - iter 172/439 - loss 0.13781779 - samples/sec: 85.74
2020-04-03 16:30:49,117 epoch 58 - iter 215/439 - loss 0.14050522 - samples/sec: 83.63
2020-04-03 16:32:14,843 epoch 58 - iter 258/439 - loss 0.14464077 - samples/sec: 82.13
2020-04-03 16:33:38,663 epoch 58 - iter 301/439 - loss 0.14514687 - samples/sec: 84.65
2020-04-03 16:35:11,085 epoch 58 - iter 344/439 - loss 0.14504815 - samples/sec: 93.53
2020-04-03 16:36:35,124 epoch 58 - iter 387/439 - loss 0.14558321 - samples/sec: 95.66
2020-04-03 16:37:56,257 epoch 58 - iter 430/439 - loss 0.14393238 - samples/sec: 98.79
2020-04-03 16:39:03,515 ----------------------------------------------------------------------------------------------------
2020-04-03 16:39:03,515 EPOCH 58 done: loss 0.1441 - lr 0.0006
2020-04-03 16:39:25,815 DEV : loss 0.5668833255767822 - score 0.9572
2020-04-03 16:39:26,253 BAD EPOCHS (no improvement): 3
2020-04-03 16:39:26,288 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 16:39:42,628 epoch 59 - iter 43/439 - loss 0.12920775 - samples/sec: 84.25
2020-04-03 16:41:06,938 epoch 59 - iter 86/439 - loss 0.13125201 - samples/sec: 84.88
2020-04-03 16:42:27,694 epoch 59 - iter 129/439 - loss 0.13372006 - samples/sec: 85.90
2020-04-03 16:43:57,052 epoch 59 - iter 172/439 - loss 0.12808342 - samples/sec: 79.53
2020-04-03 16:45:19,741 epoch 59 - iter 215/439 - loss 0.12468822 - samples/sec: 83.16
2020-04-03 16:46:43,631 epoch 59 - iter 258/439 - loss 0.12695615 - samples/sec: 82.99
2020-04-03 16:48:04,157 epoch 59 - iter 301/439 - loss 0.13082290 - samples/sec: 87.02
2020-04-03 16:49:27,883 epoch 59 - iter 344/439 - loss 0.13287741 - samples/sec: 89.86
2020-04-03 16:50:48,896 epoch 59 - iter 387/439 - loss 0.13120863 - samples/sec: 79.36
2020-04-03 16:52:12,288 epoch 59 - iter 430/439 - loss 0.13555517 - samples/sec: 83.75
2020-04-03 16:53:20,579 ----------------------------------------------------------------------------------------------------
2020-04-03 16:53:20,579 EPOCH 59 done: loss 0.1351 - lr 0.0006
2020-04-03 16:53:42,796 DEV : loss 0.5666080117225647 - score 0.9576
Epoch    59: reducing learning rate of group 0 to 3.1250e-04.
2020-04-03 16:53:43,238 BAD EPOCHS (no improvement): 4
2020-04-03 16:53:43,265 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 16:53:57,746 epoch 60 - iter 43/439 - loss 0.13970346 - samples/sec: 95.07
2020-04-03 16:55:16,720 epoch 60 - iter 86/439 - loss 0.15633184 - samples/sec: 90.46
2020-04-03 16:56:37,990 epoch 60 - iter 129/439 - loss 0.15225077 - samples/sec: 87.65
2020-04-03 16:57:57,435 epoch 60 - iter 172/439 - loss 0.14982797 - samples/sec: 83.28
2020-04-03 16:59:23,342 epoch 60 - iter 215/439 - loss 0.14486294 - samples/sec: 84.44
2020-04-03 17:00:43,853 epoch 60 - iter 258/439 - loss 0.14474082 - samples/sec: 84.15
2020-04-03 17:02:06,210 epoch 60 - iter 301/439 - loss 0.14043258 - samples/sec: 93.35
2020-04-03 17:03:32,369 epoch 60 - iter 344/439 - loss 0.14464140 - samples/sec: 80.97
2020-04-03 17:04:52,170 epoch 60 - iter 387/439 - loss 0.14083767 - samples/sec: 91.11
2020-04-03 17:06:13,117 epoch 60 - iter 430/439 - loss 0.14112549 - samples/sec: 89.91
2020-04-03 17:07:21,510 ----------------------------------------------------------------------------------------------------
2020-04-03 17:07:21,510 EPOCH 60 done: loss 0.1404 - lr 0.0003
2020-04-03 17:07:44,752 DEV : loss 0.5681077837944031 - score 0.9576
2020-04-03 17:07:45,191 BAD EPOCHS (no improvement): 1
2020-04-03 17:07:45,205 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 17:08:00,580 epoch 61 - iter 43/439 - loss 0.15664918 - samples/sec: 89.53
2020-04-03 17:09:23,535 epoch 61 - iter 86/439 - loss 0.14350676 - samples/sec: 80.16
2020-04-03 17:10:43,570 epoch 61 - iter 129/439 - loss 0.13603163 - samples/sec: 85.03
2020-04-03 17:12:02,362 epoch 61 - iter 172/439 - loss 0.12958945 - samples/sec: 83.89
2020-04-03 17:13:25,429 epoch 61 - iter 215/439 - loss 0.12572665 - samples/sec: 82.69
2020-04-03 17:14:45,201 epoch 61 - iter 258/439 - loss 0.13034618 - samples/sec: 83.60
2020-04-03 17:16:05,894 epoch 61 - iter 301/439 - loss 0.13199952 - samples/sec: 96.54
2020-04-03 17:17:27,555 epoch 61 - iter 344/439 - loss 0.13015480 - samples/sec: 89.05
2020-04-03 17:18:53,468 epoch 61 - iter 387/439 - loss 0.13433126 - samples/sec: 83.60
2020-04-03 17:20:16,792 epoch 61 - iter 430/439 - loss 0.13341483 - samples/sec: 95.13
2020-04-03 17:21:51,227 ----------------------------------------------------------------------------------------------------
2020-04-03 17:21:51,227 EPOCH 61 done: loss 0.1339 - lr 0.0003
2020-04-03 17:22:13,497 DEV : loss 0.5692821145057678 - score 0.9573
2020-04-03 17:22:14,189 BAD EPOCHS (no improvement): 2
2020-04-03 17:22:14,256 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 17:22:29,983 epoch 62 - iter 43/439 - loss 0.13302608 - samples/sec: 87.53
2020-04-03 17:23:50,765 epoch 62 - iter 86/439 - loss 0.13338901 - samples/sec: 85.77
2020-04-03 17:25:11,164 epoch 62 - iter 129/439 - loss 0.12786798 - samples/sec: 82.02
2020-04-03 17:26:34,817 epoch 62 - iter 172/439 - loss 0.12252248 - samples/sec: 87.47
2020-04-03 17:27:55,959 epoch 62 - iter 215/439 - loss 0.12565117 - samples/sec: 78.56
2020-04-03 17:29:18,982 epoch 62 - iter 258/439 - loss 0.12263521 - samples/sec: 87.57
2020-04-03 17:30:39,919 epoch 62 - iter 301/439 - loss 0.12612950 - samples/sec: 96.73
2020-04-03 17:31:59,591 epoch 62 - iter 344/439 - loss 0.12379534 - samples/sec: 95.48
2020-04-03 17:33:19,679 epoch 62 - iter 387/439 - loss 0.12343609 - samples/sec: 83.41
2020-04-03 17:34:42,142 epoch 62 - iter 430/439 - loss 0.12484328 - samples/sec: 81.69
2020-04-03 17:35:50,641 ----------------------------------------------------------------------------------------------------
2020-04-03 17:35:50,641 EPOCH 62 done: loss 0.1252 - lr 0.0003
2020-04-03 17:36:12,777 DEV : loss 0.5697394013404846 - score 0.9573
2020-04-03 17:36:13,209 BAD EPOCHS (no improvement): 3
2020-04-03 17:36:13,240 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 17:36:29,032 epoch 63 - iter 43/439 - loss 0.13994035 - samples/sec: 87.17
2020-04-03 17:37:51,687 epoch 63 - iter 86/439 - loss 0.13886940 - samples/sec: 83.30
2020-04-03 17:39:11,783 epoch 63 - iter 129/439 - loss 0.13940057 - samples/sec: 84.91
2020-04-03 17:40:34,574 epoch 63 - iter 172/439 - loss 0.14123857 - samples/sec: 80.01
2020-04-03 17:41:58,046 epoch 63 - iter 215/439 - loss 0.14302839 - samples/sec: 78.12
2020-04-03 17:43:19,642 epoch 63 - iter 258/439 - loss 0.13891472 - samples/sec: 91.41
2020-04-03 17:44:50,968 epoch 63 - iter 301/439 - loss 0.14137844 - samples/sec: 83.37
2020-04-03 17:46:13,462 epoch 63 - iter 344/439 - loss 0.14376592 - samples/sec: 84.80
2020-04-03 17:47:34,182 epoch 63 - iter 387/439 - loss 0.14405644 - samples/sec: 87.63
2020-04-03 17:48:56,890 epoch 63 - iter 430/439 - loss 0.14355609 - samples/sec: 87.86
2020-04-03 17:50:04,538 ----------------------------------------------------------------------------------------------------
2020-04-03 17:50:04,538 EPOCH 63 done: loss 0.1425 - lr 0.0003
2020-04-03 17:50:26,919 DEV : loss 0.5704808831214905 - score 0.9573
Epoch    63: reducing learning rate of group 0 to 1.5625e-04.
2020-04-03 17:50:27,353 BAD EPOCHS (no improvement): 4
2020-04-03 17:50:27,376 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 17:50:42,420 epoch 64 - iter 43/439 - loss 0.14227566 - samples/sec: 91.51
2020-04-03 17:52:05,707 epoch 64 - iter 86/439 - loss 0.12426551 - samples/sec: 84.66
2020-04-03 17:53:29,364 epoch 64 - iter 129/439 - loss 0.12036692 - samples/sec: 82.81
2020-04-03 17:54:54,082 epoch 64 - iter 172/439 - loss 0.13210964 - samples/sec: 84.22
2020-04-03 17:56:14,568 epoch 64 - iter 215/439 - loss 0.13354570 - samples/sec: 84.52
2020-04-03 17:57:39,165 epoch 64 - iter 258/439 - loss 0.12958551 - samples/sec: 80.95
2020-04-03 17:58:58,920 epoch 64 - iter 301/439 - loss 0.12662223 - samples/sec: 96.34
2020-04-03 18:00:25,333 epoch 64 - iter 344/439 - loss 0.12755997 - samples/sec: 95.98
2020-04-03 18:01:50,196 epoch 64 - iter 387/439 - loss 0.12757760 - samples/sec: 85.53
2020-04-03 18:03:12,874 epoch 64 - iter 430/439 - loss 0.12865246 - samples/sec: 84.73
2020-04-03 18:04:23,798 ----------------------------------------------------------------------------------------------------
2020-04-03 18:04:23,798 EPOCH 64 done: loss 0.1290 - lr 0.0002
2020-04-03 18:04:47,181 DEV : loss 0.5706526041030884 - score 0.957
2020-04-03 18:04:47,614 BAD EPOCHS (no improvement): 1
2020-04-03 18:04:47,636 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 18:05:04,384 epoch 65 - iter 43/439 - loss 0.12823845 - samples/sec: 82.20
2020-04-03 18:06:26,502 epoch 65 - iter 86/439 - loss 0.11996348 - samples/sec: 84.82
2020-04-03 18:08:03,580 epoch 65 - iter 129/439 - loss 0.12750936 - samples/sec: 82.50
2020-04-03 18:09:26,840 epoch 65 - iter 172/439 - loss 0.12641361 - samples/sec: 80.98
2020-04-03 18:10:53,376 epoch 65 - iter 215/439 - loss 0.13163065 - samples/sec: 85.47
2020-04-03 18:12:16,357 epoch 65 - iter 258/439 - loss 0.13292559 - samples/sec: 85.01
2020-04-03 18:13:38,603 epoch 65 - iter 301/439 - loss 0.13782007 - samples/sec: 84.75
2020-04-03 18:15:02,091 epoch 65 - iter 344/439 - loss 0.13416255 - samples/sec: 83.20
2020-04-03 18:16:25,672 epoch 65 - iter 387/439 - loss 0.13243326 - samples/sec: 86.54
2020-04-03 18:17:50,053 epoch 65 - iter 430/439 - loss 0.13253302 - samples/sec: 84.46
2020-04-03 18:18:59,118 ----------------------------------------------------------------------------------------------------
2020-04-03 18:18:59,118 EPOCH 65 done: loss 0.1334 - lr 0.0002
2020-04-03 18:19:21,417 DEV : loss 0.5704275965690613 - score 0.957
2020-04-03 18:19:21,864 BAD EPOCHS (no improvement): 2
2020-04-03 18:19:21,887 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 18:19:38,022 epoch 66 - iter 43/439 - loss 0.14005787 - samples/sec: 85.32
2020-04-03 18:20:59,373 epoch 66 - iter 86/439 - loss 0.11824231 - samples/sec: 83.04
2020-04-03 18:22:23,004 epoch 66 - iter 129/439 - loss 0.13457277 - samples/sec: 79.36
2020-04-03 18:23:43,336 epoch 66 - iter 172/439 - loss 0.13476405 - samples/sec: 95.92
2020-04-03 18:25:07,824 epoch 66 - iter 215/439 - loss 0.13671077 - samples/sec: 90.77
2020-04-03 18:26:30,709 epoch 66 - iter 258/439 - loss 0.13389680 - samples/sec: 94.81
2020-04-03 18:27:55,530 epoch 66 - iter 301/439 - loss 0.13292258 - samples/sec: 94.98
2020-04-03 18:29:22,431 epoch 66 - iter 344/439 - loss 0.13375507 - samples/sec: 79.22
2020-04-03 18:30:44,356 epoch 66 - iter 387/439 - loss 0.13379871 - samples/sec: 80.49
2020-04-03 18:32:08,556 epoch 66 - iter 430/439 - loss 0.13514231 - samples/sec: 79.76
2020-04-03 18:33:15,772 ----------------------------------------------------------------------------------------------------
2020-04-03 18:33:15,772 EPOCH 66 done: loss 0.1363 - lr 0.0002
2020-04-03 18:33:38,012 DEV : loss 0.5701438784599304 - score 0.9575
2020-04-03 18:33:38,452 BAD EPOCHS (no improvement): 3
2020-04-03 18:33:38,473 ----------------------------------------------------------------------------------------------------
train mode resetting embeddings
train mode resetting embeddings
2020-04-03 18:33:53,785 epoch 67 - iter 43/439 - loss 0.15501396 - samples/sec: 89.91
2020-04-03 18:35:14,749 epoch 67 - iter 86/439 - loss 0.13915943 - samples/sec: 86.98
2020-04-03 18:36:50,939 epoch 67 - iter 129/439 - loss 0.13803016 - samples/sec: 82.77
2020-04-03 18:38:14,702 epoch 67 - iter 172/439 - loss 0.13907977 - samples/sec: 85.10
2020-04-03 18:39:35,695 epoch 67 - iter 215/439 - loss 0.13440689 - samples/sec: 87.01
2020-04-03 18:40:58,919 epoch 67 - iter 258/439 - loss 0.13349480 - samples/sec: 88.75
2020-04-03 18:42:20,015 epoch 67 - iter 301/439 - loss 0.13400345 - samples/sec: 83.37
2020-04-03 18:43:40,598 epoch 67 - iter 344/439 - loss 0.13322754 - samples/sec: 81.06
2020-04-03 18:45:02,355 epoch 67 - iter 387/439 - loss 0.13703294 - samples/sec: 84.44
2020-04-03 18:46:24,507 epoch 67 - iter 430/439 - loss 0.13880862 - samples/sec: 91.41
2020-04-03 18:47:31,853 ----------------------------------------------------------------------------------------------------
2020-04-03 18:47:31,853 EPOCH 67 done: loss 0.1381 - lr 0.0002
2020-04-03 18:47:53,983 DEV : loss 0.5715748071670532 - score 0.957
Epoch    67: reducing learning rate of group 0 to 7.8125e-05.
2020-04-03 18:47:54,420 BAD EPOCHS (no improvement): 4
2020-04-03 18:47:54,442 ----------------------------------------------------------------------------------------------------
2020-04-03 18:47:54,442 ----------------------------------------------------------------------------------------------------
2020-04-03 18:47:54,442 learning rate too small - quitting training!
2020-04-03 18:47:54,442 ----------------------------------------------------------------------------------------------------
2020-04-03 18:48:41,927 ----------------------------------------------------------------------------------------------------
2020-04-03 18:48:41,927 Testing using best model ...
2020-04-03 18:48:41,944 loading file log/mix_xfeb_20200401210102_256/best-model.pt
Traceback (most recent call last):
  File "train.py", line 127, in <module>
    
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/trainers/trainer.py", line 553, in train
    final_score = self.final_test(base_path, mini_batch_chunk_size, num_workers)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/trainers/trainer.py", line 601, in final_test
    embedding_storage_mode="none",
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/models/sequence_tagger_model.py", line 412, in evaluate
    features = self.forward(batch)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/models/sequence_tagger_model.py", line 498, in forward
    self.embeddings.embed(sentences)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/embeddings.py", line 177, in embed
    embedding.embed(sentences)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/embeddings.py", line 96, in embed
    self._add_embeddings_internal(sentences)
  File "/home/qingpeng/anaconda3/envs/cuda100/lib/python3.6/site-packages/flair/embeddings.py", line 2157, in _add_embeddings_internal
    self.word_embeddings[token.text], local_embedding
RuntimeError: Expected object of device type cuda but got device type cpu for argument #2 'other' in call to _th_min
2020-04-08 15:22:22,534 Reading data from data
2020-04-08 15:22:22,534 Train: data/train.txt
2020-04-08 15:22:22,534 Dev: data/valid.txt
2020-04-08 15:22:22,534 Test: data/test.txt
Corpus: 14041 train + 3250 dev + 3453 test sentences
Dictionary with 12 tags: <unk>, O, B-ORG, B-MISC, B-PER, I-PER, B-LOC, I-ORG, I-MISC, I-LOC, <START>, <STOP>
bert
2020-04-08 15:22:43,569 ----------------------------------------------------------------------------------------------------
2020-04-08 15:22:43,573 Model: "SequenceTagger(
  (embeddings): BertEmbeddings(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3072, out_features=3072, bias=True)
  (rnn): LSTM(3072, 128, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=256, out_features=12, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2020-04-08 15:22:43,573 ----------------------------------------------------------------------------------------------------
2020-04-08 15:22:43,573 Corpus: "Corpus: 14041 train + 3250 dev + 3453 test sentences"
2020-04-08 15:22:43,574 ----------------------------------------------------------------------------------------------------
2020-04-08 15:22:43,574 Parameters:
2020-04-08 15:22:43,574  - learning_rate: "0.01"
2020-04-08 15:22:43,574  - mini_batch_size: "32"
2020-04-08 15:22:43,574  - patience: "3"
2020-04-08 15:22:43,574  - anneal_factor: "0.5"
2020-04-08 15:22:43,574  - max_epochs: "150"
2020-04-08 15:22:43,575  - shuffle: "True"
2020-04-08 15:22:43,575  - train_with_dev: "False"
2020-04-08 15:22:43,575  - batch_growth_annealing: "False"
2020-04-08 15:22:43,575 ----------------------------------------------------------------------------------------------------
2020-04-08 15:22:43,575 Model training base path: "log/bert_20200408152243_128"
2020-04-08 15:22:43,575 ----------------------------------------------------------------------------------------------------
2020-04-08 15:22:43,575 Device: cuda:0
2020-04-08 15:22:43,575 ----------------------------------------------------------------------------------------------------
2020-04-08 15:22:43,575 Embeddings storage mode: cpu
2020-04-08 15:22:43,580 ----------------------------------------------------------------------------------------------------
2020-04-08 15:22:41,470 Reading data from data
2020-04-08 15:22:41,471 Train: data/train.txt
2020-04-08 15:22:41,471 Dev: data/valid.txt
2020-04-08 15:22:41,471 Test: data/test.txt
Corpus: 14041 train + 3250 dev + 3453 test sentences
Dictionary with 12 tags: <unk>, O, B-ORG, B-MISC, B-PER, I-PER, B-LOC, I-ORG, I-MISC, I-LOC, <START>, <STOP>
bert
2020-04-08 15:22:58,822 ----------------------------------------------------------------------------------------------------
2020-04-08 15:22:58,824 Model: "SequenceTagger(
  (embeddings): BertEmbeddings(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=3072, out_features=3072, bias=True)
  (rnn): LSTM(3072, 512, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=1024, out_features=12, bias=True)
  (beta): 1.0
  (weights): None
  (weight_tensor) None
)"
2020-04-08 15:22:58,824 ----------------------------------------------------------------------------------------------------
2020-04-08 15:22:58,824 Corpus: "Corpus: 14041 train + 3250 dev + 3453 test sentences"
2020-04-08 15:22:58,824 ----------------------------------------------------------------------------------------------------
2020-04-08 15:22:58,824 Parameters:
2020-04-08 15:22:58,824  - learning_rate: "0.01"
2020-04-08 15:22:58,824  - mini_batch_size: "32"
2020-04-08 15:22:58,825  - patience: "3"
2020-04-08 15:22:58,825  - anneal_factor: "0.5"
2020-04-08 15:22:58,825  - max_epochs: "150"
2020-04-08 15:22:58,825  - shuffle: "True"
2020-04-08 15:22:58,825  - train_with_dev: "False"
2020-04-08 15:22:58,825  - batch_growth_annealing: "False"
2020-04-08 15:22:58,825 ----------------------------------------------------------------------------------------------------
2020-04-08 15:22:58,825 Model training base path: "log/bert_20200408152258_512"
2020-04-08 15:22:58,825 ----------------------------------------------------------------------------------------------------
2020-04-08 15:22:58,825 Device: cuda:0
2020-04-08 15:22:58,825 ----------------------------------------------------------------------------------------------------
2020-04-08 15:22:58,825 Embeddings storage mode: cpu
2020-04-08 15:22:58,828 ----------------------------------------------------------------------------------------------------
2020-04-08 15:22:58,117 epoch 1 - iter 43/439 - loss 14.83280430 - samples/sec: 94.69
2020-04-08 15:23:13,547 epoch 1 - iter 43/439 - loss 13.36300712 - samples/sec: 93.52
2020-04-08 15:23:43,961 epoch 1 - iter 86/439 - loss 11.46662699 - samples/sec: 96.41
2020-04-08 15:24:04,488 epoch 1 - iter 86/439 - loss 10.66485480 - samples/sec: 97.21
2020-04-08 15:24:35,592 epoch 1 - iter 129/439 - loss 9.60741368 - samples/sec: 88.32
2020-04-08 15:24:50,781 epoch 1 - iter 129/439 - loss 9.14859240 - samples/sec: 89.62
2020-04-08 15:25:25,105 epoch 1 - iter 172/439 - loss 8.49374567 - samples/sec: 96.36
2020-04-08 15:25:43,937 epoch 1 - iter 172/439 - loss 8.20398087 - samples/sec: 99.46
2020-04-08 15:26:16,890 epoch 1 - iter 215/439 - loss 7.72484138 - samples/sec: 95.48
2020-04-08 15:26:33,828 epoch 1 - iter 215/439 - loss 7.40503024 - samples/sec: 95.38
2020-04-08 15:27:05,433 epoch 1 - iter 258/439 - loss 7.14645049 - samples/sec: 94.50
2020-04-08 15:27:22,546 epoch 1 - iter 258/439 - loss 6.81255482 - samples/sec: 92.85
2020-04-08 15:27:55,412 epoch 1 - iter 301/439 - loss 6.68780719 - samples/sec: 91.87
2020-04-08 15:28:18,303 epoch 1 - iter 301/439 - loss 6.35788027 - samples/sec: 91.60
2020-04-08 15:28:43,967 epoch 1 - iter 344/439 - loss 6.29776717 - samples/sec: 94.68
2020-04-08 15:30:08,357 epoch 1 - iter 344/439 - loss 5.97514449 - samples/sec: 94.87
2020-04-08 15:30:17,230 epoch 1 - iter 387/439 - loss 5.99710275 - samples/sec: 90.40
2020-04-08 15:31:23,400 epoch 1 - iter 387/439 - loss 5.63883192 - samples/sec: 93.78
2020-04-08 15:32:05,012 epoch 1 - iter 430/439 - loss 5.74067097 - samples/sec: 91.42
2020-04-08 15:32:31,882 epoch 1 - iter 430/439 - loss 5.36514778 - samples/sec: 93.20
2020-04-08 15:33:22,304 ----------------------------------------------------------------------------------------------------
2020-04-08 15:33:22,304 EPOCH 1 done: loss 5.6873 - lr 0.0100
2020-04-08 15:33:44,791 DEV : loss 2.314056634902954 - score 0.7715
2020-04-08 15:33:45,027 BAD EPOCHS (no improvement): 0
2020-04-08 15:33:55,075 ----------------------------------------------------------------------------------------------------
2020-04-08 15:34:02,391 epoch 2 - iter 43/439 - loss 2.97676181 - samples/sec: 188.24
2020-04-08 15:34:01,865 ----------------------------------------------------------------------------------------------------
2020-04-08 15:34:01,866 EPOCH 1 done: loss 5.3151 - lr 0.0100
2020-04-08 15:34:26,087 DEV : loss 2.0949900150299072 - score 0.7804
2020-04-08 15:34:26,301 BAD EPOCHS (no improvement): 0
2020-04-08 15:34:36,069 ----------------------------------------------------------------------------------------------------
2020-04-08 15:34:43,972 epoch 2 - iter 43/439 - loss 2.86305808 - samples/sec: 174.25
2020-04-08 15:35:01,146 epoch 2 - iter 86/439 - loss 3.11045623 - samples/sec: 181.97
2020-04-08 15:36:22,537 epoch 2 - iter 86/439 - loss 2.76005810 - samples/sec: 175.44
2020-04-08 15:36:38,691 epoch 2 - iter 129/439 - loss 3.01831294 - samples/sec: 186.23
2020-04-08 15:38:04,042 epoch 2 - iter 172/439 - loss 2.97215858 - samples/sec: 182.54
2020-04-08 15:38:00,671 epoch 2 - iter 129/439 - loss 2.68090977 - samples/sec: 180.05
2020-04-08 15:39:44,061 epoch 2 - iter 215/439 - loss 2.92901821 - samples/sec: 183.78
2020-04-08 15:39:43,986 epoch 2 - iter 172/439 - loss 2.61362169 - samples/sec: 167.22
2020-04-08 15:41:27,945 epoch 2 - iter 258/439 - loss 2.87932617 - samples/sec: 185.89
2020-04-08 15:41:28,059 epoch 2 - iter 215/439 - loss 2.54442336 - samples/sec: 181.27
2020-04-08 15:43:11,577 epoch 2 - iter 301/439 - loss 2.83778710 - samples/sec: 190.43
2020-04-08 15:43:12,337 epoch 2 - iter 258/439 - loss 2.46612928 - samples/sec: 178.91
2020-04-08 15:44:51,654 epoch 2 - iter 344/439 - loss 2.82185869 - samples/sec: 180.39
2020-04-08 15:44:56,299 epoch 2 - iter 301/439 - loss 2.44090459 - samples/sec: 174.66
2020-04-08 15:46:24,577 epoch 2 - iter 387/439 - loss 2.78139335 - samples/sec: 183.64
2020-04-08 15:46:36,144 epoch 2 - iter 344/439 - loss 2.39340881 - samples/sec: 179.38
2020-04-08 15:48:01,745 epoch 2 - iter 430/439 - loss 2.74521506 - samples/sec: 181.55
2020-04-08 15:48:03,632 epoch 2 - iter 387/439 - loss 2.33664025 - samples/sec: 190.70
2020-04-08 15:49:19,852 ----------------------------------------------------------------------------------------------------
2020-04-08 15:49:19,852 EPOCH 2 done: loss 2.7363 - lr 0.0100
2020-04-08 15:49:27,410 DEV : loss 1.5479023456573486 - score 0.8319
2020-04-08 15:49:27,587 BAD EPOCHS (no improvement): 0
2020-04-08 15:49:27,388 epoch 2 - iter 430/439 - loss 2.29141961 - samples/sec: 182.67
2020-04-08 15:49:36,417 ----------------------------------------------------------------------------------------------------
2020-04-08 15:49:44,114 epoch 3 - iter 43/439 - loss 2.10799243 - samples/sec: 178.89
2020-04-08 15:50:32,633 ----------------------------------------------------------------------------------------------------
2020-04-08 15:50:32,633 EPOCH 2 done: loss 2.2870 - lr 0.0100
2020-04-08 15:50:39,697 DEV : loss 1.3729979991912842 - score 0.8693
2020-04-08 15:50:39,911 BAD EPOCHS (no improvement): 0
2020-04-08 15:50:46,653 epoch 3 - iter 86/439 - loss 2.14899202 - samples/sec: 185.53
2020-04-08 15:50:49,728 ----------------------------------------------------------------------------------------------------
2020-04-08 15:50:57,260 epoch 3 - iter 43/439 - loss 1.96232928 - samples/sec: 182.85
2020-04-08 15:51:56,873 epoch 3 - iter 129/439 - loss 2.17652655 - samples/sec: 182.85
2020-04-08 15:52:04,167 epoch 3 - iter 86/439 - loss 1.87329953 - samples/sec: 179.84
2020-04-08 15:53:03,711 epoch 3 - iter 172/439 - loss 2.17401060 - samples/sec: 175.21
2020-04-08 15:53:17,032 epoch 3 - iter 129/439 - loss 1.89930517 - samples/sec: 147.51
2020-04-08 15:54:03,375 epoch 3 - iter 215/439 - loss 2.16549822 - samples/sec: 173.40
2020-04-08 15:54:19,916 epoch 3 - iter 172/439 - loss 1.89336166 - samples/sec: 186.41
2020-04-08 15:55:06,527 epoch 3 - iter 258/439 - loss 2.17706417 - samples/sec: 177.26
2020-04-08 15:55:23,076 epoch 3 - iter 215/439 - loss 1.88458109 - samples/sec: 187.28
2020-04-08 15:56:10,688 epoch 3 - iter 301/439 - loss 2.14663070 - samples/sec: 185.70
2020-04-08 15:56:28,431 epoch 3 - iter 258/439 - loss 1.85370659 - samples/sec: 177.77
2020-04-08 15:57:14,549 epoch 3 - iter 344/439 - loss 2.15770080 - samples/sec: 184.01
2020-04-08 15:57:32,745 epoch 3 - iter 301/439 - loss 1.84080642 - samples/sec: 182.47
2020-04-08 15:58:17,600 epoch 3 - iter 387/439 - loss 2.15740705 - samples/sec: 176.73
2020-04-08 15:58:35,550 epoch 3 - iter 344/439 - loss 1.82321472 - samples/sec: 180.79
2020-04-08 15:59:20,508 epoch 3 - iter 430/439 - loss 2.14039743 - samples/sec: 182.67
2020-04-08 15:59:41,667 epoch 3 - iter 387/439 - loss 1.81526630 - samples/sec: 176.32
2020-04-08 16:00:16,658 ----------------------------------------------------------------------------------------------------
2020-04-08 16:00:16,658 EPOCH 3 done: loss 2.1321 - lr 0.0100
2020-04-08 16:00:24,008 DEV : loss 1.2920405864715576 - score 0.8751
2020-04-08 16:00:24,132 BAD EPOCHS (no improvement): 0
2020-04-08 16:00:33,231 ----------------------------------------------------------------------------------------------------
2020-04-08 16:00:40,836 epoch 4 - iter 43/439 - loss 2.12073197 - samples/sec: 181.08
2020-04-08 16:00:42,298 epoch 3 - iter 430/439 - loss 1.79915978 - samples/sec: 176.43
2020-04-08 16:02:03,110 ----------------------------------------------------------------------------------------------------
2020-04-08 16:02:03,110 EPOCH 3 done: loss 1.7945 - lr 0.0100
2020-04-08 16:02:07,465 epoch 4 - iter 86/439 - loss 1.99285861 - samples/sec: 181.53
2020-04-08 16:02:11,014 DEV : loss 1.1624743938446045 - score 0.8875
2020-04-08 16:02:11,208 BAD EPOCHS (no improvement): 0
2020-04-08 16:02:20,653 ----------------------------------------------------------------------------------------------------
2020-04-08 16:02:28,184 epoch 4 - iter 43/439 - loss 1.62159910 - samples/sec: 182.86
2020-04-08 16:03:17,357 epoch 4 - iter 129/439 - loss 1.98236179 - samples/sec: 179.88
2020-04-08 16:03:42,602 epoch 4 - iter 86/439 - loss 1.54932920 - samples/sec: 182.85
2020-04-08 16:04:25,282 epoch 4 - iter 172/439 - loss 1.97785623 - samples/sec: 177.99
2020-04-08 16:04:48,085 epoch 4 - iter 129/439 - loss 1.57439080 - samples/sec: 182.99
2020-04-08 16:05:28,271 epoch 4 - iter 215/439 - loss 1.94845784 - samples/sec: 179.28
2020-04-08 16:05:52,946 epoch 4 - iter 172/439 - loss 1.57639503 - samples/sec: 176.62
2020-04-08 16:06:33,426 epoch 4 - iter 258/439 - loss 1.94419090 - samples/sec: 180.74
2020-04-08 16:06:56,575 epoch 4 - iter 215/439 - loss 1.55831121 - samples/sec: 179.46
2020-04-08 16:07:38,644 epoch 4 - iter 301/439 - loss 1.93321103 - samples/sec: 177.10
2020-04-08 16:08:00,818 epoch 4 - iter 258/439 - loss 1.56423829 - samples/sec: 178.50
2020-04-08 16:08:41,661 epoch 4 - iter 344/439 - loss 1.91232286 - samples/sec: 174.71
2020-04-08 16:09:01,873 epoch 4 - iter 301/439 - loss 1.56542270 - samples/sec: 187.97
2020-04-08 16:09:44,424 epoch 4 - iter 387/439 - loss 1.91311346 - samples/sec: 191.88
2020-04-08 16:10:06,804 epoch 4 - iter 344/439 - loss 1.56264213 - samples/sec: 164.28
2020-04-08 16:10:46,147 epoch 4 - iter 430/439 - loss 1.89491982 - samples/sec: 172.60
2020-04-08 16:11:14,035 epoch 4 - iter 387/439 - loss 1.56073751 - samples/sec: 192.00
2020-04-08 16:11:50,448 ----------------------------------------------------------------------------------------------------
2020-04-08 16:11:50,449 EPOCH 4 done: loss 1.8951 - lr 0.0100
2020-04-08 16:11:58,036 DEV : loss 1.1609349250793457 - score 0.8915
2020-04-08 16:11:58,193 BAD EPOCHS (no improvement): 0
2020-04-08 16:12:15,494 epoch 4 - iter 430/439 - loss 1.56952745 - samples/sec: 184.63
2020-04-08 16:12:07,144 ----------------------------------------------------------------------------------------------------
2020-04-08 16:12:14,543 epoch 5 - iter 43/439 - loss 1.69562090 - samples/sec: 186.14
2020-04-08 16:13:52,119 ----------------------------------------------------------------------------------------------------
2020-04-08 16:13:52,119 EPOCH 4 done: loss 1.5716 - lr 0.0100
2020-04-08 16:13:53,186 epoch 5 - iter 86/439 - loss 1.72549389 - samples/sec: 181.43
2020-04-08 16:13:59,483 DEV : loss 1.0641913414001465 - score 0.8974
2020-04-08 16:13:59,623 BAD EPOCHS (no improvement): 0
2020-04-08 16:14:09,341 ----------------------------------------------------------------------------------------------------
2020-04-08 16:14:17,189 epoch 5 - iter 43/439 - loss 1.47147363 - samples/sec: 175.47
2020-04-08 16:15:10,837 epoch 5 - iter 129/439 - loss 1.71070561 - samples/sec: 173.67
2020-04-08 16:15:57,895 epoch 5 - iter 86/439 - loss 1.47480715 - samples/sec: 176.14
2020-04-08 16:16:51,935 epoch 5 - iter 172/439 - loss 1.73017664 - samples/sec: 183.45
2020-04-08 16:17:39,174 epoch 5 - iter 129/439 - loss 1.48433164 - samples/sec: 180.63
2020-04-08 16:18:37,665 epoch 5 - iter 215/439 - loss 1.72147908 - samples/sec: 184.40
2020-04-08 16:18:56,276 epoch 5 - iter 172/439 - loss 1.46551002 - samples/sec: 186.40
2020-04-08 16:20:25,755 epoch 5 - iter 215/439 - loss 1.46892665 - samples/sec: 173.35
2020-04-08 16:20:21,840 epoch 5 - iter 258/439 - loss 1.70459827 - samples/sec: 185.47
2020-04-08 16:21:53,681 epoch 5 - iter 301/439 - loss 1.68515259 - samples/sec: 168.25
2020-04-08 16:22:11,432 epoch 5 - iter 258/439 - loss 1.45449423 - samples/sec: 174.42
2020-04-08 16:23:33,895 epoch 5 - iter 344/439 - loss 1.68742645 - samples/sec: 175.63
2020-04-08 16:23:51,148 epoch 5 - iter 301/439 - loss 1.44695854 - samples/sec: 176.45
2020-04-08 16:25:20,033 epoch 5 - iter 387/439 - loss 1.68960156 - samples/sec: 178.19
2020-04-08 16:25:36,692 epoch 5 - iter 344/439 - loss 1.44383843 - samples/sec: 167.76
2020-04-08 16:27:04,277 epoch 5 - iter 430/439 - loss 1.69911029 - samples/sec: 175.95
2020-04-08 16:27:22,383 epoch 5 - iter 387/439 - loss 1.44334369 - samples/sec: 178.68
2020-04-08 16:28:48,371 ----------------------------------------------------------------------------------------------------
2020-04-08 16:28:48,372 EPOCH 5 done: loss 1.6985 - lr 0.0100
2020-04-08 16:28:55,719 DEV : loss 1.0972355604171753 - score 0.8983
2020-04-08 16:28:55,866 BAD EPOCHS (no improvement): 0
2020-04-08 16:28:57,557 epoch 5 - iter 430/439 - loss 1.44303500 - samples/sec: 188.91
2020-04-08 16:29:04,625 ----------------------------------------------------------------------------------------------------
2020-04-08 16:29:11,994 epoch 6 - iter 43/439 - loss 1.84224618 - samples/sec: 186.87
2020-04-08 16:30:45,219 ----------------------------------------------------------------------------------------------------
2020-04-08 16:30:45,220 EPOCH 5 done: loss 1.4488 - lr 0.0100
2020-04-08 16:30:55,257 epoch 6 - iter 86/439 - loss 1.72927174 - samples/sec: 186.98
2020-04-08 16:30:52,124 DEV : loss 1.006522297859192 - score 0.9019
2020-04-08 16:30:52,358 BAD EPOCHS (no improvement): 0
2020-04-08 16:31:01,647 ----------------------------------------------------------------------------------------------------
2020-04-08 16:31:09,274 epoch 6 - iter 43/439 - loss 1.42028415 - samples/sec: 180.54
2020-04-08 16:32:12,715 epoch 6 - iter 129/439 - loss 1.68388201 - samples/sec: 176.94
2020-04-08 16:32:49,838 epoch 6 - iter 86/439 - loss 1.34291310 - samples/sec: 173.53
2020-04-08 16:33:39,198 epoch 6 - iter 172/439 - loss 1.68092064 - samples/sec: 175.18
2020-04-08 16:34:23,542 epoch 6 - iter 129/439 - loss 1.33986094 - samples/sec: 172.60
2020-04-08 16:35:25,004 epoch 6 - iter 215/439 - loss 1.64029955 - samples/sec: 185.75
2020-04-08 16:36:12,156 epoch 6 - iter 172/439 - loss 1.33386139 - samples/sec: 184.80
2020-04-08 16:36:41,975 epoch 6 - iter 258/439 - loss 1.61328493 - samples/sec: 182.91
2020-04-08 16:38:03,708 epoch 6 - iter 215/439 - loss 1.33212732 - samples/sec: 172.58
2020-04-08 16:38:15,521 epoch 6 - iter 301/439 - loss 1.61566717 - samples/sec: 174.40
2020-04-08 16:39:16,086 epoch 6 - iter 258/439 - loss 1.32684871 - samples/sec: 182.85
2020-04-08 16:39:58,783 epoch 6 - iter 344/439 - loss 1.59344564 - samples/sec: 178.30
2020-04-08 16:40:57,511 epoch 6 - iter 301/439 - loss 1.31651574 - samples/sec: 175.21
2020-04-08 16:41:39,529 epoch 6 - iter 387/439 - loss 1.59401600 - samples/sec: 172.53
2020-04-08 16:42:40,430 epoch 6 - iter 344/439 - loss 1.31968238 - samples/sec: 178.61
2020-04-08 16:43:23,998 epoch 6 - iter 430/439 - loss 1.59379447 - samples/sec: 179.60
2020-04-08 16:44:26,911 epoch 6 - iter 387/439 - loss 1.33339820 - samples/sec: 184.48
2020-04-08 16:44:32,462 ----------------------------------------------------------------------------------------------------
2020-04-08 16:44:32,462 EPOCH 6 done: loss 1.5901 - lr 0.0100
2020-04-08 16:44:39,120 DEV : loss 1.0288623571395874 - score 0.9036
2020-04-08 16:44:39,288 BAD EPOCHS (no improvement): 0
2020-04-08 16:44:47,477 ----------------------------------------------------------------------------------------------------
2020-04-08 16:44:54,821 epoch 7 - iter 43/439 - loss 1.46404173 - samples/sec: 187.48
2020-04-08 16:45:48,280 epoch 6 - iter 430/439 - loss 1.34173033 - samples/sec: 174.88
2020-04-08 16:46:38,068 epoch 7 - iter 86/439 - loss 1.44450166 - samples/sec: 181.62
2020-04-08 16:47:03,537 ----------------------------------------------------------------------------------------------------
2020-04-08 16:47:03,538 EPOCH 6 done: loss 1.3434 - lr 0.0100
2020-04-08 16:47:10,586 DEV : loss 0.9650187492370605 - score 0.9074
2020-04-08 16:47:10,708 BAD EPOCHS (no improvement): 0
2020-04-08 16:47:20,369 ----------------------------------------------------------------------------------------------------
2020-04-08 16:47:27,932 epoch 7 - iter 43/439 - loss 1.25188623 - samples/sec: 182.08
2020-04-08 16:48:28,939 epoch 7 - iter 129/439 - loss 1.43105917 - samples/sec: 176.68
2020-04-08 16:48:38,235 epoch 7 - iter 86/439 - loss 1.28519770 - samples/sec: 184.01
2020-04-08 16:50:07,837 epoch 7 - iter 172/439 - loss 1.47040232 - samples/sec: 171.39
2020-04-08 16:50:22,068 epoch 7 - iter 129/439 - loss 1.29626757 - samples/sec: 173.89
2020-04-08 16:51:20,031 epoch 7 - iter 215/439 - loss 1.48396417 - samples/sec: 177.03
2020-04-08 16:52:09,851 epoch 7 - iter 172/439 - loss 1.30057908 - samples/sec: 175.63
2020-04-08 16:53:03,095 epoch 7 - iter 258/439 - loss 1.49402283 - samples/sec: 194.93
2020-04-08 16:53:52,746 epoch 7 - iter 215/439 - loss 1.28053381 - samples/sec: 182.35
2020-04-08 16:54:44,629 epoch 7 - iter 301/439 - loss 1.50047026 - samples/sec: 181.32
2020-04-08 16:55:01,408 epoch 7 - iter 258/439 - loss 1.27432829 - samples/sec: 177.05
2020-04-08 16:56:00,766 epoch 7 - iter 344/439 - loss 1.48910246 - samples/sec: 177.92
2020-04-08 16:56:50,638 epoch 7 - iter 301/439 - loss 1.26026823 - samples/sec: 182.46
2020-04-08 16:57:47,486 epoch 7 - iter 387/439 - loss 1.48871375 - samples/sec: 185.99
2020-04-08 16:58:30,234 epoch 7 - iter 344/439 - loss 1.25949760 - samples/sec: 176.08
2020-04-08 16:59:35,043 epoch 7 - iter 430/439 - loss 1.48302475 - samples/sec: 196.43
2020-04-08 16:59:47,529 epoch 7 - iter 387/439 - loss 1.25238305 - samples/sec: 182.85
2020-04-08 17:00:42,469 ----------------------------------------------------------------------------------------------------
2020-04-08 17:00:42,470 EPOCH 7 done: loss 1.4785 - lr 0.0100
2020-04-08 17:00:49,258 DEV : loss 0.9726603031158447 - score 0.9075
2020-04-08 17:00:49,450 BAD EPOCHS (no improvement): 0
2020-04-08 17:00:58,488 ----------------------------------------------------------------------------------------------------
2020-04-08 17:01:05,990 epoch 8 - iter 43/439 - loss 1.42315713 - samples/sec: 183.56
2020-04-08 17:01:38,576 epoch 7 - iter 430/439 - loss 1.25445634 - samples/sec: 166.38
2020-04-08 17:02:16,248 epoch 8 - iter 86/439 - loss 1.43552674 - samples/sec: 182.41
2020-04-08 17:03:17,993 ----------------------------------------------------------------------------------------------------
2020-04-08 17:03:17,993 EPOCH 7 done: loss 1.2582 - lr 0.0100
2020-04-08 17:03:25,152 DEV : loss 0.9419052600860596 - score 0.9039
2020-04-08 17:03:25,288 BAD EPOCHS (no improvement): 1
2020-04-08 17:03:25,295 ----------------------------------------------------------------------------------------------------
2020-04-08 17:03:33,002 epoch 8 - iter 43/439 - loss 1.18844149 - samples/sec: 178.65
2020-04-08 17:03:35,187 epoch 8 - iter 129/439 - loss 1.43730071 - samples/sec: 174.09
2020-04-08 17:05:11,883 epoch 8 - iter 86/439 - loss 1.19805824 - samples/sec: 177.69
2020-04-08 17:05:22,855 epoch 8 - iter 172/439 - loss 1.42033477 - samples/sec: 173.50
2020-04-08 17:06:53,965 epoch 8 - iter 129/439 - loss 1.17663375 - samples/sec: 181.99
2020-04-08 17:07:04,900 epoch 8 - iter 215/439 - loss 1.42726256 - samples/sec: 189.06
2020-04-08 17:08:33,209 epoch 8 - iter 172/439 - loss 1.21743840 - samples/sec: 181.04
2020-04-08 17:08:43,697 epoch 8 - iter 258/439 - loss 1.42426965 - samples/sec: 175.17
2020-04-08 17:10:16,283 epoch 8 - iter 215/439 - loss 1.20196077 - samples/sec: 182.27
2020-04-08 17:10:26,969 epoch 8 - iter 301/439 - loss 1.41611966 - samples/sec: 183.17
2020-04-08 17:11:58,118 epoch 8 - iter 258/439 - loss 1.20199924 - samples/sec: 178.28
2020-04-08 17:12:00,436 epoch 8 - iter 344/439 - loss 1.41971658 - samples/sec: 186.82
2020-04-08 17:13:38,480 epoch 8 - iter 301/439 - loss 1.22211445 - samples/sec: 107.61
2020-04-08 17:13:47,156 epoch 8 - iter 387/439 - loss 1.41690016 - samples/sec: 142.60
2020-04-08 17:14:51,555 epoch 8 - iter 344/439 - loss 1.21370793 - samples/sec: 138.40
2020-04-08 17:15:32,989 epoch 8 - iter 430/439 - loss 1.40218866 - samples/sec: 181.60
2020-04-08 17:16:31,110 epoch 8 - iter 387/439 - loss 1.20104689 - samples/sec: 172.58
2020-04-08 17:16:54,701 ----------------------------------------------------------------------------------------------------
2020-04-08 17:16:54,702 EPOCH 8 done: loss 1.4117 - lr 0.0100
2020-04-08 17:17:01,652 DEV : loss 0.95020991563797 - score 0.9096
2020-04-08 17:17:01,874 BAD EPOCHS (no improvement): 0
2020-04-08 17:17:11,026 ----------------------------------------------------------------------------------------------------
2020-04-08 17:17:18,488 epoch 9 - iter 43/439 - loss 1.30350310 - samples/sec: 184.57
2020-04-08 17:18:10,178 epoch 8 - iter 430/439 - loss 1.19370861 - samples/sec: 179.21
2020-04-08 17:19:01,727 epoch 9 - iter 86/439 - loss 1.32925740 - samples/sec: 184.07
2020-04-08 17:19:46,872 ----------------------------------------------------------------------------------------------------
2020-04-08 17:19:46,872 EPOCH 8 done: loss 1.1930 - lr 0.0100
2020-04-08 17:19:53,918 DEV : loss 0.9115900993347168 - score 0.9103
2020-04-08 17:19:54,044 BAD EPOCHS (no improvement): 0
2020-04-08 17:20:03,849 ----------------------------------------------------------------------------------------------------
2020-04-08 17:20:11,652 epoch 9 - iter 43/439 - loss 1.03022174 - samples/sec: 176.62
2020-04-08 17:20:49,431 epoch 9 - iter 129/439 - loss 1.35889866 - samples/sec: 173.09
2020-04-08 17:21:46,665 epoch 9 - iter 86/439 - loss 1.09156839 - samples/sec: 177.23
2020-04-08 17:22:38,328 epoch 9 - iter 172/439 - loss 1.37509914 - samples/sec: 193.29
2020-04-08 17:23:02,299 epoch 9 - iter 129/439 - loss 1.09530379 - samples/sec: 182.46
2020-04-08 17:24:22,210 epoch 9 - iter 215/439 - loss 1.35663355 - samples/sec: 177.53
2020-04-08 17:24:45,345 epoch 9 - iter 172/439 - loss 1.11867152 - samples/sec: 173.18
2020-04-08 17:25:33,353 epoch 9 - iter 258/439 - loss 1.35522705 - samples/sec: 169.24
2020-04-08 17:26:25,358 epoch 9 - iter 215/439 - loss 1.11454425 - samples/sec: 178.24
2020-04-08 17:26:45,339 epoch 9 - iter 301/439 - loss 1.33806531 - samples/sec: 185.14
2020-04-08 17:27:36,795 epoch 9 - iter 258/439 - loss 1.12385088 - samples/sec: 180.03
2020-04-08 17:28:29,573 epoch 9 - iter 344/439 - loss 1.32834731 - samples/sec: 174.72
2020-04-08 17:28:51,355 epoch 9 - iter 301/439 - loss 1.12549323 - samples/sec: 183.79
2020-04-08 17:29:58,246 epoch 9 - iter 387/439 - loss 1.32551260 - samples/sec: 173.78
2020-04-08 17:30:35,049 epoch 9 - iter 344/439 - loss 1.13365883 - samples/sec: 183.44
2020-04-08 17:31:11,744 epoch 9 - iter 430/439 - loss 1.33356780 - samples/sec: 179.65
2020-04-08 17:32:19,989 epoch 9 - iter 387/439 - loss 1.13729118 - samples/sec: 187.27
2020-04-08 17:32:48,475 ----------------------------------------------------------------------------------------------------
2020-04-08 17:32:48,475 EPOCH 9 done: loss 1.3398 - lr 0.0100
2020-04-08 17:32:55,374 DEV : loss 0.9087488055229187 - score 0.9138
2020-04-08 17:32:55,493 BAD EPOCHS (no improvement): 0
2020-04-08 17:33:04,640 ----------------------------------------------------------------------------------------------------
2020-04-08 17:33:12,246 epoch 10 - iter 43/439 - loss 1.33668710 - samples/sec: 181.08
2020-04-08 17:33:44,686 epoch 9 - iter 430/439 - loss 1.11970916 - samples/sec: 183.92
2020-04-08 17:34:52,494 epoch 10 - iter 86/439 - loss 1.23937632 - samples/sec: 179.27
2020-04-08 17:35:15,000 ----------------------------------------------------------------------------------------------------
2020-04-08 17:35:15,000 EPOCH 9 done: loss 1.1260 - lr 0.0100
2020-04-08 17:35:21,938 DEV : loss 0.8850393891334534 - score 0.9113
2020-04-08 17:35:22,067 BAD EPOCHS (no improvement): 0
2020-04-08 17:35:31,450 ----------------------------------------------------------------------------------------------------
2020-04-08 17:35:39,139 epoch 10 - iter 43/439 - loss 1.08948252 - samples/sec: 179.12
2020-04-08 17:36:39,117 epoch 10 - iter 129/439 - loss 1.25489943 - samples/sec: 180.24
2020-04-08 17:36:48,896 epoch 10 - iter 86/439 - loss 1.08596703 - samples/sec: 178.68
2020-04-08 17:37:49,594 epoch 10 - iter 172/439 - loss 1.25026977 - samples/sec: 189.93
2020-04-08 17:38:32,455 epoch 10 - iter 129/439 - loss 1.10682370 - samples/sec: 175.87
2020-04-08 17:39:32,450 epoch 10 - iter 215/439 - loss 1.26193004 - samples/sec: 179.33
2020-04-08 17:39:44,808 epoch 10 - iter 172/439 - loss 1.10059278 - samples/sec: 174.92
2020-04-08 17:41:25,246 epoch 10 - iter 215/439 - loss 1.09061461 - samples/sec: 170.40
2020-04-08 17:41:21,473 epoch 10 - iter 258/439 - loss 1.27561838 - samples/sec: 179.80
2020-04-08 17:42:52,475 epoch 10 - iter 301/439 - loss 1.25250757 - samples/sec: 171.97
2020-04-08 17:43:12,891 epoch 10 - iter 258/439 - loss 1.09079912 - samples/sec: 182.20
2020-04-08 17:44:39,330 epoch 10 - iter 344/439 - loss 1.24293837 - samples/sec: 181.78
2020-04-08 17:44:58,579 epoch 10 - iter 301/439 - loss 1.09429646 - samples/sec: 170.37
2020-04-08 17:46:23,816 epoch 10 - iter 387/439 - loss 1.24681781 - samples/sec: 171.07
2020-04-08 17:46:42,654 epoch 10 - iter 344/439 - loss 1.09209117 - samples/sec: 183.02
2020-04-08 17:48:09,532 epoch 10 - iter 430/439 - loss 1.25616684 - samples/sec: 181.17
2020-04-08 17:48:27,953 epoch 10 - iter 387/439 - loss 1.08791496 - samples/sec: 180.66
2020-04-08 17:49:47,736 ----------------------------------------------------------------------------------------------------
2020-04-08 17:49:47,736 EPOCH 10 done: loss 1.2493 - lr 0.0100
2020-04-08 17:49:57,388 epoch 10 - iter 430/439 - loss 1.09946704 - samples/sec: 175.73
2020-04-08 17:49:55,589 DEV : loss 0.8981807231903076 - score 0.9138
2020-04-08 17:49:55,803 BAD EPOCHS (no improvement): 1
2020-04-08 17:50:04,956 ----------------------------------------------------------------------------------------------------
2020-04-08 17:50:12,769 epoch 11 - iter 43/439 - loss 1.17676332 - samples/sec: 176.25
2020-04-08 17:51:37,865 ----------------------------------------------------------------------------------------------------
2020-04-08 17:51:37,865 EPOCH 10 done: loss 1.0955 - lr 0.0100
2020-04-08 17:51:44,721 DEV : loss 0.8728390336036682 - score 0.9132
2020-04-08 17:51:44,867 BAD EPOCHS (no improvement): 0
2020-04-08 17:51:54,274 ----------------------------------------------------------------------------------------------------
2020-04-08 17:51:52,975 epoch 11 - iter 86/439 - loss 1.17495831 - samples/sec: 179.97
2020-04-08 17:52:02,199 epoch 11 - iter 43/439 - loss 1.02885695 - samples/sec: 173.79
2020-04-08 17:53:35,298 epoch 11 - iter 129/439 - loss 1.20256080 - samples/sec: 179.21
2020-04-08 17:53:42,847 epoch 11 - iter 86/439 - loss 1.02259339 - samples/sec: 189.76
2020-04-08 17:55:18,060 epoch 11 - iter 172/439 - loss 1.19138222 - samples/sec: 178.68
2020-04-08 17:55:20,253 epoch 11 - iter 129/439 - loss 1.08307100 - samples/sec: 162.77
2020-04-08 17:56:54,000 epoch 11 - iter 215/439 - loss 1.19869335 - samples/sec: 178.70
2020-04-08 17:57:04,565 epoch 11 - iter 172/439 - loss 1.08578596 - samples/sec: 171.45
2020-04-08 17:58:10,156 epoch 11 - iter 258/439 - loss 1.18463591 - samples/sec: 173.54
2020-04-08 17:58:20,517 epoch 11 - iter 215/439 - loss 1.05832624 - samples/sec: 175.47
2020-04-08 17:59:36,633 epoch 11 - iter 301/439 - loss 1.20200091 - samples/sec: 181.50
2020-04-08 18:00:02,009 epoch 11 - iter 258/439 - loss 1.05959225 - samples/sec: 173.57
2020-04-08 18:00:46,844 epoch 11 - iter 344/439 - loss 1.20626853 - samples/sec: 185.30
2020-04-08 18:01:44,206 epoch 11 - iter 301/439 - loss 1.04351011 - samples/sec: 177.60
2020-04-08 18:02:30,040 epoch 11 - iter 387/439 - loss 1.20811702 - samples/sec: 172.09
2020-04-08 18:03:27,014 epoch 11 - iter 344/439 - loss 1.06048128 - samples/sec: 174.24
2020-04-08 18:04:11,642 epoch 11 - iter 430/439 - loss 1.21299233 - samples/sec: 189.44
2020-04-08 18:04:40,865 epoch 11 - iter 387/439 - loss 1.06371325 - samples/sec: 171.24
2020-04-08 18:05:47,785 ----------------------------------------------------------------------------------------------------
2020-04-08 18:05:47,785 EPOCH 11 done: loss 1.2097 - lr 0.0100
2020-04-08 18:05:57,127 DEV : loss 0.8727196455001831 - score 0.9136
2020-04-08 18:05:57,277 BAD EPOCHS (no improvement): 2
2020-04-08 18:05:57,292 ----------------------------------------------------------------------------------------------------
2020-04-08 18:06:05,929 epoch 12 - iter 43/439 - loss 1.20334228 - samples/sec: 159.42
2020-04-08 18:06:02,180 epoch 11 - iter 430/439 - loss 1.06799103 - samples/sec: 176.71
2020-04-08 18:07:24,261 ----------------------------------------------------------------------------------------------------
2020-04-08 18:07:24,262 EPOCH 11 done: loss 1.0680 - lr 0.0100
2020-04-08 18:07:31,432 DEV : loss 0.8401533961296082 - score 0.9141
2020-04-08 18:07:31,577 BAD EPOCHS (no improvement): 0
2020-04-08 18:07:41,025 ----------------------------------------------------------------------------------------------------
2020-04-08 18:07:48,454 epoch 12 - iter 43/439 - loss 1.00541458 - samples/sec: 185.39
2020-04-08 18:07:51,815 epoch 12 - iter 86/439 - loss 1.23385862 - samples/sec: 176.03
2020-04-08 18:09:20,147 epoch 12 - iter 86/439 - loss 1.04628230 - samples/sec: 115.08
2020-04-08 18:09:34,623 epoch 12 - iter 129/439 - loss 1.21463313 - samples/sec: 150.85
2020-04-08 18:11:05,176 epoch 12 - iter 129/439 - loss 1.03703434 - samples/sec: 165.65
2020-04-08 18:11:18,320 epoch 12 - iter 172/439 - loss 1.19406688 - samples/sec: 171.82
2020-04-08 18:12:48,341 epoch 12 - iter 172/439 - loss 1.01558126 - samples/sec: 187.81
2020-04-08 18:13:01,384 epoch 12 - iter 215/439 - loss 1.19838956 - samples/sec: 182.23
2020-04-08 18:14:30,835 epoch 12 - iter 215/439 - loss 0.99364900 - samples/sec: 179.09
2020-04-08 18:14:44,510 epoch 12 - iter 258/439 - loss 1.21523773 - samples/sec: 174.93
2020-04-08 18:16:10,599 epoch 12 - iter 258/439 - loss 1.00455696 - samples/sec: 177.61
2020-04-08 18:16:13,277 epoch 12 - iter 301/439 - loss 1.20232186 - samples/sec: 181.68
2020-04-08 18:17:46,815 epoch 12 - iter 301/439 - loss 1.00951222 - samples/sec: 160.06
2020-04-08 18:17:56,477 epoch 12 - iter 344/439 - loss 1.18488463 - samples/sec: 100.24
2020-04-08 18:18:55,626 epoch 12 - iter 344/439 - loss 1.00492794 - samples/sec: 184.52
2020-04-08 18:19:12,626 epoch 12 - iter 387/439 - loss 1.16983500 - samples/sec: 188.21
2020-04-08 18:20:35,664 epoch 12 - iter 387/439 - loss 1.00664567 - samples/sec: 174.23
2020-04-08 18:20:51,073 epoch 12 - iter 430/439 - loss 1.16774470 - samples/sec: 172.57
2020-04-08 18:21:45,055 epoch 12 - iter 430/439 - loss 1.01566142 - samples/sec: 184.38
2020-04-08 18:22:24,262 ----------------------------------------------------------------------------------------------------
2020-04-08 18:22:24,262 EPOCH 12 done: loss 1.1673 - lr 0.0100
2020-04-08 18:22:32,333 DEV : loss 0.8392486572265625 - score 0.9191
2020-04-08 18:22:32,452 BAD EPOCHS (no improvement): 0
2020-04-08 18:22:41,565 ----------------------------------------------------------------------------------------------------
2020-04-08 18:22:50,295 epoch 13 - iter 43/439 - loss 1.10970612 - samples/sec: 157.69
2020-04-08 18:22:47,834 ----------------------------------------------------------------------------------------------------
2020-04-08 18:22:47,835 EPOCH 12 done: loss 1.0120 - lr 0.0100
2020-04-08 18:22:53,621 DEV : loss 0.8214836120605469 - score 0.9149
2020-04-08 18:22:53,718 BAD EPOCHS (no improvement): 0
2020-04-08 18:23:03,157 ----------------------------------------------------------------------------------------------------
2020-04-08 18:23:09,885 epoch 13 - iter 43/439 - loss 0.97126884 - samples/sec: 204.65
2020-04-08 18:24:25,922 epoch 13 - iter 86/439 - loss 1.11884032 - samples/sec: 224.52
2020-04-08 18:24:44,879 epoch 13 - iter 86/439 - loss 1.02333955 - samples/sec: 212.25
2020-04-08 18:25:44,066 epoch 13 - iter 129/439 - loss 1.11382965 - samples/sec: 220.61
2020-04-08 18:26:29,617 epoch 13 - iter 129/439 - loss 0.96233708 - samples/sec: 212.54
2020-04-08 18:27:22,906 epoch 13 - iter 172/439 - loss 1.12695900 - samples/sec: 279.47
2020-04-08 18:28:12,105 epoch 13 - iter 172/439 - loss 0.96094924 - samples/sec: 231.52
2020-04-08 18:29:04,975 epoch 13 - iter 215/439 - loss 1.13691317 - samples/sec: 199.22
2020-04-08 18:29:54,361 epoch 13 - iter 215/439 - loss 0.95630186 - samples/sec: 219.53
2020-04-08 18:30:46,915 epoch 13 - iter 258/439 - loss 1.12115511 - samples/sec: 210.73
2020-04-08 18:31:10,876 epoch 13 - iter 258/439 - loss 0.95931745 - samples/sec: 189.17
2020-04-08 18:32:28,478 epoch 13 - iter 301/439 - loss 1.14076317 - samples/sec: 202.36
2020-04-08 18:32:52,809 epoch 13 - iter 301/439 - loss 0.97191942 - samples/sec: 227.93
2020-04-08 18:33:44,737 epoch 13 - iter 344/439 - loss 1.14064708 - samples/sec: 213.31
2020-04-08 18:34:32,249 epoch 13 - iter 344/439 - loss 0.97159052 - samples/sec: 236.73
2020-04-08 18:35:24,499 epoch 13 - iter 387/439 - loss 1.13530417 - samples/sec: 198.13
2020-04-08 18:36:13,856 epoch 13 - iter 387/439 - loss 0.96118433 - samples/sec: 204.95
2020-04-08 18:37:06,391 epoch 13 - iter 430/439 - loss 1.13400203 - samples/sec: 219.00
2020-04-08 18:37:55,399 epoch 13 - iter 430/439 - loss 0.96200464 - samples/sec: 216.61
2020-04-08 18:38:42,396 ----------------------------------------------------------------------------------------------------
2020-04-08 18:38:42,396 EPOCH 13 done: loss 1.1296 - lr 0.0100
2020-04-08 18:38:47,095 DEV : loss 0.8386668562889099 - score 0.9201
2020-04-08 18:38:47,191 BAD EPOCHS (no improvement): 0
2020-04-08 18:38:59,439 ----------------------------------------------------------------------------------------------------
2020-04-08 18:38:59,439 EPOCH 13 done: loss 0.9576 - lr 0.0100
2020-04-08 18:39:04,292 DEV : loss 0.8225874900817871 - score 0.9175
2020-04-08 18:39:04,388 BAD EPOCHS (no improvement): 0
2020-04-08 18:38:55,377 ----------------------------------------------------------------------------------------------------
2020-04-08 18:39:01,164 epoch 14 - iter 43/439 - loss 1.10514605 - samples/sec: 237.97
2020-04-08 18:39:13,979 ----------------------------------------------------------------------------------------------------
2020-04-08 18:39:20,549 epoch 14 - iter 43/439 - loss 0.89829793 - samples/sec: 209.61
2020-04-08 18:40:12,448 epoch 14 - iter 86/439 - loss 1.07535693 - samples/sec: 272.85
2020-04-08 18:41:09,752 epoch 14 - iter 86/439 - loss 0.86027374 - samples/sec: 205.85
2020-04-08 18:41:55,737 epoch 14 - iter 129/439 - loss 1.08351647 - samples/sec: 234.69
2020-04-08 18:42:29,908 epoch 14 - iter 129/439 - loss 0.90995800 - samples/sec: 217.15
2020-04-08 18:43:42,255 epoch 14 - iter 172/439 - loss 1.10350908 - samples/sec: 205.51
2020-04-08 18:43:58,029 epoch 14 - iter 172/439 - loss 0.92435438 - samples/sec: 248.09
2020-04-08 18:45:04,223 epoch 14 - iter 215/439 - loss 1.11807165 - samples/sec: 211.46
2020-04-08 18:45:42,359 epoch 14 - iter 215/439 - loss 0.93879732 - samples/sec: 235.57
2020-04-08 18:46:38,314 epoch 14 - iter 258/439 - loss 1.09540007 - samples/sec: 202.99
2020-04-08 18:47:31,377 epoch 14 - iter 258/439 - loss 0.93716274 - samples/sec: 211.43
2020-04-08 18:48:25,840 epoch 14 - iter 301/439 - loss 1.09300828 - samples/sec: 204.39
2020-04-08 18:49:13,061 epoch 14 - iter 301/439 - loss 0.93229586 - samples/sec: 272.04
2020-04-08 18:50:08,058 epoch 14 - iter 344/439 - loss 1.08799627 - samples/sec: 236.62
2020-04-08 18:50:38,247 epoch 14 - iter 344/439 - loss 0.93718759 - samples/sec: 191.33
2020-04-08 18:51:55,110 epoch 14 - iter 387/439 - loss 1.07805969 - samples/sec: 220.37
2020-04-08 18:52:08,085 epoch 14 - iter 387/439 - loss 0.92844282 - samples/sec: 220.84
2020-04-08 18:53:16,700 epoch 14 - iter 430/439 - loss 1.06983554 - samples/sec: 211.52
2020-04-08 18:53:51,824 epoch 14 - iter 430/439 - loss 0.92866015 - samples/sec: 244.35
2020-04-08 18:54:53,708 ----------------------------------------------------------------------------------------------------
2020-04-08 18:54:53,708 EPOCH 14 done: loss 1.0709 - lr 0.0100
2020-04-08 18:54:58,424 DEV : loss 0.8155465722084045 - score 0.9209
2020-04-08 18:54:58,521 BAD EPOCHS (no improvement): 0
2020-04-08 18:55:06,826 ----------------------------------------------------------------------------------------------------
2020-04-08 18:55:12,874 epoch 15 - iter 43/439 - loss 0.90340052 - samples/sec: 227.73
2020-04-08 18:55:37,256 ----------------------------------------------------------------------------------------------------
2020-04-08 18:55:37,256 EPOCH 14 done: loss 0.9317 - lr 0.0100
2020-04-08 18:55:42,339 DEV : loss 0.8036829233169556 - score 0.9167
2020-04-08 18:55:42,464 BAD EPOCHS (no improvement): 1
2020-04-08 18:55:42,493 ----------------------------------------------------------------------------------------------------
2020-04-08 18:55:48,842 epoch 15 - iter 43/439 - loss 0.90982972 - samples/sec: 216.87
2020-04-08 18:56:42,176 epoch 15 - iter 86/439 - loss 0.98693965 - samples/sec: 214.79
2020-04-08 18:57:28,900 epoch 15 - iter 86/439 - loss 0.89691521 - samples/sec: 212.31
2020-04-08 18:58:21,271 epoch 15 - iter 129/439 - loss 1.02682733 - samples/sec: 227.50
2020-04-08 18:59:10,106 epoch 15 - iter 129/439 - loss 0.88342883 - samples/sec: 220.48
2020-04-08 19:00:01,093 epoch 15 - iter 172/439 - loss 1.03707278 - samples/sec: 218.23
2020-04-08 19:00:25,453 epoch 15 - iter 172/439 - loss 0.88708014 - samples/sec: 230.51
2020-04-08 19:01:23,039 epoch 15 - iter 215/439 - loss 1.02118162 - samples/sec: 200.27
2020-04-08 19:02:08,450 epoch 15 - iter 215/439 - loss 0.88505943 - samples/sec: 219.91
2020-04-08 19:03:03,688 epoch 15 - iter 258/439 - loss 1.02659689 - samples/sec: 209.96
2020-04-08 19:03:28,685 epoch 15 - iter 258/439 - loss 0.87716804 - samples/sec: 232.68
2020-04-08 19:04:45,694 epoch 15 - iter 301/439 - loss 1.03560704 - samples/sec: 198.52
2020-04-08 19:04:49,272 epoch 15 - iter 301/439 - loss 0.88983917 - samples/sec: 271.22
2020-04-08 19:06:11,001 epoch 15 - iter 344/439 - loss 1.03236158 - samples/sec: 222.03
2020-04-08 19:06:29,304 epoch 15 - iter 344/439 - loss 0.88317054 - samples/sec: 218.64
2020-04-08 19:07:57,511 epoch 15 - iter 387/439 - loss 1.03804787 - samples/sec: 197.45
2020-04-08 19:08:14,176 epoch 15 - iter 387/439 - loss 0.89311713 - samples/sec: 211.13
2020-04-08 19:09:40,320 epoch 15 - iter 430/439 - loss 1.04445274 - samples/sec: 193.70
2020-04-08 19:09:57,651 epoch 15 - iter 430/439 - loss 0.89964325 - samples/sec: 197.75
2020-04-08 19:11:26,603 ----------------------------------------------------------------------------------------------------
2020-04-08 19:11:26,603 EPOCH 15 done: loss 1.0447 - lr 0.0100
2020-04-08 19:11:31,354 DEV : loss 0.810714066028595 - score 0.9197
2020-04-08 19:11:31,451 BAD EPOCHS (no improvement): 1
2020-04-08 19:11:31,516 ----------------------------------------------------------------------------------------------------
2020-04-08 19:11:37,549 epoch 16 - iter 43/439 - loss 1.00225663 - samples/sec: 228.26
2020-04-08 19:11:43,807 ----------------------------------------------------------------------------------------------------
2020-04-08 19:11:43,807 EPOCH 15 done: loss 0.8999 - lr 0.0100
2020-04-08 19:11:48,666 DEV : loss 0.7724746465682983 - score 0.9207
2020-04-08 19:11:48,760 BAD EPOCHS (no improvement): 0
2020-04-08 19:11:58,404 ----------------------------------------------------------------------------------------------------
2020-04-08 19:12:04,748 epoch 16 - iter 43/439 - loss 0.89710535 - samples/sec: 217.06
2020-04-08 19:13:28,824 epoch 16 - iter 86/439 - loss 0.99613360 - samples/sec: 206.47
2020-04-08 19:13:50,431 epoch 16 - iter 86/439 - loss 0.90813589 - samples/sec: 218.69
2020-04-08 19:15:16,879 epoch 16 - iter 129/439 - loss 0.99456765 - samples/sec: 216.61
2020-04-08 19:15:20,791 epoch 16 - iter 129/439 - loss 0.90237681 - samples/sec: 228.76
2020-04-08 19:16:49,175 epoch 16 - iter 172/439 - loss 1.00776714 - samples/sec: 219.95
2020-04-08 19:17:11,789 epoch 16 - iter 172/439 - loss 0.91089233 - samples/sec: 193.86
2020-04-08 19:18:11,114 epoch 16 - iter 215/439 - loss 0.99078441 - samples/sec: 213.20
2020-04-08 19:18:55,972 epoch 16 - iter 215/439 - loss 0.89003160 - samples/sec: 200.42
2020-04-08 19:19:54,775 epoch 16 - iter 258/439 - loss 0.99719762 - samples/sec: 197.25
2020-04-08 19:20:42,268 epoch 16 - iter 258/439 - loss 0.90690404 - samples/sec: 198.28
2020-04-08 19:21:37,970 epoch 16 - iter 301/439 - loss 1.00060532 - samples/sec: 222.79
2020-04-08 19:21:58,543 epoch 16 - iter 301/439 - loss 0.88320543 - samples/sec: 286.71
2020-04-08 19:23:13,343 epoch 16 - iter 344/439 - loss 0.99702839 - samples/sec: 238.28
2020-04-08 19:23:41,907 epoch 16 - iter 344/439 - loss 0.88722163 - samples/sec: 259.98
2020-04-08 19:24:57,431 epoch 16 - iter 387/439 - loss 0.99178378 - samples/sec: 188.27
2020-04-08 19:25:22,703 epoch 16 - iter 387/439 - loss 0.88253887 - samples/sec: 213.97
2020-04-08 19:26:39,503 epoch 16 - iter 430/439 - loss 1.00037508 - samples/sec: 204.04
2020-04-08 19:27:05,365 epoch 16 - iter 430/439 - loss 0.87650516 - samples/sec: 187.75
2020-04-08 19:28:18,432 ----------------------------------------------------------------------------------------------------
2020-04-08 19:28:18,432 EPOCH 16 done: loss 1.0010 - lr 0.0100
2020-04-08 19:28:23,156 DEV : loss 0.7842631936073303 - score 0.921
2020-04-08 19:28:23,253 BAD EPOCHS (no improvement): 0
2020-04-08 19:28:23,555 ----------------------------------------------------------------------------------------------------
2020-04-08 19:28:23,555 EPOCH 16 done: loss 0.8736 - lr 0.0100
2020-04-08 19:28:28,415 DEV : loss 0.7857941389083862 - score 0.923
2020-04-08 19:28:28,511 BAD EPOCHS (no improvement): 0
2020-04-08 19:28:31,676 ----------------------------------------------------------------------------------------------------
2020-04-08 19:28:39,013 epoch 17 - iter 43/439 - loss 1.01883156 - samples/sec: 187.68
2020-04-08 19:28:41,154 ----------------------------------------------------------------------------------------------------
2020-04-08 19:28:48,244 epoch 17 - iter 43/439 - loss 0.86902100 - samples/sec: 194.21
2020-04-08 19:30:25,597 epoch 17 - iter 86/439 - loss 1.03218353 - samples/sec: 242.39
2020-04-08 19:30:27,781 epoch 17 - iter 86/439 - loss 0.90404447 - samples/sec: 234.40
2020-04-08 19:31:54,964 epoch 17 - iter 129/439 - loss 0.99619165 - samples/sec: 209.46
2020-04-08 19:32:04,619 epoch 17 - iter 129/439 - loss 0.88220132 - samples/sec: 214.28
2020-04-08 19:33:37,372 epoch 17 - iter 172/439 - loss 0.99687225 - samples/sec: 266.11
2020-04-08 19:33:48,231 epoch 17 - iter 172/439 - loss 0.84405153 - samples/sec: 216.80
2020-04-08 19:35:17,061 epoch 17 - iter 215/439 - loss 0.99356683 - samples/sec: 229.76
2020-04-08 19:35:18,910 epoch 17 - iter 215/439 - loss 0.84394908 - samples/sec: 245.43
2020-04-08 19:36:54,947 epoch 17 - iter 258/439 - loss 1.00827257 - samples/sec: 210.06
2020-04-08 19:36:56,586 epoch 17 - iter 258/439 - loss 0.83852163 - samples/sec: 214.86
2020-04-08 19:38:28,072 epoch 17 - iter 301/439 - loss 0.98199688 - samples/sec: 241.85
2020-04-08 19:38:29,803 epoch 17 - iter 301/439 - loss 0.83071256 - samples/sec: 251.21
2020-04-08 19:40:04,470 epoch 17 - iter 344/439 - loss 0.97735143 - samples/sec: 246.24
2020-04-08 19:40:06,396 epoch 17 - iter 344/439 - loss 0.84243830 - samples/sec: 237.42
2020-04-08 19:41:35,482 epoch 17 - iter 387/439 - loss 0.97356673 - samples/sec: 230.69
2020-04-08 19:41:37,589 epoch 17 - iter 387/439 - loss 0.84041811 - samples/sec: 224.44
2020-04-08 19:43:04,382 epoch 17 - iter 430/439 - loss 0.97253736 - samples/sec: 218.21
2020-04-08 19:43:06,893 epoch 17 - iter 430/439 - loss 0.83728781 - samples/sec: 214.71
2020-04-08 19:44:29,595 ----------------------------------------------------------------------------------------------------
2020-04-08 19:44:29,595 EPOCH 17 done: loss 0.9761 - lr 0.0100
2020-04-08 19:44:31,867 ----------------------------------------------------------------------------------------------------
2020-04-08 19:44:31,867 EPOCH 17 done: loss 0.8356 - lr 0.0100
2020-04-08 19:44:34,333 DEV : loss 0.7828423380851746 - score 0.9228
2020-04-08 19:44:34,430 BAD EPOCHS (no improvement): 0
2020-04-08 19:44:42,724 ----------------------------------------------------------------------------------------------------
2020-04-08 19:44:36,748 DEV : loss 0.7660743594169617 - score 0.9196
2020-04-08 19:44:36,844 BAD EPOCHS (no improvement): 1
2020-04-08 19:44:37,012 ----------------------------------------------------------------------------------------------------
2020-04-08 19:44:48,900 epoch 18 - iter 43/439 - loss 0.96710476 - samples/sec: 222.98
2020-04-08 19:44:44,113 epoch 18 - iter 43/439 - loss 0.73604789 - samples/sec: 193.96
2020-04-08 19:46:10,422 epoch 18 - iter 86/439 - loss 0.93251485 - samples/sec: 209.27
2020-04-08 19:46:04,595 epoch 18 - iter 86/439 - loss 0.78899145 - samples/sec: 233.02
2020-04-08 19:47:22,915 epoch 18 - iter 129/439 - loss 0.77390125 - samples/sec: 194.41
2020-04-08 19:47:26,986 epoch 18 - iter 129/439 - loss 0.92018497 - samples/sec: 242.37
2020-04-08 19:48:51,404 epoch 18 - iter 172/439 - loss 0.92861443 - samples/sec: 224.48
2020-04-08 19:48:46,910 epoch 18 - iter 172/439 - loss 0.80562177 - samples/sec: 232.50
2020-04-08 19:50:17,059 epoch 18 - iter 215/439 - loss 0.93750710 - samples/sec: 285.32
2020-04-08 19:50:13,650 epoch 18 - iter 215/439 - loss 0.80416699 - samples/sec: 220.30
2020-04-08 19:51:41,635 epoch 18 - iter 258/439 - loss 0.80577149 - samples/sec: 211.97
2020-04-08 19:51:43,986 epoch 18 - iter 258/439 - loss 0.93672307 - samples/sec: 244.21
2020-04-08 19:53:15,827 epoch 18 - iter 301/439 - loss 0.95225460 - samples/sec: 261.02
2020-04-08 19:53:14,355 epoch 18 - iter 301/439 - loss 0.81672827 - samples/sec: 224.96
2020-04-08 19:54:49,839 epoch 18 - iter 344/439 - loss 0.94542927 - samples/sec: 306.59
2020-04-08 19:54:49,426 epoch 18 - iter 344/439 - loss 0.81404917 - samples/sec: 245.30
2020-04-08 19:56:20,353 epoch 18 - iter 387/439 - loss 0.94939636 - samples/sec: 226.91
2020-04-08 19:56:19,894 epoch 18 - iter 387/439 - loss 0.81259373 - samples/sec: 225.66
2020-04-08 19:57:59,523 epoch 18 - iter 430/439 - loss 0.95790819 - samples/sec: 242.84
2020-04-08 19:57:59,508 epoch 18 - iter 430/439 - loss 0.81441092 - samples/sec: 226.78
2020-04-08 19:59:36,872 ----------------------------------------------------------------------------------------------------
2020-04-08 19:59:36,873 EPOCH 18 done: loss 0.9572 - lr 0.0100
2020-04-08 19:59:41,608 DEV : loss 0.7585659623146057 - score 0.9232
2020-04-08 19:59:41,704 BAD EPOCHS (no improvement): 0
2020-04-08 19:59:36,590 ----------------------------------------------------------------------------------------------------
2020-04-08 19:59:36,590 EPOCH 18 done: loss 0.8150 - lr 0.0100
2020-04-08 19:59:41,507 DEV : loss 0.7509844899177551 - score 0.9233
2020-04-08 19:59:41,604 BAD EPOCHS (no improvement): 0
2020-04-08 19:59:56,457 ----------------------------------------------------------------------------------------------------
2020-04-08 20:00:02,667 epoch 19 - iter 43/439 - loss 0.89120263 - samples/sec: 221.75
2020-04-08 19:59:56,751 ----------------------------------------------------------------------------------------------------
2020-04-08 20:00:02,611 epoch 19 - iter 43/439 - loss 0.80278706 - samples/sec: 235.01
2020-04-08 20:01:38,904 epoch 19 - iter 86/439 - loss 0.91432299 - samples/sec: 243.64
2020-04-08 20:01:39,194 epoch 19 - iter 86/439 - loss 0.78803305 - samples/sec: 227.52
2020-04-08 20:03:18,880 epoch 19 - iter 129/439 - loss 0.93249141 - samples/sec: 240.81
2020-04-08 20:03:18,977 epoch 19 - iter 129/439 - loss 0.77601653 - samples/sec: 250.72
2020-04-08 20:04:59,230 epoch 19 - iter 172/439 - loss 0.91163375 - samples/sec: 241.17
2020-04-08 20:04:59,433 epoch 19 - iter 172/439 - loss 0.77876065 - samples/sec: 239.20
2020-04-08 20:06:35,821 epoch 19 - iter 215/439 - loss 0.91174782 - samples/sec: 253.17
2020-04-08 20:06:36,665 epoch 19 - iter 215/439 - loss 0.78933488 - samples/sec: 230.56
2020-04-08 20:08:15,515 epoch 19 - iter 258/439 - loss 0.90894573 - samples/sec: 208.99
2020-04-08 20:08:15,754 epoch 19 - iter 258/439 - loss 0.79886478 - samples/sec: 230.23
2020-04-08 20:09:52,298 epoch 19 - iter 301/439 - loss 0.91206690 - samples/sec: 223.77
2020-04-08 20:09:52,740 epoch 19 - iter 301/439 - loss 0.80530374 - samples/sec: 221.95
2020-04-08 20:11:26,580 epoch 19 - iter 344/439 - loss 0.91525543 - samples/sec: 257.85
2020-04-08 20:11:26,939 epoch 19 - iter 344/439 - loss 0.80626607 - samples/sec: 269.63
2020-04-08 20:13:06,550 epoch 19 - iter 387/439 - loss 0.90818223 - samples/sec: 228.23
2020-04-08 20:13:06,985 epoch 19 - iter 387/439 - loss 0.80708354 - samples/sec: 227.35
2020-04-08 20:14:45,067 epoch 19 - iter 430/439 - loss 0.90727702 - samples/sec: 225.27
2020-04-08 20:14:45,607 epoch 19 - iter 430/439 - loss 0.80107455 - samples/sec: 226.23
2020-04-08 20:16:19,187 ----------------------------------------------------------------------------------------------------
2020-04-08 20:16:19,187 EPOCH 19 done: loss 0.9061 - lr 0.0100
2020-04-08 20:16:23,910 DEV : loss 0.7502618432044983 - score 0.9249
2020-04-08 20:16:24,008 BAD EPOCHS (no improvement): 0
2020-04-08 20:16:19,343 ----------------------------------------------------------------------------------------------------
2020-04-08 20:16:19,343 EPOCH 19 done: loss 0.7997 - lr 0.0100
2020-04-08 20:16:24,220 DEV : loss 0.7283867001533508 - score 0.9243
2020-04-08 20:16:24,316 BAD EPOCHS (no improvement): 0
2020-04-08 20:16:39,964 ----------------------------------------------------------------------------------------------------
2020-04-08 20:16:46,177 epoch 20 - iter 43/439 - loss 0.88069637 - samples/sec: 221.63
2020-04-08 20:16:39,967 ----------------------------------------------------------------------------------------------------
2020-04-08 20:16:45,542 epoch 20 - iter 43/439 - loss 0.74407923 - samples/sec: 247.03
2020-04-08 20:18:17,917 epoch 20 - iter 86/439 - loss 0.85555471 - samples/sec: 257.42
2020-04-08 20:18:17,042 epoch 20 - iter 86/439 - loss 0.72155182 - samples/sec: 247.75
2020-04-08 20:19:52,398 epoch 20 - iter 129/439 - loss 0.86033597 - samples/sec: 271.59
2020-04-08 20:19:52,626 epoch 20 - iter 129/439 - loss 0.75726120 - samples/sec: 221.26
2020-04-08 20:21:36,002 epoch 20 - iter 172/439 - loss 0.84538957 - samples/sec: 266.31
2020-04-08 20:21:36,719 epoch 20 - iter 172/439 - loss 0.75257985 - samples/sec: 246.17
2020-04-08 20:23:20,585 epoch 20 - iter 215/439 - loss 0.84258936 - samples/sec: 262.15
2020-04-08 20:23:25,531 epoch 20 - iter 215/439 - loss 0.77291423 - samples/sec: 235.68
2020-04-08 20:25:14,953 epoch 20 - iter 258/439 - loss 0.84195578 - samples/sec: 216.55
2020-04-08 20:25:19,518 epoch 20 - iter 258/439 - loss 0.77575469 - samples/sec: 207.72
2020-04-08 20:26:57,618 epoch 20 - iter 301/439 - loss 0.85317472 - samples/sec: 256.08
2020-04-08 20:27:01,596 epoch 20 - iter 301/439 - loss 0.77685320 - samples/sec: 256.08
2020-04-08 20:28:58,773 epoch 20 - iter 344/439 - loss 0.86923634 - samples/sec: 209.75
2020-04-08 20:29:03,889 epoch 20 - iter 344/439 - loss 0.77821296 - samples/sec: 213.72
2020-04-08 20:30:59,134 epoch 20 - iter 387/439 - loss 0.78648450 - samples/sec: 216.26
2020-04-08 20:30:54,415 epoch 20 - iter 387/439 - loss 0.86466481 - samples/sec: 213.42
2020-04-08 20:32:53,140 epoch 20 - iter 430/439 - loss 0.78617939 - samples/sec: 279.13
2020-04-08 20:32:48,992 epoch 20 - iter 430/439 - loss 0.86681053 - samples/sec: 245.82
2020-04-08 20:34:22,851 ----------------------------------------------------------------------------------------------------
2020-04-08 20:34:22,852 EPOCH 20 done: loss 0.8663 - lr 0.0100
2020-04-08 20:34:27,668 DEV : loss 0.7507532238960266 - score 0.9264
2020-04-08 20:34:27,765 BAD EPOCHS (no improvement): 0
2020-04-08 20:34:36,710 ----------------------------------------------------------------------------------------------------
2020-04-08 20:34:43,348 epoch 21 - iter 43/439 - loss 0.79486926 - samples/sec: 207.49
2020-04-08 20:34:47,027 ----------------------------------------------------------------------------------------------------
2020-04-08 20:34:47,027 EPOCH 20 done: loss 0.7846 - lr 0.0100
2020-04-08 20:34:51,905 DEV : loss 0.7453736066818237 - score 0.9209
2020-04-08 20:34:52,002 BAD EPOCHS (no improvement): 1
2020-04-08 20:34:52,063 ----------------------------------------------------------------------------------------------------
2020-04-08 20:34:58,473 epoch 21 - iter 43/439 - loss 0.75611761 - samples/sec: 214.80
2020-04-08 20:36:45,448 epoch 21 - iter 86/439 - loss 0.82488726 - samples/sec: 191.70
2020-04-08 20:36:58,452 epoch 21 - iter 86/439 - loss 0.76889315 - samples/sec: 196.95
2020-04-08 20:38:38,308 epoch 21 - iter 129/439 - loss 0.84577691 - samples/sec: 209.15
2020-04-08 20:38:50,902 epoch 21 - iter 129/439 - loss 0.78853064 - samples/sec: 194.52
2020-04-08 20:40:38,977 epoch 21 - iter 172/439 - loss 0.87539759 - samples/sec: 202.81
2020-04-08 20:40:51,229 epoch 21 - iter 172/439 - loss 0.78626641 - samples/sec: 207.56
2020-04-08 20:42:41,256 epoch 21 - iter 215/439 - loss 0.86459343 - samples/sec: 188.62
2020-04-08 20:42:51,343 epoch 21 - iter 215/439 - loss 0.78265850 - samples/sec: 196.18
2020-04-08 20:44:24,134 epoch 21 - iter 258/439 - loss 0.86962891 - samples/sec: 287.75
2020-04-08 20:44:37,486 epoch 21 - iter 258/439 - loss 0.77537128 - samples/sec: 201.80
2020-04-08 20:46:30,005 epoch 21 - iter 301/439 - loss 0.76626145 - samples/sec: 245.48
2020-04-08 20:46:24,633 epoch 21 - iter 301/439 - loss 0.87299805 - samples/sec: 229.85
2020-04-08 20:48:07,386 epoch 21 - iter 344/439 - loss 0.86624046 - samples/sec: 212.19
2020-04-08 20:48:14,928 epoch 21 - iter 344/439 - loss 0.77085612 - samples/sec: 186.71
2020-04-08 20:49:59,715 epoch 21 - iter 387/439 - loss 0.85821236 - samples/sec: 200.47
2020-04-08 20:50:05,082 epoch 21 - iter 387/439 - loss 0.76738035 - samples/sec: 212.16
2020-04-08 20:51:52,362 epoch 21 - iter 430/439 - loss 0.85754661 - samples/sec: 204.23
2020-04-08 20:51:57,595 epoch 21 - iter 430/439 - loss 0.76420633 - samples/sec: 278.20
2020-04-08 20:53:51,175 ----------------------------------------------------------------------------------------------------
2020-04-08 20:53:51,175 EPOCH 21 done: loss 0.8566 - lr 0.0100
2020-04-08 20:53:56,907 ----------------------------------------------------------------------------------------------------
2020-04-08 20:53:56,908 EPOCH 21 done: loss 0.7590 - lr 0.0100
2020-04-08 20:54:01,899 DEV : loss 0.7146647572517395 - score 0.9235
2020-04-08 20:54:01,995 BAD EPOCHS (no improvement): 2
2020-04-08 20:53:55,945 DEV : loss 0.7369139790534973 - score 0.9277
2020-04-08 20:53:56,041 BAD EPOCHS (no improvement): 0
2020-04-08 20:54:04,956 ----------------------------------------------------------------------------------------------------
2020-04-08 20:54:10,913 epoch 22 - iter 43/439 - loss 0.68669200 - samples/sec: 231.22
2020-04-08 20:54:05,036 ----------------------------------------------------------------------------------------------------
2020-04-08 20:54:10,944 epoch 22 - iter 43/439 - loss 0.82207080 - samples/sec: 233.09
2020-04-08 20:56:00,072 epoch 22 - iter 86/439 - loss 0.69981341 - samples/sec: 229.51
2020-04-08 20:55:59,818 epoch 22 - iter 86/439 - loss 0.83371282 - samples/sec: 244.59
2020-04-08 20:57:52,076 epoch 22 - iter 129/439 - loss 0.69742239 - samples/sec: 227.70
2020-04-08 20:57:51,898 epoch 22 - iter 129/439 - loss 0.82628798 - samples/sec: 226.35
2020-04-08 20:59:44,876 epoch 22 - iter 172/439 - loss 0.69706077 - samples/sec: 233.05
2020-04-08 20:59:44,624 epoch 22 - iter 172/439 - loss 0.80606854 - samples/sec: 234.04
2020-04-08 21:01:32,979 epoch 22 - iter 215/439 - loss 0.69774551 - samples/sec: 228.04
2020-04-08 21:01:32,441 epoch 22 - iter 215/439 - loss 0.80291306 - samples/sec: 241.04
2020-04-08 21:03:29,783 epoch 22 - iter 258/439 - loss 0.80532699 - samples/sec: 236.55
2020-04-08 21:03:30,560 epoch 22 - iter 258/439 - loss 0.70615565 - samples/sec: 227.97
2020-04-08 21:05:23,678 epoch 22 - iter 301/439 - loss 0.80895393 - samples/sec: 261.67
2020-04-08 21:05:25,453 epoch 22 - iter 301/439 - loss 0.71479398 - samples/sec: 222.32
2020-04-08 21:07:18,500 epoch 22 - iter 344/439 - loss 0.82474322 - samples/sec: 232.35
2020-04-08 21:07:19,931 epoch 22 - iter 344/439 - loss 0.71092758 - samples/sec: 213.94
2020-04-08 21:09:22,797 epoch 22 - iter 387/439 - loss 0.82875750 - samples/sec: 245.74
2020-04-08 21:09:23,214 epoch 22 - iter 387/439 - loss 0.71619727 - samples/sec: 230.33
2020-04-08 21:11:19,721 epoch 22 - iter 430/439 - loss 0.82694673 - samples/sec: 216.01
2020-04-08 21:11:19,619 epoch 22 - iter 430/439 - loss 0.72625297 - samples/sec: 232.86
2020-04-08 21:13:09,931 ----------------------------------------------------------------------------------------------------
2020-04-08 21:13:09,931 EPOCH 22 done: loss 0.7252 - lr 0.0100
2020-04-08 21:13:10,005 ----------------------------------------------------------------------------------------------------
2020-04-08 21:13:10,005 EPOCH 22 done: loss 0.8250 - lr 0.0100
2020-04-08 21:13:15,498 DEV : loss 0.7140257358551025 - score 0.9268
2020-04-08 21:13:15,596 BAD EPOCHS (no improvement): 0
2020-04-08 21:13:14,915 DEV : loss 0.7291845083236694 - score 0.9292
2020-04-08 21:13:15,016 BAD EPOCHS (no improvement): 0
2020-04-08 21:13:30,363 ----------------------------------------------------------------------------------------------------
2020-04-08 21:13:30,368 ----------------------------------------------------------------------------------------------------
2020-04-08 21:13:35,809 epoch 23 - iter 43/439 - loss 0.62109260 - samples/sec: 253.10
2020-04-08 21:13:35,555 epoch 23 - iter 43/439 - loss 0.71960904 - samples/sec: 265.26
2020-04-08 21:15:24,067 epoch 23 - iter 86/439 - loss 0.62193149 - samples/sec: 229.94
2020-04-08 21:15:24,238 epoch 23 - iter 86/439 - loss 0.77249883 - samples/sec: 213.72
2020-04-08 21:17:41,495 epoch 23 - iter 129/439 - loss 0.64331696 - samples/sec: 234.28
2020-04-08 21:17:41,769 epoch 23 - iter 129/439 - loss 0.78985602 - samples/sec: 252.12
2020-04-08 21:19:36,407 epoch 23 - iter 172/439 - loss 0.64997184 - samples/sec: 235.13
2020-04-08 21:19:36,926 epoch 23 - iter 172/439 - loss 0.79097881 - samples/sec: 224.51
2020-04-08 21:21:34,136 epoch 23 - iter 215/439 - loss 0.67486896 - samples/sec: 256.84
2020-04-08 21:21:34,180 epoch 23 - iter 215/439 - loss 0.77918761 - samples/sec: 267.63
2020-04-08 21:23:35,466 epoch 23 - iter 258/439 - loss 0.68535567 - samples/sec: 236.08
2020-04-08 21:23:35,571 epoch 23 - iter 258/439 - loss 0.79347479 - samples/sec: 225.81
2020-04-08 21:25:28,164 epoch 23 - iter 301/439 - loss 0.69192151 - samples/sec: 226.80
2020-04-08 21:25:28,243 epoch 23 - iter 301/439 - loss 0.80152012 - samples/sec: 224.62
2020-04-08 21:27:26,131 epoch 23 - iter 344/439 - loss 0.69504466 - samples/sec: 229.31
2020-04-08 21:27:26,067 epoch 23 - iter 344/439 - loss 0.79928234 - samples/sec: 235.09
2020-04-08 21:29:14,500 epoch 23 - iter 387/439 - loss 0.70092720 - samples/sec: 235.25
2020-04-08 21:29:13,799 epoch 23 - iter 387/439 - loss 0.80285918 - samples/sec: 263.98
2020-04-08 21:30:58,073 epoch 23 - iter 430/439 - loss 0.70001709 - samples/sec: 232.73
2020-04-08 21:30:57,447 epoch 23 - iter 430/439 - loss 0.80199194 - samples/sec: 229.03
2020-04-08 21:32:50,100 ----------------------------------------------------------------------------------------------------
2020-04-08 21:32:50,100 EPOCH 23 done: loss 0.8072 - lr 0.0100
2020-04-08 21:32:55,552 DEV : loss 0.7307859659194946 - score 0.9308
2020-04-08 21:32:55,647 BAD EPOCHS (no improvement): 0
2020-04-08 21:32:50,587 ----------------------------------------------------------------------------------------------------
2020-04-08 21:32:50,588 EPOCH 23 done: loss 0.7011 - lr 0.0100
2020-04-08 21:32:55,521 DEV : loss 0.7232246398925781 - score 0.9245
2020-04-08 21:32:55,618 BAD EPOCHS (no improvement): 1
2020-04-08 21:32:55,666 ----------------------------------------------------------------------------------------------------
2020-04-08 21:33:02,693 epoch 24 - iter 43/439 - loss 0.67044837 - samples/sec: 195.94
2020-04-08 21:33:13,532 ----------------------------------------------------------------------------------------------------
2020-04-08 21:33:19,892 epoch 24 - iter 43/439 - loss 0.83166342 - samples/sec: 216.55
2020-04-08 21:35:01,431 epoch 24 - iter 86/439 - loss 0.79422355 - samples/sec: 268.61
2020-04-08 21:34:54,283 epoch 24 - iter 86/439 - loss 0.64995808 - samples/sec: 239.07
2020-04-08 21:36:37,500 epoch 24 - iter 129/439 - loss 0.65512795 - samples/sec: 218.21
2020-04-08 21:36:44,571 epoch 24 - iter 129/439 - loss 0.79276330 - samples/sec: 233.36
2020-04-08 21:38:30,552 epoch 24 - iter 172/439 - loss 0.80308462 - samples/sec: 224.02
2020-04-08 21:38:24,157 epoch 24 - iter 172/439 - loss 0.65580800 - samples/sec: 203.55
2020-04-08 21:40:31,078 epoch 24 - iter 215/439 - loss 0.79121371 - samples/sec: 226.76
2020-04-08 21:40:25,652 epoch 24 - iter 215/439 - loss 0.64937563 - samples/sec: 190.54
2020-04-08 21:42:13,095 epoch 24 - iter 258/439 - loss 0.65716545 - samples/sec: 285.57
2020-04-08 21:42:22,075 epoch 24 - iter 258/439 - loss 0.78878350 - samples/sec: 228.96
2020-04-08 21:44:13,475 epoch 24 - iter 301/439 - loss 0.78661136 - samples/sec: 206.88
2020-04-08 21:44:07,272 epoch 24 - iter 301/439 - loss 0.65919445 - samples/sec: 192.44
2020-04-08 21:46:04,213 epoch 24 - iter 344/439 - loss 0.77898929 - samples/sec: 243.24
2020-04-08 21:46:04,336 epoch 24 - iter 344/439 - loss 0.66407510 - samples/sec: 225.20
2020-04-08 21:48:04,315 epoch 24 - iter 387/439 - loss 0.78390968 - samples/sec: 247.08
2020-04-08 21:48:04,934 epoch 24 - iter 387/439 - loss 0.67358250 - samples/sec: 227.80
2020-04-08 21:50:10,266 epoch 24 - iter 430/439 - loss 0.68405906 - samples/sec: 244.64
2020-04-08 21:50:09,725 epoch 24 - iter 430/439 - loss 0.77733779 - samples/sec: 232.69
2020-04-08 21:51:54,923 ----------------------------------------------------------------------------------------------------
2020-04-08 21:51:54,923 EPOCH 24 done: loss 0.6854 - lr 0.0100
2020-04-08 21:51:54,658 ----------------------------------------------------------------------------------------------------
2020-04-08 21:51:54,658 EPOCH 24 done: loss 0.7785 - lr 0.0100
2020-04-08 21:51:59,908 DEV : loss 0.6985999941825867 - score 0.9286
2020-04-08 21:52:00,004 BAD EPOCHS (no improvement): 0
2020-04-08 21:51:59,361 DEV : loss 0.7388181090354919 - score 0.926
2020-04-08 21:51:59,458 BAD EPOCHS (no improvement): 1
2020-04-08 21:51:59,518 ----------------------------------------------------------------------------------------------------
2020-04-08 21:52:04,938 epoch 25 - iter 43/439 - loss 0.79602808 - samples/sec: 254.06
2020-04-08 21:52:09,067 ----------------------------------------------------------------------------------------------------
2020-04-08 21:52:15,233 epoch 25 - iter 43/439 - loss 0.69191113 - samples/sec: 223.36
2020-04-08 21:54:02,297 epoch 25 - iter 86/439 - loss 0.80569740 - samples/sec: 217.40
2020-04-08 21:54:21,823 epoch 25 - iter 86/439 - loss 0.65088327 - samples/sec: 253.58
2020-04-08 21:56:05,726 epoch 25 - iter 129/439 - loss 0.84892605 - samples/sec: 231.35
2020-04-08 21:56:14,082 epoch 25 - iter 129/439 - loss 0.64565224 - samples/sec: 225.44
2020-04-08 21:57:58,591 epoch 25 - iter 172/439 - loss 0.83040516 - samples/sec: 210.79
2020-04-08 21:58:07,623 epoch 25 - iter 172/439 - loss 0.63461979 - samples/sec: 211.94
2020-04-08 21:59:59,807 epoch 25 - iter 215/439 - loss 0.80580737 - samples/sec: 199.85
2020-04-08 22:00:08,111 epoch 25 - iter 215/439 - loss 0.63579176 - samples/sec: 204.61
2020-04-08 22:01:54,902 epoch 25 - iter 258/439 - loss 0.79486520 - samples/sec: 196.54
2020-04-08 22:02:02,719 epoch 25 - iter 258/439 - loss 0.63689693 - samples/sec: 214.88
2020-04-08 22:03:50,857 epoch 25 - iter 301/439 - loss 0.77877584 - samples/sec: 209.40
2020-04-08 22:04:00,679 epoch 25 - iter 301/439 - loss 0.63973596 - samples/sec: 196.33
2020-04-08 22:05:55,634 epoch 25 - iter 344/439 - loss 0.76986010 - samples/sec: 218.56
2020-04-08 22:06:05,968 epoch 25 - iter 344/439 - loss 0.64329007 - samples/sec: 216.58
2020-04-08 22:07:50,499 epoch 25 - iter 387/439 - loss 0.78042388 - samples/sec: 230.08
2020-04-08 22:08:00,166 epoch 25 - iter 387/439 - loss 0.65464382 - samples/sec: 233.59
2020-04-08 22:09:53,416 epoch 25 - iter 430/439 - loss 0.77873696 - samples/sec: 265.13
2020-04-08 22:10:04,192 epoch 25 - iter 430/439 - loss 0.66252824 - samples/sec: 246.57
2020-04-08 22:11:45,944 ----------------------------------------------------------------------------------------------------
2020-04-08 22:11:45,944 EPOCH 25 done: loss 0.7794 - lr 0.0100
2020-04-08 22:11:50,763 DEV : loss 0.7221338152885437 - score 0.93
2020-04-08 22:11:50,861 BAD EPOCHS (no improvement): 2
2020-04-08 22:11:50,889 ----------------------------------------------------------------------------------------------------
2020-04-08 22:11:58,190 ----------------------------------------------------------------------------------------------------
2020-04-08 22:11:58,190 EPOCH 25 done: loss 0.6664 - lr 0.0100
2020-04-08 22:11:57,278 epoch 26 - iter 43/439 - loss 0.79834752 - samples/sec: 215.50
2020-04-08 22:12:03,193 DEV : loss 0.7039762735366821 - score 0.9255
2020-04-08 22:12:03,291 BAD EPOCHS (no improvement): 1
2020-04-08 22:12:03,327 ----------------------------------------------------------------------------------------------------
2020-04-08 22:12:09,762 epoch 26 - iter 43/439 - loss 0.58925287 - samples/sec: 213.97
2020-04-08 22:13:46,740 epoch 26 - iter 86/439 - loss 0.79172406 - samples/sec: 294.95
2020-04-08 22:14:03,715 epoch 26 - iter 86/439 - loss 0.63188561 - samples/sec: 212.42
2020-04-08 22:15:41,835 epoch 26 - iter 129/439 - loss 0.76283233 - samples/sec: 202.51
2020-04-08 22:15:53,848 epoch 26 - iter 129/439 - loss 0.62284865 - samples/sec: 235.26
2020-04-08 22:17:49,750 epoch 26 - iter 172/439 - loss 0.73604648 - samples/sec: 222.29
2020-04-08 22:18:02,963 epoch 26 - iter 172/439 - loss 0.63331994 - samples/sec: 190.85
2020-04-08 22:19:52,388 epoch 26 - iter 215/439 - loss 0.72786716 - samples/sec: 261.67
2020-04-08 22:20:11,185 epoch 26 - iter 215/439 - loss 0.64037623 - samples/sec: 115.24
2020-04-08 22:21:46,340 epoch 26 - iter 258/439 - loss 0.73846062 - samples/sec: 249.86
2020-04-08 22:22:12,134 epoch 26 - iter 258/439 - loss 0.64388968 - samples/sec: 112.63
2020-04-08 22:23:40,907 epoch 26 - iter 301/439 - loss 0.74952859 - samples/sec: 258.12
2020-04-08 22:24:14,303 epoch 26 - iter 301/439 - loss 0.63965035 - samples/sec: 113.78
2020-04-08 22:25:40,073 epoch 26 - iter 344/439 - loss 0.74685596 - samples/sec: 276.61
2020-04-08 22:26:31,032 epoch 26 - iter 344/439 - loss 0.64417738 - samples/sec: 119.80
2020-04-08 22:27:52,599 epoch 26 - iter 387/439 - loss 0.73667208 - samples/sec: 261.23
2020-04-08 22:28:38,692 epoch 26 - iter 387/439 - loss 0.64433935 - samples/sec: 113.79
2020-04-08 22:29:39,890 epoch 26 - iter 430/439 - loss 0.73430033 - samples/sec: 311.19
2020-04-08 22:30:42,378 epoch 26 - iter 430/439 - loss 0.64874393 - samples/sec: 112.93
2020-04-08 22:31:36,680 ----------------------------------------------------------------------------------------------------
2020-04-08 22:31:36,681 EPOCH 26 done: loss 0.7352 - lr 0.0100
2020-04-08 22:31:41,401 DEV : loss 0.7136229872703552 - score 0.9331
2020-04-08 22:31:41,500 BAD EPOCHS (no improvement): 0
2020-04-08 22:31:50,506 ----------------------------------------------------------------------------------------------------
2020-04-08 22:31:55,123 epoch 27 - iter 43/439 - loss 0.73137332 - samples/sec: 298.20
2020-04-08 22:33:06,928 ----------------------------------------------------------------------------------------------------
2020-04-08 22:33:06,928 EPOCH 26 done: loss 0.6474 - lr 0.0100
2020-04-08 22:33:19,967 DEV : loss 0.6862694621086121 - score 0.928
2020-04-08 22:33:20,066 BAD EPOCHS (no improvement): 2
2020-04-08 22:33:20,101 ----------------------------------------------------------------------------------------------------
2020-04-08 22:33:32,316 epoch 27 - iter 43/439 - loss 0.71498877 - samples/sec: 112.68
2020-04-08 22:34:07,800 epoch 27 - iter 86/439 - loss 0.72053519 - samples/sec: 246.65
2020-04-08 22:35:31,574 epoch 27 - iter 86/439 - loss 0.67030722 - samples/sec: 118.94
2020-04-08 22:36:00,279 epoch 27 - iter 129/439 - loss 0.71199666 - samples/sec: 255.63
2020-04-08 22:37:32,093 epoch 27 - iter 129/439 - loss 0.66639333 - samples/sec: 113.81
2020-04-08 22:37:52,728 epoch 27 - iter 172/439 - loss 0.71680387 - samples/sec: 259.96
