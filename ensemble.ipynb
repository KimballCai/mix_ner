{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-09 03:50:07,713 Reading data from data\n",
      "2020-04-09 03:50:07,714 Train: data/train.txt\n",
      "2020-04-09 03:50:07,715 Dev: data/valid.txt\n",
      "2020-04-09 03:50:07,716 Test: data/test.txt\n",
      "Corpus: 14041 train + 3250 dev + 3453 test sentences\n",
      "Dictionary with 12 tags: <unk>, O, B-ORG, B-MISC, B-PER, I-PER, B-LOC, I-ORG, I-MISC, I-LOC, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "\n",
    "columns = {0: 'text', 1: '_', 2: '_', 3: 'ner'}\n",
    "\n",
    "data_folder = './data'\n",
    "\n",
    "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
    "                              train_file='train.txt',\n",
    "                              test_file='test.txt',\n",
    "                              dev_file='valid.txt')\n",
    "print(corpus)\n",
    "tag_type = 'ner'\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Tagger: [\n",
      "SequenceTagger(\n",
      "  (embeddings): XLNetEmbeddings(\n",
      "    model=xlnet-large-cased\n",
      "    (model): XLNetModel(\n",
      "      (word_embedding): Embedding(32000, 1024)\n",
      "      (layer): ModuleList(\n",
      "        (0): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (3): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (4): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (5): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (6): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (7): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (8): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (9): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (10): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (11): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (12): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (13): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (14): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (15): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (16): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (17): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (18): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (19): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (20): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (21): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (22): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (23): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (rnn): LSTM(2048, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=12, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      "),\n",
      "SequenceTagger(\n",
      "  (embeddings): ELMoEmbeddings(model=elmo-small)\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (rnn): LSTM(768, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=12, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      "),\n",
      "SequenceTagger(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=3072, out_features=3072, bias=True)\n",
      "  (rnn): LSTM(3072, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=12, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import ELMoEmbeddings,BertEmbeddings,FlairEmbeddings,XLNetEmbeddings\n",
    "from flair.models import SequenceTagger\n",
    "from ensemble_tagger import EnsembleTagger\n",
    "from typing import List\n",
    "\n",
    "elmo_tagger = SequenceTagger(hidden_size=256,\n",
    "                             embeddings=ELMoEmbeddings('small'),\n",
    "                             tag_dictionary=tag_dictionary,\n",
    "                             tag_type=tag_type,\n",
    "                             use_crf=True)\n",
    "bert_tagger = SequenceTagger(hidden_size=256,\n",
    "                             embeddings=BertEmbeddings(),\n",
    "                             tag_dictionary=tag_dictionary,\n",
    "                             tag_type=tag_type,\n",
    "                             use_crf=True)\n",
    "xlnet_tagger = SequenceTagger(hidden_size=256,\n",
    "                              embeddings=XLNetEmbeddings(),\n",
    "                              tag_dictionary=tag_dictionary,\n",
    "                              tag_type=tag_type,\n",
    "                              use_crf=True)\n",
    "# flair_tagger = SequenceTagger(hidden_size=256,\n",
    "#                               embeddings=FlairEmbeddings('en-forward'),\n",
    "#                               tag_dictionary=tag_dictionary,\n",
    "#                               tag_type=tag_type,\n",
    "#                               use_crf=True)\n",
    "ensemble_tagger = EnsembleTagger(models=[xlnet_tagger, elmo_tagger, bert_tagger],\n",
    "                                 tag_type=tag_type,\n",
    "                                 mode='loss')\n",
    "print(str(ensemble_tagger))\n",
    "model_path = \"/hdd1/kurisu/cs6207/log/ensemble/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-09 03:51:07,202 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 03:51:07,210 Model: \"Ensemble Tagger: [\n",
      "SequenceTagger(\n",
      "  (embeddings): XLNetEmbeddings(\n",
      "    model=xlnet-large-cased\n",
      "    (model): XLNetModel(\n",
      "      (word_embedding): Embedding(32000, 1024)\n",
      "      (layer): ModuleList(\n",
      "        (0): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (1): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (2): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (3): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (4): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (5): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (6): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (7): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (8): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (9): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (10): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (11): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (12): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (13): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (14): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (15): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (16): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (17): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (18): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (19): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (20): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (21): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (22): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (23): XLNetLayer(\n",
      "          (rel_attn): XLNetRelativeAttention(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (ff): XLNetFeedForward(\n",
      "            (layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (layer_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (layer_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (rnn): LSTM(2048, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=12, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      "),\n",
      "SequenceTagger(\n",
      "  (embeddings): ELMoEmbeddings(model=elmo-small)\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (rnn): LSTM(768, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=12, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      "),\n",
      "SequenceTagger(\n",
      "  (embeddings): BertEmbeddings(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=3072, out_features=3072, bias=True)\n",
      "  (rnn): LSTM(3072, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=12, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\n",
      "]\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-09 03:51:07,212 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 03:51:07,214 Corpus: \"Corpus: 14041 train + 3250 dev + 3453 test sentences\"\n",
      "2020-04-09 03:51:07,215 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 03:51:07,216 Parameters:\n",
      "2020-04-09 03:51:07,217  - learning_rate: \"0.01\"\n",
      "2020-04-09 03:51:07,217  - mini_batch_size: \"32\"\n",
      "2020-04-09 03:51:07,218  - patience: \"3\"\n",
      "2020-04-09 03:51:07,219  - anneal_factor: \"0.5\"\n",
      "2020-04-09 03:51:07,221  - max_epochs: \"150\"\n",
      "2020-04-09 03:51:07,222  - shuffle: \"True\"\n",
      "2020-04-09 03:51:07,223  - train_with_dev: \"False\"\n",
      "2020-04-09 03:51:07,224  - batch_growth_annealing: \"False\"\n",
      "2020-04-09 03:51:07,224 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 03:51:07,225 Model training base path: \"/hdd1/kurisu/cs6207/log/ensemble\"\n",
      "2020-04-09 03:51:07,225 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 03:51:07,226 Device: cuda:0\n",
      "2020-04-09 03:51:07,228 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 03:51:07,228 Embeddings storage mode: cpu\n",
      "2020-04-09 03:51:07,249 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 03:51:58,692 epoch 1 - iter 43/439 - loss 19.03754540 - samples/sec: 26.75\n",
      "2020-04-09 03:53:41,364 epoch 1 - iter 86/439 - loss 14.91561935 - samples/sec: 26.78\n",
      "2020-04-09 03:55:24,475 epoch 1 - iter 129/439 - loss 13.04846628 - samples/sec: 26.37\n",
      "2020-04-09 03:57:07,998 epoch 1 - iter 172/439 - loss 11.78842960 - samples/sec: 26.31\n",
      "2020-04-09 03:58:52,045 epoch 1 - iter 215/439 - loss 10.83632651 - samples/sec: 26.23\n",
      "2020-04-09 04:00:34,793 epoch 1 - iter 258/439 - loss 10.09006294 - samples/sec: 26.54\n",
      "2020-04-09 04:02:15,702 epoch 1 - iter 301/439 - loss 9.47017150 - samples/sec: 27.60\n",
      "2020-04-09 04:03:59,031 epoch 1 - iter 344/439 - loss 9.00847593 - samples/sec: 26.43\n",
      "2020-04-09 04:05:41,337 epoch 1 - iter 387/439 - loss 8.57095051 - samples/sec: 26.86\n",
      "2020-04-09 04:07:25,654 epoch 1 - iter 430/439 - loss 8.20974369 - samples/sec: 26.25\n",
      "2020-04-09 04:08:27,589 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 04:08:27,590 EPOCH 1 done: loss 8.1466 - lr 0.0100\n",
      "2020-04-09 04:11:45,414 DEV : loss 3.9065756482236527 - score 0.6271\n",
      "2020-04-09 04:11:45,451 BAD EPOCHS (no improvement): 0\n",
      "2020-04-09 04:12:13,409 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 04:13:04,910 epoch 2 - iter 43/439 - loss 4.53322706 - samples/sec: 26.72\n",
      "2020-04-09 04:14:49,019 epoch 2 - iter 86/439 - loss 4.49846200 - samples/sec: 26.09\n",
      "2020-04-09 04:16:33,257 epoch 2 - iter 129/439 - loss 4.44682574 - samples/sec: 26.06\n",
      "2020-04-09 04:18:15,099 epoch 2 - iter 172/439 - loss 4.33479141 - samples/sec: 27.19\n",
      "2020-04-09 04:20:01,042 epoch 2 - iter 215/439 - loss 4.21717518 - samples/sec: 26.28\n",
      "2020-04-09 04:21:47,446 epoch 2 - iter 258/439 - loss 4.14525096 - samples/sec: 26.25\n",
      "2020-04-09 04:23:33,810 epoch 2 - iter 301/439 - loss 4.08099404 - samples/sec: 26.39\n",
      "2020-04-09 04:25:20,023 epoch 2 - iter 344/439 - loss 4.00002938 - samples/sec: 26.37\n",
      "2020-04-09 04:27:04,975 epoch 2 - iter 387/439 - loss 3.95681302 - samples/sec: 26.80\n",
      "2020-04-09 04:28:51,455 epoch 2 - iter 430/439 - loss 3.89696490 - samples/sec: 26.40\n",
      "2020-04-09 04:29:55,504 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 04:29:55,505 EPOCH 2 done: loss 3.8866 - lr 0.0100\n",
      "2020-04-09 04:33:15,581 DEV : loss 2.5109645743288245 - score 0.7731\n",
      "2020-04-09 04:33:15,619 BAD EPOCHS (no improvement): 0\n",
      "2020-04-09 04:33:41,792 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 04:34:33,710 epoch 3 - iter 43/439 - loss 3.30935076 - samples/sec: 26.51\n",
      "2020-04-09 04:36:18,849 epoch 3 - iter 86/439 - loss 3.28143075 - samples/sec: 26.74\n",
      "2020-04-09 04:38:04,478 epoch 3 - iter 129/439 - loss 3.19211203 - samples/sec: 26.79\n",
      "2020-04-09 04:39:50,487 epoch 3 - iter 172/439 - loss 3.20606823 - samples/sec: 26.37\n",
      "2020-04-09 04:41:36,509 epoch 3 - iter 215/439 - loss 3.19431169 - samples/sec: 26.50\n",
      "2020-04-09 04:43:28,781 epoch 3 - iter 258/439 - loss 3.13300906 - samples/sec: 26.52\n",
      "2020-04-09 04:45:14,218 epoch 3 - iter 301/439 - loss 3.10623258 - samples/sec: 26.42\n",
      "2020-04-09 04:46:59,512 epoch 3 - iter 344/439 - loss 3.08227249 - samples/sec: 26.79\n",
      "2020-04-09 04:48:45,185 epoch 3 - iter 387/439 - loss 3.05220099 - samples/sec: 26.34\n",
      "2020-04-09 04:50:31,337 epoch 3 - iter 430/439 - loss 3.01898958 - samples/sec: 26.24\n",
      "2020-04-09 04:51:36,635 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 04:51:36,636 EPOCH 3 done: loss 3.0173 - lr 0.0100\n",
      "2020-04-09 04:54:57,256 DEV : loss 1.9851676945154573 - score 0.8245\n",
      "2020-04-09 04:54:57,294 BAD EPOCHS (no improvement): 0\n",
      "2020-04-09 04:55:23,148 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 04:56:13,505 epoch 4 - iter 43/439 - loss 2.69746951 - samples/sec: 27.33\n",
      "2020-04-09 04:57:59,574 epoch 4 - iter 86/439 - loss 2.65367822 - samples/sec: 26.28\n",
      "2020-04-09 04:59:44,391 epoch 4 - iter 129/439 - loss 2.60836289 - samples/sec: 27.02\n",
      "2020-04-09 05:01:29,024 epoch 4 - iter 172/439 - loss 2.58928732 - samples/sec: 26.90\n",
      "2020-04-09 05:03:15,254 epoch 4 - iter 215/439 - loss 2.59898736 - samples/sec: 26.47\n",
      "2020-04-09 05:05:01,188 epoch 4 - iter 258/439 - loss 2.58695902 - samples/sec: 26.56\n",
      "2020-04-09 05:06:45,883 epoch 4 - iter 301/439 - loss 2.55471380 - samples/sec: 27.00\n",
      "2020-04-09 05:08:31,295 epoch 4 - iter 344/439 - loss 2.56264615 - samples/sec: 26.70\n",
      "2020-04-09 05:10:17,455 epoch 4 - iter 387/439 - loss 2.54982341 - samples/sec: 26.40\n",
      "2020-04-09 05:12:03,225 epoch 4 - iter 430/439 - loss 2.54938743 - samples/sec: 26.49\n",
      "2020-04-09 05:13:09,933 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 05:13:09,934 EPOCH 4 done: loss 2.5459 - lr 0.0100\n",
      "2020-04-09 05:16:29,194 DEV : loss 1.7019116850022007 - score 0.8615\n",
      "2020-04-09 05:16:29,231 BAD EPOCHS (no improvement): 0\n",
      "2020-04-09 05:16:58,380 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 05:17:50,000 epoch 5 - iter 43/439 - loss 2.42800688 - samples/sec: 26.66\n",
      "2020-04-09 05:19:37,558 epoch 5 - iter 86/439 - loss 2.45376802 - samples/sec: 26.18\n",
      "2020-04-09 05:21:25,664 epoch 5 - iter 129/439 - loss 2.37547183 - samples/sec: 26.15\n",
      "2020-04-09 05:23:11,899 epoch 5 - iter 172/439 - loss 2.36190721 - samples/sec: 27.02\n",
      "2020-04-09 05:24:59,807 epoch 5 - iter 215/439 - loss 2.31364723 - samples/sec: 26.14\n",
      "2020-04-09 05:26:47,620 epoch 5 - iter 258/439 - loss 2.31153417 - samples/sec: 26.21\n",
      "2020-04-09 05:28:35,558 epoch 5 - iter 301/439 - loss 2.32524066 - samples/sec: 26.27\n",
      "2020-04-09 05:30:22,387 epoch 5 - iter 344/439 - loss 2.31429844 - samples/sec: 26.68\n",
      "2020-04-09 05:32:08,658 epoch 5 - iter 387/439 - loss 2.29857618 - samples/sec: 26.85\n",
      "2020-04-09 05:33:55,599 epoch 5 - iter 430/439 - loss 2.28577830 - samples/sec: 26.36\n",
      "2020-04-09 05:35:01,826 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 05:35:01,827 EPOCH 5 done: loss 2.2824 - lr 0.0100\n",
      "2020-04-09 05:38:22,441 DEV : loss 1.5357766043321759 - score 0.8731\n",
      "2020-04-09 05:38:22,478 BAD EPOCHS (no improvement): 0\n",
      "2020-04-09 05:38:48,683 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 05:39:39,094 epoch 6 - iter 43/439 - loss 2.06385472 - samples/sec: 27.30\n",
      "2020-04-09 05:41:24,651 epoch 6 - iter 86/439 - loss 2.11429295 - samples/sec: 27.07\n",
      "2020-04-09 05:43:10,922 epoch 6 - iter 129/439 - loss 2.12793096 - samples/sec: 26.97\n",
      "2020-04-09 05:44:58,039 epoch 6 - iter 172/439 - loss 2.12315969 - samples/sec: 26.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-09 05:46:43,870 epoch 6 - iter 215/439 - loss 2.12181409 - samples/sec: 27.32\n",
      "2020-04-09 05:48:32,141 epoch 6 - iter 258/439 - loss 2.09430246 - samples/sec: 26.01\n",
      "2020-04-09 05:50:18,658 epoch 6 - iter 301/439 - loss 2.08973149 - samples/sec: 26.90\n",
      "2020-04-09 05:52:06,076 epoch 6 - iter 344/439 - loss 2.10253926 - samples/sec: 26.32\n",
      "2020-04-09 05:54:00,127 epoch 6 - iter 387/439 - loss 2.09163527 - samples/sec: 27.04\n",
      "2020-04-09 05:55:55,042 epoch 6 - iter 430/439 - loss 2.08742856 - samples/sec: 26.16\n",
      "2020-04-09 05:57:00,681 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 05:57:00,683 EPOCH 6 done: loss 2.0808 - lr 0.0100\n",
      "2020-04-09 06:00:21,306 DEV : loss 1.4148730258731281 - score 0.8857\n",
      "2020-04-09 06:00:21,344 BAD EPOCHS (no improvement): 0\n",
      "2020-04-09 06:00:47,570 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 06:01:39,279 epoch 7 - iter 43/439 - loss 2.09555305 - samples/sec: 26.62\n",
      "2020-04-09 06:03:27,137 epoch 7 - iter 86/439 - loss 1.98391234 - samples/sec: 26.17\n",
      "2020-04-09 06:05:14,379 epoch 7 - iter 129/439 - loss 1.99346571 - samples/sec: 26.42\n",
      "2020-04-09 06:07:01,732 epoch 7 - iter 172/439 - loss 2.00321028 - samples/sec: 26.40\n",
      "2020-04-09 06:08:49,382 epoch 7 - iter 215/439 - loss 1.99304758 - samples/sec: 25.85\n",
      "2020-04-09 06:10:34,832 epoch 7 - iter 258/439 - loss 1.98077696 - samples/sec: 27.47\n",
      "2020-04-09 06:12:23,290 epoch 7 - iter 301/439 - loss 1.95430754 - samples/sec: 26.32\n",
      "2020-04-09 06:14:11,690 epoch 7 - iter 344/439 - loss 1.96539002 - samples/sec: 26.31\n",
      "2020-04-09 06:16:00,450 epoch 7 - iter 387/439 - loss 1.95845694 - samples/sec: 26.11\n",
      "2020-04-09 06:17:45,972 epoch 7 - iter 430/439 - loss 1.94420392 - samples/sec: 27.54\n",
      "2020-04-09 06:18:53,166 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 06:18:53,167 EPOCH 7 done: loss 1.9429 - lr 0.0100\n",
      "2020-04-09 06:22:13,856 DEV : loss 1.308767139875129 - score 0.8921\n",
      "2020-04-09 06:22:13,893 BAD EPOCHS (no improvement): 0\n",
      "2020-04-09 06:22:39,802 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 06:23:32,148 epoch 8 - iter 43/439 - loss 1.78447044 - samples/sec: 26.29\n",
      "2020-04-09 06:25:20,145 epoch 8 - iter 86/439 - loss 1.78255131 - samples/sec: 26.46\n",
      "2020-04-09 06:38:07,962 epoch 8 - iter 129/439 - loss 1.78900822 - samples/sec: 26.71\n",
      "2020-04-09 06:39:54,950 epoch 8 - iter 172/439 - loss 1.80873621 - samples/sec: 26.86\n",
      "2020-04-09 06:41:41,481 epoch 8 - iter 215/439 - loss 1.80859310 - samples/sec: 26.90\n",
      "2020-04-09 06:43:27,239 epoch 8 - iter 258/439 - loss 1.83174105 - samples/sec: 27.38\n",
      "2020-04-09 06:45:15,412 epoch 8 - iter 301/439 - loss 1.85373172 - samples/sec: 25.99\n",
      "2020-04-09 06:47:03,168 epoch 8 - iter 344/439 - loss 1.84421827 - samples/sec: 26.08\n",
      "2020-04-09 06:48:48,631 epoch 8 - iter 387/439 - loss 1.83508555 - samples/sec: 27.19\n",
      "2020-04-09 06:50:36,032 epoch 8 - iter 430/439 - loss 1.83116785 - samples/sec: 26.46\n",
      "2020-04-09 06:51:42,012 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 06:51:42,013 EPOCH 8 done: loss 1.8309 - lr 0.0100\n",
      "2020-04-09 06:55:01,776 DEV : loss 1.2477005840662647 - score 0.8994\n",
      "2020-04-09 06:55:01,813 BAD EPOCHS (no improvement): 0\n",
      "2020-04-09 06:55:27,610 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 06:56:19,461 epoch 9 - iter 43/439 - loss 1.79144302 - samples/sec: 26.54\n",
      "2020-04-09 06:58:04,577 epoch 9 - iter 86/439 - loss 1.76826592 - samples/sec: 27.43\n",
      "2020-04-09 06:59:52,209 epoch 9 - iter 129/439 - loss 1.76613184 - samples/sec: 26.26\n",
      "2020-04-09 07:01:39,820 epoch 9 - iter 172/439 - loss 1.74589636 - samples/sec: 26.59\n",
      "2020-04-09 07:03:27,975 epoch 9 - iter 215/439 - loss 1.73334309 - samples/sec: 26.43\n",
      "2020-04-09 07:05:16,353 epoch 9 - iter 258/439 - loss 1.71585727 - samples/sec: 26.12\n",
      "2020-04-09 07:07:03,975 epoch 9 - iter 301/439 - loss 1.70651689 - samples/sec: 26.76\n",
      "2020-04-09 07:08:51,915 epoch 9 - iter 344/439 - loss 1.70880491 - samples/sec: 26.32\n",
      "2020-04-09 07:10:40,303 epoch 9 - iter 387/439 - loss 1.70184336 - samples/sec: 26.36\n",
      "2020-04-09 07:12:28,286 epoch 9 - iter 430/439 - loss 1.71519587 - samples/sec: 26.16\n",
      "2020-04-09 07:13:34,171 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 07:13:34,172 EPOCH 9 done: loss 1.7174 - lr 0.0100\n",
      "2020-04-09 07:16:54,247 DEV : loss 1.1860238204290177 - score 0.8976\n",
      "2020-04-09 07:16:54,285 BAD EPOCHS (no improvement): 1\n",
      "2020-04-09 07:16:54,308 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 07:17:45,714 epoch 10 - iter 43/439 - loss 1.68868110 - samples/sec: 26.77\n",
      "2020-04-09 07:19:33,623 epoch 10 - iter 86/439 - loss 1.66435763 - samples/sec: 26.62\n",
      "2020-04-09 07:21:22,732 epoch 10 - iter 129/439 - loss 1.61321960 - samples/sec: 26.46\n",
      "2020-04-09 07:23:12,345 epoch 10 - iter 172/439 - loss 1.61414563 - samples/sec: 26.06\n",
      "2020-04-09 07:25:00,476 epoch 10 - iter 215/439 - loss 1.63483428 - samples/sec: 26.76\n",
      "2020-04-09 07:26:49,150 epoch 10 - iter 258/439 - loss 1.63517437 - samples/sec: 26.57\n",
      "2020-04-09 07:28:39,759 epoch 10 - iter 301/439 - loss 1.62788465 - samples/sec: 25.98\n",
      "2020-04-09 07:30:27,809 epoch 10 - iter 344/439 - loss 1.63105346 - samples/sec: 27.06\n",
      "2020-04-09 07:32:16,831 epoch 10 - iter 387/439 - loss 1.62729367 - samples/sec: 26.45\n",
      "2020-04-09 07:34:05,466 epoch 10 - iter 430/439 - loss 1.64294185 - samples/sec: 26.66\n",
      "2020-04-09 07:35:13,085 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 07:35:13,086 EPOCH 10 done: loss 1.6433 - lr 0.0100\n",
      "2020-04-09 07:38:32,394 DEV : loss 1.1355473858249538 - score 0.909\n",
      "2020-04-09 07:38:32,431 BAD EPOCHS (no improvement): 0\n",
      "2020-04-09 07:38:58,670 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 07:39:50,935 epoch 11 - iter 43/439 - loss 1.55897184 - samples/sec: 26.33\n",
      "2020-04-09 07:41:44,127 epoch 11 - iter 86/439 - loss 1.56974409 - samples/sec: 26.33\n",
      "2020-04-09 07:43:32,781 epoch 11 - iter 129/439 - loss 1.56051807 - samples/sec: 26.55\n",
      "2020-04-09 07:45:22,073 epoch 11 - iter 172/439 - loss 1.57989116 - samples/sec: 26.20\n",
      "2020-04-09 07:47:11,264 epoch 11 - iter 215/439 - loss 1.59253561 - samples/sec: 26.23\n",
      "2020-04-09 07:49:01,239 epoch 11 - iter 258/439 - loss 1.59659402 - samples/sec: 26.18\n",
      "2020-04-09 07:50:50,659 epoch 11 - iter 301/439 - loss 1.57646521 - samples/sec: 26.42\n",
      "2020-04-09 07:52:39,063 epoch 11 - iter 344/439 - loss 1.58232752 - samples/sec: 26.73\n",
      "2020-04-09 07:54:27,652 epoch 11 - iter 387/439 - loss 1.57514848 - samples/sec: 26.69\n",
      "2020-04-09 07:56:17,435 epoch 11 - iter 430/439 - loss 1.57283017 - samples/sec: 26.27\n",
      "2020-04-09 07:57:24,465 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 07:57:24,466 EPOCH 11 done: loss 1.5727 - lr 0.0100\n",
      "2020-04-09 08:00:44,225 DEV : loss 1.1075447731487014 - score 0.9083\n",
      "2020-04-09 08:00:44,262 BAD EPOCHS (no improvement): 1\n",
      "2020-04-09 08:00:44,278 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 08:01:34,491 epoch 12 - iter 43/439 - loss 1.52798755 - samples/sec: 27.41\n",
      "2020-04-09 08:03:23,340 epoch 12 - iter 86/439 - loss 1.57642303 - samples/sec: 26.43\n",
      "2020-04-09 08:05:11,921 epoch 12 - iter 129/439 - loss 1.56703781 - samples/sec: 26.64\n",
      "2020-04-09 08:07:00,642 epoch 12 - iter 172/439 - loss 1.55366084 - samples/sec: 26.51\n",
      "2020-04-09 08:08:49,829 epoch 12 - iter 215/439 - loss 1.53740473 - samples/sec: 26.42\n",
      "2020-04-09 08:10:38,424 epoch 12 - iter 258/439 - loss 1.52000170 - samples/sec: 26.73\n",
      "2020-04-09 08:12:27,791 epoch 12 - iter 301/439 - loss 1.52254972 - samples/sec: 26.33\n",
      "2020-04-09 08:14:17,553 epoch 12 - iter 344/439 - loss 1.52250913 - samples/sec: 26.22\n",
      "2020-04-09 08:16:08,354 epoch 12 - iter 387/439 - loss 1.51392374 - samples/sec: 26.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-09 08:17:57,065 epoch 12 - iter 430/439 - loss 1.50854994 - samples/sec: 26.52\n",
      "2020-04-09 08:19:03,896 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 08:19:03,898 EPOCH 12 done: loss 1.5085 - lr 0.0100\n",
      "2020-04-09 08:22:22,881 DEV : loss 1.0733929993767364 - score 0.9107\n",
      "2020-04-09 08:22:22,918 BAD EPOCHS (no improvement): 0\n",
      "2020-04-09 08:22:49,622 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 08:23:41,823 epoch 13 - iter 43/439 - loss 1.53249447 - samples/sec: 26.36\n",
      "2020-04-09 08:25:31,313 epoch 13 - iter 86/439 - loss 1.49757430 - samples/sec: 26.20\n",
      "2020-04-09 08:27:21,354 epoch 13 - iter 129/439 - loss 1.47264957 - samples/sec: 26.09\n",
      "2020-04-09 08:29:10,872 epoch 13 - iter 172/439 - loss 1.46099316 - samples/sec: 26.25\n",
      "2020-04-09 08:30:59,358 epoch 13 - iter 215/439 - loss 1.46703105 - samples/sec: 27.09\n",
      "2020-04-09 08:32:48,254 epoch 13 - iter 258/439 - loss 1.46812695 - samples/sec: 26.42\n",
      "2020-04-09 08:34:37,239 epoch 13 - iter 301/439 - loss 1.47186716 - samples/sec: 26.54\n",
      "2020-04-09 08:36:26,381 epoch 13 - iter 344/439 - loss 1.46658224 - samples/sec: 26.38\n",
      "2020-04-09 08:38:13,765 epoch 13 - iter 387/439 - loss 1.46281743 - samples/sec: 27.46\n",
      "2020-04-09 08:40:03,209 epoch 13 - iter 430/439 - loss 1.44743461 - samples/sec: 26.28\n",
      "2020-04-09 08:41:10,846 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 08:41:10,847 EPOCH 13 done: loss 1.4483 - lr 0.0100\n",
      "2020-04-09 08:44:30,702 DEV : loss 1.0423252736674804 - score 0.9177\n",
      "2020-04-09 08:44:30,754 BAD EPOCHS (no improvement): 0\n",
      "2020-04-09 08:44:57,265 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 08:45:47,899 epoch 14 - iter 43/439 - loss 1.28888517 - samples/sec: 27.18\n",
      "2020-04-09 08:47:36,612 epoch 14 - iter 86/439 - loss 1.36789704 - samples/sec: 26.55\n",
      "2020-04-09 08:49:24,085 epoch 14 - iter 129/439 - loss 1.38482545 - samples/sec: 27.16\n",
      "2020-04-09 08:51:18,910 epoch 14 - iter 172/439 - loss 1.40020324 - samples/sec: 26.37\n",
      "2020-04-09 08:53:08,036 epoch 14 - iter 215/439 - loss 1.39984081 - samples/sec: 26.62\n",
      "2020-04-09 08:54:57,086 epoch 14 - iter 258/439 - loss 1.40533405 - samples/sec: 26.38\n",
      "2020-04-09 08:56:45,684 epoch 14 - iter 301/439 - loss 1.39756789 - samples/sec: 26.70\n",
      "2020-04-09 08:58:34,409 epoch 14 - iter 344/439 - loss 1.39846830 - samples/sec: 26.55\n",
      "2020-04-09 09:00:23,011 epoch 14 - iter 387/439 - loss 1.38437427 - samples/sec: 26.53\n",
      "2020-04-09 09:02:11,630 epoch 14 - iter 430/439 - loss 1.40109158 - samples/sec: 26.53\n",
      "2020-04-09 09:03:18,726 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 09:03:18,728 EPOCH 14 done: loss 1.4059 - lr 0.0100\n",
      "2020-04-09 09:06:38,608 DEV : loss 1.0195928901689602 - score 0.9187\n",
      "2020-04-09 09:06:38,645 BAD EPOCHS (no improvement): 0\n",
      "2020-04-09 09:07:04,975 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 09:07:55,224 epoch 15 - iter 43/439 - loss 1.42752505 - samples/sec: 27.39\n",
      "2020-04-09 09:09:43,473 epoch 15 - iter 86/439 - loss 1.34509589 - samples/sec: 26.53\n",
      "2020-04-09 09:11:32,986 epoch 15 - iter 129/439 - loss 1.34902471 - samples/sec: 26.08\n",
      "2020-04-09 09:13:22,458 epoch 15 - iter 172/439 - loss 1.36051303 - samples/sec: 26.23\n",
      "2020-04-09 09:15:11,344 epoch 15 - iter 215/439 - loss 1.35708186 - samples/sec: 26.41\n",
      "2020-04-09 09:16:58,248 epoch 15 - iter 258/439 - loss 1.35290652 - samples/sec: 27.34\n",
      "2020-04-09 09:18:46,272 epoch 15 - iter 301/439 - loss 1.35301609 - samples/sec: 26.71\n",
      "2020-04-09 09:20:35,611 epoch 15 - iter 344/439 - loss 1.36290638 - samples/sec: 26.40\n",
      "2020-04-09 09:22:24,064 epoch 15 - iter 387/439 - loss 1.35352552 - samples/sec: 26.42\n",
      "2020-04-09 09:24:13,383 epoch 15 - iter 430/439 - loss 1.35370773 - samples/sec: 26.21\n",
      "2020-04-09 09:25:20,248 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 09:25:20,249 EPOCH 15 done: loss 1.3522 - lr 0.0100\n",
      "2020-04-09 09:28:38,935 DEV : loss 0.9833078473148977 - score 0.9228\n",
      "2020-04-09 09:28:38,972 BAD EPOCHS (no improvement): 0\n",
      "2020-04-09 09:29:05,000 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 09:29:56,698 epoch 16 - iter 43/439 - loss 1.29281424 - samples/sec: 26.62\n",
      "2020-04-09 09:31:46,053 epoch 16 - iter 86/439 - loss 1.31295950 - samples/sec: 26.15\n",
      "2020-04-09 09:33:35,065 epoch 16 - iter 129/439 - loss 1.29660274 - samples/sec: 26.48\n",
      "2020-04-09 09:35:23,978 epoch 16 - iter 172/439 - loss 1.32499486 - samples/sec: 26.26\n",
      "2020-04-09 09:37:11,775 epoch 16 - iter 215/439 - loss 1.32346559 - samples/sec: 26.98\n",
      "2020-04-09 09:39:01,315 epoch 16 - iter 258/439 - loss 1.30362375 - samples/sec: 26.24\n",
      "2020-04-09 09:40:51,398 epoch 16 - iter 301/439 - loss 1.31813799 - samples/sec: 26.03\n",
      "2020-04-09 09:42:41,302 epoch 16 - iter 344/439 - loss 1.30393326 - samples/sec: 26.24\n",
      "2020-04-09 09:44:28,322 epoch 16 - iter 387/439 - loss 1.30986700 - samples/sec: 27.39\n",
      "2020-04-09 09:46:17,189 epoch 16 - iter 430/439 - loss 1.31393648 - samples/sec: 26.49\n",
      "2020-04-09 09:47:25,134 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 09:47:25,135 EPOCH 16 done: loss 1.3154 - lr 0.0100\n",
      "2020-04-09 09:50:45,038 DEV : loss 0.9669352066794447 - score 0.9212\n",
      "2020-04-09 09:50:45,075 BAD EPOCHS (no improvement): 1\n",
      "2020-04-09 09:50:45,091 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 09:51:36,886 epoch 17 - iter 43/439 - loss 1.20762305 - samples/sec: 26.57\n",
      "2020-04-09 09:53:25,733 epoch 17 - iter 86/439 - loss 1.26937131 - samples/sec: 26.42\n",
      "2020-04-09 09:55:12,953 epoch 17 - iter 129/439 - loss 1.26744871 - samples/sec: 27.46\n",
      "2020-04-09 09:57:02,122 epoch 17 - iter 172/439 - loss 1.26906578 - samples/sec: 26.46\n",
      "2020-04-09 09:58:51,768 epoch 17 - iter 215/439 - loss 1.28805409 - samples/sec: 26.09\n",
      "2020-04-09 10:00:52,280 epoch 17 - iter 258/439 - loss 1.29397309 - samples/sec: 26.26\n",
      "2020-04-09 10:02:40,880 epoch 17 - iter 301/439 - loss 1.29328358 - samples/sec: 26.78\n",
      "2020-04-09 10:04:30,341 epoch 17 - iter 344/439 - loss 1.28964332 - samples/sec: 26.46\n",
      "2020-04-09 10:06:17,701 epoch 17 - iter 387/439 - loss 1.28805879 - samples/sec: 27.34\n",
      "2020-04-09 10:08:07,999 epoch 17 - iter 430/439 - loss 1.27943882 - samples/sec: 26.12\n",
      "2020-04-09 10:09:15,687 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 10:09:15,689 EPOCH 17 done: loss 1.2825 - lr 0.0100\n",
      "2020-04-09 10:12:35,197 DEV : loss 0.9587139048814481 - score 0.9232\n",
      "2020-04-09 10:12:35,234 BAD EPOCHS (no improvement): 0\n",
      "2020-04-09 10:13:01,224 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 10:13:51,862 epoch 18 - iter 43/439 - loss 1.22431443 - samples/sec: 27.18\n",
      "2020-04-09 10:15:40,582 epoch 18 - iter 86/439 - loss 1.17540141 - samples/sec: 26.34\n",
      "2020-04-09 10:17:30,256 epoch 18 - iter 129/439 - loss 1.20715296 - samples/sec: 26.32\n",
      "2020-04-09 10:19:18,803 epoch 18 - iter 172/439 - loss 1.20727815 - samples/sec: 26.52\n",
      "2020-04-09 10:21:07,783 epoch 18 - iter 215/439 - loss 1.23614571 - samples/sec: 26.23\n",
      "2020-04-09 10:22:54,792 epoch 18 - iter 258/439 - loss 1.23673916 - samples/sec: 27.56\n",
      "2020-04-09 10:24:43,937 epoch 18 - iter 301/439 - loss 1.23191385 - samples/sec: 26.25\n",
      "2020-04-09 10:26:32,462 epoch 18 - iter 344/439 - loss 1.22874044 - samples/sec: 26.36\n",
      "2020-04-09 10:28:21,808 epoch 18 - iter 387/439 - loss 1.23801899 - samples/sec: 26.04\n",
      "2020-04-09 10:30:09,846 epoch 18 - iter 430/439 - loss 1.24216987 - samples/sec: 26.99\n",
      "2020-04-09 10:31:17,472 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 10:31:17,473 EPOCH 18 done: loss 1.2389 - lr 0.0100\n",
      "2020-04-09 10:34:37,153 DEV : loss 0.934872517928335 - score 0.9256\n",
      "2020-04-09 10:34:37,191 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-09 10:35:03,126 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 10:35:55,250 epoch 19 - iter 43/439 - loss 1.13429280 - samples/sec: 26.40\n",
      "2020-04-09 10:37:43,473 epoch 19 - iter 86/439 - loss 1.17742671 - samples/sec: 26.63\n",
      "2020-04-09 10:39:32,484 epoch 19 - iter 129/439 - loss 1.18181824 - samples/sec: 26.86\n",
      "2020-04-09 10:41:22,232 epoch 19 - iter 172/439 - loss 1.18643664 - samples/sec: 26.18\n",
      "2020-04-09 10:43:10,707 epoch 19 - iter 215/439 - loss 1.19045662 - samples/sec: 26.52\n",
      "2020-04-09 10:45:00,559 epoch 19 - iter 258/439 - loss 1.19545245 - samples/sec: 26.18\n",
      "2020-04-09 10:46:49,165 epoch 19 - iter 301/439 - loss 1.19693297 - samples/sec: 26.49\n",
      "2020-04-09 10:48:37,241 epoch 19 - iter 344/439 - loss 1.20093590 - samples/sec: 26.84\n",
      "2020-04-09 10:50:27,088 epoch 19 - iter 387/439 - loss 1.20607905 - samples/sec: 26.16\n",
      "2020-04-09 10:52:17,010 epoch 19 - iter 430/439 - loss 1.21338079 - samples/sec: 26.05\n",
      "2020-04-09 10:53:24,654 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 10:53:24,655 EPOCH 19 done: loss 1.2112 - lr 0.0100\n",
      "2020-04-09 10:56:44,897 DEV : loss 0.9229836970312046 - score 0.9268\n",
      "2020-04-09 10:56:44,934 BAD EPOCHS (no improvement): 0\n",
      "2020-04-09 10:57:11,037 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 10:58:03,361 epoch 20 - iter 43/439 - loss 1.16519088 - samples/sec: 26.30\n",
      "2020-04-09 10:59:52,772 epoch 20 - iter 86/439 - loss 1.20260067 - samples/sec: 26.40\n",
      "2020-04-09 11:01:41,057 epoch 20 - iter 129/439 - loss 1.21268206 - samples/sec: 26.85\n",
      "2020-04-09 11:03:30,752 epoch 20 - iter 172/439 - loss 1.18141032 - samples/sec: 26.15\n",
      "2020-04-09 11:05:19,964 epoch 20 - iter 215/439 - loss 1.18107910 - samples/sec: 26.12\n",
      "2020-04-09 11:07:08,684 epoch 20 - iter 258/439 - loss 1.17903535 - samples/sec: 26.51\n",
      "2020-04-09 11:08:57,566 epoch 20 - iter 301/439 - loss 1.17468418 - samples/sec: 26.22\n",
      "2020-04-09 11:10:45,434 epoch 20 - iter 344/439 - loss 1.17613935 - samples/sec: 26.96\n",
      "2020-04-09 11:12:34,743 epoch 20 - iter 387/439 - loss 1.17319974 - samples/sec: 26.38\n",
      "2020-04-09 11:14:25,693 epoch 20 - iter 430/439 - loss 1.17424199 - samples/sec: 26.43\n",
      "2020-04-09 11:15:33,914 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 11:15:33,915 EPOCH 20 done: loss 1.1747 - lr 0.0100\n",
      "2020-04-09 11:18:55,515 DEV : loss 0.8944182355714706 - score 0.9287\n",
      "2020-04-09 11:18:55,552 BAD EPOCHS (no improvement): 0\n",
      "2020-04-09 11:19:21,535 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 11:20:12,462 epoch 21 - iter 43/439 - loss 1.10192106 - samples/sec: 27.02\n",
      "2020-04-09 11:22:01,276 epoch 21 - iter 86/439 - loss 1.10387274 - samples/sec: 26.39\n",
      "2020-04-09 11:23:50,535 epoch 21 - iter 129/439 - loss 1.11693185 - samples/sec: 26.16\n",
      "2020-04-09 11:25:39,862 epoch 21 - iter 172/439 - loss 1.14794959 - samples/sec: 26.42\n",
      "2020-04-09 11:27:29,069 epoch 21 - iter 215/439 - loss 1.12623216 - samples/sec: 26.44\n",
      "2020-04-09 11:29:17,157 epoch 21 - iter 258/439 - loss 1.12534003 - samples/sec: 26.85\n",
      "2020-04-09 11:31:06,814 epoch 21 - iter 301/439 - loss 1.10941495 - samples/sec: 26.19\n",
      "2020-04-09 11:32:56,125 epoch 21 - iter 344/439 - loss 1.11449562 - samples/sec: 26.08\n",
      "2020-04-09 11:34:46,070 epoch 21 - iter 387/439 - loss 1.12265470 - samples/sec: 26.41\n",
      "2020-04-09 11:36:34,115 epoch 21 - iter 430/439 - loss 1.14307430 - samples/sec: 26.84\n",
      "2020-04-09 11:37:42,418 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 11:37:42,419 EPOCH 21 done: loss 1.1440 - lr 0.0100\n",
      "2020-04-09 11:41:01,298 DEV : loss 0.8790304103281861 - score 0.9298\n",
      "2020-04-09 11:41:01,335 BAD EPOCHS (no improvement): 0\n",
      "2020-04-09 11:41:34,117 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 11:42:26,180 epoch 22 - iter 43/439 - loss 1.25047116 - samples/sec: 26.43\n",
      "2020-04-09 11:44:14,797 epoch 22 - iter 86/439 - loss 1.17939570 - samples/sec: 26.70\n",
      "2020-04-09 11:46:03,187 epoch 22 - iter 129/439 - loss 1.17035188 - samples/sec: 26.54\n",
      "2020-04-09 11:47:51,566 epoch 22 - iter 172/439 - loss 1.14520181 - samples/sec: 26.67\n",
      "2020-04-09 11:49:38,877 epoch 22 - iter 215/439 - loss 1.14975301 - samples/sec: 27.07\n",
      "2020-04-09 11:51:27,032 epoch 22 - iter 258/439 - loss 1.14848549 - samples/sec: 26.51\n",
      "2020-04-09 11:53:14,890 epoch 22 - iter 301/439 - loss 1.13386286 - samples/sec: 27.11\n",
      "2020-04-09 11:55:03,274 epoch 22 - iter 344/439 - loss 1.12694296 - samples/sec: 26.52\n",
      "2020-04-09 11:56:50,390 epoch 22 - iter 387/439 - loss 1.12777575 - samples/sec: 27.38\n",
      "2020-04-09 11:58:38,555 epoch 22 - iter 430/439 - loss 1.12461591 - samples/sec: 26.52\n",
      "2020-04-09 11:59:45,952 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 11:59:45,953 EPOCH 22 done: loss 1.1241 - lr 0.0100\n",
      "2020-04-09 12:03:06,478 DEV : loss 0.8736104210793022 - score 0.932\n",
      "2020-04-09 12:03:06,516 BAD EPOCHS (no improvement): 0\n",
      "2020-04-09 12:03:33,019 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 12:04:24,608 epoch 23 - iter 43/439 - loss 1.09780400 - samples/sec: 26.68\n",
      "2020-04-09 12:06:13,098 epoch 23 - iter 86/439 - loss 1.09217923 - samples/sec: 26.93\n",
      "2020-04-09 12:08:01,551 epoch 23 - iter 129/439 - loss 1.07840826 - samples/sec: 26.39\n",
      "2020-04-09 12:09:51,677 epoch 23 - iter 172/439 - loss 1.08709107 - samples/sec: 26.14\n",
      "2020-04-09 12:11:40,483 epoch 23 - iter 215/439 - loss 1.07787875 - samples/sec: 26.47\n",
      "2020-04-09 12:13:28,731 epoch 23 - iter 258/439 - loss 1.07372066 - samples/sec: 26.69\n",
      "2020-04-09 12:15:17,009 epoch 23 - iter 301/439 - loss 1.08251607 - samples/sec: 26.67\n",
      "2020-04-09 12:17:05,990 epoch 23 - iter 344/439 - loss 1.09561664 - samples/sec: 26.31\n",
      "2020-04-09 12:18:55,115 epoch 23 - iter 387/439 - loss 1.09964884 - samples/sec: 26.16\n",
      "2020-04-09 12:20:44,004 epoch 23 - iter 430/439 - loss 1.09331439 - samples/sec: 26.39\n",
      "2020-04-09 12:21:51,096 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 12:21:51,098 EPOCH 23 done: loss 1.0940 - lr 0.0100\n",
      "2020-04-09 12:25:12,168 DEV : loss 0.85782480118431 - score 0.935\n",
      "2020-04-09 12:25:12,206 BAD EPOCHS (no improvement): 0\n",
      "2020-04-09 12:25:39,758 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 12:26:30,523 epoch 24 - iter 43/439 - loss 1.08909828 - samples/sec: 27.11\n",
      "2020-04-09 12:28:19,821 epoch 24 - iter 86/439 - loss 1.04211458 - samples/sec: 26.16\n",
      "2020-04-09 12:30:08,188 epoch 24 - iter 129/439 - loss 1.06122247 - samples/sec: 26.47\n",
      "2020-04-09 12:31:56,122 epoch 24 - iter 172/439 - loss 1.06058830 - samples/sec: 26.84\n",
      "2020-04-09 12:33:44,447 epoch 24 - iter 215/439 - loss 1.06845846 - samples/sec: 26.89\n",
      "2020-04-09 12:35:32,864 epoch 24 - iter 258/439 - loss 1.06133291 - samples/sec: 26.51\n",
      "2020-04-09 12:37:22,257 epoch 24 - iter 301/439 - loss 1.06202128 - samples/sec: 27.02\n",
      "2020-04-09 12:39:12,091 epoch 24 - iter 344/439 - loss 1.06513576 - samples/sec: 26.03\n",
      "2020-04-09 12:41:00,478 epoch 24 - iter 387/439 - loss 1.05257366 - samples/sec: 26.81\n",
      "2020-04-09 12:42:48,762 epoch 24 - iter 430/439 - loss 1.05764073 - samples/sec: 26.88\n",
      "2020-04-09 12:43:55,794 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 12:43:55,795 EPOCH 24 done: loss 1.0612 - lr 0.0100\n",
      "2020-04-09 12:47:15,191 DEV : loss 0.856867372729432 - score 0.9346\n",
      "2020-04-09 12:47:15,227 BAD EPOCHS (no improvement): 1\n",
      "2020-04-09 12:47:15,243 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 12:48:06,924 epoch 25 - iter 43/439 - loss 1.04279577 - samples/sec: 26.63\n",
      "2020-04-09 12:49:56,315 epoch 25 - iter 86/439 - loss 1.05857109 - samples/sec: 26.35\n",
      "2020-04-09 12:51:45,177 epoch 25 - iter 129/439 - loss 1.06113483 - samples/sec: 26.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-09 12:53:33,230 epoch 25 - iter 172/439 - loss 1.03953488 - samples/sec: 27.01\n",
      "2020-04-09 12:55:21,909 epoch 25 - iter 215/439 - loss 1.04553555 - samples/sec: 26.52\n",
      "2020-04-09 12:57:11,085 epoch 25 - iter 258/439 - loss 1.03644982 - samples/sec: 26.36\n",
      "2020-04-09 12:59:00,186 epoch 25 - iter 301/439 - loss 1.04528149 - samples/sec: 26.42\n",
      "2020-04-09 13:00:49,946 epoch 25 - iter 344/439 - loss 1.05690599 - samples/sec: 26.82\n",
      "2020-04-09 13:02:38,818 epoch 25 - iter 387/439 - loss 1.05694051 - samples/sec: 26.36\n",
      "2020-04-09 13:04:28,505 epoch 25 - iter 430/439 - loss 1.05031599 - samples/sec: 26.02\n",
      "2020-04-09 13:05:47,354 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 13:05:47,356 EPOCH 25 done: loss 1.0523 - lr 0.0100\n",
      "2020-04-09 13:09:07,316 DEV : loss 0.8442029889088636 - score 0.9338\n",
      "2020-04-09 13:09:07,354 BAD EPOCHS (no improvement): 2\n",
      "2020-04-09 13:09:07,370 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 13:09:58,185 epoch 26 - iter 43/439 - loss 0.98422605 - samples/sec: 27.08\n",
      "2020-04-09 13:11:46,272 epoch 26 - iter 86/439 - loss 0.99550502 - samples/sec: 26.60\n",
      "2020-04-09 13:13:34,013 epoch 26 - iter 129/439 - loss 0.99746621 - samples/sec: 26.92\n",
      "2020-04-09 13:15:22,897 epoch 26 - iter 172/439 - loss 0.98343281 - samples/sec: 26.21\n",
      "2020-04-09 13:17:11,882 epoch 26 - iter 215/439 - loss 0.99262263 - samples/sec: 26.19\n",
      "2020-04-09 13:19:00,370 epoch 26 - iter 258/439 - loss 1.00291391 - samples/sec: 26.52\n",
      "2020-04-09 13:20:48,993 epoch 26 - iter 301/439 - loss 1.00478760 - samples/sec: 26.40\n",
      "2020-04-09 13:22:38,339 epoch 26 - iter 344/439 - loss 1.00669364 - samples/sec: 26.37\n",
      "2020-04-09 13:24:27,941 epoch 26 - iter 387/439 - loss 1.01692593 - samples/sec: 26.03\n",
      "2020-04-09 13:26:16,188 epoch 26 - iter 430/439 - loss 1.02366881 - samples/sec: 26.70\n",
      "2020-04-09 13:27:25,499 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 13:27:25,500 EPOCH 26 done: loss 1.0255 - lr 0.0100\n",
      "2020-04-09 13:30:44,499 DEV : loss 0.8381533914373493 - score 0.9353\n",
      "2020-04-09 13:30:44,536 BAD EPOCHS (no improvement): 0\n",
      "2020-04-09 13:31:13,154 ----------------------------------------------------------------------------------------------------\n",
      "2020-04-09 13:32:04,250 epoch 27 - iter 43/439 - loss 0.98220416 - samples/sec: 26.93\n",
      "2020-04-09 13:33:54,337 epoch 27 - iter 86/439 - loss 1.01013208 - samples/sec: 26.55\n",
      "2020-04-09 13:35:44,926 epoch 27 - iter 129/439 - loss 1.01665690 - samples/sec: 26.35\n",
      "2020-04-09 13:37:35,011 epoch 27 - iter 172/439 - loss 1.02044348 - samples/sec: 26.43\n",
      "2020-04-09 13:39:25,497 epoch 27 - iter 215/439 - loss 1.01826518 - samples/sec: 26.21\n",
      "2020-04-09 13:41:15,881 epoch 27 - iter 258/439 - loss 1.00669839 - samples/sec: 26.48\n"
     ]
    }
   ],
   "source": [
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(ensemble_tagger, corpus)\n",
    "\n",
    "trainer.train(model_path,\n",
    "              learning_rate=0.01,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ensemble_tagger = EnsembleTagger.load(model_path + 'best-model.pt')\n",
    "\n",
    "sentence = corpus.test[0]\n",
    "\n",
    "for entity in sentence.get_spans('ner'):\n",
    "    print(entity)\n",
    "\n",
    "for token in sentence.tokens:\n",
    "    print(str(token.get_tag(\"ner\")))\n",
    "    print(str(token.get_tags_proba_dist(\"ner\")))\n",
    "\n",
    "test_ensemble_tagger.predict(sentence,all_tag_prob=True)\n",
    "\n",
    "for token in sentence.tokens:\n",
    "    print(token.get_tag(\"ner\").value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 46435 tokens with 6847 phrases; found: 6417 phrases; correct: 61.\n",
      "accuracy:   2.41%; (non-O)\n",
      "accuracy:   2.56%; precision:   0.95%; recall:   0.89%; FB1:   0.92\n",
      "              LOC: precision:   2.59%; recall:   1.51%; FB1:   1.91  1895\n",
      "             MISC: precision:   0.00%; recall:   0.00%; FB1:   0.00  367\n",
      "              ORG: precision:   0.56%; recall:   8.89%; FB1:   1.05  2140\n",
      "              PER: precision:   0.00%; recall:   0.00%; FB1:   0.00  2015\n",
      "(0.9505999688327879, 0.8909011245801081, 0.9197828709288298)\n"
     ]
    }
   ],
   "source": [
    "from conlleval import evaluate\n",
    "\n",
    "real = []\n",
    "for sentence in corpus.test:\n",
    "    for token in sentence.tokens:\n",
    "        real.append(token.get_tag(\"ner\").value)\n",
    "\n",
    "def test(model, data):\n",
    "    results = []\n",
    "    for sentence in data:\n",
    "        model.predict(sentence,all_tag_prob=True)\n",
    "        for token in sentence.tokens:\n",
    "            results.append(token.get_tag(\"ner\").value)\n",
    "    return results\n",
    "\n",
    "ensemble_pred = test(test_ensemble_tagger, corpus.test)\n",
    "print(evaluate(real, ensemble_pred))\n",
    "elmo_pred = test(elmo_tagger, corpus.test)\n",
    "print(evaluate(real, elmo_pred))\n",
    "# bert_pred = test(bert_tagger, corpus.test)\n",
    "# print(evaluate(real, bert_pred))\n",
    "# xlnet_pred = test(xlnet_tagger, corpus.test)\n",
    "# print(evaluate(real, xlnet_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
